2022-01-18 17:09:42,008 - INFO - ==> Preparing data..
2022-01-18 17:09:42,587 - INFO - checkpoint filename: experiments/coarse/mos/FC2_LRp1_R1/checkpoint.pt
2022-01-18 17:09:42,588 - INFO - log filename: experiments/coarse/mos/FC2_LRp1_R1/train.log
2022-01-18 17:09:42,588 - INFO - ********************************************************
2022-01-18 17:09:42,588 - INFO - Starting Iter: 0 / 1
2022-01-18 17:09:42,589 - INFO - ********************************************************
2022-01-18 17:09:48,551 - INFO - cuda
2022-01-18 17:09:48,599 - INFO - 
Epoch: 0
2022-01-18 17:09:48,599 - INFO - 
Learning Rate: 0.0100
2022-01-18 17:12:00,478 - INFO - [Step=250]	Loss=7.1936	242.6 examples/second
2022-01-18 17:14:01,335 - INFO - [Step=500]	Loss=5.4042	264.8 examples/second
2022-01-18 17:16:06,984 - INFO - [Step=750]	Loss=5.2320	254.7 examples/second
2022-01-18 17:16:59,795 - INFO - Test Loss=5.0820, Test top-1 acc=0.0643
2022-01-18 17:16:59,796 - INFO - Group Accuracy:

2022-01-18 17:16:59,796 - INFO - [0.939759  0.939759  0.939759  0.9359036 0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.9392771 0.939759
 0.939759  0.939759  0.9518072]
2022-01-18 17:16:59,797 - INFO - Saving...
2022-01-18 17:16:59,977 - INFO - Epoch time: 431.37768507003784
2022-01-18 17:16:59,977 - INFO - 
Epoch: 1
2022-01-18 17:16:59,977 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:18:23,271 - INFO - [Step=1000]	Loss=5.1892	234.8 examples/second
2022-01-18 17:20:31,375 - INFO - [Step=1250]	Loss=4.9143	249.8 examples/second
2022-01-18 17:22:33,367 - INFO - [Step=1500]	Loss=4.6998	262.3 examples/second
2022-01-18 17:24:13,925 - INFO - Test Loss=4.3764, Test top-1 acc=0.1520
2022-01-18 17:24:13,927 - INFO - Group Accuracy:

2022-01-18 17:24:13,927 - INFO - [0.939759   0.94120485 0.939759   0.94506025 0.939759   0.94216865
 0.9395181  0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.9395181  0.9518072 ]
2022-01-18 17:24:13,929 - INFO - Saving...
2022-01-18 17:24:14,510 - INFO - Epoch time: 434.5333662033081
2022-01-18 17:24:14,512 - INFO - 
Epoch: 2
2022-01-18 17:24:14,512 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:25:01,382 - INFO - [Step=1750]	Loss=4.5694	216.2 examples/second
2022-01-18 17:27:06,131 - INFO - [Step=2000]	Loss=4.4314	256.5 examples/second
2022-01-18 17:29:08,238 - INFO - [Step=2250]	Loss=4.2254	262.1 examples/second
2022-01-18 17:31:14,354 - INFO - [Step=2500]	Loss=4.0576	253.7 examples/second
2022-01-18 17:31:29,432 - INFO - Test Loss=3.7886, Test top-1 acc=0.2465
2022-01-18 17:31:29,433 - INFO - Group Accuracy:

2022-01-18 17:31:29,433 - INFO - [0.94096386 0.940241   0.940241   0.95349395 0.94096386 0.9515663
 0.9433735  0.9433735  0.94626504 0.9395181  0.95228916 0.94120485
 0.94       0.939759   0.939759   0.94216865 0.9561446 ]
2022-01-18 17:31:29,436 - INFO - Saving...
2022-01-18 17:31:30,085 - INFO - Epoch time: 435.5728816986084
2022-01-18 17:31:30,086 - INFO - 
Epoch: 3
2022-01-18 17:31:30,087 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:33:37,606 - INFO - [Step=2750]	Loss=4.0409	223.4 examples/second
2022-01-18 17:35:52,614 - INFO - [Step=3000]	Loss=3.8552	237.0 examples/second
2022-01-18 17:37:57,363 - INFO - [Step=3250]	Loss=3.6859	256.5 examples/second
2022-01-18 17:38:56,667 - INFO - Test Loss=3.5099, Test top-1 acc=0.3330
2022-01-18 17:38:56,669 - INFO - Group Accuracy:

2022-01-18 17:38:56,669 - INFO - [0.94433737 0.9474699  0.9433735  0.9612048  0.9436145  0.9626506
 0.9453012  0.9460241  0.9448193  0.933253   0.9515663  0.9436145
 0.9407229  0.9407229  0.94240963 0.94891566 0.9657831 ]
2022-01-18 17:38:56,671 - INFO - Saving...
2022-01-18 17:38:57,370 - INFO - Epoch time: 447.2831859588623
2022-01-18 17:38:57,371 - INFO - 
Epoch: 4
2022-01-18 17:38:57,371 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:40:23,880 - INFO - [Step=3500]	Loss=3.6343	218.4 examples/second
2022-01-18 17:42:29,920 - INFO - [Step=3750]	Loss=3.5125	253.9 examples/second
2022-01-18 17:44:36,627 - INFO - [Step=4000]	Loss=3.4838	252.6 examples/second
2022-01-18 17:46:14,472 - INFO - Test Loss=3.4070, Test top-1 acc=0.3296
2022-01-18 17:46:14,473 - INFO - Group Accuracy:

2022-01-18 17:46:14,473 - INFO - [0.94120485 0.9498795  0.93783134 0.9633735  0.94120485 0.9612048
 0.9440964  0.94554216 0.9592771  0.9433735  0.9544578  0.9445783
 0.9404819  0.94120485 0.9436145  0.9486747  0.9657831 ]
2022-01-18 17:46:14,473 - INFO - Epoch time: 437.1028139591217
2022-01-18 17:46:14,473 - INFO - 
Epoch: 5
2022-01-18 17:46:14,474 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:46:55,100 - INFO - [Step=4250]	Loss=3.3237	231.1 examples/second
2022-01-18 17:48:54,391 - INFO - [Step=4500]	Loss=3.1703	268.3 examples/second
2022-01-18 17:50:57,348 - INFO - [Step=4750]	Loss=3.0516	260.3 examples/second
2022-01-18 17:53:00,245 - INFO - [Step=5000]	Loss=2.9832	260.4 examples/second
2022-01-18 17:53:12,767 - INFO - Test Loss=3.2900, Test top-1 acc=0.3802
2022-01-18 17:53:12,767 - INFO - Group Accuracy:

2022-01-18 17:53:12,768 - INFO - [0.94192773 0.9561446  0.9438554  0.9696385  0.9477109  0.97156626
 0.94506025 0.9508434  0.9387952  0.9498795  0.9580723  0.94240963
 0.9426506  0.94433737 0.9387952  0.946506   0.9737349 ]
2022-01-18 17:53:12,768 - INFO - Saving...
2022-01-18 17:53:13,265 - INFO - Epoch time: 418.79136657714844
2022-01-18 17:53:13,265 - INFO - 
Epoch: 6
2022-01-18 17:53:13,265 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:55:12,232 - INFO - [Step=5250]	Loss=2.8709	242.4 examples/second
2022-01-18 17:57:15,146 - INFO - [Step=5500]	Loss=2.8017	260.3 examples/second
2022-01-18 17:59:16,147 - INFO - [Step=5750]	Loss=2.7364	264.5 examples/second
2022-01-18 18:00:12,393 - INFO - Test Loss=2.8054, Test top-1 acc=0.4255
2022-01-18 18:00:12,393 - INFO - Group Accuracy:

2022-01-18 18:00:12,393 - INFO - [0.9440964  0.9580723  0.9513253  0.9626506  0.94843376 0.9727711
 0.9508434  0.94963855 0.9544578  0.94939756 0.9595181  0.9549398
 0.94120485 0.94192773 0.9440964  0.95349395 0.9771084 ]
2022-01-18 18:00:12,394 - INFO - Saving...
2022-01-18 18:00:12,834 - INFO - Epoch time: 419.5693211555481
2022-01-18 18:00:12,835 - INFO - 
Epoch: 7
2022-01-18 18:00:12,835 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:01:32,880 - INFO - [Step=6000]	Loss=2.6505	234.0 examples/second
2022-01-18 18:03:36,462 - INFO - [Step=6250]	Loss=2.5997	258.9 examples/second
2022-01-18 18:05:37,548 - INFO - [Step=6500]	Loss=2.5417	264.3 examples/second
2022-01-18 18:07:16,653 - INFO - Test Loss=2.6002, Test top-1 acc=0.4708
2022-01-18 18:07:16,653 - INFO - Group Accuracy:

2022-01-18 18:07:16,654 - INFO - [0.9549398  0.95566267 0.9472289  0.96698797 0.9510843  0.9775904
 0.9486747  0.96072286 0.9633735  0.9544578  0.9612048  0.9580723
 0.9436145  0.9486747  0.9508434  0.95638555 0.9737349 ]
2022-01-18 18:07:16,654 - INFO - Saving...
2022-01-18 18:07:17,134 - INFO - Epoch time: 424.29958033561707
2022-01-18 18:07:17,134 - INFO - 
Epoch: 8
2022-01-18 18:07:17,135 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:07:54,688 - INFO - [Step=6750]	Loss=2.4550	233.3 examples/second
2022-01-18 18:09:55,860 - INFO - [Step=7000]	Loss=2.4022	264.1 examples/second
2022-01-18 18:11:54,671 - INFO - [Step=7250]	Loss=2.3816	269.3 examples/second
2022-01-18 18:13:54,491 - INFO - [Step=7500]	Loss=2.3263	267.1 examples/second
2022-01-18 18:14:11,101 - INFO - Test Loss=2.1734, Test top-1 acc=0.5390
2022-01-18 18:14:11,102 - INFO - Group Accuracy:

2022-01-18 18:14:11,102 - INFO - [0.9580723  0.96771085 0.9621687  0.9742169  0.95662653 0.97927713
 0.9501205  0.966747   0.97204816 0.95662653 0.9672289  0.9612048
 0.9479518  0.946506   0.94915664 0.96       0.9816868 ]
2022-01-18 18:14:11,102 - INFO - Saving...
2022-01-18 18:14:11,546 - INFO - Epoch time: 414.4115340709686
2022-01-18 18:14:11,546 - INFO - 
Epoch: 9
2022-01-18 18:14:11,546 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:16:10,332 - INFO - [Step=7750]	Loss=2.2445	235.6 examples/second
2022-01-18 18:18:14,626 - INFO - [Step=8000]	Loss=2.2292	257.5 examples/second
2022-01-18 18:20:18,343 - INFO - [Step=8250]	Loss=2.2054	258.7 examples/second
2022-01-18 18:21:12,771 - INFO - Test Loss=2.1912, Test top-1 acc=0.5388
2022-01-18 18:21:12,771 - INFO - Group Accuracy:

2022-01-18 18:21:12,771 - INFO - [0.95301205 0.9624096  0.9544578  0.97638553 0.9587952  0.9787952
 0.95710844 0.9585542  0.97180724 0.9590362  0.9691566  0.9655422
 0.9486747  0.9479518  0.9546988  0.9660241  0.97951806]
2022-01-18 18:21:12,772 - INFO - Epoch time: 421.22573947906494
2022-01-18 18:21:12,772 - INFO - 
Epoch: 10
2022-01-18 18:21:12,772 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:22:30,518 - INFO - [Step=8500]	Loss=2.1733	242.1 examples/second
2022-01-18 18:24:36,888 - INFO - [Step=8750]	Loss=2.1016	253.2 examples/second
2022-01-18 18:26:44,319 - INFO - [Step=9000]	Loss=2.1067	251.1 examples/second
2022-01-18 18:28:23,552 - INFO - Test Loss=1.9230, Test top-1 acc=0.5867
2022-01-18 18:28:23,552 - INFO - Group Accuracy:

2022-01-18 18:28:23,552 - INFO - [0.9631325  0.96506023 0.9573494  0.9819277  0.96096385 0.98433733
 0.9580723  0.9628916  0.97831327 0.9621687  0.9742169  0.966747
 0.9508434  0.9518072  0.9578313  0.96698797 0.9848193 ]
2022-01-18 18:28:23,553 - INFO - Saving...
2022-01-18 18:28:23,864 - INFO - Epoch time: 431.0920832157135
2022-01-18 18:28:23,864 - INFO - 
Epoch: 11
2022-01-18 18:28:23,864 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:28:55,918 - INFO - [Step=9250]	Loss=2.0664	243.2 examples/second
2022-01-18 18:31:02,010 - INFO - [Step=9500]	Loss=2.0458	253.8 examples/second
2022-01-18 18:33:09,563 - INFO - [Step=9750]	Loss=2.0209	250.9 examples/second
2022-01-18 18:35:16,309 - INFO - [Step=10000]	Loss=1.9950	252.5 examples/second
2022-01-18 18:35:36,687 - INFO - Test Loss=1.9416, Test top-1 acc=0.5836
2022-01-18 18:35:36,687 - INFO - Group Accuracy:

2022-01-18 18:35:36,687 - INFO - [0.96361446 0.9660241  0.9660241  0.9821687  0.96072286 0.9848193
 0.95759034 0.9624096  0.9785542  0.94915664 0.97108436 0.9626506
 0.9546988  0.95638555 0.9590362  0.9703615  0.9768675 ]
2022-01-18 18:35:36,688 - INFO - Epoch time: 432.82331466674805
2022-01-18 18:35:36,688 - INFO - 
Epoch: 12
2022-01-18 18:35:36,688 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:37:32,533 - INFO - [Step=10250]	Loss=1.9231	234.9 examples/second
2022-01-18 18:39:41,372 - INFO - [Step=10500]	Loss=1.9449	248.4 examples/second
2022-01-18 18:41:49,967 - INFO - [Step=10750]	Loss=1.9312	248.8 examples/second
2022-01-18 18:42:46,536 - INFO - Test Loss=2.2403, Test top-1 acc=0.5648
2022-01-18 18:42:46,536 - INFO - Group Accuracy:

2022-01-18 18:42:46,537 - INFO - [0.95710844 0.9691566  0.95759034 0.9768675  0.9631325  0.9780723
 0.95662653 0.96361446 0.9778313  0.96457833 0.97204816 0.9469879
 0.95710844 0.9549398  0.95228916 0.966747   0.98361444]
2022-01-18 18:42:46,537 - INFO - Epoch time: 429.8495192527771
2022-01-18 18:42:46,537 - INFO - 
Epoch: 13
2022-01-18 18:42:46,537 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:43:56,394 - INFO - [Step=11000]	Loss=1.8981	253.1 examples/second
2022-01-18 18:45:58,703 - INFO - [Step=11250]	Loss=1.8367	261.6 examples/second
2022-01-18 18:48:05,613 - INFO - [Step=11500]	Loss=1.8488	252.1 examples/second
2022-01-18 18:49:51,822 - INFO - Test Loss=1.8294, Test top-1 acc=0.6092
2022-01-18 18:49:51,822 - INFO - Group Accuracy:

2022-01-18 18:49:51,822 - INFO - [0.96481925 0.97204816 0.96096385 0.98240966 0.96385545 0.98361444
 0.96       0.966747   0.9766265  0.96698797 0.97614455 0.96698797
 0.9498795  0.9590362  0.95662653 0.9713253  0.98578316]
2022-01-18 18:49:51,823 - INFO - Saving...
2022-01-18 18:49:52,451 - INFO - Epoch time: 425.9133667945862
2022-01-18 18:49:52,451 - INFO - 
Epoch: 14
2022-01-18 18:49:52,451 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:50:26,126 - INFO - [Step=11750]	Loss=1.8406	227.7 examples/second
2022-01-18 18:52:28,339 - INFO - [Step=12000]	Loss=1.7963	261.8 examples/second
2022-01-18 18:54:35,599 - INFO - [Step=12250]	Loss=1.7902	251.5 examples/second
2022-01-18 18:56:39,189 - INFO - [Step=12500]	Loss=1.7883	258.9 examples/second
2022-01-18 18:57:02,080 - INFO - Test Loss=4.9203, Test top-1 acc=0.5446
2022-01-18 18:57:02,082 - INFO - Group Accuracy:

2022-01-18 18:57:02,082 - INFO - [0.9539759  0.9686747  0.95638555 0.9775904  0.9592771  0.9804819
 0.9559036  0.9655422  0.97204816 0.9628916  0.9706024  0.96481925
 0.9518072  0.9479518  0.95662653 0.96409637 0.9853012 ]
2022-01-18 18:57:02,092 - INFO - Epoch time: 429.6405358314514
2022-01-18 18:57:02,094 - INFO - 
Epoch: 15
2022-01-18 18:57:02,096 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:58:58,665 - INFO - [Step=12750]	Loss=1.7253	229.4 examples/second
2022-01-18 19:01:05,406 - INFO - [Step=13000]	Loss=1.7377	252.5 examples/second
2022-01-18 19:03:08,160 - INFO - [Step=13250]	Loss=1.7239	260.7 examples/second
2022-01-18 19:04:13,177 - INFO - Test Loss=2.0029, Test top-1 acc=0.5764
2022-01-18 19:04:13,177 - INFO - Group Accuracy:

2022-01-18 19:04:13,177 - INFO - [0.96       0.9713253  0.9628916  0.9785542  0.9674699  0.98578316
 0.9628916  0.96433735 0.9698795  0.96168673 0.9706024  0.9706024
 0.93710846 0.9554217  0.95349395 0.9691566  0.9807229 ]
2022-01-18 19:04:13,178 - INFO - Epoch time: 431.08428978919983
2022-01-18 19:04:13,178 - INFO - 
Epoch: 16
2022-01-18 19:04:13,178 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:05:26,850 - INFO - [Step=13500]	Loss=1.7096	230.7 examples/second
2022-01-18 19:07:25,482 - INFO - [Step=13750]	Loss=1.7042	269.7 examples/second
2022-01-18 19:09:28,535 - INFO - [Step=14000]	Loss=1.6872	260.1 examples/second
2022-01-18 19:11:22,926 - INFO - Test Loss=1.8235, Test top-1 acc=0.6243
2022-01-18 19:11:22,927 - INFO - Group Accuracy:

2022-01-18 19:11:22,928 - INFO - [0.9657831  0.9713253  0.9703615  0.98240966 0.96819276 0.9860241
 0.9626506  0.96433735 0.97975904 0.96506023 0.97228914 0.9693976
 0.9549398  0.95975906 0.96433735 0.9737349  0.98771083]
2022-01-18 19:11:22,931 - INFO - Saving...
2022-01-18 19:11:23,539 - INFO - Epoch time: 430.360151052475
2022-01-18 19:11:23,539 - INFO - 
Epoch: 17
2022-01-18 19:11:23,539 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:11:56,268 - INFO - [Step=14250]	Loss=1.6585	216.6 examples/second
2022-01-18 19:14:02,176 - INFO - [Step=14500]	Loss=1.6534	254.2 examples/second
2022-01-18 19:16:11,003 - INFO - [Step=14750]	Loss=1.6219	248.4 examples/second
2022-01-18 19:18:15,146 - INFO - [Step=15000]	Loss=1.6279	257.8 examples/second
2022-01-18 19:18:42,403 - INFO - Test Loss=1.7690, Test top-1 acc=0.6193
2022-01-18 19:18:42,404 - INFO - Group Accuracy:

2022-01-18 19:18:42,404 - INFO - [0.966506   0.97590363 0.9614458  0.97903615 0.9727711  0.9816868
 0.9587952  0.96698797 0.97831327 0.96891564 0.97566265 0.96891564
 0.9590362  0.96024096 0.9595181  0.9660241  0.98698795]
2022-01-18 19:18:42,405 - INFO - Epoch time: 438.86591720581055
2022-01-18 19:18:42,405 - INFO - 
Epoch: 18
2022-01-18 19:18:42,405 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:20:39,833 - INFO - [Step=15250]	Loss=1.6068	221.2 examples/second
2022-01-18 19:22:45,616 - INFO - [Step=15500]	Loss=1.6040	254.4 examples/second
2022-01-18 19:24:48,912 - INFO - [Step=15750]	Loss=1.6033	259.5 examples/second
2022-01-18 19:25:50,213 - INFO - Test Loss=2.3924, Test top-1 acc=0.6034
2022-01-18 19:25:50,213 - INFO - Group Accuracy:

2022-01-18 19:25:50,213 - INFO - [0.9633735  0.9742169  0.9672289  0.98433733 0.9479518  0.98433733
 0.9583132  0.97156626 0.9746988  0.96168673 0.97566265 0.9662651
 0.9281928  0.9583132  0.96457833 0.97204816 0.9860241 ]
2022-01-18 19:25:50,214 - INFO - Epoch time: 427.8092167377472
2022-01-18 19:25:50,214 - INFO - 
Epoch: 19
2022-01-18 19:25:50,214 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:26:57,858 - INFO - [Step=16000]	Loss=1.5899	248.2 examples/second
2022-01-18 19:28:58,969 - INFO - [Step=16250]	Loss=1.5872	264.2 examples/second
2022-01-18 19:31:04,731 - INFO - [Step=16500]	Loss=1.5497	254.5 examples/second
2022-01-18 19:32:55,016 - INFO - Test Loss=1.6646, Test top-1 acc=0.6386
2022-01-18 19:32:55,017 - INFO - Group Accuracy:

2022-01-18 19:32:55,017 - INFO - [0.9655422  0.9775904  0.9655422  0.9812048  0.96891564 0.9889157
 0.96409637 0.9696385  0.9698795  0.9672289  0.97493976 0.9696385
 0.9580723  0.96096385 0.9624096  0.9706024  0.98963857]
2022-01-18 19:32:55,017 - INFO - Saving...
2022-01-18 19:32:55,502 - INFO - Epoch time: 425.2875702381134
2022-01-18 19:32:55,502 - INFO - 
Epoch: 20
2022-01-18 19:32:55,502 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:33:23,154 - INFO - [Step=16750]	Loss=1.5652	231.2 examples/second
2022-01-18 19:35:27,075 - INFO - [Step=17000]	Loss=1.5367	258.2 examples/second
2022-01-18 19:37:30,840 - INFO - [Step=17250]	Loss=1.5473	258.6 examples/second
2022-01-18 19:39:37,290 - INFO - [Step=17500]	Loss=1.5526	253.1 examples/second
2022-01-18 19:40:04,068 - INFO - Test Loss=1.4097, Test top-1 acc=0.6795
2022-01-18 19:40:04,070 - INFO - Group Accuracy:

2022-01-18 19:40:04,070 - INFO - [0.9713253  0.9775904  0.97204816 0.9881928  0.9706024  0.98722893
 0.9621687  0.97445786 0.9840964  0.96698797 0.9816868  0.9739759
 0.9631325  0.9619277  0.96433735 0.9787952  0.9893976 ]
2022-01-18 19:40:04,074 - INFO - Saving...
2022-01-18 19:40:04,447 - INFO - Epoch time: 428.94457030296326
2022-01-18 19:40:04,447 - INFO - 
Epoch: 21
2022-01-18 19:40:04,447 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:41:55,729 - INFO - [Step=17750]	Loss=1.5066	231.2 examples/second
2022-01-18 19:43:55,307 - INFO - [Step=18000]	Loss=1.5187	267.6 examples/second
2022-01-18 19:45:58,792 - INFO - [Step=18250]	Loss=1.5165	259.1 examples/second
2022-01-18 19:47:08,318 - INFO - Test Loss=3.6604, Test top-1 acc=0.5675
2022-01-18 19:47:08,318 - INFO - Group Accuracy:

2022-01-18 19:47:08,318 - INFO - [0.95421684 0.96361446 0.96096385 0.9833735  0.9657831  0.9816868
 0.9626506  0.9655422  0.97445786 0.96819276 0.9672289  0.96506023
 0.9561446  0.9595181  0.9583132  0.96481925 0.9819277 ]
2022-01-18 19:47:08,319 - INFO - Epoch time: 423.8721945285797
2022-01-18 19:47:08,319 - INFO - 
Epoch: 22
2022-01-18 19:47:08,319 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:48:15,523 - INFO - [Step=18500]	Loss=1.4940	234.0 examples/second
2022-01-18 19:50:17,864 - INFO - [Step=18750]	Loss=1.4983	261.6 examples/second
2022-01-18 19:52:21,073 - INFO - [Step=19000]	Loss=1.5001	259.7 examples/second
2022-01-18 19:54:13,433 - INFO - Test Loss=1.7906, Test top-1 acc=0.6169
2022-01-18 19:54:13,434 - INFO - Group Accuracy:

2022-01-18 19:54:13,434 - INFO - [0.96698797 0.97614455 0.9657831  0.97975904 0.966747   0.97975904
 0.96096385 0.9655422  0.9787952  0.96433735 0.9698795  0.9628916
 0.96168673 0.95686746 0.9624096  0.97180724 0.98313254]
2022-01-18 19:54:13,435 - INFO - Epoch time: 425.11564540863037
2022-01-18 19:54:13,435 - INFO - 
Epoch: 23
2022-01-18 19:54:13,435 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:54:38,628 - INFO - [Step=19250]	Loss=1.4887	232.6 examples/second
2022-01-18 19:56:41,174 - INFO - [Step=19500]	Loss=1.4543	261.1 examples/second
2022-01-18 19:58:40,646 - INFO - [Step=19750]	Loss=1.4879	267.8 examples/second
2022-01-18 20:00:43,721 - INFO - [Step=20000]	Loss=1.4779	260.0 examples/second
2022-01-18 20:01:16,940 - INFO - Test Loss=1.4301, Test top-1 acc=0.6742
2022-01-18 20:01:16,941 - INFO - Group Accuracy:

2022-01-18 20:01:16,941 - INFO - [0.9691566  0.97590363 0.97518075 0.9860241  0.9686747  0.9898795
 0.96698797 0.97445786 0.9826506  0.96409637 0.98024094 0.973253
 0.95638555 0.96795183 0.96168673 0.97951806 0.98746985]
2022-01-18 20:01:16,942 - INFO - Epoch time: 423.5072159767151
2022-01-18 20:01:16,942 - INFO - 
Epoch: 24
2022-01-18 20:01:16,942 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:03:08,501 - INFO - [Step=20250]	Loss=1.4444	221.0 examples/second
2022-01-18 20:05:11,325 - INFO - [Step=20500]	Loss=1.4460	260.5 examples/second
2022-01-18 20:07:16,014 - INFO - [Step=20750]	Loss=1.4471	256.6 examples/second
2022-01-18 20:08:28,045 - INFO - Test Loss=1.3943, Test top-1 acc=0.6870
2022-01-18 20:08:28,046 - INFO - Group Accuracy:

2022-01-18 20:08:28,046 - INFO - [0.96771085 0.9819277  0.97542167 0.9848193  0.97156626 0.9891566
 0.96891564 0.97590363 0.9850602  0.9660241  0.97903615 0.97180724
 0.9653012  0.9674699  0.9619277  0.9768675  0.99060243]
2022-01-18 20:08:28,047 - INFO - Saving...
2022-01-18 20:08:28,648 - INFO - Epoch time: 431.70524978637695
2022-01-18 20:08:28,648 - INFO - 
Epoch: 25
2022-01-18 20:08:28,649 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:09:35,969 - INFO - [Step=21000]	Loss=1.4382	228.6 examples/second
2022-01-18 20:11:38,291 - INFO - [Step=21250]	Loss=1.4350	261.6 examples/second
2022-01-18 20:13:42,405 - INFO - [Step=21500]	Loss=1.4496	257.8 examples/second
2022-01-18 20:15:32,108 - INFO - Test Loss=1.5607, Test top-1 acc=0.6704
2022-01-18 20:15:32,109 - INFO - Group Accuracy:

2022-01-18 20:15:32,109 - INFO - [0.9703615  0.9812048  0.9713253  0.9838554  0.9713253  0.98722893
 0.9318072  0.97518075 0.9838554  0.9662651  0.9804819  0.9706024
 0.96506023 0.96698797 0.9708434  0.97566265 0.98963857]
2022-01-18 20:15:32,110 - INFO - Epoch time: 423.46117973327637
2022-01-18 20:15:32,110 - INFO - 
Epoch: 26
2022-01-18 20:15:32,110 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:15:54,900 - INFO - [Step=21750]	Loss=1.4317	241.5 examples/second
2022-01-18 20:17:55,291 - INFO - [Step=22000]	Loss=1.4154	265.8 examples/second
2022-01-18 20:19:58,229 - INFO - [Step=22250]	Loss=1.4140	260.3 examples/second
2022-01-18 20:22:01,786 - INFO - [Step=22500]	Loss=1.4422	259.0 examples/second
2022-01-18 20:22:35,849 - INFO - Test Loss=1.5557, Test top-1 acc=0.6581
2022-01-18 20:22:35,850 - INFO - Group Accuracy:

2022-01-18 20:22:35,850 - INFO - [0.96819276 0.9768675  0.9674699  0.9807229  0.9631325  0.9853012
 0.9662651  0.96819276 0.98       0.96771085 0.97542167 0.9739759
 0.96361446 0.96361446 0.9660241  0.97542167 0.9889157 ]
2022-01-18 20:22:35,851 - INFO - Epoch time: 423.7410764694214
2022-01-18 20:22:35,851 - INFO - 
Epoch: 27
2022-01-18 20:22:35,851 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:24:21,968 - INFO - [Step=22750]	Loss=1.3789	228.3 examples/second
2022-01-18 20:26:22,773 - INFO - [Step=23000]	Loss=1.3982	264.9 examples/second
2022-01-18 20:28:26,709 - INFO - [Step=23250]	Loss=1.3983	258.2 examples/second
2022-01-18 20:29:42,791 - INFO - Test Loss=1.4089, Test top-1 acc=0.6887
2022-01-18 20:29:42,792 - INFO - Group Accuracy:

2022-01-18 20:29:42,792 - INFO - [0.97156626 0.97927713 0.97566265 0.98771083 0.9691566  0.9893976
 0.973494   0.9785542  0.97831327 0.97301203 0.9804819  0.973253
 0.9590362  0.9662651  0.9590362  0.9746988  0.98963857]
2022-01-18 20:29:42,793 - INFO - Saving...
2022-01-18 20:29:43,391 - INFO - Epoch time: 427.5399031639099
2022-01-18 20:29:43,391 - INFO - 
Epoch: 28
2022-01-18 20:29:43,391 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:30:42,662 - INFO - [Step=23500]	Loss=1.3953	235.4 examples/second
2022-01-18 20:32:45,470 - INFO - [Step=23750]	Loss=1.3758	260.6 examples/second
2022-01-18 20:34:46,001 - INFO - [Step=24000]	Loss=1.3979	265.5 examples/second
2022-01-18 20:36:43,196 - INFO - Test Loss=1.6775, Test top-1 acc=0.6501
2022-01-18 20:36:43,196 - INFO - Group Accuracy:

2022-01-18 20:36:43,196 - INFO - [0.966506   0.9775904  0.9583132  0.97831327 0.96843374 0.9860241
 0.966747   0.973253   0.98433733 0.96506023 0.96843374 0.9693976
 0.9631325  0.96433735 0.96506023 0.96795183 0.98722893]
2022-01-18 20:36:43,197 - INFO - Epoch time: 419.8060522079468
2022-01-18 20:36:43,197 - INFO - 
Epoch: 29
2022-01-18 20:36:43,198 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:37:01,746 - INFO - [Step=24250]	Loss=1.3499	235.7 examples/second
2022-01-18 20:39:11,225 - INFO - [Step=24500]	Loss=1.0880	247.1 examples/second
2022-01-18 20:41:21,892 - INFO - [Step=24750]	Loss=1.0177	244.9 examples/second
2022-01-18 20:43:28,735 - INFO - [Step=25000]	Loss=0.9884	252.3 examples/second
2022-01-18 20:44:07,998 - INFO - Test Loss=0.9188, Test top-1 acc=0.7766
2022-01-18 20:44:07,999 - INFO - Group Accuracy:

2022-01-18 20:44:07,999 - INFO - [0.9773494  0.9881928  0.9819277  0.99156624 0.9804819  0.993253
 0.97927713 0.9809638  0.9891566  0.97445786 0.98963857 0.98313254
 0.9727711  0.9780723  0.97590363 0.9853012  0.9927711 ]
2022-01-18 20:44:08,000 - INFO - Saving...
2022-01-18 20:44:08,580 - INFO - Epoch time: 445.38276720046997
2022-01-18 20:44:08,581 - INFO - 
Epoch: 30
2022-01-18 20:44:08,581 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:45:56,169 - INFO - [Step=25250]	Loss=0.9442	217.0 examples/second
2022-01-18 20:48:01,445 - INFO - [Step=25500]	Loss=0.9374	255.4 examples/second
2022-01-18 20:50:14,032 - INFO - [Step=25750]	Loss=0.9269	241.4 examples/second
2022-01-18 20:51:26,410 - INFO - Test Loss=0.9018, Test top-1 acc=0.7776
2022-01-18 20:51:26,412 - INFO - Group Accuracy:

2022-01-18 20:51:26,412 - INFO - [0.9787952  0.98963857 0.98240966 0.99108434 0.9809638  0.993253
 0.98024094 0.9816868  0.98963857 0.97542167 0.9886747  0.9845783
 0.9727711  0.9787952  0.97542167 0.98433733 0.9930121 ]
2022-01-18 20:51:26,415 - INFO - Saving...
2022-01-18 20:51:27,098 - INFO - Epoch time: 438.5177307128906
2022-01-18 20:51:27,099 - INFO - 
Epoch: 31
2022-01-18 20:51:27,099 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:52:32,267 - INFO - [Step=26000]	Loss=0.9224	231.5 examples/second
2022-01-18 20:54:41,790 - INFO - [Step=26250]	Loss=0.9003	247.1 examples/second
2022-01-18 20:56:37,584 - INFO - [Step=26500]	Loss=0.9026	276.4 examples/second
2022-01-18 20:58:31,321 - INFO - Test Loss=0.8843, Test top-1 acc=0.7872
2022-01-18 20:58:31,322 - INFO - Group Accuracy:

2022-01-18 20:58:31,322 - INFO - [0.9787952  0.9901205  0.9814458  0.9918072  0.98       0.993494
 0.97951806 0.98361444 0.99036145 0.97542167 0.99036145 0.9850602
 0.97445786 0.97975904 0.97638553 0.98626506 0.9930121 ]
2022-01-18 20:58:31,323 - INFO - Saving...
2022-01-18 20:58:31,796 - INFO - Epoch time: 424.697226524353
2022-01-18 20:58:31,796 - INFO - 
Epoch: 32
2022-01-18 20:58:31,796 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:58:47,661 - INFO - [Step=26750]	Loss=0.9009	246.0 examples/second
2022-01-18 21:00:47,775 - INFO - [Step=27000]	Loss=0.8767	266.4 examples/second
2022-01-18 21:02:46,774 - INFO - [Step=27250]	Loss=0.8742	268.9 examples/second
2022-01-18 21:04:46,975 - INFO - [Step=27500]	Loss=0.8687	266.2 examples/second
2022-01-18 21:05:20,588 - INFO - Test Loss=0.8707, Test top-1 acc=0.7908
2022-01-18 21:05:20,588 - INFO - Group Accuracy:

2022-01-18 21:05:20,588 - INFO - [0.9775904  0.9893976  0.9833735  0.99156624 0.9814458  0.993253
 0.97927713 0.9838554  0.98963857 0.97590363 0.99156624 0.9853012
 0.97518075 0.9807229  0.97638553 0.9853012  0.9930121 ]
2022-01-18 21:05:20,589 - INFO - Saving...
2022-01-18 21:05:21,088 - INFO - Epoch time: 409.29186272621155
2022-01-18 21:05:21,088 - INFO - 
Epoch: 33
2022-01-18 21:05:21,088 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:06:57,531 - INFO - [Step=27750]	Loss=0.8571	245.1 examples/second
2022-01-18 21:08:57,300 - INFO - [Step=28000]	Loss=0.8422	267.2 examples/second
2022-01-18 21:10:57,338 - INFO - [Step=28250]	Loss=0.8572	266.6 examples/second
2022-01-18 21:12:11,360 - INFO - Test Loss=0.8717, Test top-1 acc=0.7894
2022-01-18 21:12:11,360 - INFO - Group Accuracy:

2022-01-18 21:12:11,360 - INFO - [0.97831327 0.9893976  0.9826506  0.9925301  0.98240966 0.99373496
 0.97975904 0.9833735  0.9893976  0.9768675  0.9893976  0.9840964
 0.97614455 0.97951806 0.97614455 0.98771083 0.993253  ]
2022-01-18 21:12:11,361 - INFO - Epoch time: 410.2730839252472
2022-01-18 21:12:11,361 - INFO - 
Epoch: 34
2022-01-18 21:12:11,361 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:13:06,995 - INFO - [Step=28500]	Loss=0.8345	246.8 examples/second
2022-01-18 21:15:12,323 - INFO - [Step=28750]	Loss=0.8323	255.3 examples/second
2022-01-18 21:17:13,064 - INFO - [Step=29000]	Loss=0.8474	265.1 examples/second
2022-01-18 21:19:06,875 - INFO - Test Loss=0.8481, Test top-1 acc=0.7961
2022-01-18 21:19:06,875 - INFO - Group Accuracy:

2022-01-18 21:19:06,876 - INFO - [0.9773494  0.99036145 0.9838554  0.9918072  0.9826506  0.99445784
 0.9809638  0.98313254 0.99060243 0.9766265  0.9918072  0.9845783
 0.97493976 0.9780723  0.9773494  0.9879518  0.9925301 ]
2022-01-18 21:19:06,876 - INFO - Saving...
2022-01-18 21:19:07,278 - INFO - Epoch time: 415.9167079925537
2022-01-18 21:19:07,278 - INFO - 
Epoch: 35
2022-01-18 21:19:07,278 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:19:21,437 - INFO - [Step=29250]	Loss=0.8530	249.3 examples/second
2022-01-18 21:21:21,422 - INFO - [Step=29500]	Loss=0.8322	266.7 examples/second
2022-01-18 21:23:21,600 - INFO - [Step=29750]	Loss=0.8219	266.3 examples/second
2022-01-18 21:25:19,489 - INFO - [Step=30000]	Loss=0.8213	271.4 examples/second
2022-01-18 21:25:56,134 - INFO - Test Loss=0.8668, Test top-1 acc=0.7949
2022-01-18 21:25:56,135 - INFO - Group Accuracy:

2022-01-18 21:25:56,135 - INFO - [0.97975904 0.98963857 0.9848193  0.9925301  0.9814458  0.99373496
 0.9807229  0.9838554  0.9889157  0.9768675  0.9893976  0.9855422
 0.97518075 0.9787952  0.9773494  0.98578316 0.9939759 ]
2022-01-18 21:25:56,137 - INFO - Epoch time: 408.85886430740356
2022-01-18 21:25:56,137 - INFO - 
Epoch: 36
2022-01-18 21:25:56,138 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:27:30,567 - INFO - [Step=30250]	Loss=0.8272	244.1 examples/second
2022-01-18 21:29:31,882 - INFO - [Step=30500]	Loss=0.8256	263.8 examples/second
2022-01-18 21:31:47,149 - INFO - [Step=30750]	Loss=0.8141	236.6 examples/second
2022-01-18 21:33:04,642 - INFO - Test Loss=0.8574, Test top-1 acc=0.7933
2022-01-18 21:33:04,643 - INFO - Group Accuracy:

2022-01-18 21:33:04,643 - INFO - [0.9778313  0.98963857 0.98361444 0.9918072  0.9826506  0.99421686
 0.98024094 0.9833735  0.9898795  0.97518075 0.99036145 0.9845783
 0.97590363 0.97903615 0.97542167 0.9860241  0.99421686]
2022-01-18 21:33:04,644 - INFO - Epoch time: 428.5063235759735
2022-01-18 21:33:04,644 - INFO - 
Epoch: 37
2022-01-18 21:33:04,644 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:33:58,211 - INFO - [Step=31000]	Loss=0.8116	244.2 examples/second
2022-01-18 21:36:03,894 - INFO - [Step=31250]	Loss=0.7913	254.6 examples/second
2022-01-18 21:38:06,114 - INFO - [Step=31500]	Loss=0.8051	261.8 examples/second
2022-01-18 21:40:16,091 - INFO - Test Loss=0.8297, Test top-1 acc=0.7998
2022-01-18 21:40:16,091 - INFO - Group Accuracy:

2022-01-18 21:40:16,091 - INFO - [0.97927713 0.99084336 0.9833735  0.9930121  0.9838554  0.99445784
 0.9821687  0.9855422  0.9898795  0.9771084  0.9901205  0.9826506
 0.97518075 0.9816868  0.9780723  0.9879518  0.99373496]
2022-01-18 21:40:16,092 - INFO - Saving...
2022-01-18 21:40:16,733 - INFO - Epoch time: 432.0893449783325
2022-01-18 21:40:16,733 - INFO - 
Epoch: 38
2022-01-18 21:40:16,734 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:40:32,348 - INFO - [Step=31750]	Loss=0.8011	218.8 examples/second
2022-01-18 21:42:33,997 - INFO - [Step=32000]	Loss=0.7860	263.1 examples/second
2022-01-18 21:44:38,980 - INFO - [Step=32250]	Loss=0.7876	256.0 examples/second
2022-01-18 21:46:35,596 - INFO - [Step=32500]	Loss=0.8085	274.4 examples/second
2022-01-18 21:47:18,442 - INFO - Test Loss=0.8335, Test top-1 acc=0.8002
2022-01-18 21:47:18,443 - INFO - Group Accuracy:

2022-01-18 21:47:18,443 - INFO - [0.97903615 0.99036145 0.9833735  0.9922892  0.98289156 0.99373496
 0.97975904 0.9848193  0.99036145 0.97614455 0.99084336 0.9845783
 0.9768675  0.97951806 0.9773494  0.98722893 0.99373496]
2022-01-18 21:47:18,444 - INFO - Saving...
2022-01-18 21:47:18,964 - INFO - Epoch time: 422.2298758029938
2022-01-18 21:47:18,965 - INFO - 
Epoch: 39
2022-01-18 21:47:18,965 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:48:50,858 - INFO - [Step=32750]	Loss=0.7793	236.6 examples/second
2022-01-18 21:50:56,794 - INFO - [Step=33000]	Loss=0.7891	254.1 examples/second
2022-01-18 21:52:59,338 - INFO - [Step=33250]	Loss=0.7695	261.1 examples/second
2022-01-18 21:54:26,487 - INFO - Test Loss=0.8406, Test top-1 acc=0.7978
2022-01-18 21:54:26,487 - INFO - Group Accuracy:

2022-01-18 21:54:26,487 - INFO - [0.97903615 0.99084336 0.9838554  0.9920482  0.9826506  0.9946988
 0.98024094 0.9848193  0.9893976  0.97590363 0.99084336 0.98361444
 0.97590363 0.97975904 0.9785542  0.98650604 0.99445784]
2022-01-18 21:54:26,488 - INFO - Epoch time: 427.52313017845154
2022-01-18 21:54:26,488 - INFO - 
Epoch: 40
2022-01-18 21:54:26,488 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:55:20,968 - INFO - [Step=33500]	Loss=0.7794	225.9 examples/second
2022-01-18 21:57:25,022 - INFO - [Step=33750]	Loss=0.7664	258.0 examples/second
2022-01-18 21:59:26,657 - INFO - [Step=34000]	Loss=0.7697	263.1 examples/second
2022-01-18 22:01:33,678 - INFO - Test Loss=0.8599, Test top-1 acc=0.7918
2022-01-18 22:01:33,678 - INFO - Group Accuracy:

2022-01-18 22:01:33,678 - INFO - [0.98       0.98963857 0.9845783  0.9918072  0.98240966 0.9939759
 0.9807229  0.98361444 0.98963857 0.97566265 0.9898795  0.9853012
 0.97590363 0.9785542  0.97638553 0.98771083 0.9925301 ]
2022-01-18 22:01:33,679 - INFO - Epoch time: 427.19074058532715
2022-01-18 22:01:33,679 - INFO - 
Epoch: 41
2022-01-18 22:01:33,679 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:01:43,110 - INFO - [Step=34250]	Loss=0.7772	234.5 examples/second
2022-01-18 22:03:48,361 - INFO - [Step=34500]	Loss=0.7579	255.5 examples/second
2022-01-18 22:05:51,596 - INFO - [Step=34750]	Loss=0.7688	259.7 examples/second
2022-01-18 22:07:56,645 - INFO - [Step=35000]	Loss=0.7668	255.9 examples/second
2022-01-18 22:08:44,974 - INFO - Test Loss=0.8389, Test top-1 acc=0.7971
2022-01-18 22:08:44,974 - INFO - Group Accuracy:

2022-01-18 22:08:44,974 - INFO - [0.9768675  0.9913253  0.98433733 0.993253   0.98433733 0.99445784
 0.98       0.9833735  0.99036145 0.9787952  0.9893976  0.9848193
 0.97493976 0.9821687  0.9778313  0.98650604 0.9939759 ]
2022-01-18 22:08:44,976 - INFO - Epoch time: 431.2971148490906
2022-01-18 22:08:44,976 - INFO - 
Epoch: 42
2022-01-18 22:08:44,976 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:10:36,666 - INFO - [Step=35250]	Loss=0.7407	200.0 examples/second
2022-01-18 22:12:47,066 - INFO - [Step=35500]	Loss=0.7506	245.4 examples/second
2022-01-18 22:14:58,678 - INFO - [Step=35750]	Loss=0.7656	243.1 examples/second
2022-01-18 22:16:39,690 - INFO - Test Loss=0.8660, Test top-1 acc=0.7928
2022-01-18 22:16:39,692 - INFO - Group Accuracy:

2022-01-18 22:16:39,692 - INFO - [0.9773494  0.9901205  0.9838554  0.9922892  0.9807229  0.99421686
 0.98024094 0.9826506  0.99060243 0.9766265  0.99156624 0.98313254
 0.9746988  0.98024094 0.9778313  0.9860241  0.993494  ]
2022-01-18 22:16:39,696 - INFO - Epoch time: 474.71992778778076
2022-01-18 22:16:39,697 - INFO - 
Epoch: 43
2022-01-18 22:16:39,697 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:17:38,660 - INFO - [Step=36000]	Loss=0.7351	200.0 examples/second
2022-01-18 22:19:51,181 - INFO - [Step=36250]	Loss=0.7323	241.5 examples/second
2022-01-18 22:21:58,626 - INFO - [Step=36500]	Loss=0.7489	251.1 examples/second
2022-01-18 22:24:01,738 - INFO - Test Loss=0.8531, Test top-1 acc=0.7993
2022-01-18 22:24:01,739 - INFO - Group Accuracy:

2022-01-18 22:24:01,739 - INFO - [0.98       0.9913253  0.9848193  0.9930121  0.9819277  0.9939759
 0.98       0.9833735  0.9901205  0.9773494  0.9913253  0.9853012
 0.9768675  0.97927713 0.9771084  0.98771083 0.9922892 ]
2022-01-18 22:24:01,740 - INFO - Epoch time: 442.0426297187805
2022-01-18 22:24:01,740 - INFO - 
Epoch: 44
2022-01-18 22:24:01,740 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:24:09,313 - INFO - [Step=36750]	Loss=0.7404	244.9 examples/second
2022-01-18 22:26:08,997 - INFO - [Step=37000]	Loss=0.7201	267.4 examples/second
2022-01-18 22:28:08,461 - INFO - [Step=37250]	Loss=0.7370	267.9 examples/second
2022-01-18 22:30:06,958 - INFO - [Step=37500]	Loss=0.7398	270.1 examples/second
2022-01-18 22:30:52,489 - INFO - Test Loss=0.8864, Test top-1 acc=0.7930
2022-01-18 22:30:52,490 - INFO - Group Accuracy:

2022-01-18 22:30:52,491 - INFO - [0.9780723  0.99036145 0.9838554  0.9925301  0.9809638  0.99445784
 0.9814458  0.9821687  0.9889157  0.97614455 0.99036145 0.9840964
 0.97518075 0.97975904 0.9768675  0.9879518  0.993494  ]
2022-01-18 22:30:52,493 - INFO - Epoch time: 410.753470659256
2022-01-18 22:30:52,494 - INFO - 
Epoch: 45
2022-01-18 22:30:52,494 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:32:18,746 - INFO - [Step=37750]	Loss=0.7224	242.8 examples/second
2022-01-18 22:34:17,776 - INFO - [Step=38000]	Loss=0.7335	268.8 examples/second
2022-01-18 22:36:15,901 - INFO - [Step=38250]	Loss=0.7455	270.9 examples/second
2022-01-18 22:37:42,353 - INFO - Test Loss=0.8269, Test top-1 acc=0.7998
2022-01-18 22:37:42,354 - INFO - Group Accuracy:

2022-01-18 22:37:42,354 - INFO - [0.9780723  0.99060243 0.9850602  0.9922892  0.98289156 0.9946988
 0.9814458  0.9853012  0.9898795  0.9768675  0.99108434 0.9853012
 0.97590363 0.9812048  0.97493976 0.9891566  0.99445784]
2022-01-18 22:37:42,354 - INFO - Epoch time: 409.860773563385
2022-01-18 22:37:42,355 - INFO - 
Epoch: 46
2022-01-18 22:37:42,355 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:38:29,535 - INFO - [Step=38500]	Loss=0.7264	239.5 examples/second
2022-01-18 22:40:28,423 - INFO - [Step=38750]	Loss=0.7254	269.2 examples/second
2022-01-18 22:42:33,236 - INFO - [Step=39000]	Loss=0.7045	256.4 examples/second
2022-01-18 22:44:44,775 - INFO - Test Loss=0.8855, Test top-1 acc=0.7954
2022-01-18 22:44:44,776 - INFO - Group Accuracy:

2022-01-18 22:44:44,776 - INFO - [0.97975904 0.99036145 0.9833735  0.9930121  0.9833735  0.9939759
 0.9826506  0.9845783  0.9901205  0.97542167 0.9901205  0.98289156
 0.97445786 0.9787952  0.9775904  0.9884337  0.993494  ]
2022-01-18 22:44:44,776 - INFO - Epoch time: 422.42190647125244
2022-01-18 22:44:44,777 - INFO - 
Epoch: 47
2022-01-18 22:44:44,777 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:44:49,712 - INFO - [Step=39250]	Loss=0.7174	234.5 examples/second
2022-01-18 22:46:47,989 - INFO - [Step=39500]	Loss=0.7195	270.6 examples/second
2022-01-18 22:48:47,363 - INFO - [Step=39750]	Loss=0.7130	268.1 examples/second
2022-01-18 22:50:46,605 - INFO - [Step=40000]	Loss=0.7243	268.4 examples/second
2022-01-18 22:51:32,953 - INFO - Test Loss=0.8345, Test top-1 acc=0.8022
2022-01-18 22:51:32,954 - INFO - Group Accuracy:

2022-01-18 22:51:32,954 - INFO - [0.98024094 0.9898795  0.9848193  0.9925301  0.9816868  0.99373496
 0.9812048  0.98433733 0.9889157  0.9785542  0.99156624 0.9853012
 0.97542167 0.98       0.9766265  0.98722893 0.9939759 ]
2022-01-18 22:51:32,957 - INFO - Saving...
2022-01-18 22:51:33,521 - INFO - Epoch time: 408.7442879676819
2022-01-18 22:51:33,522 - INFO - 
Epoch: 48
2022-01-18 22:51:33,522 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:52:58,231 - INFO - [Step=40250]	Loss=0.6977	243.1 examples/second
2022-01-18 22:54:59,693 - INFO - [Step=40500]	Loss=0.7111	263.5 examples/second
2022-01-18 22:57:04,176 - INFO - [Step=40750]	Loss=0.7061	257.1 examples/second
2022-01-18 22:58:36,872 - INFO - Test Loss=0.8545, Test top-1 acc=0.7966
2022-01-18 22:58:36,873 - INFO - Group Accuracy:

2022-01-18 22:58:36,873 - INFO - [0.98024094 0.99036145 0.9848193  0.9920482  0.9821687  0.9939759
 0.97975904 0.9833735  0.9881928  0.97566265 0.99036145 0.9860241
 0.97614455 0.9787952  0.97542167 0.9881928  0.993494  ]
2022-01-18 22:58:36,874 - INFO - Epoch time: 423.3522107601166
2022-01-18 22:58:36,874 - INFO - 
Epoch: 49
2022-01-18 22:58:36,874 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:59:23,656 - INFO - [Step=41000]	Loss=0.6926	229.4 examples/second
2022-01-18 23:01:31,544 - INFO - [Step=41250]	Loss=0.6942	250.2 examples/second
2022-01-18 23:03:33,548 - INFO - [Step=41500]	Loss=0.6984	262.3 examples/second
2022-01-18 23:05:39,879 - INFO - [Step=41750]	Loss=0.7039	253.3 examples/second
2022-01-18 23:05:51,549 - INFO - Test Loss=0.8460, Test top-1 acc=0.8000
2022-01-18 23:05:51,549 - INFO - Group Accuracy:

2022-01-18 23:05:51,549 - INFO - [0.98       0.9913253  0.98578316 0.9922892  0.98433733 0.99421686
 0.98       0.98361444 0.9881928  0.9768675  0.99108434 0.9848193
 0.97566265 0.97975904 0.9773494  0.9889157  0.993494  ]
2022-01-18 23:05:51,550 - INFO - Epoch time: 434.6756000518799
2022-01-18 23:05:51,550 - INFO - 
Epoch: 50
2022-01-18 23:05:51,550 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:07:59,397 - INFO - [Step=42000]	Loss=0.6915	229.4 examples/second
2022-01-18 23:10:07,913 - INFO - [Step=42250]	Loss=0.6964	249.0 examples/second
2022-01-18 23:12:04,911 - INFO - [Step=42500]	Loss=0.7161	273.5 examples/second
2022-01-18 23:13:01,520 - INFO - Test Loss=0.8530, Test top-1 acc=0.7983
2022-01-18 23:13:01,521 - INFO - Group Accuracy:

2022-01-18 23:13:01,522 - INFO - [0.9778313  0.99156624 0.9853012  0.99108434 0.9819277  0.99445784
 0.98       0.9807229  0.9901205  0.9778313  0.99373496 0.9833735
 0.97542167 0.9807229  0.9778313  0.9886747  0.9939759 ]
2022-01-18 23:13:01,523 - INFO - Epoch time: 429.9732279777527
2022-01-18 23:13:01,523 - INFO - 
Epoch: 51
2022-01-18 23:13:01,523 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:14:25,591 - INFO - [Step=42750]	Loss=0.6773	227.5 examples/second
2022-01-18 23:16:37,721 - INFO - [Step=43000]	Loss=0.6812	242.2 examples/second
2022-01-18 23:18:41,606 - INFO - [Step=43250]	Loss=0.6960	258.3 examples/second
2022-01-18 23:20:23,586 - INFO - Test Loss=0.8388, Test top-1 acc=0.7978
2022-01-18 23:20:23,587 - INFO - Group Accuracy:

2022-01-18 23:20:23,587 - INFO - [0.9804819  0.99060243 0.98626506 0.9925301  0.9819277  0.9939759
 0.97951806 0.9838554  0.9898795  0.9766265  0.99108434 0.9826506
 0.97614455 0.98024094 0.9778313  0.98746985 0.9946988 ]
2022-01-18 23:20:23,588 - INFO - Epoch time: 442.0645923614502
2022-01-18 23:20:23,588 - INFO - 
Epoch: 52
2022-01-18 23:20:23,588 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:21:10,763 - INFO - [Step=43500]	Loss=0.7132	214.5 examples/second
2022-01-18 23:23:15,888 - INFO - [Step=43750]	Loss=0.6780	255.7 examples/second
2022-01-18 23:25:27,776 - INFO - [Step=44000]	Loss=0.7120	242.6 examples/second
2022-01-18 23:27:35,675 - INFO - [Step=44250]	Loss=0.6814	250.2 examples/second
2022-01-18 23:27:45,834 - INFO - Test Loss=0.8517, Test top-1 acc=0.7986
2022-01-18 23:27:45,834 - INFO - Group Accuracy:

2022-01-18 23:27:45,834 - INFO - [0.97951806 0.99036145 0.98578316 0.9925301  0.9807229  0.9939759
 0.97951806 0.98361444 0.9893976  0.9771084  0.9920482  0.9838554
 0.9746988  0.9804819  0.9771084  0.98722893 0.99421686]
2022-01-18 23:27:45,835 - INFO - Epoch time: 442.2469553947449
2022-01-18 23:27:45,835 - INFO - 
Epoch: 53
2022-01-18 23:27:45,835 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:29:54,174 - INFO - [Step=44500]	Loss=0.6671	231.0 examples/second
2022-01-18 23:31:59,891 - INFO - [Step=44750]	Loss=0.6748	254.5 examples/second
2022-01-18 23:33:55,875 - INFO - [Step=45000]	Loss=0.6848	275.9 examples/second
2022-01-18 23:34:48,394 - INFO - Test Loss=0.8799, Test top-1 acc=0.7949
2022-01-18 23:34:48,394 - INFO - Group Accuracy:

2022-01-18 23:34:48,394 - INFO - [0.97903615 0.99084336 0.98433733 0.99108434 0.9826506  0.993253
 0.97975904 0.98240966 0.9893976  0.97518075 0.99060243 0.9850602
 0.97493976 0.9819277  0.97566265 0.9886747  0.993494  ]
2022-01-18 23:34:48,395 - INFO - Epoch time: 422.5599172115326
2022-01-18 23:34:48,395 - INFO - 
Epoch: 54
2022-01-18 23:34:48,395 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:36:07,656 - INFO - [Step=45250]	Loss=0.6655	242.8 examples/second
2022-01-18 23:38:06,175 - INFO - [Step=45500]	Loss=0.6688	270.0 examples/second
2022-01-18 23:40:05,518 - INFO - [Step=45750]	Loss=0.6781	268.1 examples/second
2022-01-18 23:41:38,754 - INFO - Test Loss=0.8458, Test top-1 acc=0.8019
2022-01-18 23:41:38,755 - INFO - Group Accuracy:

2022-01-18 23:41:38,755 - INFO - [0.97975904 0.9918072  0.9853012  0.99060243 0.9855422  0.99445784
 0.97975904 0.98433733 0.99036145 0.97445786 0.9901205  0.9853012
 0.97638553 0.9814458  0.97590363 0.9879518  0.9946988 ]
2022-01-18 23:41:38,756 - INFO - Epoch time: 410.3606927394867
2022-01-18 23:41:38,756 - INFO - 
Epoch: 55
2022-01-18 23:41:38,756 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:42:18,071 - INFO - [Step=46000]	Loss=0.6800	241.4 examples/second
2022-01-18 23:44:15,359 - INFO - [Step=46250]	Loss=0.6557	272.8 examples/second
2022-01-18 23:46:14,882 - INFO - [Step=46500]	Loss=0.6760	267.7 examples/second
2022-01-18 23:48:14,203 - INFO - [Step=46750]	Loss=0.6822	268.2 examples/second
2022-01-18 23:48:28,572 - INFO - Test Loss=0.8676, Test top-1 acc=0.7976
2022-01-18 23:48:28,572 - INFO - Group Accuracy:

2022-01-18 23:48:28,572 - INFO - [0.98       0.9913253  0.9853012  0.99060243 0.9845783  0.99445784
 0.9787952  0.9848193  0.98963857 0.97590363 0.99084336 0.9848193
 0.97614455 0.97927713 0.97638553 0.9881928  0.99445784]
2022-01-18 23:48:28,573 - INFO - Epoch time: 409.81724786758423
2022-01-18 23:48:28,573 - INFO - 
Epoch: 56
2022-01-18 23:48:28,573 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:50:24,786 - INFO - [Step=47000]	Loss=0.6474	245.1 examples/second
2022-01-18 23:52:24,020 - INFO - [Step=47250]	Loss=0.6577	268.4 examples/second
2022-01-18 23:54:23,365 - INFO - [Step=47500]	Loss=0.6749	268.1 examples/second
2022-01-18 23:55:19,241 - INFO - Test Loss=0.8528, Test top-1 acc=0.7990
2022-01-18 23:55:19,242 - INFO - Group Accuracy:

2022-01-18 23:55:19,242 - INFO - [0.9809638  0.9918072  0.9845783  0.99156624 0.98289156 0.99421686
 0.9773494  0.9850602  0.9893976  0.9778313  0.99084336 0.9826506
 0.97542167 0.9812048  0.97493976 0.98746985 0.9939759 ]
2022-01-18 23:55:19,242 - INFO - Epoch time: 410.66943168640137
2022-01-18 23:55:19,243 - INFO - 
Epoch: 57
2022-01-18 23:55:19,243 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:56:35,968 - INFO - [Step=47750]	Loss=0.6542	241.3 examples/second
2022-01-18 23:58:34,030 - INFO - [Step=48000]	Loss=0.6486	271.0 examples/second
2022-01-19 00:00:32,894 - INFO - [Step=48250]	Loss=0.6696	269.2 examples/second
2022-01-19 00:02:07,291 - INFO - Test Loss=0.8550, Test top-1 acc=0.8005
2022-01-19 00:02:07,291 - INFO - Group Accuracy:

2022-01-19 00:02:07,291 - INFO - [0.9807229  0.9927711  0.9850602  0.99156624 0.9833735  0.99445784
 0.97975904 0.98313254 0.9901205  0.9778313  0.99108434 0.9855422
 0.9780723  0.9787952  0.97614455 0.98746985 0.99373496]
2022-01-19 00:02:07,292 - INFO - Epoch time: 408.04934883117676
2022-01-19 00:02:07,292 - INFO - 
Epoch: 58
2022-01-19 00:02:07,292 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:02:42,161 - INFO - [Step=48500]	Loss=0.6646	247.6 examples/second
2022-01-19 00:04:42,484 - INFO - [Step=48750]	Loss=0.6602	266.0 examples/second
2022-01-19 00:06:44,446 - INFO - [Step=49000]	Loss=0.6520	262.4 examples/second
2022-01-19 00:08:51,998 - INFO - [Step=49250]	Loss=0.6610	250.9 examples/second
2022-01-19 00:09:10,433 - INFO - Test Loss=0.8945, Test top-1 acc=0.7904
2022-01-19 00:09:10,433 - INFO - Group Accuracy:

2022-01-19 00:09:10,433 - INFO - [0.9780723  0.9901205  0.9838554  0.9920482  0.9809638  0.99421686
 0.9804819  0.9853012  0.9881928  0.97638553 0.9918072  0.9840964
 0.9739759  0.97951806 0.9742169  0.98674697 0.9939759 ]
2022-01-19 00:09:10,434 - INFO - Epoch time: 423.14223170280457
2022-01-19 00:09:10,434 - INFO - 
Epoch: 59
2022-01-19 00:09:10,434 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:11:10,170 - INFO - [Step=49500]	Loss=0.6170	231.6 examples/second
2022-01-19 00:13:15,309 - INFO - [Step=49750]	Loss=0.5894	255.7 examples/second
2022-01-19 00:15:21,597 - INFO - [Step=50000]	Loss=0.5700	253.4 examples/second
2022-01-19 00:16:17,405 - INFO - Test Loss=0.8144, Test top-1 acc=0.8087
2022-01-19 00:16:17,406 - INFO - Group Accuracy:

2022-01-19 00:16:17,406 - INFO - [0.98024094 0.9920482  0.9853012  0.9918072  0.9833735  0.99493974
 0.9816868  0.9855422  0.9898795  0.9778313  0.9922892  0.98626506
 0.9771084  0.9814458  0.9775904  0.9884337  0.99421686]
2022-01-19 00:16:17,407 - INFO - Saving...
2022-01-19 00:16:17,884 - INFO - Epoch time: 427.4496352672577
2022-01-19 00:16:17,884 - INFO - 
Epoch: 60
2022-01-19 00:16:17,884 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:17:34,208 - INFO - [Step=50250]	Loss=0.5673	241.3 examples/second
2022-01-19 00:19:41,170 - INFO - [Step=50500]	Loss=0.5595	252.0 examples/second
2022-01-19 00:21:44,454 - INFO - [Step=50750]	Loss=0.5530	259.6 examples/second
2022-01-19 00:23:27,994 - INFO - Test Loss=0.8122, Test top-1 acc=0.8108
2022-01-19 00:23:27,994 - INFO - Group Accuracy:

2022-01-19 00:23:27,995 - INFO - [0.9814458  0.99084336 0.98626506 0.9918072  0.98313254 0.9946988
 0.9814458  0.9853012  0.9891566  0.9785542  0.993494   0.9855422
 0.97614455 0.9816868  0.9773494  0.9893976  0.9946988 ]
2022-01-19 00:23:27,995 - INFO - Saving...
2022-01-19 00:23:28,558 - INFO - Epoch time: 430.67332553863525
2022-01-19 00:23:28,558 - INFO - 
Epoch: 61
2022-01-19 00:23:28,558 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:24:04,333 - INFO - [Step=51000]	Loss=0.5614	228.8 examples/second
2022-01-19 00:26:07,483 - INFO - [Step=51250]	Loss=0.5672	259.8 examples/second
2022-01-19 00:28:03,527 - INFO - [Step=51500]	Loss=0.5588	275.8 examples/second
2022-01-19 00:30:06,901 - INFO - [Step=51750]	Loss=0.5614	259.4 examples/second
2022-01-19 00:30:23,600 - INFO - Test Loss=0.8106, Test top-1 acc=0.8101
2022-01-19 00:30:23,600 - INFO - Group Accuracy:

2022-01-19 00:30:23,600 - INFO - [0.9807229  0.9920482  0.98626506 0.99156624 0.98361444 0.9946988
 0.9814458  0.98433733 0.9891566  0.97831327 0.9925301  0.98650604
 0.9775904  0.9819277  0.9768675  0.9893976  0.9939759 ]
2022-01-19 00:30:23,601 - INFO - Epoch time: 415.04326820373535
2022-01-19 00:30:23,601 - INFO - 
Epoch: 62
2022-01-19 00:30:23,601 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:32:26,146 - INFO - [Step=52000]	Loss=0.5517	229.8 examples/second
2022-01-19 00:34:38,172 - INFO - [Step=52250]	Loss=0.5387	242.4 examples/second
2022-01-19 00:36:44,762 - INFO - [Step=52500]	Loss=0.5441	252.8 examples/second
2022-01-19 00:37:51,492 - INFO - Test Loss=0.8070, Test top-1 acc=0.8072
2022-01-19 00:37:51,492 - INFO - Group Accuracy:

2022-01-19 00:37:51,493 - INFO - [0.9809638  0.9925301  0.9855422  0.99108434 0.98361444 0.99445784
 0.9809638  0.9838554  0.9889157  0.9780723  0.9922892  0.98626506
 0.9771084  0.9816868  0.9780723  0.9901205  0.99421686]
2022-01-19 00:37:51,493 - INFO - Epoch time: 447.8922290802002
2022-01-19 00:37:51,493 - INFO - 
Epoch: 63
2022-01-19 00:37:51,494 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:39:12,160 - INFO - [Step=52750]	Loss=0.5463	217.1 examples/second
2022-01-19 00:41:18,630 - INFO - [Step=53000]	Loss=0.5396	253.0 examples/second
2022-01-19 00:43:30,289 - INFO - [Step=53250]	Loss=0.5547	243.1 examples/second
2022-01-19 00:45:15,922 - INFO - Test Loss=0.8100, Test top-1 acc=0.8070
2022-01-19 00:45:15,922 - INFO - Group Accuracy:

2022-01-19 00:45:15,922 - INFO - [0.9819277  0.9922892  0.98674697 0.99108434 0.9840964  0.99445784
 0.9816868  0.98433733 0.9893976  0.9780723  0.9920482  0.9853012
 0.9768675  0.9814458  0.9778313  0.9898795  0.99421686]
2022-01-19 00:45:15,923 - INFO - Epoch time: 444.42989897727966
2022-01-19 00:45:15,924 - INFO - 
Epoch: 64
2022-01-19 00:45:15,924 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:45:51,151 - INFO - [Step=53500]	Loss=0.5493	227.2 examples/second
2022-01-19 00:48:02,716 - INFO - [Step=53750]	Loss=0.5408	243.2 examples/second
2022-01-19 00:49:58,821 - INFO - [Step=54000]	Loss=0.5324	275.6 examples/second
2022-01-19 00:52:01,307 - INFO - [Step=54250]	Loss=0.5477	261.3 examples/second
2022-01-19 00:52:23,848 - INFO - Test Loss=0.8049, Test top-1 acc=0.8060
2022-01-19 00:52:23,849 - INFO - Group Accuracy:

2022-01-19 00:52:23,849 - INFO - [0.9809638  0.9927711  0.98626506 0.99156624 0.9845783  0.99445784
 0.98       0.98313254 0.9884337  0.97831327 0.9920482  0.98578316
 0.9766265  0.9814458  0.9780723  0.98963857 0.99421686]
2022-01-19 00:52:23,851 - INFO - Epoch time: 427.9276626110077
2022-01-19 00:52:23,851 - INFO - 
Epoch: 65
2022-01-19 00:52:23,852 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:54:20,621 - INFO - [Step=54500]	Loss=0.5459	229.7 examples/second
2022-01-19 00:56:26,882 - INFO - [Step=54750]	Loss=0.5330	253.5 examples/second
2022-01-19 00:58:29,545 - INFO - [Step=55000]	Loss=0.5301	260.9 examples/second
2022-01-19 00:59:35,415 - INFO - Test Loss=0.8024, Test top-1 acc=0.8104
2022-01-19 00:59:35,415 - INFO - Group Accuracy:

2022-01-19 00:59:35,415 - INFO - [0.9819277  0.9925301  0.98674697 0.9922892  0.98361444 0.9946988
 0.9807229  0.98433733 0.9889157  0.9778313  0.993253   0.9855422
 0.9775904  0.9809638  0.9766265  0.9901205  0.99445784]
2022-01-19 00:59:35,416 - INFO - Epoch time: 431.5647485256195
2022-01-19 00:59:35,416 - INFO - 
Epoch: 66
2022-01-19 00:59:35,416 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:00:49,715 - INFO - [Step=55250]	Loss=0.5356	228.3 examples/second
2022-01-19 01:02:52,563 - INFO - [Step=55500]	Loss=0.5253	260.5 examples/second
2022-01-19 01:04:56,955 - INFO - [Step=55750]	Loss=0.5393	257.3 examples/second
2022-01-19 01:06:45,082 - INFO - Test Loss=0.8052, Test top-1 acc=0.8104
2022-01-19 01:06:45,083 - INFO - Group Accuracy:

2022-01-19 01:06:45,083 - INFO - [0.9814458  0.99156624 0.98674697 0.9925301  0.98361444 0.99421686
 0.9807229  0.98361444 0.9889157  0.9785542  0.9925301  0.98578316
 0.9766265  0.9814458  0.97831327 0.98963857 0.99445784]
2022-01-19 01:06:45,084 - INFO - Epoch time: 429.66739320755005
2022-01-19 01:06:45,084 - INFO - 
Epoch: 67
2022-01-19 01:06:45,084 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:07:15,504 - INFO - [Step=56000]	Loss=0.5264	231.0 examples/second
2022-01-19 01:09:17,004 - INFO - [Step=56250]	Loss=0.5237	263.4 examples/second
2022-01-19 01:11:22,084 - INFO - [Step=56500]	Loss=0.5220	255.8 examples/second
2022-01-19 01:13:23,713 - INFO - [Step=56750]	Loss=0.5393	263.1 examples/second
2022-01-19 01:13:46,664 - INFO - Test Loss=0.8059, Test top-1 acc=0.8094
2022-01-19 01:13:46,665 - INFO - Group Accuracy:

2022-01-19 01:13:46,665 - INFO - [0.9816868  0.9922892  0.98650604 0.9925301  0.9838554  0.9946988
 0.9807229  0.98289156 0.9891566  0.97831327 0.993253   0.9855422
 0.9773494  0.9814458  0.9771084  0.9898795  0.99421686]
2022-01-19 01:13:46,666 - INFO - Epoch time: 421.58182859420776
2022-01-19 01:13:46,666 - INFO - 
Epoch: 68
2022-01-19 01:13:46,666 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:15:35,670 - INFO - [Step=57000]	Loss=0.5216	242.5 examples/second
2022-01-19 01:17:37,487 - INFO - [Step=57250]	Loss=0.5290	262.7 examples/second
2022-01-19 01:19:41,808 - INFO - [Step=57500]	Loss=0.5278	257.4 examples/second
2022-01-19 01:20:49,260 - INFO - Test Loss=0.8077, Test top-1 acc=0.8096
2022-01-19 01:20:49,260 - INFO - Group Accuracy:

2022-01-19 01:20:49,260 - INFO - [0.9812048  0.9925301  0.98746985 0.9920482  0.98313254 0.99421686
 0.98024094 0.9848193  0.9898795  0.9778313  0.9925301  0.9853012
 0.9773494  0.9819277  0.9780723  0.98963857 0.9939759 ]
2022-01-19 01:20:49,261 - INFO - Epoch time: 422.5952708721161
2022-01-19 01:20:49,261 - INFO - 
Epoch: 69
2022-01-19 01:20:49,261 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:22:00,806 - INFO - [Step=57750]	Loss=0.5319	230.2 examples/second
2022-01-19 01:24:02,992 - INFO - [Step=58000]	Loss=0.5154	261.9 examples/second
2022-01-19 01:26:06,596 - INFO - [Step=58250]	Loss=0.5242	258.9 examples/second
2022-01-19 01:27:52,684 - INFO - Test Loss=0.8095, Test top-1 acc=0.8075
2022-01-19 01:27:52,684 - INFO - Group Accuracy:

2022-01-19 01:27:52,684 - INFO - [0.9816868  0.9922892  0.98698795 0.99156624 0.9845783  0.99421686
 0.98       0.9850602  0.9898795  0.9778313  0.9920482  0.9853012
 0.9768675  0.9809638  0.9775904  0.9893976  0.99421686]
2022-01-19 01:27:52,685 - INFO - Epoch time: 423.4238250255585
2022-01-19 01:27:52,685 - INFO - 
Epoch: 70
2022-01-19 01:27:52,685 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:28:17,903 - INFO - [Step=58500]	Loss=0.5279	243.7 examples/second
2022-01-19 01:30:21,924 - INFO - [Step=58750]	Loss=0.5206	258.0 examples/second
2022-01-19 01:32:21,344 - INFO - [Step=59000]	Loss=0.5348	268.0 examples/second
2022-01-19 01:34:24,110 - INFO - [Step=59250]	Loss=0.5263	260.7 examples/second
2022-01-19 01:34:56,996 - INFO - Test Loss=0.8104, Test top-1 acc=0.8104
2022-01-19 01:34:56,996 - INFO - Group Accuracy:

2022-01-19 01:34:56,996 - INFO - [0.9816868  0.9925301  0.98650604 0.99156624 0.9848193  0.99421686
 0.98024094 0.98361444 0.9889157  0.9780723  0.9922892  0.9855422
 0.97614455 0.9812048  0.9780723  0.99036145 0.9946988 ]
2022-01-19 01:34:56,997 - INFO - Epoch time: 424.3125
2022-01-19 01:34:56,998 - INFO - 
Epoch: 71
2022-01-19 01:34:56,998 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:37:01,073 - INFO - [Step=59500]	Loss=0.5267	203.9 examples/second
2022-01-19 01:39:09,325 - INFO - [Step=59750]	Loss=0.5250	249.5 examples/second
2022-01-19 01:41:18,698 - INFO - [Step=60000]	Loss=0.5151	247.4 examples/second
2022-01-19 01:42:38,790 - INFO - Test Loss=0.8176, Test top-1 acc=0.8094
2022-01-19 01:42:38,791 - INFO - Group Accuracy:

2022-01-19 01:42:38,791 - INFO - [0.9816868  0.9930121  0.9860241  0.9920482  0.98433733 0.99445784
 0.98024094 0.9848193  0.98963857 0.9778313  0.9918072  0.9840964
 0.9768675  0.9821687  0.9773494  0.9898795  0.9946988 ]
2022-01-19 01:42:38,795 - INFO - Epoch time: 461.79752111434937
2022-01-19 01:42:38,796 - INFO - 
Epoch: 72
2022-01-19 01:42:38,796 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:43:56,546 - INFO - [Step=60250]	Loss=0.5207	202.7 examples/second
2022-01-19 01:46:06,337 - INFO - [Step=60500]	Loss=0.5227	246.6 examples/second
2022-01-19 01:48:10,477 - INFO - [Step=60750]	Loss=0.5196	257.8 examples/second
2022-01-19 01:50:00,037 - INFO - Test Loss=0.8150, Test top-1 acc=0.8087
2022-01-19 01:50:00,038 - INFO - Group Accuracy:

2022-01-19 01:50:00,038 - INFO - [0.9812048  0.9922892  0.98722893 0.99156624 0.98313254 0.99445784
 0.97927713 0.9840964  0.9886747  0.9773494  0.9920482  0.9860241
 0.9768675  0.9821687  0.9778313  0.9891566  0.99493974]
2022-01-19 01:50:00,039 - INFO - Epoch time: 441.2427942752838
2022-01-19 01:50:00,039 - INFO - 
Epoch: 73
2022-01-19 01:50:00,039 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:50:24,492 - INFO - [Step=61000]	Loss=0.5167	238.8 examples/second
2022-01-19 01:52:32,365 - INFO - [Step=61250]	Loss=0.5144	250.3 examples/second
2022-01-19 01:54:40,042 - INFO - [Step=61500]	Loss=0.5163	250.6 examples/second
2022-01-19 01:56:48,860 - INFO - [Step=61750]	Loss=0.5258	248.4 examples/second
2022-01-19 01:57:21,175 - INFO - Test Loss=0.8099, Test top-1 acc=0.8087
2022-01-19 01:57:21,175 - INFO - Group Accuracy:

2022-01-19 01:57:21,175 - INFO - [0.9812048  0.9925301  0.98722893 0.99156624 0.9853012  0.99445784
 0.97903615 0.98361444 0.9889157  0.9780723  0.9927711  0.98578316
 0.9766265  0.9814458  0.9778313  0.9891566  0.99445784]
2022-01-19 01:57:21,176 - INFO - Epoch time: 441.13702630996704
2022-01-19 01:57:21,176 - INFO - 
Epoch: 74
2022-01-19 01:57:21,176 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:59:10,347 - INFO - [Step=62000]	Loss=0.5046	226.2 examples/second
2022-01-19 02:01:17,250 - INFO - [Step=62250]	Loss=0.5155	252.2 examples/second
2022-01-19 02:03:27,372 - INFO - [Step=62500]	Loss=0.5081	245.9 examples/second
2022-01-19 02:04:39,829 - INFO - Test Loss=0.8062, Test top-1 acc=0.8080
2022-01-19 02:04:39,830 - INFO - Group Accuracy:

2022-01-19 02:04:39,830 - INFO - [0.9812048  0.9927711  0.98746985 0.9913253  0.9845783  0.9946988
 0.9807229  0.9833735  0.9893976  0.9775904  0.9925301  0.98626506
 0.97638553 0.9826506  0.9771084  0.9901205  0.99493974]
2022-01-19 02:04:39,831 - INFO - Epoch time: 438.655234336853
2022-01-19 02:04:39,831 - INFO - 
Epoch: 75
2022-01-19 02:04:39,831 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:05:48,051 - INFO - [Step=62750]	Loss=0.5121	227.5 examples/second
2022-01-19 02:07:51,445 - INFO - [Step=63000]	Loss=0.5053	259.3 examples/second
2022-01-19 02:09:54,929 - INFO - [Step=63250]	Loss=0.5058	259.1 examples/second
2022-01-19 02:11:46,601 - INFO - Test Loss=0.8140, Test top-1 acc=0.8080
2022-01-19 02:11:46,602 - INFO - Group Accuracy:

2022-01-19 02:11:46,602 - INFO - [0.98240966 0.9922892  0.98698795 0.9920482  0.9845783  0.99421686
 0.97927713 0.98361444 0.9889157  0.9775904  0.9930121  0.98626506
 0.97566265 0.98289156 0.9778313  0.98963857 0.99421686]
2022-01-19 02:11:46,603 - INFO - Epoch time: 426.7713520526886
2022-01-19 02:11:46,603 - INFO - 
Epoch: 76
2022-01-19 02:11:46,603 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:12:09,620 - INFO - [Step=63500]	Loss=0.5212	237.6 examples/second
2022-01-19 02:14:21,976 - INFO - [Step=63750]	Loss=0.5051	241.8 examples/second
2022-01-19 02:16:31,629 - INFO - [Step=64000]	Loss=0.5055	246.8 examples/second
2022-01-19 02:18:40,491 - INFO - [Step=64250]	Loss=0.5076	248.3 examples/second
2022-01-19 02:19:10,017 - INFO - Test Loss=0.8106, Test top-1 acc=0.8092
2022-01-19 02:19:10,018 - INFO - Group Accuracy:

2022-01-19 02:19:10,018 - INFO - [0.9819277  0.9920482  0.98674697 0.9927711  0.9840964  0.9939759
 0.97903615 0.9848193  0.9891566  0.9785542  0.9925301  0.9860241
 0.97638553 0.9821687  0.9773494  0.98963857 0.99445784]
2022-01-19 02:19:10,018 - INFO - Epoch time: 443.415607213974
2022-01-19 02:19:10,018 - INFO - 
Epoch: 77
2022-01-19 02:19:10,018 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:20:55,668 - INFO - [Step=64500]	Loss=0.5050	236.7 examples/second
2022-01-19 02:23:05,594 - INFO - [Step=64750]	Loss=0.4962	246.3 examples/second
2022-01-19 02:25:15,789 - INFO - [Step=65000]	Loss=0.5152	245.8 examples/second
2022-01-19 02:26:31,987 - INFO - Test Loss=0.8127, Test top-1 acc=0.8092
2022-01-19 02:26:31,988 - INFO - Group Accuracy:

2022-01-19 02:26:31,988 - INFO - [0.9814458  0.9925301  0.9860241  0.9922892  0.9840964  0.9939759
 0.97903615 0.9845783  0.9893976  0.9787952  0.99373496 0.9850602
 0.97614455 0.9814458  0.9785542  0.9893976  0.99421686]
2022-01-19 02:26:31,988 - INFO - Epoch time: 441.96995210647583
2022-01-19 02:26:31,988 - INFO - 
Epoch: 78
2022-01-19 02:26:31,989 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:27:32,069 - INFO - [Step=65250]	Loss=0.5054	234.8 examples/second
2022-01-19 02:29:42,709 - INFO - [Step=65500]	Loss=0.5082	245.0 examples/second
2022-01-19 02:31:57,182 - INFO - [Step=65750]	Loss=0.5030	238.0 examples/second
2022-01-19 02:33:59,972 - INFO - Test Loss=0.8218, Test top-1 acc=0.8065
2022-01-19 02:33:59,972 - INFO - Group Accuracy:

2022-01-19 02:33:59,972 - INFO - [0.9819277  0.9920482  0.98626506 0.99108434 0.9840964  0.99421686
 0.98       0.98361444 0.9893976  0.9768675  0.9920482  0.9860241
 0.97614455 0.9826506  0.9773494  0.9889157  0.99445784]
2022-01-19 02:33:59,973 - INFO - Epoch time: 447.98468947410583
2022-01-19 02:33:59,973 - INFO - 
Epoch: 79
2022-01-19 02:33:59,973 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:34:21,690 - INFO - [Step=66000]	Loss=0.5174	221.4 examples/second
2022-01-19 02:36:27,656 - INFO - [Step=66250]	Loss=0.5011	254.0 examples/second
2022-01-19 02:38:40,705 - INFO - [Step=66500]	Loss=0.4953	240.5 examples/second
2022-01-19 02:40:54,045 - INFO - [Step=66750]	Loss=0.5140	240.0 examples/second
2022-01-19 02:41:30,376 - INFO - Test Loss=0.8211, Test top-1 acc=0.8070
2022-01-19 02:41:30,377 - INFO - Group Accuracy:

2022-01-19 02:41:30,377 - INFO - [0.9814458  0.9922892  0.98650604 0.9925301  0.98433733 0.99445784
 0.97975904 0.9840964  0.9891566  0.97518075 0.993253   0.98578316
 0.97590363 0.9821687  0.9773494  0.9891566  0.99445784]
2022-01-19 02:41:30,380 - INFO - Epoch time: 450.4064071178436
2022-01-19 02:41:30,380 - INFO - 
Epoch: 80
2022-01-19 02:41:30,380 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:43:07,142 - INFO - [Step=67000]	Loss=0.4983	240.4 examples/second
2022-01-19 02:45:11,439 - INFO - [Step=67250]	Loss=0.5047	257.4 examples/second
2022-01-19 02:47:23,781 - INFO - [Step=67500]	Loss=0.4997	241.8 examples/second
2022-01-19 02:48:45,297 - INFO - Test Loss=0.8235, Test top-1 acc=0.8111
2022-01-19 02:48:45,297 - INFO - Group Accuracy:

2022-01-19 02:48:45,298 - INFO - [0.9816868  0.9927711  0.98746985 0.9925301  0.98433733 0.99421686
 0.98024094 0.9833735  0.98963857 0.9771084  0.993494   0.98674697
 0.97590363 0.9819277  0.9775904  0.9889157  0.99445784]
2022-01-19 02:48:45,298 - INFO - Saving...
2022-01-19 02:48:45,799 - INFO - Epoch time: 435.41943407058716
2022-01-19 02:48:45,799 - INFO - 
Epoch: 81
2022-01-19 02:48:45,800 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:49:46,843 - INFO - [Step=67750]	Loss=0.4996	223.7 examples/second
2022-01-19 02:52:08,648 - INFO - [Step=68000]	Loss=0.4964	225.7 examples/second
2022-01-19 02:54:19,831 - INFO - [Step=68250]	Loss=0.4976	243.9 examples/second
2022-01-19 02:56:23,485 - INFO - Test Loss=0.8194, Test top-1 acc=0.8118
2022-01-19 02:56:23,486 - INFO - Group Accuracy:

2022-01-19 02:56:23,486 - INFO - [0.9819277  0.9918072  0.98746985 0.9918072  0.9845783  0.99421686
 0.98024094 0.9838554  0.98963857 0.9778313  0.993253   0.98698795
 0.97590363 0.98313254 0.9775904  0.9891566  0.9951807 ]
2022-01-19 02:56:23,487 - INFO - Saving...
2022-01-19 02:56:23,972 - INFO - Epoch time: 458.1724932193756
2022-01-19 02:56:23,972 - INFO - 
Epoch: 82
2022-01-19 02:56:23,972 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:56:44,958 - INFO - [Step=68500]	Loss=0.4972	220.5 examples/second
2022-01-19 02:59:03,180 - INFO - [Step=68750]	Loss=0.4934	231.5 examples/second
2022-01-19 03:01:02,769 - INFO - [Step=69000]	Loss=0.4922	267.6 examples/second
2022-01-19 03:03:08,909 - INFO - [Step=69250]	Loss=0.5033	253.7 examples/second
2022-01-19 03:03:51,621 - INFO - Test Loss=0.8260, Test top-1 acc=0.8104
2022-01-19 03:03:51,621 - INFO - Group Accuracy:

2022-01-19 03:03:51,621 - INFO - [0.9814458  0.993494   0.98626506 0.9922892  0.9850602  0.99421686
 0.9787952  0.9840964  0.9891566  0.9778313  0.993494   0.9860241
 0.97590363 0.98289156 0.9778313  0.98963857 0.99445784]
2022-01-19 03:03:51,622 - INFO - Epoch time: 447.65008902549744
2022-01-19 03:03:51,622 - INFO - 
Epoch: 83
2022-01-19 03:03:51,623 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:05:42,975 - INFO - [Step=69500]	Loss=0.5000	207.7 examples/second
2022-01-19 03:07:48,905 - INFO - [Step=69750]	Loss=0.4944	254.1 examples/second
2022-01-19 03:09:58,896 - INFO - [Step=70000]	Loss=0.4990	246.2 examples/second
2022-01-19 03:11:18,307 - INFO - Test Loss=0.8257, Test top-1 acc=0.8111
2022-01-19 03:11:18,308 - INFO - Group Accuracy:

2022-01-19 03:11:18,308 - INFO - [0.9816868  0.9927711  0.98746985 0.9922892  0.9840964  0.99421686
 0.97927713 0.9848193  0.98963857 0.9773494  0.9927711  0.98626506
 0.9766265  0.9819277  0.9775904  0.99036145 0.99373496]
2022-01-19 03:11:18,308 - INFO - Epoch time: 446.68592739105225
2022-01-19 03:11:18,308 - INFO - 
Epoch: 84
2022-01-19 03:11:18,309 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:12:13,491 - INFO - [Step=70250]	Loss=0.4976	237.8 examples/second
2022-01-19 03:14:25,698 - INFO - [Step=70500]	Loss=0.4884	242.1 examples/second
2022-01-19 03:16:30,932 - INFO - [Step=70750]	Loss=0.4828	255.5 examples/second
2022-01-19 03:18:40,651 - INFO - Test Loss=0.8200, Test top-1 acc=0.8082
2022-01-19 03:18:40,652 - INFO - Group Accuracy:

2022-01-19 03:18:40,652 - INFO - [0.9816868  0.9927711  0.98722893 0.9918072  0.9838554  0.9939759
 0.97975904 0.9853012  0.98963857 0.9778313  0.9939759  0.98578316
 0.97590363 0.9809638  0.9775904  0.9898795  0.99421686]
2022-01-19 03:18:40,653 - INFO - Epoch time: 442.34464406967163
2022-01-19 03:18:40,653 - INFO - 
Epoch: 85
2022-01-19 03:18:40,653 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:18:57,600 - INFO - [Step=71000]	Loss=0.4894	218.2 examples/second
2022-01-19 03:21:00,487 - INFO - [Step=71250]	Loss=0.4860	260.4 examples/second
2022-01-19 03:23:02,066 - INFO - [Step=71500]	Loss=0.4793	263.2 examples/second
2022-01-19 03:25:06,683 - INFO - [Step=71750]	Loss=0.4902	256.8 examples/second
2022-01-19 03:25:51,145 - INFO - Test Loss=0.8275, Test top-1 acc=0.8089
2022-01-19 03:25:51,146 - INFO - Group Accuracy:

2022-01-19 03:25:51,146 - INFO - [0.9826506  0.993494   0.98698795 0.9930121  0.98433733 0.9946988
 0.9785542  0.98361444 0.9889157  0.9773494  0.993253   0.9860241
 0.97542167 0.9821687  0.9768675  0.98963857 0.9946988 ]
2022-01-19 03:25:51,147 - INFO - Epoch time: 430.4933557510376
2022-01-19 03:25:51,147 - INFO - 
Epoch: 86
2022-01-19 03:25:51,147 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:27:29,020 - INFO - [Step=72000]	Loss=0.4867	224.8 examples/second
2022-01-19 03:29:36,380 - INFO - [Step=72250]	Loss=0.4806	251.3 examples/second
2022-01-19 03:31:39,070 - INFO - [Step=72500]	Loss=0.4893	260.8 examples/second
2022-01-19 03:33:03,400 - INFO - Test Loss=0.8357, Test top-1 acc=0.8094
2022-01-19 03:33:03,400 - INFO - Group Accuracy:

2022-01-19 03:33:03,400 - INFO - [0.9826506  0.9925301  0.98674697 0.9920482  0.9848193  0.99373496
 0.97975904 0.98313254 0.98963857 0.9780723  0.9930121  0.98650604
 0.97590363 0.98313254 0.9771084  0.9891566  0.99493974]
2022-01-19 03:33:03,401 - INFO - Epoch time: 432.2544889450073
2022-01-19 03:33:03,401 - INFO - 
Epoch: 87
2022-01-19 03:33:03,401 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:33:59,501 - INFO - [Step=72750]	Loss=0.4835	227.9 examples/second
2022-01-19 03:35:58,480 - INFO - [Step=73000]	Loss=0.4967	269.0 examples/second
2022-01-19 03:38:01,628 - INFO - [Step=73250]	Loss=0.4845	259.9 examples/second
2022-01-19 03:39:59,016 - INFO - Test Loss=0.8265, Test top-1 acc=0.8089
2022-01-19 03:39:59,016 - INFO - Group Accuracy:

2022-01-19 03:39:59,016 - INFO - [0.98240966 0.9925301  0.98650604 0.9925301  0.9838554  0.99421686
 0.98       0.98433733 0.9898795  0.9775904  0.993494   0.98578316
 0.97638553 0.9816868  0.9775904  0.9901205  0.99421686]
2022-01-19 03:39:59,017 - INFO - Epoch time: 415.6160407066345
2022-01-19 03:39:59,017 - INFO - 
Epoch: 88
2022-01-19 03:39:59,017 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:40:10,917 - INFO - [Step=73500]	Loss=0.4821	247.5 examples/second
2022-01-19 03:42:11,889 - INFO - [Step=73750]	Loss=0.4722	264.5 examples/second
2022-01-19 03:44:19,107 - INFO - [Step=74000]	Loss=0.4824	251.5 examples/second
2022-01-19 03:46:23,055 - INFO - [Step=74250]	Loss=0.4861	258.2 examples/second
2022-01-19 03:47:08,267 - INFO - Test Loss=0.8274, Test top-1 acc=0.8118
2022-01-19 03:47:08,267 - INFO - Group Accuracy:

2022-01-19 03:47:08,267 - INFO - [0.9814458  0.9922892  0.98698795 0.9918072  0.98433733 0.99445784
 0.97927713 0.9845783  0.9901205  0.9778313  0.993253   0.98674697
 0.97614455 0.9821687  0.97831327 0.9893976  0.9939759 ]
2022-01-19 03:47:08,268 - INFO - Epoch time: 429.2508819103241
2022-01-19 03:47:08,268 - INFO - 
Epoch: 89
2022-01-19 03:47:08,268 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:48:44,300 - INFO - [Step=74500]	Loss=0.4791	226.6 examples/second
2022-01-19 03:50:46,906 - INFO - [Step=74750]	Loss=0.4734	261.0 examples/second
2022-01-19 03:52:52,343 - INFO - [Step=75000]	Loss=0.4895	255.1 examples/second
2022-01-19 03:54:16,658 - INFO - Test Loss=0.8408, Test top-1 acc=0.8099
2022-01-19 03:54:16,658 - INFO - Group Accuracy:

2022-01-19 03:54:16,658 - INFO - [0.98289156 0.9920482  0.98674697 0.9922892  0.98289156 0.9951807
 0.97927713 0.98433733 0.98963857 0.9773494  0.9927711  0.9860241
 0.9773494  0.9821687  0.97831327 0.9891566  0.99421686]
2022-01-19 03:54:16,659 - INFO - Epoch time: 428.39083099365234
2022-01-19 03:54:34,458 - INFO - Computing OOD Statistics...
2022-01-19 03:54:34,465 - INFO - 	Baseline.          AUROC: 0.3659. TNR@95TPR: 0.0235. AUPR OUT: 0.1290
2022-01-19 03:54:34,471 - INFO - 	ODIN (T=1000).     AUROC: 0.8905. TNR@95TPR: 0.4624. AUPR OUT: 0.6179
2022-01-19 03:54:34,471 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 03:54:34,472 - INFO - Top 1 Accuracy:  Min: 0.8118; Max: 0.8118; Avg: 0.8118; Std: 0.0000; Len: 1
2022-01-19 03:54:34,472 - INFO - Top 5 Accuracy:  Min: 0.9862; Max: 0.9862; Avg: 0.9862; Std: 0.0000; Len: 1
2022-01-19 03:54:34,472 - INFO - **********************************************************************
2022-01-19 03:54:34,472 - INFO - 	MSP (auroc): [0.36589510985116935] Min: 0.3659; Max: 0.3659; Avg: 0.3659; Std: 0.0000; Len: 1
2022-01-19 03:54:34,472 - INFO - 	MSP (tnr): [0.02352941176470591] Min: 0.0235; Max: 0.0235; Avg: 0.0235; Std: 0.0000; Len: 1
2022-01-19 03:54:34,472 - INFO - 	MSP (aupr): [0.12903148352791832] Min: 0.1290; Max: 0.1290; Avg: 0.1290; Std: 0.0000; Len: 1
2022-01-19 03:54:34,472 - INFO - 	ODIN (auroc): [0.8904955350815025] Min: 0.8905; Max: 0.8905; Avg: 0.8905; Std: 0.0000; Len: 1
2022-01-19 03:54:34,473 - INFO - 	ODIN (tnr): [0.46235294117647063] Min: 0.4624; Max: 0.4624; Avg: 0.4624; Std: 0.0000; Len: 1
2022-01-19 03:54:34,473 - INFO - 	ODIN (aupr): [0.6178964703202336] Min: 0.6179; Max: 0.6179; Avg: 0.6179; Std: 0.0000; Len: 1

2022-01-18 16:55:56,920 - INFO - ==> Preparing data..
2022-01-18 16:55:57,289 - INFO - checkpoint filename: experiments/coarse/mos/FC5_LRp1_R2/checkpoint.pt
2022-01-18 16:55:57,289 - INFO - log filename: experiments/coarse/mos/FC5_LRp1_R2/train.log
2022-01-18 16:55:57,289 - INFO - ********************************************************
2022-01-18 16:55:57,289 - INFO - Starting Iter: 0 / 1
2022-01-18 16:55:57,289 - INFO - ********************************************************
2022-01-18 16:56:00,446 - INFO - cuda
2022-01-18 16:56:00,485 - INFO - 
Epoch: 0
2022-01-18 16:56:00,485 - INFO - 
Learning Rate: 0.0100
2022-01-18 16:57:57,588 - INFO - [Step=250]	Loss=7.1480	273.3 examples/second
2022-01-18 16:59:53,107 - INFO - [Step=500]	Loss=5.4467	277.0 examples/second
2022-01-18 17:01:48,579 - INFO - [Step=750]	Loss=5.2799	277.1 examples/second
2022-01-18 17:02:34,805 - INFO - Test Loss=5.3629, Test top-1 acc=0.0475
2022-01-18 17:02:34,806 - INFO - Group Accuracy:

2022-01-18 17:02:34,806 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.9392771 0.9518072]
2022-01-18 17:02:34,807 - INFO - Saving...
2022-01-18 17:02:35,036 - INFO - Epoch time: 394.5507571697235
2022-01-18 17:02:35,036 - INFO - 
Epoch: 1
2022-01-18 17:02:35,036 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:03:52,741 - INFO - [Step=1000]	Loss=5.1759	257.7 examples/second
2022-01-18 17:05:48,418 - INFO - [Step=1250]	Loss=5.0137	276.6 examples/second
2022-01-18 17:07:44,188 - INFO - [Step=1500]	Loss=4.8497	276.4 examples/second
2022-01-18 17:09:09,922 - INFO - Test Loss=4.7969, Test top-1 acc=0.1072
2022-01-18 17:09:09,922 - INFO - Group Accuracy:

2022-01-18 17:09:09,922 - INFO - [0.939759   0.9392771  0.940241   0.94144577 0.939759   0.9404819
 0.939759   0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.93903613 0.9518072 ]
2022-01-18 17:09:09,923 - INFO - Saving...
2022-01-18 17:09:10,189 - INFO - Epoch time: 395.15311884880066
2022-01-18 17:09:10,189 - INFO - 
Epoch: 2
2022-01-18 17:09:10,190 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:09:48,886 - INFO - [Step=1750]	Loss=4.7259	256.6 examples/second
2022-01-18 17:11:44,587 - INFO - [Step=2000]	Loss=4.5587	276.6 examples/second
2022-01-18 17:13:40,306 - INFO - [Step=2250]	Loss=4.3592	276.5 examples/second
2022-01-18 17:15:35,787 - INFO - [Step=2500]	Loss=4.1746	277.1 examples/second
2022-01-18 17:15:44,946 - INFO - Test Loss=4.1039, Test top-1 acc=0.2289
2022-01-18 17:15:44,946 - INFO - Group Accuracy:

2022-01-18 17:15:44,946 - INFO - [0.94216865 0.94120485 0.9407229  0.9498795  0.94168675 0.9445783
 0.94240963 0.94144577 0.933494   0.93759036 0.9520482  0.94120485
 0.939759   0.93903613 0.939759   0.9431325  0.9539759 ]
2022-01-18 17:15:44,947 - INFO - Saving...
2022-01-18 17:15:45,218 - INFO - Epoch time: 395.0283737182617
2022-01-18 17:15:45,218 - INFO - 
Epoch: 3
2022-01-18 17:15:45,218 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:17:39,172 - INFO - [Step=2750]	Loss=4.0402	259.4 examples/second
2022-01-18 17:19:33,649 - INFO - [Step=3000]	Loss=3.8838	279.5 examples/second
2022-01-18 17:21:28,335 - INFO - [Step=3250]	Loss=3.7381	279.0 examples/second
2022-01-18 17:22:16,608 - INFO - Test Loss=3.3977, Test top-1 acc=0.3087
2022-01-18 17:22:16,608 - INFO - Group Accuracy:

2022-01-18 17:22:16,608 - INFO - [0.9448193  0.9510843  0.94096386 0.95662653 0.94289154 0.9621687
 0.9438554  0.9453012  0.94915664 0.9433735  0.9551807  0.94433737
 0.94120485 0.94096386 0.940241   0.9474699  0.9612048 ]
2022-01-18 17:22:16,609 - INFO - Saving...
2022-01-18 17:22:16,837 - INFO - Epoch time: 391.6191473007202
2022-01-18 17:22:16,837 - INFO - 
Epoch: 4
2022-01-18 17:22:16,838 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:23:31,891 - INFO - [Step=3500]	Loss=3.7043	259.0 examples/second
2022-01-18 17:25:26,298 - INFO - [Step=3750]	Loss=3.5644	279.7 examples/second
2022-01-18 17:27:20,749 - INFO - [Step=4000]	Loss=3.4827	279.6 examples/second
2022-01-18 17:28:48,045 - INFO - Test Loss=3.4567, Test top-1 acc=0.3359
2022-01-18 17:28:48,046 - INFO - Group Accuracy:

2022-01-18 17:28:48,046 - INFO - [0.9445783  0.95325303 0.94168675 0.9583132  0.94216865 0.96433735
 0.92963856 0.9520482  0.94891566 0.9438554  0.95277107 0.94289154
 0.94120485 0.9426506  0.94289154 0.94939756 0.9662651 ]
2022-01-18 17:28:48,047 - INFO - Saving...
2022-01-18 17:28:48,242 - INFO - Epoch time: 391.4045386314392
2022-01-18 17:28:48,242 - INFO - 
Epoch: 5
2022-01-18 17:28:48,242 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:29:24,679 - INFO - [Step=4250]	Loss=3.3710	258.2 examples/second
2022-01-18 17:31:20,357 - INFO - [Step=4500]	Loss=3.2031	276.6 examples/second
2022-01-18 17:33:16,244 - INFO - [Step=4750]	Loss=3.0555	276.1 examples/second
2022-01-18 17:35:12,301 - INFO - [Step=5000]	Loss=2.9887	275.7 examples/second
2022-01-18 17:35:24,106 - INFO - Test Loss=2.9838, Test top-1 acc=0.4048
2022-01-18 17:35:24,107 - INFO - Group Accuracy:

2022-01-18 17:35:24,107 - INFO - [0.9498795  0.9544578  0.9453012  0.9672289  0.946747   0.97108436
 0.9479518  0.94433737 0.9595181  0.9474699  0.95975906 0.94915664
 0.93903613 0.94216865 0.9477109  0.95277107 0.96819276]
2022-01-18 17:35:24,107 - INFO - Saving...
2022-01-18 17:35:24,352 - INFO - Epoch time: 396.1100583076477
2022-01-18 17:35:24,353 - INFO - 
Epoch: 6
2022-01-18 17:35:24,353 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:37:15,830 - INFO - [Step=5250]	Loss=2.8846	259.1 examples/second
2022-01-18 17:39:10,464 - INFO - [Step=5500]	Loss=2.8233	279.2 examples/second
2022-01-18 17:41:05,144 - INFO - [Step=5750]	Loss=2.7549	279.0 examples/second
2022-01-18 17:41:55,742 - INFO - Test Loss=3.0410, Test top-1 acc=0.4605
2022-01-18 17:41:55,742 - INFO - Group Accuracy:

2022-01-18 17:41:55,743 - INFO - [0.95325303 0.95662653 0.94915664 0.96843374 0.94506025 0.97542167
 0.94915664 0.9585542  0.9693976  0.95228916 0.95759034 0.95373493
 0.94289154 0.9460241  0.9479518  0.95421684 0.97156626]
2022-01-18 17:41:55,744 - INFO - Saving...
2022-01-18 17:41:55,998 - INFO - Epoch time: 391.6458377838135
2022-01-18 17:41:55,999 - INFO - 
Epoch: 7
2022-01-18 17:41:55,999 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:43:09,170 - INFO - [Step=6000]	Loss=2.6937	258.0 examples/second
2022-01-18 17:45:04,525 - INFO - [Step=6250]	Loss=2.6383	277.4 examples/second
2022-01-18 17:46:59,856 - INFO - [Step=6500]	Loss=2.6083	277.5 examples/second
2022-01-18 17:48:30,640 - INFO - Test Loss=2.5030, Test top-1 acc=0.4839
2022-01-18 17:48:30,640 - INFO - Group Accuracy:

2022-01-18 17:48:30,640 - INFO - [0.9559036  0.9559036  0.9510843  0.97493976 0.94554216 0.97638553
 0.95253015 0.9595181  0.9698795  0.9546988  0.96168673 0.95253015
 0.93807226 0.9479518  0.9448193  0.96168673 0.97903615]
2022-01-18 17:48:30,641 - INFO - Saving...
2022-01-18 17:48:30,814 - INFO - Epoch time: 394.8154399394989
2022-01-18 17:48:30,814 - INFO - 
Epoch: 8
2022-01-18 17:48:30,814 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:49:05,062 - INFO - [Step=6750]	Loss=2.5177	255.6 examples/second
2022-01-18 17:51:01,330 - INFO - [Step=7000]	Loss=2.4613	275.2 examples/second
2022-01-18 17:52:57,845 - INFO - [Step=7250]	Loss=2.4095	274.6 examples/second
2022-01-18 17:54:54,304 - INFO - [Step=7500]	Loss=2.3777	274.8 examples/second
2022-01-18 17:55:08,054 - INFO - Test Loss=2.3567, Test top-1 acc=0.5077
2022-01-18 17:55:08,055 - INFO - Group Accuracy:

2022-01-18 17:55:08,055 - INFO - [0.95566267 0.9587952  0.95301205 0.9746988  0.95253015 0.9766265
 0.9544578  0.9585542  0.96795183 0.95349395 0.9657831  0.95638555
 0.9469879  0.94939756 0.9481928  0.9624096  0.97951806]
2022-01-18 17:55:08,055 - INFO - Saving...
2022-01-18 17:55:08,318 - INFO - Epoch time: 397.5030987262726
2022-01-18 17:55:08,318 - INFO - 
Epoch: 9
2022-01-18 17:55:08,318 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:56:58,904 - INFO - [Step=7750]	Loss=2.2927	256.8 examples/second
2022-01-18 17:58:54,236 - INFO - [Step=8000]	Loss=2.2695	277.5 examples/second
2022-01-18 18:00:49,713 - INFO - [Step=8250]	Loss=2.2324	277.1 examples/second
2022-01-18 18:01:42,877 - INFO - Test Loss=2.0603, Test top-1 acc=0.5605
2022-01-18 18:01:42,878 - INFO - Group Accuracy:

2022-01-18 18:01:42,878 - INFO - [0.9595181  0.9653012  0.9619277  0.9778313  0.9580723  0.9826506
 0.95349395 0.96096385 0.97638553 0.96       0.9653012  0.9626506
 0.9474699  0.9469879  0.9549398  0.9655422  0.9785542 ]
2022-01-18 18:01:42,878 - INFO - Saving...
2022-01-18 18:01:43,116 - INFO - Epoch time: 394.7984733581543
2022-01-18 18:01:43,116 - INFO - 
Epoch: 10
2022-01-18 18:01:43,117 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:02:53,741 - INFO - [Step=8500]	Loss=2.1863	258.0 examples/second
2022-01-18 18:04:48,159 - INFO - [Step=8750]	Loss=2.1753	279.7 examples/second
2022-01-18 18:06:42,804 - INFO - [Step=9000]	Loss=2.1307	279.1 examples/second
2022-01-18 18:08:14,673 - INFO - Test Loss=2.1940, Test top-1 acc=0.5402
2022-01-18 18:08:14,673 - INFO - Group Accuracy:

2022-01-18 18:08:14,673 - INFO - [0.95710844 0.9655422  0.9544578  0.9785542  0.9624096  0.9787952
 0.9510843  0.95975906 0.9674699  0.95975906 0.9713253  0.96072286
 0.95036143 0.94915664 0.95036143 0.9657831  0.98024094]
2022-01-18 18:08:14,674 - INFO - Epoch time: 391.5574903488159
2022-01-18 18:08:14,674 - INFO - 
Epoch: 11
2022-01-18 18:08:14,674 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:08:46,339 - INFO - [Step=9250]	Loss=2.1018	259.0 examples/second
2022-01-18 18:10:41,827 - INFO - [Step=9500]	Loss=2.0507	277.1 examples/second
2022-01-18 18:12:37,366 - INFO - [Step=9750]	Loss=2.0426	277.0 examples/second
2022-01-18 18:14:33,130 - INFO - [Step=10000]	Loss=2.0239	276.4 examples/second
2022-01-18 18:14:49,240 - INFO - Test Loss=1.9414, Test top-1 acc=0.5812
2022-01-18 18:14:49,241 - INFO - Group Accuracy:

2022-01-18 18:14:49,241 - INFO - [0.9587952  0.96698797 0.9624096  0.9775904  0.9653012  0.98433733
 0.9539759  0.96433735 0.9725301  0.96481925 0.97108436 0.9619277
 0.9515663  0.9544578  0.9578313  0.96795183 0.9850602 ]
2022-01-18 18:14:49,242 - INFO - Saving...
2022-01-18 18:14:49,488 - INFO - Epoch time: 394.81387639045715
2022-01-18 18:14:49,488 - INFO - 
Epoch: 12
2022-01-18 18:14:49,488 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:16:37,583 - INFO - [Step=10250]	Loss=1.9769	257.1 examples/second
2022-01-18 18:18:33,496 - INFO - [Step=10500]	Loss=1.9507	276.1 examples/second
2022-01-18 18:20:29,506 - INFO - [Step=10750]	Loss=1.9373	275.8 examples/second
2022-01-18 18:21:25,125 - INFO - Test Loss=2.0367, Test top-1 acc=0.5552
2022-01-18 18:21:25,125 - INFO - Group Accuracy:

2022-01-18 18:21:25,125 - INFO - [0.96024096 0.9698795  0.9561446  0.9819277  0.9592771  0.9833735
 0.9612048  0.95759034 0.9768675  0.9628916  0.96481925 0.9580723
 0.9498795  0.9448193  0.9508434  0.966747   0.9778313 ]
2022-01-18 18:21:25,126 - INFO - Epoch time: 395.6380205154419
2022-01-18 18:21:25,126 - INFO - 
Epoch: 13
2022-01-18 18:21:25,126 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:22:33,494 - INFO - [Step=11000]	Loss=1.9036	258.1 examples/second
2022-01-18 18:24:28,749 - INFO - [Step=11250]	Loss=1.8729	277.6 examples/second
2022-01-18 18:26:24,101 - INFO - [Step=11500]	Loss=1.8731	277.4 examples/second
2022-01-18 18:27:58,962 - INFO - Test Loss=2.1442, Test top-1 acc=0.5677
2022-01-18 18:27:58,962 - INFO - Group Accuracy:

2022-01-18 18:27:58,962 - INFO - [0.95975906 0.9725301  0.9633735  0.9773494  0.9633735  0.98433733
 0.9578313  0.9436145  0.97301203 0.96457833 0.9624096  0.9580723
 0.95253015 0.94963855 0.9580723  0.9672289  0.98240966]
2022-01-18 18:27:58,963 - INFO - Epoch time: 393.83640599250793
2022-01-18 18:27:58,963 - INFO - 
Epoch: 14
2022-01-18 18:27:58,963 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:28:28,266 - INFO - [Step=11750]	Loss=1.8739	257.7 examples/second
2022-01-18 18:30:22,800 - INFO - [Step=12000]	Loss=1.8216	279.4 examples/second
2022-01-18 18:32:17,449 - INFO - [Step=12250]	Loss=1.8025	279.1 examples/second
2022-01-18 18:34:12,256 - INFO - [Step=12500]	Loss=1.7991	278.7 examples/second
2022-01-18 18:34:30,655 - INFO - Test Loss=1.8486, Test top-1 acc=0.5976
2022-01-18 18:34:30,655 - INFO - Group Accuracy:

2022-01-18 18:34:30,655 - INFO - [0.9626506  0.9773494  0.9628916  0.9768675  0.9612048  0.98361444
 0.9612048  0.9660241  0.97951806 0.9653012  0.9727711  0.96771085
 0.9385542  0.95349395 0.9554217  0.9742169  0.9840964 ]
2022-01-18 18:34:30,657 - INFO - Saving...
2022-01-18 18:34:30,923 - INFO - Epoch time: 391.9600739479065
2022-01-18 18:34:30,923 - INFO - 
Epoch: 15
2022-01-18 18:34:30,923 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:36:16,769 - INFO - [Step=12750]	Loss=1.7618	257.0 examples/second
2022-01-18 18:38:12,249 - INFO - [Step=13000]	Loss=1.7477	277.1 examples/second
2022-01-18 18:40:08,190 - INFO - [Step=13250]	Loss=1.7520	276.0 examples/second
2022-01-18 18:41:06,099 - INFO - Test Loss=1.7657, Test top-1 acc=0.6255
2022-01-18 18:41:06,099 - INFO - Group Accuracy:

2022-01-18 18:41:06,099 - INFO - [0.9653012  0.9619277  0.9583132  0.98289156 0.96843374 0.98698795
 0.9554217  0.96891564 0.9812048  0.9660241  0.9780723  0.9703615
 0.96       0.96168673 0.9583132  0.9727711  0.98722893]
2022-01-18 18:41:06,100 - INFO - Saving...
2022-01-18 18:41:06,367 - INFO - Epoch time: 395.44373631477356
2022-01-18 18:41:06,367 - INFO - 
Epoch: 16
2022-01-18 18:41:06,367 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:42:12,300 - INFO - [Step=13500]	Loss=1.7205	257.8 examples/second
2022-01-18 18:44:08,794 - INFO - [Step=13750]	Loss=1.7041	274.7 examples/second
2022-01-18 18:46:05,635 - INFO - [Step=14000]	Loss=1.6977	273.9 examples/second
2022-01-18 18:47:44,014 - INFO - Test Loss=2.6503, Test top-1 acc=0.5940
2022-01-18 18:47:44,014 - INFO - Group Accuracy:

2022-01-18 18:47:44,014 - INFO - [0.9631325  0.9725301  0.9619277  0.97951806 0.9612048  0.9778313
 0.9621687  0.966506   0.9816868  0.96771085 0.97445786 0.96698797
 0.95373493 0.9551807  0.9551807  0.966506   0.9840964 ]
2022-01-18 18:47:44,015 - INFO - Epoch time: 397.64781618118286
2022-01-18 18:47:44,015 - INFO - 
Epoch: 17
2022-01-18 18:47:44,015 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:48:11,558 - INFO - [Step=14250]	Loss=1.6833	254.1 examples/second
2022-01-18 18:50:07,802 - INFO - [Step=14500]	Loss=1.6420	275.3 examples/second
2022-01-18 18:52:04,148 - INFO - [Step=14750]	Loss=1.6500	275.0 examples/second
2022-01-18 18:54:00,535 - INFO - [Step=15000]	Loss=1.6369	274.9 examples/second
2022-01-18 18:54:21,516 - INFO - Test Loss=1.7537, Test top-1 acc=0.6137
2022-01-18 18:54:21,516 - INFO - Group Accuracy:

2022-01-18 18:54:21,517 - INFO - [0.9631325  0.97566265 0.9653012  0.98289156 0.96506023 0.9816868
 0.9628916  0.9693976  0.96795183 0.9696385  0.9746988  0.9686747
 0.9551807  0.9549398  0.96       0.973494   0.98722893]
2022-01-18 18:54:21,518 - INFO - Epoch time: 397.50289845466614
2022-01-18 18:54:21,518 - INFO - 
Epoch: 18
2022-01-18 18:54:21,518 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:56:05,539 - INFO - [Step=15250]	Loss=1.5844	256.0 examples/second
2022-01-18 18:58:01,855 - INFO - [Step=15500]	Loss=1.6109	275.1 examples/second
2022-01-18 18:59:58,354 - INFO - [Step=15750]	Loss=1.6000	274.7 examples/second
2022-01-18 19:00:58,976 - INFO - Test Loss=1.8456, Test top-1 acc=0.6113
2022-01-18 19:00:58,976 - INFO - Group Accuracy:

2022-01-18 19:00:58,976 - INFO - [0.966747   0.97518075 0.9672289  0.9773494  0.96385545 0.98698795
 0.9626506  0.94915664 0.97493976 0.9653012  0.9737349  0.9628916
 0.9583132  0.9595181  0.9612048  0.9725301  0.9884337 ]
2022-01-18 19:00:58,977 - INFO - Epoch time: 397.45946311950684
2022-01-18 19:00:58,978 - INFO - 
Epoch: 19
2022-01-18 19:00:58,978 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:02:03,631 - INFO - [Step=16000]	Loss=1.5985	255.4 examples/second
2022-01-18 19:03:59,947 - INFO - [Step=16250]	Loss=1.5699	275.1 examples/second
2022-01-18 19:05:55,677 - INFO - [Step=16500]	Loss=1.5716	276.5 examples/second
2022-01-18 19:07:35,225 - INFO - Test Loss=2.0132, Test top-1 acc=0.5978
2022-01-18 19:07:35,226 - INFO - Group Accuracy:

2022-01-18 19:07:35,226 - INFO - [0.96506023 0.973253   0.9551807  0.9742169  0.96843374 0.9845783
 0.95301205 0.966747   0.97831327 0.9510843  0.9727711  0.9674699
 0.9549398  0.9580723  0.9592771  0.9691566  0.9855422 ]
2022-01-18 19:07:35,226 - INFO - Epoch time: 396.2488462924957
2022-01-18 19:07:35,226 - INFO - 
Epoch: 20
2022-01-18 19:07:35,226 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:07:59,858 - INFO - [Step=16750]	Loss=1.5567	257.7 examples/second
2022-01-18 19:09:54,374 - INFO - [Step=17000]	Loss=1.5465	279.4 examples/second
2022-01-18 19:11:49,080 - INFO - [Step=17250]	Loss=1.5394	279.0 examples/second
2022-01-18 19:13:43,870 - INFO - [Step=17500]	Loss=1.5430	278.8 examples/second
2022-01-18 19:14:06,802 - INFO - Test Loss=1.6405, Test top-1 acc=0.6480
2022-01-18 19:14:06,802 - INFO - Group Accuracy:

2022-01-18 19:14:06,802 - INFO - [0.9686747  0.97638553 0.973253   0.98240966 0.97108436 0.9860241
 0.9655422  0.96409637 0.97566265 0.966747   0.97518075 0.97108436
 0.96433735 0.96048194 0.95975906 0.96385545 0.9893976 ]
2022-01-18 19:14:06,803 - INFO - Saving...
2022-01-18 19:14:06,981 - INFO - Epoch time: 391.754114151001
2022-01-18 19:14:06,981 - INFO - 
Epoch: 21
2022-01-18 19:14:06,981 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:15:47,344 - INFO - [Step=17750]	Loss=1.5034	259.2 examples/second
2022-01-18 19:17:42,086 - INFO - [Step=18000]	Loss=1.5175	278.9 examples/second
2022-01-18 19:19:36,930 - INFO - [Step=18250]	Loss=1.5127	278.6 examples/second
2022-01-18 19:20:38,924 - INFO - Test Loss=1.6248, Test top-1 acc=0.6429
2022-01-18 19:20:38,925 - INFO - Group Accuracy:

2022-01-18 19:20:38,925 - INFO - [0.96771085 0.9768675  0.9693976  0.98674697 0.9691566  0.98626506
 0.96168673 0.9706024  0.973253   0.9631325  0.97493976 0.9686747
 0.9624096  0.96168673 0.95975906 0.9706024  0.9893976 ]
2022-01-18 19:20:38,926 - INFO - Epoch time: 391.9447841644287
2022-01-18 19:20:38,926 - INFO - 
Epoch: 22
2022-01-18 19:20:38,926 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:21:40,338 - INFO - [Step=18500]	Loss=1.4774	259.3 examples/second
2022-01-18 19:23:34,683 - INFO - [Step=18750]	Loss=1.4853	279.9 examples/second
2022-01-18 19:25:29,123 - INFO - [Step=19000]	Loss=1.4993	279.6 examples/second
2022-01-18 19:27:10,029 - INFO - Test Loss=1.7336, Test top-1 acc=0.6337
2022-01-18 19:27:10,029 - INFO - Group Accuracy:

2022-01-18 19:27:10,029 - INFO - [0.9592771  0.9768675  0.9633735  0.97156626 0.9693976  0.98746985
 0.9662651  0.9657831  0.9804819  0.96506023 0.9739759  0.9703615
 0.96361446 0.9624096  0.9578313  0.97566265 0.9901205 ]
2022-01-18 19:27:10,030 - INFO - Epoch time: 391.10487031936646
2022-01-18 19:27:10,031 - INFO - 
Epoch: 23
2022-01-18 19:27:10,031 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:27:32,402 - INFO - [Step=19250]	Loss=1.4865	259.6 examples/second
2022-01-18 19:29:28,073 - INFO - [Step=19500]	Loss=1.4614	276.6 examples/second
2022-01-18 19:31:24,111 - INFO - [Step=19750]	Loss=1.4853	275.8 examples/second
2022-01-18 19:33:19,944 - INFO - [Step=20000]	Loss=1.4645	276.3 examples/second
2022-01-18 19:33:45,327 - INFO - Test Loss=1.4684, Test top-1 acc=0.6740
2022-01-18 19:33:45,327 - INFO - Group Accuracy:

2022-01-18 19:33:45,327 - INFO - [0.9590362  0.9821687  0.9701205  0.98746985 0.9713253  0.98963857
 0.9725301  0.97614455 0.9746988  0.9693976  0.9816868  0.97518075
 0.9621687  0.96024096 0.966747   0.97638553 0.9855422 ]
2022-01-18 19:33:45,328 - INFO - Saving...
2022-01-18 19:33:45,596 - INFO - Epoch time: 395.5656032562256
2022-01-18 19:33:45,596 - INFO - 
Epoch: 24
2022-01-18 19:33:45,596 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:35:24,131 - INFO - [Step=20250]	Loss=1.4264	257.7 examples/second
2022-01-18 19:37:19,649 - INFO - [Step=20500]	Loss=1.4497	277.0 examples/second
2022-01-18 19:39:15,348 - INFO - [Step=20750]	Loss=1.4587	276.6 examples/second
2022-01-18 19:40:20,118 - INFO - Test Loss=1.4012, Test top-1 acc=0.6911
2022-01-18 19:40:20,118 - INFO - Group Accuracy:

2022-01-18 19:40:20,119 - INFO - [0.9701205  0.9775904  0.9737349  0.9848193  0.97180724 0.98771083
 0.9686747  0.97542167 0.98578316 0.9686747  0.98240966 0.9713253
 0.9655422  0.966747   0.9653012  0.9766265  0.9881928 ]
2022-01-18 19:40:20,120 - INFO - Saving...
2022-01-18 19:40:20,373 - INFO - Epoch time: 394.77659010887146
2022-01-18 19:40:20,373 - INFO - 
Epoch: 25
2022-01-18 19:40:20,373 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:41:19,952 - INFO - [Step=21000]	Loss=1.4196	256.8 examples/second
2022-01-18 19:43:15,789 - INFO - [Step=21250]	Loss=1.4321	276.3 examples/second
2022-01-18 19:45:11,686 - INFO - [Step=21500]	Loss=1.4361	276.1 examples/second
2022-01-18 19:46:56,007 - INFO - Test Loss=1.4506, Test top-1 acc=0.6798
2022-01-18 19:46:56,007 - INFO - Group Accuracy:

2022-01-18 19:46:56,007 - INFO - [0.96771085 0.9746988  0.9725301  0.9845783  0.9706024  0.9893976
 0.96409637 0.97493976 0.98240966 0.9713253  0.9809638  0.97493976
 0.9614458  0.96457833 0.9657831  0.9775904  0.99156624]
2022-01-18 19:46:56,008 - INFO - Epoch time: 395.63480949401855
2022-01-18 19:46:56,008 - INFO - 
Epoch: 26
2022-01-18 19:46:56,008 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:47:15,800 - INFO - [Step=21750]	Loss=1.4367	257.8 examples/second
2022-01-18 19:49:10,089 - INFO - [Step=22000]	Loss=1.3747	280.0 examples/second
2022-01-18 19:51:04,371 - INFO - [Step=22250]	Loss=1.4117	280.0 examples/second
2022-01-18 19:52:58,944 - INFO - [Step=22500]	Loss=1.4215	279.3 examples/second
2022-01-18 19:53:26,524 - INFO - Test Loss=1.4940, Test top-1 acc=0.6747
2022-01-18 19:53:26,525 - INFO - Group Accuracy:

2022-01-18 19:53:26,525 - INFO - [0.9701205  0.9775904  0.9725301  0.9853012  0.96506023 0.9901205
 0.9706024  0.9737349  0.9773494  0.97108436 0.9821687  0.9742169
 0.95975906 0.9628916  0.96385545 0.9775904  0.99084336]
2022-01-18 19:53:26,526 - INFO - Epoch time: 390.51767110824585
2022-01-18 19:53:26,526 - INFO - 
Epoch: 27
2022-01-18 19:53:26,526 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:55:02,901 - INFO - [Step=22750]	Loss=1.3655	258.2 examples/second
2022-01-18 19:56:58,447 - INFO - [Step=23000]	Loss=1.3796	276.9 examples/second
2022-01-18 19:58:54,103 - INFO - [Step=23250]	Loss=1.4158	276.7 examples/second
2022-01-18 20:00:01,585 - INFO - Test Loss=1.8439, Test top-1 acc=0.6407
2022-01-18 20:00:01,586 - INFO - Group Accuracy:

2022-01-18 20:00:01,586 - INFO - [0.9628916  0.97445786 0.96481925 0.9848193  0.9706024  0.98361444
 0.9686747  0.9696385  0.9814458  0.9633735  0.9739759  0.9701205
 0.9587952  0.9626506  0.9619277  0.9713253  0.9860241 ]
2022-01-18 20:00:01,587 - INFO - Epoch time: 395.06055521965027
2022-01-18 20:00:01,587 - INFO - 
Epoch: 28
2022-01-18 20:00:01,587 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:00:58,352 - INFO - [Step=23500]	Loss=1.3834	257.5 examples/second
2022-01-18 20:02:52,662 - INFO - [Step=23750]	Loss=1.3663	279.9 examples/second
2022-01-18 20:04:47,116 - INFO - [Step=24000]	Loss=1.3818	279.6 examples/second
2022-01-18 20:06:32,579 - INFO - Test Loss=1.3056, Test top-1 acc=0.7034
2022-01-18 20:06:32,579 - INFO - Group Accuracy:

2022-01-18 20:06:32,579 - INFO - [0.9708434  0.97975904 0.97445786 0.98674697 0.97590363 0.99060243
 0.97542167 0.97638553 0.98722893 0.9713253  0.9807229  0.97566265
 0.9595181  0.9660241  0.966506   0.9778313  0.98963857]
2022-01-18 20:06:32,580 - INFO - Saving...
2022-01-18 20:06:32,839 - INFO - Epoch time: 391.25250911712646
2022-01-18 20:06:32,839 - INFO - 
Epoch: 29
2022-01-18 20:06:32,839 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:06:50,783 - INFO - [Step=24250]	Loss=1.3558	258.8 examples/second
2022-01-18 20:08:45,286 - INFO - [Step=24500]	Loss=1.0822	279.5 examples/second
2022-01-18 20:10:39,739 - INFO - [Step=24750]	Loss=1.0042	279.6 examples/second
2022-01-18 20:12:34,543 - INFO - [Step=25000]	Loss=0.9826	278.7 examples/second
2022-01-18 20:13:04,235 - INFO - Test Loss=0.9009, Test top-1 acc=0.7800
2022-01-18 20:13:04,235 - INFO - Group Accuracy:

2022-01-18 20:13:04,235 - INFO - [0.97638553 0.9879518  0.98361444 0.99156624 0.9826506  0.99373496
 0.9787952  0.98240966 0.9891566  0.97542167 0.9886747  0.98313254
 0.9742169  0.97831327 0.97518075 0.9853012  0.99445784]
2022-01-18 20:13:04,236 - INFO - Saving...
2022-01-18 20:13:04,471 - INFO - Epoch time: 391.6313142776489
2022-01-18 20:13:04,471 - INFO - 
Epoch: 30
2022-01-18 20:13:04,471 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:14:38,778 - INFO - [Step=25250]	Loss=0.9412	257.6 examples/second
2022-01-18 20:16:34,609 - INFO - [Step=25500]	Loss=0.9241	276.3 examples/second
2022-01-18 20:18:30,486 - INFO - [Step=25750]	Loss=0.9184	276.2 examples/second
2022-01-18 20:19:39,941 - INFO - Test Loss=0.8671, Test top-1 acc=0.7863
2022-01-18 20:19:39,941 - INFO - Group Accuracy:

2022-01-18 20:19:39,941 - INFO - [0.97927713 0.9881928  0.9855422  0.9922892  0.9816868  0.9939759
 0.98024094 0.9816868  0.9898795  0.97614455 0.9891566  0.9840964
 0.9771084  0.97638553 0.97445786 0.98674697 0.99421686]
2022-01-18 20:19:39,942 - INFO - Saving...
2022-01-18 20:19:40,199 - INFO - Epoch time: 395.7280969619751
2022-01-18 20:19:40,199 - INFO - 
Epoch: 31
2022-01-18 20:19:40,199 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:20:34,693 - INFO - [Step=26000]	Loss=0.9256	257.6 examples/second
2022-01-18 20:22:29,685 - INFO - [Step=26250]	Loss=0.8900	278.3 examples/second
2022-01-18 20:24:24,628 - INFO - [Step=26500]	Loss=0.8799	278.4 examples/second
2022-01-18 20:26:13,026 - INFO - Test Loss=0.8545, Test top-1 acc=0.7940
2022-01-18 20:26:13,027 - INFO - Group Accuracy:

2022-01-18 20:26:13,027 - INFO - [0.97903615 0.9891566  0.9845783  0.9922892  0.98361444 0.99373496
 0.9812048  0.98361444 0.9901205  0.9780723  0.98963857 0.98361444
 0.97590363 0.98       0.9766265  0.9860241  0.9951807 ]
2022-01-18 20:26:13,028 - INFO - Saving...
2022-01-18 20:26:13,270 - INFO - Epoch time: 393.0707609653473
2022-01-18 20:26:13,270 - INFO - 
Epoch: 32
2022-01-18 20:26:13,270 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:26:28,565 - INFO - [Step=26750]	Loss=0.8875	258.2 examples/second
2022-01-18 20:28:24,127 - INFO - [Step=27000]	Loss=0.8621	276.9 examples/second
2022-01-18 20:30:19,560 - INFO - [Step=27250]	Loss=0.8712	277.2 examples/second
2022-01-18 20:32:15,084 - INFO - [Step=27500]	Loss=0.8633	277.0 examples/second
2022-01-18 20:32:47,558 - INFO - Test Loss=0.8580, Test top-1 acc=0.7899
2022-01-18 20:32:47,558 - INFO - Group Accuracy:

2022-01-18 20:32:47,558 - INFO - [0.9785542  0.9893976  0.98433733 0.9922892  0.98289156 0.99445784
 0.9807229  0.98240966 0.99060243 0.97614455 0.9889157  0.9845783
 0.9771084  0.98       0.97493976 0.9853012  0.9954217 ]
2022-01-18 20:32:47,559 - INFO - Epoch time: 394.2888283729553
2022-01-18 20:32:47,559 - INFO - 
Epoch: 33
2022-01-18 20:32:47,559 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:34:19,083 - INFO - [Step=27750]	Loss=0.8473	258.1 examples/second
2022-01-18 20:36:13,948 - INFO - [Step=28000]	Loss=0.8573	278.6 examples/second
2022-01-18 20:38:08,980 - INFO - [Step=28250]	Loss=0.8324	278.2 examples/second
2022-01-18 20:39:20,252 - INFO - Test Loss=0.8339, Test top-1 acc=0.7933
2022-01-18 20:39:20,252 - INFO - Group Accuracy:

2022-01-18 20:39:20,252 - INFO - [0.9787952  0.98963857 0.9850602  0.9927711  0.98240966 0.9946988
 0.9814458  0.98361444 0.99036145 0.97590363 0.98963857 0.9845783
 0.97566265 0.9809638  0.97614455 0.98578316 0.99421686]
2022-01-18 20:39:20,253 - INFO - Epoch time: 392.6943805217743
2022-01-18 20:39:20,253 - INFO - 
Epoch: 34
2022-01-18 20:39:20,254 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:40:12,424 - INFO - [Step=28500]	Loss=0.8509	259.2 examples/second
2022-01-18 20:42:06,915 - INFO - [Step=28750]	Loss=0.8540	279.5 examples/second
2022-01-18 20:44:01,273 - INFO - [Step=29000]	Loss=0.8256	279.8 examples/second
2022-01-18 20:45:51,326 - INFO - Test Loss=0.8361, Test top-1 acc=0.7916
2022-01-18 20:45:51,326 - INFO - Group Accuracy:

2022-01-18 20:45:51,326 - INFO - [0.97951806 0.9889157  0.9850602  0.9922892  0.9812048  0.9946988
 0.9812048  0.98240966 0.99036145 0.97638553 0.98963857 0.98433733
 0.97566265 0.97975904 0.97566265 0.9881928  0.9951807 ]
2022-01-18 20:45:51,327 - INFO - Epoch time: 391.07386922836304
2022-01-18 20:45:51,327 - INFO - 
Epoch: 35
2022-01-18 20:45:51,328 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:46:04,451 - INFO - [Step=29250]	Loss=0.8312	259.8 examples/second
2022-01-18 20:48:00,040 - INFO - [Step=29500]	Loss=0.8289	276.8 examples/second
2022-01-18 20:49:55,809 - INFO - [Step=29750]	Loss=0.8351	276.4 examples/second
2022-01-18 20:51:51,589 - INFO - [Step=30000]	Loss=0.8206	276.4 examples/second
2022-01-18 20:52:26,327 - INFO - Test Loss=0.8297, Test top-1 acc=0.7959
2022-01-18 20:52:26,327 - INFO - Group Accuracy:

2022-01-18 20:52:26,328 - INFO - [0.97951806 0.9884337  0.98626506 0.9927711  0.98433733 0.9946988
 0.9819277  0.9821687  0.9901205  0.97542167 0.9891566  0.9840964
 0.9773494  0.9809638  0.97590363 0.98722893 0.99493974]
2022-01-18 20:52:26,329 - INFO - Saving...
2022-01-18 20:52:26,594 - INFO - Epoch time: 395.2665388584137
2022-01-18 20:52:26,594 - INFO - 
Epoch: 36
2022-01-18 20:52:26,594 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:53:55,811 - INFO - [Step=30250]	Loss=0.7955	257.6 examples/second
2022-01-18 20:55:51,182 - INFO - [Step=30500]	Loss=0.8079	277.4 examples/second
2022-01-18 20:57:46,701 - INFO - [Step=30750]	Loss=0.8066	277.0 examples/second
2022-01-18 20:59:00,766 - INFO - Test Loss=0.8340, Test top-1 acc=0.7973
2022-01-18 20:59:00,766 - INFO - Group Accuracy:

2022-01-18 20:59:00,766 - INFO - [0.9787952  0.99060243 0.98578316 0.9913253  0.9812048  0.99445784
 0.9814458  0.9826506  0.99084336 0.9766265  0.99108434 0.98433733
 0.97638553 0.9807229  0.97566265 0.98698795 0.9954217 ]
2022-01-18 20:59:00,767 - INFO - Saving...
2022-01-18 20:59:01,039 - INFO - Epoch time: 394.4447319507599
2022-01-18 20:59:01,039 - INFO - 
Epoch: 37
2022-01-18 20:59:01,039 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:59:51,657 - INFO - [Step=31000]	Loss=0.7995	256.1 examples/second
2022-01-18 21:01:47,417 - INFO - [Step=31250]	Loss=0.7962	276.4 examples/second
2022-01-18 21:03:42,935 - INFO - [Step=31500]	Loss=0.8090	277.0 examples/second
2022-01-18 21:05:36,464 - INFO - Test Loss=0.8237, Test top-1 acc=0.7998
2022-01-18 21:05:36,465 - INFO - Group Accuracy:

2022-01-18 21:05:36,465 - INFO - [0.9804819  0.9901205  0.9855422  0.9920482  0.98361444 0.9946988
 0.9819277  0.98289156 0.99084336 0.9768675  0.99084336 0.9845783
 0.9785542  0.9804819  0.9766265  0.98626506 0.99421686]
2022-01-18 21:05:36,465 - INFO - Saving...
2022-01-18 21:05:36,720 - INFO - Epoch time: 395.680504322052
2022-01-18 21:05:36,720 - INFO - 
Epoch: 38
2022-01-18 21:05:36,720 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:05:47,737 - INFO - [Step=31750]	Loss=0.7766	256.4 examples/second
2022-01-18 21:07:43,735 - INFO - [Step=32000]	Loss=0.7723	275.9 examples/second
2022-01-18 21:09:39,556 - INFO - [Step=32250]	Loss=0.7849	276.3 examples/second
2022-01-18 21:11:35,360 - INFO - [Step=32500]	Loss=0.7864	276.3 examples/second
2022-01-18 21:12:12,419 - INFO - Test Loss=0.8312, Test top-1 acc=0.7998
2022-01-18 21:12:12,420 - INFO - Group Accuracy:

2022-01-18 21:12:12,420 - INFO - [0.9778313  0.9889157  0.9848193  0.99084336 0.98313254 0.99445784
 0.98240966 0.9845783  0.9893976  0.97638553 0.9901205  0.9848193
 0.9766265  0.9812048  0.9778313  0.98626506 0.9959036 ]
2022-01-18 21:12:12,421 - INFO - Epoch time: 395.7011606693268
2022-01-18 21:12:12,421 - INFO - 
Epoch: 39
2022-01-18 21:12:12,421 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:13:39,335 - INFO - [Step=32750]	Loss=0.7778	258.1 examples/second
2022-01-18 21:15:35,549 - INFO - [Step=33000]	Loss=0.7647	275.4 examples/second
2022-01-18 21:17:32,577 - INFO - [Step=33250]	Loss=0.7580	273.4 examples/second
2022-01-18 21:18:49,914 - INFO - Test Loss=0.8101, Test top-1 acc=0.7993
2022-01-18 21:18:49,914 - INFO - Group Accuracy:

2022-01-18 21:18:49,914 - INFO - [0.9787952  0.98963857 0.9860241  0.993253   0.9814458  0.9951807
 0.9819277  0.9850602  0.98963857 0.97566265 0.9918072  0.9850602
 0.97638553 0.97951806 0.97638553 0.98650604 0.9954217 ]
2022-01-18 21:18:49,915 - INFO - Epoch time: 397.49385380744934
2022-01-18 21:18:49,915 - INFO - 
Epoch: 40
2022-01-18 21:18:49,915 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:19:38,314 - INFO - [Step=33500]	Loss=0.7729	254.5 examples/second
2022-01-18 21:21:34,770 - INFO - [Step=33750]	Loss=0.7416	274.8 examples/second
2022-01-18 21:23:31,349 - INFO - [Step=34000]	Loss=0.7722	274.5 examples/second
2022-01-18 21:25:28,236 - INFO - Test Loss=0.8155, Test top-1 acc=0.8014
2022-01-18 21:25:28,236 - INFO - Group Accuracy:

2022-01-18 21:25:28,236 - INFO - [0.9809638  0.9901205  0.98674697 0.9930121  0.98240966 0.9951807
 0.9826506  0.9838554  0.99036145 0.97566265 0.9901205  0.9853012
 0.97614455 0.9814458  0.97590363 0.98722893 0.9951807 ]
2022-01-18 21:25:28,237 - INFO - Saving...
2022-01-18 21:25:28,469 - INFO - Epoch time: 398.55372285842896
2022-01-18 21:25:28,469 - INFO - 
Epoch: 41
2022-01-18 21:25:28,469 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:25:37,166 - INFO - [Step=34250]	Loss=0.7769	254.3 examples/second
2022-01-18 21:27:33,833 - INFO - [Step=34500]	Loss=0.7515	274.3 examples/second
2022-01-18 21:29:30,445 - INFO - [Step=34750]	Loss=0.7507	274.4 examples/second
2022-01-18 21:31:27,185 - INFO - [Step=35000]	Loss=0.7548	274.1 examples/second
2022-01-18 21:32:07,065 - INFO - Test Loss=0.8161, Test top-1 acc=0.8014
2022-01-18 21:32:07,066 - INFO - Group Accuracy:

2022-01-18 21:32:07,066 - INFO - [0.9809638  0.9889157  0.9860241  0.9920482  0.9819277  0.9951807
 0.9814458  0.9853012  0.9898795  0.9771084  0.98963857 0.9855422
 0.9775904  0.9816868  0.97614455 0.98674697 0.9951807 ]
2022-01-18 21:32:07,067 - INFO - Epoch time: 398.5978784561157
2022-01-18 21:32:07,067 - INFO - 
Epoch: 42
2022-01-18 21:32:07,067 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:33:32,880 - INFO - [Step=35250]	Loss=0.7393	254.6 examples/second
2022-01-18 21:35:29,396 - INFO - [Step=35500]	Loss=0.7464	274.6 examples/second
2022-01-18 21:37:25,949 - INFO - [Step=35750]	Loss=0.7468	274.6 examples/second
2022-01-18 21:38:45,058 - INFO - Test Loss=0.8036, Test top-1 acc=0.8051
2022-01-18 21:38:45,059 - INFO - Group Accuracy:

2022-01-18 21:38:45,059 - INFO - [0.9809638  0.9893976  0.9855422  0.99421686 0.9833735  0.9939759
 0.9814458  0.98433733 0.99060243 0.9778313  0.9889157  0.98626506
 0.97927713 0.9812048  0.9768675  0.98771083 0.9954217 ]
2022-01-18 21:38:45,059 - INFO - Saving...
2022-01-18 21:38:45,297 - INFO - Epoch time: 398.2303774356842
2022-01-18 21:38:45,298 - INFO - 
Epoch: 43
2022-01-18 21:38:45,298 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:39:31,198 - INFO - [Step=36000]	Loss=0.7414	255.5 examples/second
2022-01-18 21:41:26,116 - INFO - [Step=36250]	Loss=0.7262	278.5 examples/second
2022-01-18 21:43:20,990 - INFO - [Step=36500]	Loss=0.7369	278.6 examples/second
2022-01-18 21:45:18,994 - INFO - Test Loss=0.8208, Test top-1 acc=0.7978
2022-01-18 21:45:18,994 - INFO - Group Accuracy:

2022-01-18 21:45:18,994 - INFO - [0.98       0.99036145 0.98626506 0.9925301  0.9816868  0.9946988
 0.9819277  0.98361444 0.99060243 0.97542167 0.99060243 0.9840964
 0.9771084  0.9819277  0.9771084  0.9855422  0.9954217 ]
2022-01-18 21:45:18,995 - INFO - Epoch time: 393.6970634460449
2022-01-18 21:45:18,995 - INFO - 
Epoch: 44
2022-01-18 21:45:18,995 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:45:25,206 - INFO - [Step=36750]	Loss=0.7312	257.6 examples/second
2022-01-18 21:47:20,547 - INFO - [Step=37000]	Loss=0.7072	277.4 examples/second
2022-01-18 21:49:15,896 - INFO - [Step=37250]	Loss=0.7372	277.4 examples/second
2022-01-18 21:51:11,250 - INFO - [Step=37500]	Loss=0.7335	277.4 examples/second
2022-01-18 21:51:52,965 - INFO - Test Loss=0.8155, Test top-1 acc=0.7983
2022-01-18 21:51:52,966 - INFO - Group Accuracy:

2022-01-18 21:51:52,966 - INFO - [0.98       0.99036145 0.98771083 0.9920482  0.9826506  0.9951807
 0.9816868  0.9821687  0.99084336 0.9768675  0.99036145 0.98289156
 0.97590363 0.9816868  0.97590363 0.98722893 0.9951807 ]
2022-01-18 21:51:52,966 - INFO - Epoch time: 393.97149634361267
2022-01-18 21:51:52,966 - INFO - 
Epoch: 45
2022-01-18 21:51:52,966 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:53:15,054 - INFO - [Step=37750]	Loss=0.7142	258.5 examples/second
2022-01-18 21:55:09,882 - INFO - [Step=38000]	Loss=0.7187	278.7 examples/second
2022-01-18 21:57:04,922 - INFO - [Step=38250]	Loss=0.7260	278.2 examples/second
2022-01-18 21:58:25,722 - INFO - Test Loss=0.8436, Test top-1 acc=0.8007
2022-01-18 21:58:25,722 - INFO - Group Accuracy:

2022-01-18 21:58:25,722 - INFO - [0.98024094 0.9886747  0.98746985 0.9930121  0.98240966 0.99421686
 0.9807229  0.9821687  0.99108434 0.9780723  0.9913253  0.9855422
 0.9773494  0.9814458  0.97614455 0.98626506 0.9954217 ]
2022-01-18 21:58:25,724 - INFO - Epoch time: 392.75765585899353
2022-01-18 21:58:25,724 - INFO - 
Epoch: 46
2022-01-18 21:58:25,724 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:59:09,779 - INFO - [Step=38500]	Loss=0.7318	256.3 examples/second
2022-01-18 22:01:05,942 - INFO - [Step=38750]	Loss=0.7168	275.5 examples/second
2022-01-18 22:03:02,100 - INFO - [Step=39000]	Loss=0.7247	275.5 examples/second
2022-01-18 22:05:03,006 - INFO - Test Loss=0.8290, Test top-1 acc=0.8010
2022-01-18 22:05:03,006 - INFO - Group Accuracy:

2022-01-18 22:05:03,006 - INFO - [0.9807229  0.9886747  0.98698795 0.9920482  0.9819277  0.99373496
 0.9826506  0.98289156 0.99060243 0.97566265 0.99108434 0.9850602
 0.9773494  0.9804819  0.97590363 0.98650604 0.99493974]
2022-01-18 22:05:03,007 - INFO - Epoch time: 397.2827754020691
2022-01-18 22:05:03,007 - INFO - 
Epoch: 47
2022-01-18 22:05:03,007 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:05:07,503 - INFO - [Step=39250]	Loss=0.7145	255.2 examples/second
2022-01-18 22:07:03,436 - INFO - [Step=39500]	Loss=0.7061	276.0 examples/second
2022-01-18 22:08:59,167 - INFO - [Step=39750]	Loss=0.7081	276.5 examples/second
2022-01-18 22:10:55,196 - INFO - [Step=40000]	Loss=0.7124	275.8 examples/second
2022-01-18 22:11:39,207 - INFO - Test Loss=0.8247, Test top-1 acc=0.7981
2022-01-18 22:11:39,207 - INFO - Group Accuracy:

2022-01-18 22:11:39,207 - INFO - [0.97927713 0.99084336 0.98626506 0.993253   0.98313254 0.99493974
 0.98240966 0.9826506  0.9884337  0.973494   0.99084336 0.9833735
 0.97614455 0.97951806 0.97614455 0.9884337  0.9951807 ]
2022-01-18 22:11:39,208 - INFO - Epoch time: 396.20133996009827
2022-01-18 22:11:39,208 - INFO - 
Epoch: 48
2022-01-18 22:11:39,208 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:12:59,021 - INFO - [Step=40250]	Loss=0.6983	258.4 examples/second
2022-01-18 22:14:53,687 - INFO - [Step=40500]	Loss=0.6932	279.1 examples/second
2022-01-18 22:16:48,391 - INFO - [Step=40750]	Loss=0.7051	279.0 examples/second
2022-01-18 22:18:11,364 - INFO - Test Loss=0.8252, Test top-1 acc=0.8007
2022-01-18 22:18:11,365 - INFO - Group Accuracy:

2022-01-18 22:18:11,365 - INFO - [0.9809638  0.9893976  0.9850602  0.9925301  0.9845783  0.9946988
 0.9807229  0.98289156 0.99084336 0.97493976 0.9927711  0.9845783
 0.97518075 0.9809638  0.97614455 0.98771083 0.9954217 ]
2022-01-18 22:18:11,366 - INFO - Epoch time: 392.1573646068573
2022-01-18 22:18:11,366 - INFO - 
Epoch: 49
2022-01-18 22:18:11,366 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:18:52,266 - INFO - [Step=41000]	Loss=0.7034	258.3 examples/second
2022-01-18 22:20:47,959 - INFO - [Step=41250]	Loss=0.6860	276.6 examples/second
2022-01-18 22:22:43,388 - INFO - [Step=41500]	Loss=0.6860	277.2 examples/second
2022-01-18 22:24:38,986 - INFO - [Step=41750]	Loss=0.7129	276.8 examples/second
2022-01-18 22:24:46,202 - INFO - Test Loss=0.8348, Test top-1 acc=0.7971
2022-01-18 22:24:46,203 - INFO - Group Accuracy:

2022-01-18 22:24:46,203 - INFO - [0.97903615 0.9901205  0.9855422  0.9925301  0.98289156 0.9946988
 0.9814458  0.9838554  0.99084336 0.97638553 0.9879518  0.9848193
 0.9773494  0.97975904 0.9771084  0.9881928  0.9956626 ]
2022-01-18 22:24:46,203 - INFO - Epoch time: 394.83766508102417
2022-01-18 22:24:46,204 - INFO - 
Epoch: 50
2022-01-18 22:24:46,204 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:26:43,075 - INFO - [Step=42000]	Loss=0.6851	257.9 examples/second
2022-01-18 22:28:38,007 - INFO - [Step=42250]	Loss=0.6864	278.4 examples/second
2022-01-18 22:30:33,150 - INFO - [Step=42500]	Loss=0.6998	277.9 examples/second
2022-01-18 22:31:19,350 - INFO - Test Loss=0.8439, Test top-1 acc=0.8048
2022-01-18 22:31:19,351 - INFO - Group Accuracy:

2022-01-18 22:31:19,351 - INFO - [0.98240966 0.99108434 0.98746985 0.9922892  0.9816868  0.9956626
 0.9814458  0.9840964  0.9922892  0.9771084  0.99060243 0.9845783
 0.9766265  0.9807229  0.9768675  0.9879518  0.9959036 ]
2022-01-18 22:31:19,352 - INFO - Epoch time: 393.1480915546417
2022-01-18 22:31:19,352 - INFO - 
Epoch: 51
2022-01-18 22:31:19,352 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:32:37,377 - INFO - [Step=42750]	Loss=0.7005	257.6 examples/second
2022-01-18 22:34:32,200 - INFO - [Step=43000]	Loss=0.6746	278.7 examples/second
2022-01-18 22:36:26,944 - INFO - [Step=43250]	Loss=0.6963	278.9 examples/second
2022-01-18 22:37:51,943 - INFO - Test Loss=0.8472, Test top-1 acc=0.8029
2022-01-18 22:37:51,944 - INFO - Group Accuracy:

2022-01-18 22:37:51,944 - INFO - [0.9809638  0.99108434 0.9855422  0.9918072  0.9826506  0.9951807
 0.9812048  0.98361444 0.99108434 0.97542167 0.9879518  0.98433733
 0.9771084  0.9809638  0.97951806 0.98722893 0.9956626 ]
2022-01-18 22:37:51,945 - INFO - Epoch time: 392.5934064388275
2022-01-18 22:37:51,945 - INFO - 
Epoch: 52
2022-01-18 22:37:51,945 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:38:30,448 - INFO - [Step=43500]	Loss=0.6811	259.1 examples/second
2022-01-18 22:40:25,076 - INFO - [Step=43750]	Loss=0.6791	279.2 examples/second
2022-01-18 22:42:19,720 - INFO - [Step=44000]	Loss=0.6714	279.1 examples/second
2022-01-18 22:44:14,731 - INFO - [Step=44250]	Loss=0.6901	278.2 examples/second
2022-01-18 22:44:24,355 - INFO - Test Loss=0.8493, Test top-1 acc=0.8053
2022-01-18 22:44:24,355 - INFO - Group Accuracy:

2022-01-18 22:44:24,355 - INFO - [0.98       0.99036145 0.98722893 0.9925301  0.98361444 0.99445784
 0.9819277  0.98240966 0.9901205  0.97638553 0.9889157  0.9845783
 0.9773494  0.9814458  0.9771084  0.9893976  0.99493974]
2022-01-18 22:44:24,356 - INFO - Saving...
2022-01-18 22:44:24,536 - INFO - Epoch time: 392.59063172340393
2022-01-18 22:44:24,536 - INFO - 
Epoch: 53
2022-01-18 22:44:24,536 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:46:19,390 - INFO - [Step=44500]	Loss=0.6665	256.7 examples/second
2022-01-18 22:48:15,000 - INFO - [Step=44750]	Loss=0.6679	276.8 examples/second
2022-01-18 22:50:10,481 - INFO - [Step=45000]	Loss=0.6892	277.1 examples/second
2022-01-18 22:50:59,262 - INFO - Test Loss=0.8365, Test top-1 acc=0.8041
2022-01-18 22:50:59,263 - INFO - Group Accuracy:

2022-01-18 22:50:59,263 - INFO - [0.98       0.9901205  0.9860241  0.993253   0.98433733 0.99445784
 0.9821687  0.9814458  0.9918072  0.97566265 0.9901205  0.9848193
 0.9766265  0.98289156 0.97590363 0.9884337  0.9954217 ]
2022-01-18 22:50:59,263 - INFO - Epoch time: 394.7274537086487
2022-01-18 22:50:59,264 - INFO - 
Epoch: 54
2022-01-18 22:50:59,264 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:52:15,092 - INFO - [Step=45250]	Loss=0.6651	256.8 examples/second
2022-01-18 22:54:10,581 - INFO - [Step=45500]	Loss=0.6718	277.1 examples/second
2022-01-18 22:56:06,386 - INFO - [Step=45750]	Loss=0.6698	276.3 examples/second
2022-01-18 22:57:34,331 - INFO - Test Loss=0.8331, Test top-1 acc=0.8101
2022-01-18 22:57:34,331 - INFO - Group Accuracy:

2022-01-18 22:57:34,331 - INFO - [0.9809638  0.9891566  0.98650604 0.9927711  0.9848193  0.9939759
 0.98240966 0.9833735  0.99108434 0.97614455 0.9913253  0.9848193
 0.9771084  0.9807229  0.98       0.9879518  0.9959036 ]
2022-01-18 22:57:34,332 - INFO - Saving...
2022-01-18 22:57:34,544 - INFO - Epoch time: 395.28068375587463
2022-01-18 22:57:34,544 - INFO - 
Epoch: 55
2022-01-18 22:57:34,545 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:58:11,088 - INFO - [Step=46000]	Loss=0.6649	256.6 examples/second
2022-01-18 23:00:06,090 - INFO - [Step=46250]	Loss=0.6622	278.3 examples/second
2022-01-18 23:02:00,949 - INFO - [Step=46500]	Loss=0.6654	278.6 examples/second
2022-01-18 23:03:56,097 - INFO - [Step=46750]	Loss=0.6694	277.9 examples/second
2022-01-18 23:04:08,053 - INFO - Test Loss=0.8292, Test top-1 acc=0.7998
2022-01-18 23:04:08,053 - INFO - Group Accuracy:

2022-01-18 23:04:08,053 - INFO - [0.98024094 0.99108434 0.9838554  0.9925301  0.9840964  0.9946988
 0.9821687  0.98289156 0.9893976  0.9771084  0.99036145 0.9838554
 0.9742169  0.97951806 0.97566265 0.9889157  0.9956626 ]
2022-01-18 23:04:08,054 - INFO - Epoch time: 393.5095748901367
2022-01-18 23:04:08,054 - INFO - 
Epoch: 56
2022-01-18 23:04:08,054 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:06:00,933 - INFO - [Step=47000]	Loss=0.6494	256.3 examples/second
2022-01-18 23:07:56,925 - INFO - [Step=47250]	Loss=0.6720	275.9 examples/second
2022-01-18 23:09:53,049 - INFO - [Step=47500]	Loss=0.6660	275.6 examples/second
2022-01-18 23:10:44,363 - INFO - Test Loss=0.8484, Test top-1 acc=0.8039
2022-01-18 23:10:44,363 - INFO - Group Accuracy:

2022-01-18 23:10:44,363 - INFO - [0.97975904 0.9898795  0.98626506 0.99373496 0.9848193  0.99373496
 0.9809638  0.9848193  0.9893976  0.9771084  0.9881928  0.9845783
 0.97566265 0.97903615 0.9780723  0.98722893 0.9963855 ]
2022-01-18 23:10:44,364 - INFO - Epoch time: 396.3096733093262
2022-01-18 23:10:44,364 - INFO - 
Epoch: 57
2022-01-18 23:10:44,364 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:11:57,513 - INFO - [Step=47750]	Loss=0.6604	257.1 examples/second
2022-01-18 23:13:52,461 - INFO - [Step=48000]	Loss=0.6464	278.4 examples/second
2022-01-18 23:15:47,495 - INFO - [Step=48250]	Loss=0.6603	278.2 examples/second
2022-01-18 23:17:17,654 - INFO - Test Loss=0.8570, Test top-1 acc=0.8046
2022-01-18 23:17:17,655 - INFO - Group Accuracy:

2022-01-18 23:17:17,655 - INFO - [0.9814458  0.9913253  0.9848193  0.99156624 0.98433733 0.9959036
 0.9785542  0.9833735  0.9898795  0.9768675  0.99084336 0.98674697
 0.97566265 0.9804819  0.9773494  0.98650604 0.9961446 ]
2022-01-18 23:17:17,656 - INFO - Epoch time: 393.2922730445862
2022-01-18 23:17:17,656 - INFO - 
Epoch: 58
2022-01-18 23:17:17,656 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:17:51,525 - INFO - [Step=48500]	Loss=0.6591	258.0 examples/second
2022-01-18 23:19:46,553 - INFO - [Step=48750]	Loss=0.6445	278.2 examples/second
2022-01-18 23:21:41,624 - INFO - [Step=49000]	Loss=0.6448	278.1 examples/second
2022-01-18 23:23:36,950 - INFO - [Step=49250]	Loss=0.6534	277.5 examples/second
2022-01-18 23:23:51,277 - INFO - Test Loss=0.8535, Test top-1 acc=0.8017
2022-01-18 23:23:51,277 - INFO - Group Accuracy:

2022-01-18 23:23:51,277 - INFO - [0.9785542  0.9893976  0.9860241  0.993253   0.9845783  0.99445784
 0.98240966 0.9804819  0.99084336 0.9766265  0.99036145 0.9840964
 0.97614455 0.98       0.97831327 0.9886747  0.9951807 ]
2022-01-18 23:23:51,278 - INFO - Epoch time: 393.6220028400421
2022-01-18 23:23:51,278 - INFO - 
Epoch: 59
2022-01-18 23:23:51,278 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:25:41,132 - INFO - [Step=49500]	Loss=0.6160	257.7 examples/second
2022-01-18 23:27:35,972 - INFO - [Step=49750]	Loss=0.5881	278.6 examples/second
2022-01-18 23:29:30,902 - INFO - [Step=50000]	Loss=0.5633	278.4 examples/second
2022-01-18 23:30:23,905 - INFO - Test Loss=0.7860, Test top-1 acc=0.8096
2022-01-18 23:30:23,905 - INFO - Group Accuracy:

2022-01-18 23:30:23,905 - INFO - [0.98024094 0.9920482  0.98674697 0.9930121  0.9853012  0.9951807
 0.9812048  0.9838554  0.99060243 0.97614455 0.99036145 0.98698795
 0.9778313  0.98289156 0.9780723  0.9884337  0.9959036 ]
2022-01-18 23:30:23,906 - INFO - Epoch time: 392.62774682044983
2022-01-18 23:30:23,906 - INFO - 
Epoch: 60
2022-01-18 23:30:23,906 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:31:34,725 - INFO - [Step=50250]	Loss=0.5646	258.4 examples/second
2022-01-18 23:33:29,411 - INFO - [Step=50500]	Loss=0.5765	279.0 examples/second
2022-01-18 23:35:24,196 - INFO - [Step=50750]	Loss=0.5581	278.8 examples/second
2022-01-18 23:36:56,167 - INFO - Test Loss=0.7827, Test top-1 acc=0.8111
2022-01-18 23:36:56,168 - INFO - Group Accuracy:

2022-01-18 23:36:56,168 - INFO - [0.9804819  0.9918072  0.98650604 0.9927711  0.98578316 0.99493974
 0.9819277  0.9840964  0.99060243 0.9773494  0.99036145 0.98650604
 0.97831327 0.9821687  0.9775904  0.9889157  0.9963855 ]
2022-01-18 23:36:56,169 - INFO - Saving...
2022-01-18 23:36:56,412 - INFO - Epoch time: 392.5060729980469
2022-01-18 23:36:56,412 - INFO - 
Epoch: 61
2022-01-18 23:36:56,413 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:37:28,323 - INFO - [Step=51000]	Loss=0.5567	257.8 examples/second
2022-01-18 23:39:23,641 - INFO - [Step=51250]	Loss=0.5461	277.5 examples/second
2022-01-18 23:41:19,069 - INFO - [Step=51500]	Loss=0.5511	277.2 examples/second
2022-01-18 23:43:14,455 - INFO - [Step=51750]	Loss=0.5443	277.3 examples/second
2022-01-18 23:43:30,738 - INFO - Test Loss=0.7782, Test top-1 acc=0.8118
2022-01-18 23:43:30,739 - INFO - Group Accuracy:

2022-01-18 23:43:30,739 - INFO - [0.9809638  0.9918072  0.98722893 0.9930121  0.9853012  0.9951807
 0.9816868  0.9845783  0.9901205  0.9768675  0.99084336 0.9853012
 0.9780723  0.9821687  0.9787952  0.9891566  0.9968675 ]
2022-01-18 23:43:30,740 - INFO - Saving...
2022-01-18 23:43:31,005 - INFO - Epoch time: 394.5924508571625
2022-01-18 23:43:31,005 - INFO - 
Epoch: 62
2022-01-18 23:43:31,005 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:45:18,630 - INFO - [Step=52000]	Loss=0.5393	257.7 examples/second
2022-01-18 23:47:13,672 - INFO - [Step=52250]	Loss=0.5414	278.2 examples/second
2022-01-18 23:49:08,834 - INFO - [Step=52500]	Loss=0.5478	277.9 examples/second
2022-01-18 23:50:04,505 - INFO - Test Loss=0.7821, Test top-1 acc=0.8123
2022-01-18 23:50:04,505 - INFO - Group Accuracy:

2022-01-18 23:50:04,505 - INFO - [0.9809638  0.9925301  0.98650604 0.9927711  0.98698795 0.9954217
 0.9821687  0.9838554  0.98963857 0.9768675  0.99108434 0.98650604
 0.9775904  0.9819277  0.9778313  0.9889157  0.9966265 ]
2022-01-18 23:50:04,506 - INFO - Saving...
2022-01-18 23:50:04,793 - INFO - Epoch time: 393.78825974464417
2022-01-18 23:50:04,794 - INFO - 
Epoch: 63
2022-01-18 23:50:04,794 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:51:13,267 - INFO - [Step=52750]	Loss=0.5445	257.2 examples/second
2022-01-18 23:53:08,480 - INFO - [Step=53000]	Loss=0.5466	277.7 examples/second
2022-01-18 23:55:03,730 - INFO - [Step=53250]	Loss=0.5421	277.7 examples/second
2022-01-18 23:56:38,384 - INFO - Test Loss=0.7820, Test top-1 acc=0.8149
2022-01-18 23:56:38,384 - INFO - Group Accuracy:

2022-01-18 23:56:38,384 - INFO - [0.9807229  0.9927711  0.98674697 0.9927711  0.98578316 0.9954217
 0.98289156 0.98361444 0.9898795  0.9778313  0.99084336 0.98650604
 0.9780723  0.9821687  0.9785542  0.9891566  0.9966265 ]
2022-01-18 23:56:38,385 - INFO - Saving...
2022-01-18 23:56:38,578 - INFO - Epoch time: 393.78402304649353
2022-01-18 23:56:38,578 - INFO - 
Epoch: 64
2022-01-18 23:56:38,578 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:57:07,879 - INFO - [Step=53500]	Loss=0.5389	257.8 examples/second
2022-01-18 23:59:02,997 - INFO - [Step=53750]	Loss=0.5306	278.0 examples/second
2022-01-19 00:00:57,876 - INFO - [Step=54000]	Loss=0.5390	278.6 examples/second
2022-01-19 00:02:53,219 - INFO - [Step=54250]	Loss=0.5317	277.4 examples/second
2022-01-19 00:03:11,629 - INFO - Test Loss=0.7801, Test top-1 acc=0.8147
2022-01-19 00:03:11,629 - INFO - Group Accuracy:

2022-01-19 00:03:11,629 - INFO - [0.9809638  0.9918072  0.98698795 0.9925301  0.9855422  0.9951807
 0.98240966 0.9848193  0.9898795  0.9775904  0.99084336 0.98650604
 0.9785542  0.9833735  0.97927713 0.9891566  0.9963855 ]
2022-01-19 00:03:11,630 - INFO - Epoch time: 393.0523064136505
2022-01-19 00:03:11,630 - INFO - 
Epoch: 65
2022-01-19 00:03:11,630 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:04:57,942 - INFO - [Step=54500]	Loss=0.5118	256.6 examples/second
2022-01-19 00:06:53,678 - INFO - [Step=54750]	Loss=0.5325	276.5 examples/second
2022-01-19 00:08:49,525 - INFO - [Step=55000]	Loss=0.5503	276.2 examples/second
2022-01-19 00:09:47,765 - INFO - Test Loss=0.7784, Test top-1 acc=0.8147
2022-01-19 00:09:47,766 - INFO - Group Accuracy:

2022-01-19 00:09:47,766 - INFO - [0.9814458  0.99156624 0.98698795 0.9920482  0.98650604 0.9954217
 0.98240966 0.98433733 0.9893976  0.9771084  0.99060243 0.98578316
 0.9780723  0.98240966 0.9785542  0.9893976  0.9966265 ]
2022-01-19 00:09:47,767 - INFO - Epoch time: 396.1366367340088
2022-01-19 00:09:47,767 - INFO - 
Epoch: 66
2022-01-19 00:09:47,767 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:10:54,060 - INFO - [Step=55250]	Loss=0.5226	257.0 examples/second
2022-01-19 00:12:48,726 - INFO - [Step=55500]	Loss=0.5217	279.1 examples/second
2022-01-19 00:14:43,439 - INFO - [Step=55750]	Loss=0.5084	279.0 examples/second
2022-01-19 00:16:20,222 - INFO - Test Loss=0.7786, Test top-1 acc=0.8140
2022-01-19 00:16:20,222 - INFO - Group Accuracy:

2022-01-19 00:16:20,222 - INFO - [0.9816868  0.99156624 0.98650604 0.9927711  0.98650604 0.9951807
 0.9826506  0.98361444 0.9898795  0.9768675  0.99108434 0.98626506
 0.97831327 0.9819277  0.9785542  0.9891566  0.9956626 ]
2022-01-19 00:16:20,223 - INFO - Epoch time: 392.45568680763245
2022-01-19 00:16:20,223 - INFO - 
Epoch: 67
2022-01-19 00:16:20,223 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:16:47,133 - INFO - [Step=56000]	Loss=0.5270	258.7 examples/second
2022-01-19 00:18:41,902 - INFO - [Step=56250]	Loss=0.5239	278.8 examples/second
2022-01-19 00:20:36,605 - INFO - [Step=56500]	Loss=0.5266	279.0 examples/second
2022-01-19 00:22:31,439 - INFO - [Step=56750]	Loss=0.5284	278.7 examples/second
2022-01-19 00:22:52,845 - INFO - Test Loss=0.7873, Test top-1 acc=0.8152
2022-01-19 00:22:52,845 - INFO - Group Accuracy:

2022-01-19 00:22:52,845 - INFO - [0.9804819  0.9913253  0.98698795 0.9920482  0.98698795 0.99493974
 0.9816868  0.9845783  0.9901205  0.9771084  0.99036145 0.98698795
 0.9780723  0.9838554  0.9773494  0.98963857 0.9963855 ]
2022-01-19 00:22:52,846 - INFO - Saving...
2022-01-19 00:22:53,107 - INFO - Epoch time: 392.8840718269348
2022-01-19 00:22:53,107 - INFO - 
Epoch: 68
2022-01-19 00:22:53,107 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:24:35,962 - INFO - [Step=57000]	Loss=0.5188	257.0 examples/second
2022-01-19 00:26:30,810 - INFO - [Step=57250]	Loss=0.5145	278.6 examples/second
2022-01-19 00:28:25,699 - INFO - [Step=57500]	Loss=0.5213	278.5 examples/second
2022-01-19 00:29:25,716 - INFO - Test Loss=0.7895, Test top-1 acc=0.8154
2022-01-19 00:29:25,717 - INFO - Group Accuracy:

2022-01-19 00:29:25,717 - INFO - [0.9816868  0.9918072  0.98771083 0.9920482  0.98626506 0.99493974
 0.9821687  0.9848193  0.9901205  0.97614455 0.99036145 0.98698795
 0.9778313  0.9826506  0.9785542  0.9891566  0.9961446 ]
2022-01-19 00:29:25,718 - INFO - Saving...
2022-01-19 00:29:25,979 - INFO - Epoch time: 392.87139081954956
2022-01-19 00:29:25,979 - INFO - 
Epoch: 69
2022-01-19 00:29:25,979 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:30:29,784 - INFO - [Step=57750]	Loss=0.5357	257.9 examples/second
2022-01-19 00:32:24,556 - INFO - [Step=58000]	Loss=0.5152	278.8 examples/second
2022-01-19 00:34:19,157 - INFO - [Step=58250]	Loss=0.5129	279.2 examples/second
2022-01-19 00:35:58,499 - INFO - Test Loss=0.7901, Test top-1 acc=0.8149
2022-01-19 00:35:58,499 - INFO - Group Accuracy:

2022-01-19 00:35:58,499 - INFO - [0.9814458  0.9918072  0.98722893 0.9927711  0.98698795 0.9951807
 0.9819277  0.9845783  0.9893976  0.9773494  0.99084336 0.9860241
 0.9778313  0.98289156 0.97903615 0.9891566  0.9963855 ]
2022-01-19 00:35:58,500 - INFO - Epoch time: 392.52166652679443
2022-01-19 00:35:58,500 - INFO - 
Epoch: 70
2022-01-19 00:35:58,501 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:36:23,676 - INFO - [Step=58500]	Loss=0.5125	257.0 examples/second
2022-01-19 00:38:18,455 - INFO - [Step=58750]	Loss=0.5188	278.8 examples/second
2022-01-19 00:40:13,413 - INFO - [Step=59000]	Loss=0.5124	278.4 examples/second
2022-01-19 00:42:08,241 - INFO - [Step=59250]	Loss=0.5202	278.7 examples/second
2022-01-19 00:42:31,295 - INFO - Test Loss=0.7822, Test top-1 acc=0.8166
2022-01-19 00:42:31,295 - INFO - Group Accuracy:

2022-01-19 00:42:31,295 - INFO - [0.9812048  0.9918072  0.98722893 0.9927711  0.98698795 0.99493974
 0.9812048  0.9848193  0.9901205  0.9780723  0.99156624 0.98746985
 0.9785542  0.9826506  0.9785542  0.9886747  0.9968675 ]
2022-01-19 00:42:31,296 - INFO - Saving...
2022-01-19 00:42:31,586 - INFO - Epoch time: 393.085325717926
2022-01-19 00:42:31,586 - INFO - 
Epoch: 71
2022-01-19 00:42:31,586 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:44:12,009 - INFO - [Step=59500]	Loss=0.5080	258.5 examples/second
2022-01-19 00:46:06,714 - INFO - [Step=59750]	Loss=0.5090	279.0 examples/second
2022-01-19 00:48:01,440 - INFO - [Step=60000]	Loss=0.5237	278.9 examples/second
2022-01-19 00:49:03,434 - INFO - Test Loss=0.7859, Test top-1 acc=0.8135
2022-01-19 00:49:03,434 - INFO - Group Accuracy:

2022-01-19 00:49:03,434 - INFO - [0.9812048  0.99108434 0.98722893 0.9927711  0.98650604 0.9946988
 0.9821687  0.9845783  0.9898795  0.9768675  0.9913253  0.98674697
 0.9771084  0.98240966 0.97903615 0.9886747  0.9966265 ]
2022-01-19 00:49:03,435 - INFO - Epoch time: 391.8492374420166
2022-01-19 00:49:03,435 - INFO - 
Epoch: 72
2022-01-19 00:49:03,435 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:50:05,616 - INFO - [Step=60250]	Loss=0.5132	257.7 examples/second
2022-01-19 00:52:00,373 - INFO - [Step=60500]	Loss=0.5019	278.9 examples/second
2022-01-19 00:53:55,101 - INFO - [Step=60750]	Loss=0.5038	278.9 examples/second
2022-01-19 00:55:36,427 - INFO - Test Loss=0.7889, Test top-1 acc=0.8120
2022-01-19 00:55:36,427 - INFO - Group Accuracy:

2022-01-19 00:55:36,427 - INFO - [0.9807229  0.99156624 0.98674697 0.993253   0.98626506 0.99493974
 0.9816868  0.9848193  0.99060243 0.9780723  0.99060243 0.98626506
 0.9771084  0.9821687  0.9780723  0.9889157  0.9966265 ]
2022-01-19 00:55:36,429 - INFO - Epoch time: 392.9933466911316
2022-01-19 00:55:36,429 - INFO - 
Epoch: 73
2022-01-19 00:55:36,429 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:55:58,853 - INFO - [Step=61000]	Loss=0.5259	258.6 examples/second
2022-01-19 00:57:53,602 - INFO - [Step=61250]	Loss=0.5107	278.9 examples/second
2022-01-19 00:59:48,557 - INFO - [Step=61500]	Loss=0.5090	278.4 examples/second
2022-01-19 01:01:43,371 - INFO - [Step=61750]	Loss=0.5084	278.7 examples/second
2022-01-19 01:02:08,660 - INFO - Test Loss=0.7872, Test top-1 acc=0.8137
2022-01-19 01:02:08,661 - INFO - Group Accuracy:

2022-01-19 01:02:08,670 - INFO - [0.9814458  0.9913253  0.98698795 0.993253   0.98698795 0.9951807
 0.9809638  0.9850602  0.98963857 0.9768675  0.99084336 0.98674697
 0.9778313  0.9821687  0.9785542  0.9886747  0.9963855 ]
2022-01-19 01:02:08,671 - INFO - Epoch time: 392.24223589897156
2022-01-19 01:02:08,671 - INFO - 
Epoch: 74
2022-01-19 01:02:08,671 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:03:46,939 - INFO - [Step=62000]	Loss=0.5205	259.0 examples/second
2022-01-19 01:05:41,884 - INFO - [Step=62250]	Loss=0.4944	278.4 examples/second
2022-01-19 01:07:36,906 - INFO - [Step=62500]	Loss=0.4933	278.2 examples/second
2022-01-19 01:08:41,399 - INFO - Test Loss=0.7928, Test top-1 acc=0.8123
2022-01-19 01:08:41,400 - INFO - Group Accuracy:

2022-01-19 01:08:41,400 - INFO - [0.9809638  0.99084336 0.98746985 0.993494   0.98650604 0.9954217
 0.9807229  0.9845783  0.9889157  0.9778313  0.99108434 0.98746985
 0.9775904  0.9826506  0.9785542  0.9881928  0.9966265 ]
2022-01-19 01:08:41,401 - INFO - Epoch time: 392.7301290035248
2022-01-19 01:08:41,401 - INFO - 
Epoch: 75
2022-01-19 01:08:41,402 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:09:41,059 - INFO - [Step=62750]	Loss=0.4945	257.7 examples/second
2022-01-19 01:11:36,122 - INFO - [Step=63000]	Loss=0.4948	278.1 examples/second
2022-01-19 01:13:31,131 - INFO - [Step=63250]	Loss=0.5045	278.2 examples/second
2022-01-19 01:15:14,804 - INFO - Test Loss=0.7998, Test top-1 acc=0.8106
2022-01-19 01:15:14,804 - INFO - Group Accuracy:

2022-01-19 01:15:14,804 - INFO - [0.9804819  0.99108434 0.98722893 0.9927711  0.9853012  0.9954217
 0.9812048  0.9840964  0.9898795  0.9775904  0.99108434 0.98746985
 0.9785542  0.9816868  0.97903615 0.9889157  0.9963855 ]
2022-01-19 01:15:14,805 - INFO - Epoch time: 393.40352511405945
2022-01-19 01:15:14,805 - INFO - 
Epoch: 76
2022-01-19 01:15:14,805 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:15:34,892 - INFO - [Step=63500]	Loss=0.5007	258.6 examples/second
2022-01-19 01:17:29,569 - INFO - [Step=63750]	Loss=0.5012	279.0 examples/second
2022-01-19 01:19:24,377 - INFO - [Step=64000]	Loss=0.4884	278.7 examples/second
2022-01-19 01:21:19,043 - INFO - [Step=64250]	Loss=0.4809	279.1 examples/second
2022-01-19 01:21:46,877 - INFO - Test Loss=0.7944, Test top-1 acc=0.8118
2022-01-19 01:21:46,878 - INFO - Group Accuracy:

2022-01-19 01:21:46,878 - INFO - [0.9809638  0.99156624 0.98674697 0.9927711  0.9848193  0.9951807
 0.9816868  0.9845783  0.9898795  0.9768675  0.99036145 0.98674697
 0.9780723  0.98289156 0.9785542  0.9886747  0.9966265 ]
2022-01-19 01:21:46,878 - INFO - Epoch time: 392.07320976257324
2022-01-19 01:21:46,878 - INFO - 
Epoch: 77
2022-01-19 01:21:46,878 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:23:23,051 - INFO - [Step=64500]	Loss=0.5008	258.0 examples/second
2022-01-19 01:25:18,040 - INFO - [Step=64750]	Loss=0.4989	278.3 examples/second
2022-01-19 01:27:13,167 - INFO - [Step=65000]	Loss=0.4979	278.0 examples/second
2022-01-19 01:28:20,572 - INFO - Test Loss=0.8020, Test top-1 acc=0.8176
2022-01-19 01:28:20,572 - INFO - Group Accuracy:

2022-01-19 01:28:20,572 - INFO - [0.9812048  0.99060243 0.98771083 0.9939759  0.98578316 0.9951807
 0.9809638  0.9838554  0.9901205  0.9778313  0.9920482  0.98746985
 0.97975904 0.9826506  0.9785542  0.9879518  0.9966265 ]
2022-01-19 01:28:20,573 - INFO - Saving...
2022-01-19 01:28:20,822 - INFO - Epoch time: 393.9436140060425
2022-01-19 01:28:20,822 - INFO - 
Epoch: 78
2022-01-19 01:28:20,822 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:29:18,187 - INFO - [Step=65250]	Loss=0.4929	256.0 examples/second
2022-01-19 01:31:14,149 - INFO - [Step=65500]	Loss=0.4946	276.0 examples/second
2022-01-19 01:33:10,219 - INFO - [Step=65750]	Loss=0.4938	275.7 examples/second
2022-01-19 01:34:57,547 - INFO - Test Loss=0.7997, Test top-1 acc=0.8178
2022-01-19 01:34:57,547 - INFO - Group Accuracy:

2022-01-19 01:34:57,547 - INFO - [0.9819277  0.99156624 0.98771083 0.993253   0.9860241  0.9951807
 0.9819277  0.9845783  0.98963857 0.9773494  0.99156624 0.98698795
 0.9787952  0.9826506  0.9787952  0.9893976  0.9968675 ]
2022-01-19 01:34:57,549 - INFO - Saving...
2022-01-19 01:34:57,860 - INFO - Epoch time: 397.0380382537842
2022-01-19 01:34:57,861 - INFO - 
Epoch: 79
2022-01-19 01:34:57,861 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:35:15,824 - INFO - [Step=66000]	Loss=0.5037	254.8 examples/second
2022-01-19 01:37:11,261 - INFO - [Step=66250]	Loss=0.5019	277.2 examples/second
2022-01-19 01:39:06,731 - INFO - [Step=66500]	Loss=0.4870	277.1 examples/second
2022-01-19 01:41:02,255 - INFO - [Step=66750]	Loss=0.4987	277.0 examples/second
2022-01-19 01:41:32,534 - INFO - Test Loss=0.7938, Test top-1 acc=0.8147
2022-01-19 01:41:32,534 - INFO - Group Accuracy:

2022-01-19 01:41:32,534 - INFO - [0.9816868  0.99108434 0.98722893 0.993253   0.98698795 0.9951807
 0.9809638  0.9838554  0.9893976  0.9771084  0.99060243 0.98650604
 0.97975904 0.98240966 0.97927713 0.9893976  0.9963855 ]
2022-01-19 01:41:32,535 - INFO - Epoch time: 394.6748571395874
2022-01-19 01:41:32,536 - INFO - 
Epoch: 80
2022-01-19 01:41:32,536 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:43:06,758 - INFO - [Step=67000]	Loss=0.4807	257.0 examples/second
2022-01-19 01:45:02,455 - INFO - [Step=67250]	Loss=0.4942	276.6 examples/second
2022-01-19 01:46:58,215 - INFO - [Step=67500]	Loss=0.4896	276.4 examples/second
2022-01-19 01:48:07,922 - INFO - Test Loss=0.7976, Test top-1 acc=0.8145
2022-01-19 01:48:07,922 - INFO - Group Accuracy:

2022-01-19 01:48:07,922 - INFO - [0.9821687  0.99108434 0.98746985 0.993494   0.9860241  0.9951807
 0.9816868  0.9838554  0.99060243 0.9780723  0.9913253  0.98722893
 0.9771084  0.9816868  0.97951806 0.9898795  0.9963855 ]
2022-01-19 01:48:07,923 - INFO - Epoch time: 395.38762640953064
2022-01-19 01:48:07,923 - INFO - 
Epoch: 81
2022-01-19 01:48:07,923 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:49:02,650 - INFO - [Step=67750]	Loss=0.4896	257.2 examples/second
2022-01-19 01:50:57,895 - INFO - [Step=68000]	Loss=0.4891	277.7 examples/second
2022-01-19 01:52:53,128 - INFO - [Step=68250]	Loss=0.4905	277.7 examples/second
2022-01-19 01:54:42,086 - INFO - Test Loss=0.7987, Test top-1 acc=0.8142
2022-01-19 01:54:42,086 - INFO - Group Accuracy:

2022-01-19 01:54:42,087 - INFO - [0.9812048  0.9913253  0.98722893 0.993494   0.9860241  0.99493974
 0.9812048  0.9845783  0.99036145 0.9773494  0.99108434 0.98722893
 0.9780723  0.98361444 0.9778313  0.9886747  0.9961446 ]
2022-01-19 01:54:42,088 - INFO - Epoch time: 394.16458892822266
2022-01-19 01:54:42,088 - INFO - 
Epoch: 82
2022-01-19 01:54:42,088 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:54:57,508 - INFO - [Step=68500]	Loss=0.4841	257.3 examples/second
2022-01-19 01:56:52,573 - INFO - [Step=68750]	Loss=0.4884	278.1 examples/second
2022-01-19 01:58:47,540 - INFO - [Step=69000]	Loss=0.4928	278.3 examples/second
2022-01-19 02:00:42,544 - INFO - [Step=69250]	Loss=0.4846	278.3 examples/second
2022-01-19 02:01:14,663 - INFO - Test Loss=0.8007, Test top-1 acc=0.8140
2022-01-19 02:01:14,663 - INFO - Group Accuracy:

2022-01-19 02:01:14,664 - INFO - [0.9807229  0.99156624 0.98771083 0.9927711  0.98578316 0.9951807
 0.9821687  0.98361444 0.99084336 0.9780723  0.99156624 0.98722893
 0.9773494  0.9819277  0.9785542  0.9886747  0.99710846]
2022-01-19 02:01:14,664 - INFO - Epoch time: 392.5763692855835
2022-01-19 02:01:14,664 - INFO - 
Epoch: 83
2022-01-19 02:01:14,664 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:02:46,120 - INFO - [Step=69500]	Loss=0.4734	259.0 examples/second
2022-01-19 02:04:40,576 - INFO - [Step=69750]	Loss=0.4887	279.6 examples/second
2022-01-19 02:06:35,230 - INFO - [Step=70000]	Loss=0.5086	279.1 examples/second
2022-01-19 02:07:46,639 - INFO - Test Loss=0.7988, Test top-1 acc=0.8108
2022-01-19 02:07:46,640 - INFO - Group Accuracy:

2022-01-19 02:07:46,640 - INFO - [0.98       0.99156624 0.98698795 0.993253   0.98650604 0.9951807
 0.9819277  0.9838554  0.98963857 0.9773494  0.9918072  0.98650604
 0.9773494  0.9821687  0.97903615 0.9884337  0.9968675 ]
2022-01-19 02:07:46,641 - INFO - Epoch time: 391.97622561454773
2022-01-19 02:07:46,641 - INFO - 
Epoch: 84
2022-01-19 02:07:46,641 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:08:39,188 - INFO - [Step=70250]	Loss=0.4791	258.2 examples/second
2022-01-19 02:10:34,674 - INFO - [Step=70500]	Loss=0.4781	277.1 examples/second
2022-01-19 02:12:30,432 - INFO - [Step=70750]	Loss=0.4786	276.4 examples/second
2022-01-19 02:14:21,892 - INFO - Test Loss=0.8008, Test top-1 acc=0.8135
2022-01-19 02:14:21,892 - INFO - Group Accuracy:

2022-01-19 02:14:21,892 - INFO - [0.9804819  0.99108434 0.98771083 0.9927711  0.9860241  0.99493974
 0.9812048  0.9840964  0.9891566  0.9773494  0.9913253  0.98771083
 0.9771084  0.98313254 0.9780723  0.9891566  0.9966265 ]
2022-01-19 02:14:21,893 - INFO - Epoch time: 395.2526812553406
2022-01-19 02:14:21,893 - INFO - 
Epoch: 85
2022-01-19 02:14:21,893 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:14:35,456 - INFO - [Step=71000]	Loss=0.4777	256.0 examples/second
2022-01-19 02:16:30,648 - INFO - [Step=71250]	Loss=0.5031	277.8 examples/second
2022-01-19 02:18:25,793 - INFO - [Step=71500]	Loss=0.4903	277.9 examples/second
2022-01-19 02:20:21,175 - INFO - [Step=71750]	Loss=0.4839	277.3 examples/second
2022-01-19 02:20:55,885 - INFO - Test Loss=0.8106, Test top-1 acc=0.8096
2022-01-19 02:20:55,886 - INFO - Group Accuracy:

2022-01-19 02:20:55,886 - INFO - [0.9807229  0.9913253  0.98771083 0.9930121  0.98650604 0.99493974
 0.9809638  0.98289156 0.9898795  0.9773494  0.99060243 0.98698795
 0.9771084  0.98240966 0.97927713 0.98963857 0.9966265 ]
2022-01-19 02:20:55,887 - INFO - Epoch time: 393.9931182861328
2022-01-19 02:20:55,887 - INFO - 
Epoch: 86
2022-01-19 02:20:55,887 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:22:24,836 - INFO - [Step=72000]	Loss=0.4730	258.8 examples/second
2022-01-19 02:24:19,445 - INFO - [Step=72250]	Loss=0.4929	279.2 examples/second
2022-01-19 02:26:14,136 - INFO - [Step=72500]	Loss=0.4798	279.0 examples/second
2022-01-19 02:27:28,057 - INFO - Test Loss=0.8020, Test top-1 acc=0.8111
2022-01-19 02:27:28,058 - INFO - Group Accuracy:

2022-01-19 02:27:28,058 - INFO - [0.98024094 0.99084336 0.98771083 0.993253   0.9860241  0.99493974
 0.9809638  0.9833735  0.9898795  0.9773494  0.99156624 0.98722893
 0.97831327 0.98289156 0.9780723  0.9884337  0.9966265 ]
2022-01-19 02:27:28,059 - INFO - Epoch time: 392.1720564365387
2022-01-19 02:27:28,059 - INFO - 
Epoch: 87
2022-01-19 02:27:28,059 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:28:18,276 - INFO - [Step=72750]	Loss=0.4854	257.8 examples/second
2022-01-19 02:30:13,254 - INFO - [Step=73000]	Loss=0.4729	278.3 examples/second
2022-01-19 02:32:08,106 - INFO - [Step=73250]	Loss=0.4733	278.6 examples/second
2022-01-19 02:34:00,426 - INFO - Test Loss=0.8058, Test top-1 acc=0.8125
2022-01-19 02:34:00,426 - INFO - Group Accuracy:

2022-01-19 02:34:00,426 - INFO - [0.9812048  0.9913253  0.98771083 0.993253   0.9860241  0.9951807
 0.9819277  0.98361444 0.9891566  0.97638553 0.9920482  0.98650604
 0.9773494  0.9833735  0.9787952  0.9891566  0.9966265 ]
2022-01-19 02:34:00,428 - INFO - Epoch time: 392.3688266277313
2022-01-19 02:34:00,428 - INFO - 
Epoch: 88
2022-01-19 02:34:00,428 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:34:11,334 - INFO - [Step=73500]	Loss=0.4767	259.7 examples/second
2022-01-19 02:36:07,599 - INFO - [Step=73750]	Loss=0.4753	275.2 examples/second
2022-01-19 02:38:03,896 - INFO - [Step=74000]	Loss=0.4699	275.2 examples/second
2022-01-19 02:40:00,341 - INFO - [Step=74250]	Loss=0.4805	274.8 examples/second
2022-01-19 02:40:37,826 - INFO - Test Loss=0.8085, Test top-1 acc=0.8104
2022-01-19 02:40:37,827 - INFO - Group Accuracy:

2022-01-19 02:40:37,827 - INFO - [0.9807229  0.99108434 0.98771083 0.9930121  0.98578316 0.99493974
 0.9814458  0.9833735  0.99036145 0.9771084  0.99108434 0.98722893
 0.9775904  0.9812048  0.97927713 0.9879518  0.9963855 ]
2022-01-19 02:40:37,827 - INFO - Epoch time: 397.39961671829224
2022-01-19 02:40:37,827 - INFO - 
Epoch: 89
2022-01-19 02:40:37,827 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:42:05,759 - INFO - [Step=74500]	Loss=0.4763	255.1 examples/second
2022-01-19 02:44:01,759 - INFO - [Step=74750]	Loss=0.4621	275.9 examples/second
2022-01-19 02:45:57,931 - INFO - [Step=75000]	Loss=0.4852	275.5 examples/second
2022-01-19 02:47:15,166 - INFO - Test Loss=0.8062, Test top-1 acc=0.8111
2022-01-19 02:47:15,166 - INFO - Group Accuracy:

2022-01-19 02:47:15,166 - INFO - [0.9809638  0.99156624 0.9884337  0.9922892  0.98578316 0.9946988
 0.9816868  0.9838554  0.9893976  0.97614455 0.99060243 0.98626506
 0.9785542  0.98289156 0.97903615 0.9889157  0.9966265 ]
2022-01-19 02:47:15,167 - INFO - Epoch time: 397.3400218486786
2022-01-19 02:47:24,944 - INFO - Computing OOD Statistics...
2022-01-19 02:47:24,952 - INFO - 	Baseline.          AUROC: 0.3565. TNR@95TPR: 0.0153. AUPR OUT: 0.1257
2022-01-19 02:47:24,958 - INFO - 	ODIN (T=1000).     AUROC: 0.9008. TNR@95TPR: 0.5306. AUPR OUT: 0.6655
2022-01-19 02:47:24,958 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 02:47:24,958 - INFO - Top 1 Accuracy:  Min: 0.8178; Max: 0.8178; Avg: 0.8178; Std: 0.0000; Len: 1
2022-01-19 02:47:24,958 - INFO - Top 5 Accuracy:  Min: 0.9867; Max: 0.9867; Avg: 0.9867; Std: 0.0000; Len: 1
2022-01-19 02:47:24,958 - INFO - **********************************************************************
2022-01-19 02:47:24,958 - INFO - 	MSP (auroc): [0.3565499645641389] Min: 0.3565; Max: 0.3565; Avg: 0.3565; Std: 0.0000; Len: 1
2022-01-19 02:47:24,959 - INFO - 	MSP (tnr): [0.015294117647058791] Min: 0.0153; Max: 0.0153; Avg: 0.0153; Std: 0.0000; Len: 1
2022-01-19 02:47:24,959 - INFO - 	MSP (aupr): [0.12565246577878053] Min: 0.1257; Max: 0.1257; Avg: 0.1257; Std: 0.0000; Len: 1
2022-01-19 02:47:24,959 - INFO - 	ODIN (auroc): [0.9007727852586819] Min: 0.9008; Max: 0.9008; Avg: 0.9008; Std: 0.0000; Len: 1
2022-01-19 02:47:24,959 - INFO - 	ODIN (tnr): [0.5305882352941176] Min: 0.5306; Max: 0.5306; Avg: 0.5306; Std: 0.0000; Len: 1
2022-01-19 02:47:24,959 - INFO - 	ODIN (aupr): [0.6654929257058625] Min: 0.6655; Max: 0.6655; Avg: 0.6655; Std: 0.0000; Len: 1

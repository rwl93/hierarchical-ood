2022-01-19 15:16:39,151 - INFO - ==> Preparing data..
2022-01-19 15:16:39,519 - INFO - checkpoint filename: experiments/coarse/mos/FC4_LRp1_R1/checkpoint.pt
2022-01-19 15:16:39,520 - INFO - log filename: experiments/coarse/mos/FC4_LRp1_R1/train.log
2022-01-19 15:16:39,520 - INFO - ********************************************************
2022-01-19 15:16:39,520 - INFO - Starting Iter: 0 / 1
2022-01-19 15:16:39,520 - INFO - ********************************************************
2022-01-19 15:16:42,572 - INFO - cuda
2022-01-19 15:16:42,612 - INFO - 
Epoch: 0
2022-01-19 15:16:42,612 - INFO - 
Learning Rate: 0.0100
2022-01-19 15:18:40,568 - INFO - [Step=250]	Loss=7.1709	271.3 examples/second
2022-01-19 15:20:36,232 - INFO - [Step=500]	Loss=5.4272	276.7 examples/second
2022-01-19 15:22:31,996 - INFO - [Step=750]	Loss=5.2943	276.4 examples/second
2022-01-19 15:23:18,728 - INFO - Test Loss=5.0885, Test top-1 acc=0.0533
2022-01-19 15:23:18,729 - INFO - Group Accuracy:

2022-01-19 15:23:18,729 - INFO - [0.939759   0.939759   0.939759   0.93807226 0.939759   0.939759
 0.9395181  0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.939759   0.9518072 ]
2022-01-19 15:23:18,730 - INFO - Saving...
2022-01-19 15:23:18,873 - INFO - Epoch time: 396.26105213165283
2022-01-19 15:23:18,873 - INFO - 
Epoch: 1
2022-01-19 15:23:18,873 - INFO - 
Learning Rate: 0.0280
2022-01-19 15:24:37,232 - INFO - [Step=1000]	Loss=5.1335	255.5 examples/second
2022-01-19 15:26:33,184 - INFO - [Step=1250]	Loss=4.9555	276.0 examples/second
2022-01-19 15:28:29,024 - INFO - [Step=1500]	Loss=4.7790	276.2 examples/second
2022-01-19 15:29:55,297 - INFO - Test Loss=4.5003, Test top-1 acc=0.1436
2022-01-19 15:29:55,297 - INFO - Group Accuracy:

2022-01-19 15:29:55,297 - INFO - [0.939759  0.9395181 0.939759  0.9433735 0.939759  0.94      0.9404819
 0.939759  0.9392771 0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-19 15:29:55,298 - INFO - Saving...
2022-01-19 15:29:55,545 - INFO - Epoch time: 396.67166543006897
2022-01-19 15:29:55,545 - INFO - 
Epoch: 2
2022-01-19 15:29:55,545 - INFO - 
Learning Rate: 0.0460
2022-01-19 15:30:34,764 - INFO - [Step=1750]	Loss=4.6498	254.5 examples/second
2022-01-19 15:32:30,562 - INFO - [Step=2000]	Loss=4.5308	276.3 examples/second
2022-01-19 15:34:25,948 - INFO - [Step=2250]	Loss=4.3164	277.3 examples/second
2022-01-19 15:36:21,676 - INFO - [Step=2500]	Loss=4.1496	276.5 examples/second
2022-01-19 15:36:31,306 - INFO - Test Loss=3.8463, Test top-1 acc=0.2451
2022-01-19 15:36:31,306 - INFO - Group Accuracy:

2022-01-19 15:36:31,307 - INFO - [0.94192773 0.9407229  0.940241   0.9539759  0.94168675 0.9508434
 0.94144577 0.94120485 0.9448193  0.939759   0.95373493 0.94096386
 0.9404819  0.939759   0.939759   0.94096386 0.95253015]
2022-01-19 15:36:31,308 - INFO - Saving...
2022-01-19 15:36:31,554 - INFO - Epoch time: 396.00894355773926
2022-01-19 15:36:31,554 - INFO - 
Epoch: 3
2022-01-19 15:36:31,554 - INFO - 
Learning Rate: 0.0640
2022-01-19 15:38:27,776 - INFO - [Step=2750]	Loss=4.0466	253.8 examples/second
2022-01-19 15:40:23,862 - INFO - [Step=3000]	Loss=3.9214	275.7 examples/second
2022-01-19 15:42:19,996 - INFO - [Step=3250]	Loss=3.7646	275.5 examples/second
2022-01-19 15:43:09,316 - INFO - Test Loss=3.6505, Test top-1 acc=0.2737
2022-01-19 15:43:09,316 - INFO - Group Accuracy:

2022-01-19 15:43:09,316 - INFO - [0.9440964  0.93807226 0.9407229  0.9544578  0.94120485 0.95421684
 0.9433735  0.9479518  0.9474699  0.9404819  0.9486747  0.94144577
 0.9404819  0.9404819  0.9395181  0.94433737 0.95975906]
2022-01-19 15:43:09,317 - INFO - Saving...
2022-01-19 15:43:09,603 - INFO - Epoch time: 398.04859042167664
2022-01-19 15:43:09,603 - INFO - 
Epoch: 4
2022-01-19 15:43:09,603 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:44:25,809 - INFO - [Step=3500]	Loss=3.8014	254.3 examples/second
2022-01-19 15:46:21,886 - INFO - [Step=3750]	Loss=3.6844	275.7 examples/second
2022-01-19 15:48:18,139 - INFO - [Step=4000]	Loss=3.5407	275.3 examples/second
2022-01-19 15:49:46,958 - INFO - Test Loss=3.6068, Test top-1 acc=0.2916
2022-01-19 15:49:46,958 - INFO - Group Accuracy:

2022-01-19 15:49:46,959 - INFO - [0.9433735  0.9453012  0.94216865 0.9561446  0.9407229  0.9561446
 0.9313253  0.9481928  0.9546988  0.94096386 0.95228916 0.94120485
 0.939759   0.93783134 0.94216865 0.9501205  0.9510843 ]
2022-01-19 15:49:46,959 - INFO - Saving...
2022-01-19 15:49:47,142 - INFO - Epoch time: 397.5391478538513
2022-01-19 15:49:47,142 - INFO - 
Epoch: 5
2022-01-19 15:49:47,142 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:50:23,734 - INFO - [Step=4250]	Loss=3.4113	254.8 examples/second
2022-01-19 15:52:19,702 - INFO - [Step=4500]	Loss=3.2773	275.9 examples/second
2022-01-19 15:54:15,473 - INFO - [Step=4750]	Loss=3.1543	276.4 examples/second
2022-01-19 15:56:11,332 - INFO - [Step=5000]	Loss=3.0985	276.2 examples/second
2022-01-19 15:56:23,313 - INFO - Test Loss=3.1935, Test top-1 acc=0.3723
2022-01-19 15:56:23,314 - INFO - Group Accuracy:

2022-01-19 15:56:23,314 - INFO - [0.9445783  0.9520482  0.9453012  0.9653012  0.9433735  0.9440964
 0.94506025 0.9520482  0.9592771  0.94843376 0.95277107 0.9436145
 0.94144577 0.9433735  0.9286747  0.94891566 0.96891564]
2022-01-19 15:56:23,314 - INFO - Saving...
2022-01-19 15:56:23,497 - INFO - Epoch time: 396.35469484329224
2022-01-19 15:56:23,497 - INFO - 
Epoch: 6
2022-01-19 15:56:23,497 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:58:16,131 - INFO - [Step=5250]	Loss=3.0445	256.4 examples/second
2022-01-19 16:00:10,761 - INFO - [Step=5500]	Loss=2.9100	279.2 examples/second
2022-01-19 16:02:05,609 - INFO - [Step=5750]	Loss=2.8277	278.6 examples/second
2022-01-19 16:02:56,699 - INFO - Test Loss=2.8073, Test top-1 acc=0.4260
2022-01-19 16:02:56,699 - INFO - Group Accuracy:

2022-01-19 16:02:56,709 - INFO - [0.9474699  0.95662653 0.94915664 0.9653012  0.94963855 0.973494
 0.95228916 0.9469879  0.9551807  0.9472289  0.9612048  0.94963855
 0.94168675 0.94433737 0.94289154 0.9578313  0.9737349 ]
2022-01-19 16:02:56,710 - INFO - Saving...
2022-01-19 16:02:56,968 - INFO - Epoch time: 393.47118520736694
2022-01-19 16:02:56,968 - INFO - 
Epoch: 7
2022-01-19 16:02:56,969 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:04:10,560 - INFO - [Step=6000]	Loss=2.7474	256.1 examples/second
2022-01-19 16:06:06,155 - INFO - [Step=6250]	Loss=2.6788	276.8 examples/second
2022-01-19 16:08:01,825 - INFO - [Step=6500]	Loss=2.6379	276.7 examples/second
2022-01-19 16:09:32,422 - INFO - Test Loss=2.7087, Test top-1 acc=0.4561
2022-01-19 16:09:32,423 - INFO - Group Accuracy:

2022-01-19 16:09:32,423 - INFO - [0.9561446  0.9621687  0.9498795  0.96819276 0.94433737 0.9771084
 0.9453012  0.9587952  0.9339759  0.9518072  0.9660241  0.9583132
 0.9433735  0.9460241  0.9469879  0.9551807  0.97301203]
2022-01-19 16:09:32,424 - INFO - Saving...
2022-01-19 16:09:32,672 - INFO - Epoch time: 395.7039563655853
2022-01-19 16:09:32,673 - INFO - 
Epoch: 8
2022-01-19 16:09:32,673 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:10:06,853 - INFO - [Step=6750]	Loss=2.5547	255.9 examples/second
2022-01-19 16:12:02,631 - INFO - [Step=7000]	Loss=2.4999	276.4 examples/second
2022-01-19 16:13:58,371 - INFO - [Step=7250]	Loss=2.4675	276.5 examples/second
2022-01-19 16:15:54,097 - INFO - [Step=7500]	Loss=2.4242	276.5 examples/second
2022-01-19 16:16:08,249 - INFO - Test Loss=2.2500, Test top-1 acc=0.5207
2022-01-19 16:16:08,249 - INFO - Group Accuracy:

2022-01-19 16:16:08,249 - INFO - [0.9554217  0.96096385 0.95349395 0.9766265  0.9513253  0.97975904
 0.9549398  0.9633735  0.9737349  0.95373493 0.96457833 0.9631325
 0.9501205  0.9474699  0.9486747  0.9590362  0.9816868 ]
2022-01-19 16:16:08,250 - INFO - Saving...
2022-01-19 16:16:08,501 - INFO - Epoch time: 395.8280990123749
2022-01-19 16:16:08,501 - INFO - 
Epoch: 9
2022-01-19 16:16:08,501 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:17:59,091 - INFO - [Step=7750]	Loss=2.3358	256.0 examples/second
2022-01-19 16:19:54,634 - INFO - [Step=8000]	Loss=2.3180	277.0 examples/second
2022-01-19 16:21:50,234 - INFO - [Step=8250]	Loss=2.2867	276.8 examples/second
2022-01-19 16:22:43,722 - INFO - Test Loss=2.2951, Test top-1 acc=0.5159
2022-01-19 16:22:43,722 - INFO - Group Accuracy:

2022-01-19 16:22:43,722 - INFO - [0.9498795  0.96168673 0.95686746 0.97590363 0.9592771  0.98
 0.95710844 0.9621687  0.973494   0.9506024  0.96168673 0.95662653
 0.94891566 0.946747   0.9544578  0.96409637 0.98      ]
2022-01-19 16:22:43,723 - INFO - Epoch time: 395.22232723236084
2022-01-19 16:22:43,723 - INFO - 
Epoch: 10
2022-01-19 16:22:43,724 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:23:54,559 - INFO - [Step=8500]	Loss=2.2634	257.4 examples/second
2022-01-19 16:25:49,299 - INFO - [Step=8750]	Loss=2.1803	278.9 examples/second
2022-01-19 16:27:44,242 - INFO - [Step=9000]	Loss=2.1738	278.4 examples/second
2022-01-19 16:29:16,506 - INFO - Test Loss=2.1849, Test top-1 acc=0.5328
2022-01-19 16:29:16,507 - INFO - Group Accuracy:

2022-01-19 16:29:16,507 - INFO - [0.9633735  0.9693976  0.9474699  0.9771084  0.9546988  0.98289156
 0.95421684 0.9472289  0.96361446 0.96385545 0.9701205  0.95975906
 0.9445783  0.9501205  0.95638555 0.9660241  0.97927713]
2022-01-19 16:29:16,508 - INFO - Saving...
2022-01-19 16:29:16,749 - INFO - Epoch time: 393.02595925331116
2022-01-19 16:29:16,750 - INFO - 
Epoch: 11
2022-01-19 16:29:16,750 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:29:48,828 - INFO - [Step=9250]	Loss=2.1461	256.9 examples/second
2022-01-19 16:31:44,193 - INFO - [Step=9500]	Loss=2.1093	277.4 examples/second
2022-01-19 16:33:39,464 - INFO - [Step=9750]	Loss=2.0870	277.6 examples/second
2022-01-19 16:35:34,901 - INFO - [Step=10000]	Loss=2.0638	277.2 examples/second
2022-01-19 16:35:51,303 - INFO - Test Loss=2.0388, Test top-1 acc=0.5648
2022-01-19 16:35:51,303 - INFO - Group Accuracy:

2022-01-19 16:35:51,303 - INFO - [0.9614458  0.9693976  0.95036143 0.9785542  0.96024096 0.98289156
 0.9626506  0.966747   0.97831327 0.9498795  0.9698795  0.95686746
 0.9508434  0.9549398  0.9561446  0.96433735 0.9848193 ]
2022-01-19 16:35:51,305 - INFO - Saving...
2022-01-19 16:35:51,580 - INFO - Epoch time: 394.8298919200897
2022-01-19 16:35:51,580 - INFO - 
Epoch: 12
2022-01-19 16:35:51,580 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:37:39,648 - INFO - [Step=10250]	Loss=1.9922	256.5 examples/second
2022-01-19 16:39:34,938 - INFO - [Step=10500]	Loss=2.0090	277.6 examples/second
2022-01-19 16:41:30,218 - INFO - [Step=10750]	Loss=1.9811	277.6 examples/second
2022-01-19 16:42:26,033 - INFO - Test Loss=1.8367, Test top-1 acc=0.6043
2022-01-19 16:42:26,034 - INFO - Group Accuracy:

2022-01-19 16:42:26,034 - INFO - [0.96481925 0.97493976 0.96024096 0.97831327 0.96481925 0.9812048
 0.96024096 0.9693976  0.97228914 0.9660241  0.9766265  0.9633735
 0.95253015 0.9520482  0.95975906 0.96843374 0.98313254]
2022-01-19 16:42:26,035 - INFO - Saving...
2022-01-19 16:42:26,277 - INFO - Epoch time: 394.6972031593323
2022-01-19 16:42:26,277 - INFO - 
Epoch: 13
2022-01-19 16:42:26,277 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:43:35,054 - INFO - [Step=11000]	Loss=1.9551	256.3 examples/second
2022-01-19 16:45:29,665 - INFO - [Step=11250]	Loss=1.8819	279.2 examples/second
2022-01-19 16:47:24,190 - INFO - [Step=11500]	Loss=1.9091	279.4 examples/second
2022-01-19 16:48:58,789 - INFO - Test Loss=1.8885, Test top-1 acc=0.6005
2022-01-19 16:48:58,790 - INFO - Group Accuracy:

2022-01-19 16:48:58,790 - INFO - [0.96       0.9701205  0.9626506  0.97638553 0.96072286 0.98433733
 0.9628916  0.96433735 0.98024094 0.95975906 0.9742169  0.96795183
 0.9559036  0.95662653 0.9583132  0.9701205  0.9845783 ]
2022-01-19 16:48:58,791 - INFO - Epoch time: 392.513391494751
2022-01-19 16:48:58,791 - INFO - 
Epoch: 14
2022-01-19 16:48:58,791 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:49:28,468 - INFO - [Step=11750]	Loss=1.8858	257.5 examples/second
2022-01-19 16:51:23,779 - INFO - [Step=12000]	Loss=1.8511	277.5 examples/second
2022-01-19 16:53:18,968 - INFO - [Step=12250]	Loss=1.8568	277.8 examples/second
2022-01-19 16:55:14,373 - INFO - [Step=12500]	Loss=1.8381	277.3 examples/second
2022-01-19 16:55:33,490 - INFO - Test Loss=1.7178, Test top-1 acc=0.6173
2022-01-19 16:55:33,491 - INFO - Group Accuracy:

2022-01-19 16:55:33,491 - INFO - [0.9657831  0.9766265  0.9624096  0.9826506  0.9592771  0.98674697
 0.9592771  0.9633735  0.97566265 0.96481925 0.9775904  0.9703615
 0.9590362  0.95349395 0.9585542  0.9725301  0.9881928 ]
2022-01-19 16:55:33,492 - INFO - Saving...
2022-01-19 16:55:33,744 - INFO - Epoch time: 394.95369505882263
2022-01-19 16:55:33,745 - INFO - 
Epoch: 15
2022-01-19 16:55:33,745 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:57:19,415 - INFO - [Step=12750]	Loss=1.7755	255.9 examples/second
2022-01-19 16:59:14,882 - INFO - [Step=13000]	Loss=1.7977	277.1 examples/second
2022-01-19 17:01:10,499 - INFO - [Step=13250]	Loss=1.7741	276.8 examples/second
2022-01-19 17:02:08,817 - INFO - Test Loss=1.7771, Test top-1 acc=0.6120
2022-01-19 17:02:08,818 - INFO - Group Accuracy:

2022-01-19 17:02:08,818 - INFO - [0.9633735  0.97638553 0.9691566  0.97204816 0.96506023 0.98578316
 0.9592771  0.96819276 0.9737349  0.9660241  0.97614455 0.97228914
 0.9549398  0.9580723  0.9561446  0.96843374 0.9833735 ]
2022-01-19 17:02:08,819 - INFO - Epoch time: 395.0746786594391
2022-01-19 17:02:08,820 - INFO - 
Epoch: 16
2022-01-19 17:02:08,820 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:03:15,098 - INFO - [Step=13500]	Loss=1.7525	256.8 examples/second
2022-01-19 17:05:09,509 - INFO - [Step=13750]	Loss=1.7489	279.7 examples/second
2022-01-19 17:07:04,130 - INFO - [Step=14000]	Loss=1.7578	279.2 examples/second
2022-01-19 17:08:40,862 - INFO - Test Loss=1.6715, Test top-1 acc=0.6347
2022-01-19 17:08:40,863 - INFO - Group Accuracy:

2022-01-19 17:08:40,863 - INFO - [0.9703615  0.9633735  0.96409637 0.9812048  0.96506023 0.9884337
 0.9626506  0.9701205  0.9809638  0.9674699  0.97301203 0.96843374
 0.95253015 0.9583132  0.96361446 0.9737349  0.9850602 ]
2022-01-19 17:08:40,864 - INFO - Saving...
2022-01-19 17:08:41,047 - INFO - Epoch time: 392.227352142334
2022-01-19 17:08:41,047 - INFO - 
Epoch: 17
2022-01-19 17:08:41,047 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:09:08,335 - INFO - [Step=14250]	Loss=1.7000	257.6 examples/second
2022-01-19 17:11:03,717 - INFO - [Step=14500]	Loss=1.7107	277.3 examples/second
2022-01-19 17:12:59,036 - INFO - [Step=14750]	Loss=1.6716	277.5 examples/second
2022-01-19 17:14:54,428 - INFO - [Step=15000]	Loss=1.6896	277.3 examples/second
2022-01-19 17:15:15,506 - INFO - Test Loss=1.8106, Test top-1 acc=0.6159
2022-01-19 17:15:15,506 - INFO - Group Accuracy:

2022-01-19 17:15:15,506 - INFO - [0.95975906 0.973253   0.94915664 0.9833735  0.96843374 0.9809638
 0.96433735 0.9713253  0.97566265 0.9691566  0.96843374 0.97228914
 0.9544578  0.95710844 0.9619277  0.96048194 0.9898795 ]
2022-01-19 17:15:15,507 - INFO - Epoch time: 394.46007108688354
2022-01-19 17:15:15,507 - INFO - 
Epoch: 18
2022-01-19 17:15:15,507 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:16:59,032 - INFO - [Step=15250]	Loss=1.6654	256.8 examples/second
2022-01-19 17:18:54,754 - INFO - [Step=15500]	Loss=1.6712	276.5 examples/second
2022-01-19 17:20:50,540 - INFO - [Step=15750]	Loss=1.6654	276.4 examples/second
2022-01-19 17:21:51,026 - INFO - Test Loss=1.6981, Test top-1 acc=0.6186
2022-01-19 17:21:51,026 - INFO - Group Accuracy:

2022-01-19 17:21:51,026 - INFO - [0.96843374 0.9674699  0.96771085 0.9848193  0.95975906 0.98771083
 0.95759034 0.9739759  0.97518075 0.96891564 0.97204816 0.96891564
 0.95759034 0.95373493 0.96385545 0.97156626 0.9850602 ]
2022-01-19 17:21:51,027 - INFO - Epoch time: 395.5201449394226
2022-01-19 17:21:51,028 - INFO - 
Epoch: 19
2022-01-19 17:21:51,028 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:22:55,292 - INFO - [Step=16000]	Loss=1.6309	256.5 examples/second
2022-01-19 17:24:50,775 - INFO - [Step=16250]	Loss=1.6378	277.1 examples/second
2022-01-19 17:26:46,155 - INFO - [Step=16500]	Loss=1.6094	277.3 examples/second
2022-01-19 17:28:25,979 - INFO - Test Loss=2.0473, Test top-1 acc=0.5788
2022-01-19 17:28:25,979 - INFO - Group Accuracy:

2022-01-19 17:28:25,979 - INFO - [0.96048194 0.9725301  0.95686746 0.97204816 0.96409637 0.98626506
 0.9621687  0.9614458  0.97590363 0.9655422  0.9706024  0.96819276
 0.95036143 0.940241   0.95710844 0.9706024  0.9812048 ]
2022-01-19 17:28:25,981 - INFO - Epoch time: 394.9533095359802
2022-01-19 17:28:25,981 - INFO - 
Epoch: 20
2022-01-19 17:28:25,981 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:28:50,657 - INFO - [Step=16750]	Loss=1.5987	257.0 examples/second
2022-01-19 17:30:45,697 - INFO - [Step=17000]	Loss=1.5970	278.2 examples/second
2022-01-19 17:32:40,946 - INFO - [Step=17250]	Loss=1.6029	277.7 examples/second
2022-01-19 17:34:36,374 - INFO - [Step=17500]	Loss=1.6075	277.2 examples/second
2022-01-19 17:35:00,006 - INFO - Test Loss=2.2963, Test top-1 acc=0.6222
2022-01-19 17:35:00,006 - INFO - Group Accuracy:

2022-01-19 17:35:00,006 - INFO - [0.9631325  0.973253   0.96795183 0.98433733 0.96433735 0.98361444
 0.96409637 0.9657831  0.9804819  0.9633735  0.9725301  0.9706024
 0.9583132  0.9633735  0.9624096  0.97301203 0.98626506]
2022-01-19 17:35:00,007 - INFO - Epoch time: 394.0259048938751
2022-01-19 17:35:00,007 - INFO - 
Epoch: 21
2022-01-19 17:35:00,007 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:36:41,555 - INFO - [Step=17750]	Loss=1.5647	255.6 examples/second
2022-01-19 17:38:37,626 - INFO - [Step=18000]	Loss=1.5676	275.7 examples/second
2022-01-19 17:40:33,676 - INFO - [Step=18250]	Loss=1.5795	275.7 examples/second
2022-01-19 17:41:36,553 - INFO - Test Loss=1.5069, Test top-1 acc=0.6576
2022-01-19 17:41:36,553 - INFO - Group Accuracy:

2022-01-19 17:41:36,553 - INFO - [0.96506023 0.9686747  0.97108436 0.9855422  0.97180724 0.98722893
 0.96409637 0.97156626 0.9850602  0.9698795  0.9785542  0.973494
 0.9595181  0.9628916  0.9628916  0.97566265 0.9886747 ]
2022-01-19 17:41:36,554 - INFO - Saving...
2022-01-19 17:41:36,845 - INFO - Epoch time: 396.838299036026
2022-01-19 17:41:36,846 - INFO - 
Epoch: 22
2022-01-19 17:41:36,846 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:42:38,868 - INFO - [Step=18500]	Loss=1.5479	255.6 examples/second
2022-01-19 17:44:34,216 - INFO - [Step=18750]	Loss=1.5310	277.4 examples/second
2022-01-19 17:46:29,716 - INFO - [Step=19000]	Loss=1.5465	277.1 examples/second
2022-01-19 17:48:11,709 - INFO - Test Loss=1.7707, Test top-1 acc=0.6383
2022-01-19 17:48:11,710 - INFO - Group Accuracy:

2022-01-19 17:48:11,710 - INFO - [0.9662651  0.9773494  0.9660241  0.98746985 0.9633735  0.9855422
 0.96481925 0.96361446 0.98       0.9619277  0.9725301  0.96698797
 0.9592771  0.96       0.9612048  0.9737349  0.9898795 ]
2022-01-19 17:48:11,711 - INFO - Epoch time: 394.8650748729706
2022-01-19 17:48:11,711 - INFO - 
Epoch: 23
2022-01-19 17:48:11,711 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:48:34,307 - INFO - [Step=19250]	Loss=1.5266	256.8 examples/second
2022-01-19 17:50:30,051 - INFO - [Step=19500]	Loss=1.4949	276.5 examples/second
2022-01-19 17:52:25,366 - INFO - [Step=19750]	Loss=1.5227	277.5 examples/second
2022-01-19 17:54:21,103 - INFO - [Step=20000]	Loss=1.5233	276.5 examples/second
2022-01-19 17:54:46,915 - INFO - Test Loss=1.7147, Test top-1 acc=0.6243
2022-01-19 17:54:46,916 - INFO - Group Accuracy:

2022-01-19 17:54:46,916 - INFO - [0.95710844 0.95662653 0.9662651  0.9845783  0.9674699  0.9860241
 0.96385545 0.9696385  0.9850602  0.9578313  0.9739759  0.9672289
 0.9628916  0.96433735 0.95975906 0.97301203 0.98650604]
2022-01-19 17:54:46,918 - INFO - Epoch time: 395.20685338974
2022-01-19 17:54:46,918 - INFO - 
Epoch: 24
2022-01-19 17:54:46,918 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:56:25,155 - INFO - [Step=20250]	Loss=1.4743	258.0 examples/second
2022-01-19 17:58:20,042 - INFO - [Step=20500]	Loss=1.4825	278.5 examples/second
2022-01-19 18:00:14,669 - INFO - [Step=20750]	Loss=1.4868	279.2 examples/second
2022-01-19 18:01:19,306 - INFO - Test Loss=1.4921, Test top-1 acc=0.6687
2022-01-19 18:01:19,306 - INFO - Group Accuracy:

2022-01-19 18:01:19,306 - INFO - [0.96843374 0.9812048  0.97204816 0.9848193  0.97301203 0.99036145
 0.96771085 0.97590363 0.9804819  0.96771085 0.9778313  0.97228914
 0.9631325  0.96481925 0.9561446  0.97542167 0.98626506]
2022-01-19 18:01:19,307 - INFO - Saving...
2022-01-19 18:01:19,577 - INFO - Epoch time: 392.6594150066376
2022-01-19 18:01:19,577 - INFO - 
Epoch: 25
2022-01-19 18:01:19,577 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:02:19,251 - INFO - [Step=21000]	Loss=1.4610	256.9 examples/second
2022-01-19 18:04:14,689 - INFO - [Step=21250]	Loss=1.4608	277.2 examples/second
2022-01-19 18:06:09,976 - INFO - [Step=21500]	Loss=1.4983	277.6 examples/second
2022-01-19 18:07:54,341 - INFO - Test Loss=1.5527, Test top-1 acc=0.6583
2022-01-19 18:07:54,342 - INFO - Group Accuracy:

2022-01-19 18:07:54,342 - INFO - [0.97156626 0.9840964  0.9653012  0.98698795 0.9708434  0.9881928
 0.9573494  0.9737349  0.98289156 0.96024096 0.9814458  0.9660241
 0.96048194 0.96       0.9631325  0.97614455 0.9913253 ]
2022-01-19 18:07:54,343 - INFO - Epoch time: 394.76590847969055
2022-01-19 18:07:54,343 - INFO - 
Epoch: 26
2022-01-19 18:07:54,343 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:08:14,770 - INFO - [Step=21750]	Loss=1.4809	256.4 examples/second
2022-01-19 18:10:10,386 - INFO - [Step=22000]	Loss=1.4434	276.8 examples/second
2022-01-19 18:12:05,831 - INFO - [Step=22250]	Loss=1.4521	277.2 examples/second
2022-01-19 18:14:01,392 - INFO - [Step=22500]	Loss=1.4717	276.9 examples/second
2022-01-19 18:14:29,559 - INFO - Test Loss=1.6134, Test top-1 acc=0.6427
2022-01-19 18:14:29,559 - INFO - Group Accuracy:

2022-01-19 18:14:29,559 - INFO - [0.9686747  0.9771084  0.9674699  0.9819277  0.9693976  0.98698795
 0.96385545 0.96385545 0.9812048  0.96819276 0.9766265  0.9737349
 0.96072286 0.95759034 0.9614458  0.97614455 0.98963857]
2022-01-19 18:14:29,560 - INFO - Epoch time: 395.21692633628845
2022-01-19 18:14:29,560 - INFO - 
Epoch: 27
2022-01-19 18:14:29,560 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:16:05,972 - INFO - [Step=22750]	Loss=1.4187	256.9 examples/second
2022-01-19 18:18:01,730 - INFO - [Step=23000]	Loss=1.4187	276.4 examples/second
2022-01-19 18:19:57,500 - INFO - [Step=23250]	Loss=1.4358	276.4 examples/second
2022-01-19 18:21:05,057 - INFO - Test Loss=1.7716, Test top-1 acc=0.6361
2022-01-19 18:21:05,058 - INFO - Group Accuracy:

2022-01-19 18:21:05,058 - INFO - [0.9686747  0.9766265  0.97228914 0.9812048  0.9691566  0.98650604
 0.9660241  0.9612048  0.97228914 0.966506   0.973494   0.966506
 0.9554217  0.9621687  0.95373493 0.97156626 0.9838554 ]
2022-01-19 18:21:05,059 - INFO - Epoch time: 395.4982190132141
2022-01-19 18:21:05,059 - INFO - 
Epoch: 28
2022-01-19 18:21:05,059 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:22:02,350 - INFO - [Step=23500]	Loss=1.4328	256.3 examples/second
2022-01-19 18:23:58,095 - INFO - [Step=23750]	Loss=1.4069	276.5 examples/second
2022-01-19 18:25:53,737 - INFO - [Step=24000]	Loss=1.4328	276.7 examples/second
2022-01-19 18:27:40,654 - INFO - Test Loss=1.5206, Test top-1 acc=0.6706
2022-01-19 18:27:40,654 - INFO - Group Accuracy:

2022-01-19 18:27:40,654 - INFO - [0.9713253  0.9809638  0.96819276 0.9838554  0.9701205  0.9855422
 0.9708434  0.97614455 0.9833735  0.9701205  0.9787952  0.97204816
 0.9573494  0.966506   0.9628916  0.97445786 0.9898795 ]
2022-01-19 18:27:40,656 - INFO - Saving...
2022-01-19 18:27:40,922 - INFO - Epoch time: 395.86324095726013
2022-01-19 18:27:40,922 - INFO - 
Epoch: 29
2022-01-19 18:27:40,922 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:27:58,928 - INFO - [Step=24250]	Loss=1.3738	255.6 examples/second
2022-01-19 18:29:55,022 - INFO - [Step=24500]	Loss=1.1064	275.6 examples/second
2022-01-19 18:31:51,626 - INFO - [Step=24750]	Loss=1.0360	274.4 examples/second
2022-01-19 18:33:48,218 - INFO - [Step=25000]	Loss=1.0035	274.5 examples/second
2022-01-19 18:34:18,735 - INFO - Test Loss=0.9189, Test top-1 acc=0.7798
2022-01-19 18:34:18,736 - INFO - Group Accuracy:

2022-01-19 18:34:18,736 - INFO - [0.9775904  0.9881928  0.98313254 0.99156624 0.9804819  0.99373496
 0.9778313  0.9819277  0.9898795  0.9766265  0.9879518  0.9814458
 0.97542167 0.9775904  0.97566265 0.98626506 0.99421686]
2022-01-19 18:34:18,736 - INFO - Saving...
2022-01-19 18:34:18,913 - INFO - Epoch time: 397.99042320251465
2022-01-19 18:34:18,913 - INFO - 
Epoch: 30
2022-01-19 18:34:18,913 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:35:53,716 - INFO - [Step=25250]	Loss=0.9650	255.0 examples/second
2022-01-19 18:37:49,928 - INFO - [Step=25500]	Loss=0.9586	275.4 examples/second
2022-01-19 18:39:45,768 - INFO - [Step=25750]	Loss=0.9493	276.2 examples/second
2022-01-19 18:40:55,566 - INFO - Test Loss=0.8983, Test top-1 acc=0.7834
2022-01-19 18:40:55,567 - INFO - Group Accuracy:

2022-01-19 18:40:55,567 - INFO - [0.9768675  0.9889157  0.98361444 0.9925301  0.98240966 0.9939759
 0.97927713 0.98240966 0.9901205  0.97638553 0.98698795 0.9838554
 0.97445786 0.97903615 0.9746988  0.98746985 0.99421686]
2022-01-19 18:40:55,568 - INFO - Saving...
2022-01-19 18:40:55,748 - INFO - Epoch time: 396.8352224826813
2022-01-19 18:40:55,748 - INFO - 
Epoch: 31
2022-01-19 18:40:55,748 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:41:50,456 - INFO - [Step=26000]	Loss=0.9430	256.6 examples/second
2022-01-19 18:43:45,195 - INFO - [Step=26250]	Loss=0.9200	278.9 examples/second
2022-01-19 18:45:39,725 - INFO - [Step=26500]	Loss=0.9254	279.4 examples/second
2022-01-19 18:47:28,173 - INFO - Test Loss=0.8923, Test top-1 acc=0.7865
2022-01-19 18:47:28,173 - INFO - Group Accuracy:

2022-01-19 18:47:28,173 - INFO - [0.9775904  0.9886747  0.98313254 0.9925301  0.9821687  0.99493974
 0.9780723  0.9807229  0.98963857 0.97638553 0.9901205  0.98433733
 0.9773494  0.9785542  0.97590363 0.98674697 0.99421686]
2022-01-19 18:47:28,174 - INFO - Saving...
2022-01-19 18:47:28,442 - INFO - Epoch time: 392.69339179992676
2022-01-19 18:47:28,442 - INFO - 
Epoch: 32
2022-01-19 18:47:28,442 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:47:44,188 - INFO - [Step=26750]	Loss=0.9135	257.1 examples/second
2022-01-19 18:49:39,059 - INFO - [Step=27000]	Loss=0.8980	278.6 examples/second
2022-01-19 18:51:34,197 - INFO - [Step=27250]	Loss=0.9027	277.9 examples/second
2022-01-19 18:53:29,241 - INFO - [Step=27500]	Loss=0.8912	278.2 examples/second
2022-01-19 18:54:01,861 - INFO - Test Loss=0.8777, Test top-1 acc=0.7894
2022-01-19 18:54:01,862 - INFO - Group Accuracy:

2022-01-19 18:54:01,862 - INFO - [0.9771084  0.98963857 0.98361444 0.9927711  0.9816868  0.99421686
 0.9787952  0.98313254 0.9901205  0.9773494  0.9891566  0.9850602
 0.97566265 0.97903615 0.97614455 0.98698795 0.99373496]
2022-01-19 18:54:01,862 - INFO - Saving...
2022-01-19 18:54:02,114 - INFO - Epoch time: 393.67181611061096
2022-01-19 18:54:02,114 - INFO - 
Epoch: 33
2022-01-19 18:54:02,114 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:55:33,321 - INFO - [Step=27750]	Loss=0.8685	257.9 examples/second
2022-01-19 18:57:27,456 - INFO - [Step=28000]	Loss=0.8592	280.4 examples/second
2022-01-19 18:59:21,391 - INFO - [Step=28250]	Loss=0.8797	280.9 examples/second
2022-01-19 19:00:32,752 - INFO - Test Loss=0.8761, Test top-1 acc=0.7831
2022-01-19 19:00:32,752 - INFO - Group Accuracy:

2022-01-19 19:00:32,752 - INFO - [0.97614455 0.9884337  0.98289156 0.9913253  0.9819277  0.99493974
 0.97975904 0.9812048  0.9893976  0.9768675  0.98722893 0.9833735
 0.97566265 0.9787952  0.9742169  0.98626506 0.99493974]
2022-01-19 19:00:32,753 - INFO - Epoch time: 390.6389334201813
2022-01-19 19:00:32,753 - INFO - 
Epoch: 34
2022-01-19 19:00:32,753 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:01:25,309 - INFO - [Step=28500]	Loss=0.8574	258.2 examples/second
2022-01-19 19:03:20,469 - INFO - [Step=28750]	Loss=0.8562	277.9 examples/second
2022-01-19 19:05:15,214 - INFO - [Step=29000]	Loss=0.8625	278.9 examples/second
2022-01-19 19:07:05,793 - INFO - Test Loss=0.8590, Test top-1 acc=0.7880
2022-01-19 19:07:05,794 - INFO - Group Accuracy:

2022-01-19 19:07:05,794 - INFO - [0.97638553 0.99036145 0.9833735  0.99108434 0.98240966 0.99421686
 0.97975904 0.9814458  0.9893976  0.97614455 0.98963857 0.98289156
 0.9768675  0.9766265  0.9768675  0.98771083 0.99445784]
2022-01-19 19:07:05,794 - INFO - Epoch time: 393.04155921936035
2022-01-19 19:07:05,795 - INFO - 
Epoch: 35
2022-01-19 19:07:05,795 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:07:19,195 - INFO - [Step=29250]	Loss=0.8707	258.1 examples/second
2022-01-19 19:09:14,480 - INFO - [Step=29500]	Loss=0.8471	277.6 examples/second
2022-01-19 19:11:09,726 - INFO - [Step=29750]	Loss=0.8434	277.7 examples/second
2022-01-19 19:13:04,660 - INFO - [Step=30000]	Loss=0.8424	278.4 examples/second
2022-01-19 19:13:39,643 - INFO - Test Loss=0.8753, Test top-1 acc=0.7896
2022-01-19 19:13:39,643 - INFO - Group Accuracy:

2022-01-19 19:13:39,643 - INFO - [0.9778313  0.9901205  0.9833735  0.9927711  0.9807229  0.99445784
 0.97975904 0.9821687  0.9898795  0.97614455 0.9889157  0.98289156
 0.97566265 0.9804819  0.97638553 0.9884337  0.9946988 ]
2022-01-19 19:13:39,645 - INFO - Saving...
2022-01-19 19:13:39,932 - INFO - Epoch time: 394.1377320289612
2022-01-19 19:13:39,933 - INFO - 
Epoch: 36
2022-01-19 19:13:39,933 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:15:08,792 - INFO - [Step=30250]	Loss=0.8470	257.8 examples/second
2022-01-19 19:17:03,084 - INFO - [Step=30500]	Loss=0.8349	280.0 examples/second
2022-01-19 19:18:57,479 - INFO - [Step=30750]	Loss=0.8305	279.7 examples/second
2022-01-19 19:20:11,126 - INFO - Test Loss=0.8606, Test top-1 acc=0.7848
2022-01-19 19:20:11,127 - INFO - Group Accuracy:

2022-01-19 19:20:11,127 - INFO - [0.9778313  0.9891566  0.9840964  0.9913253  0.9807229  0.99421686
 0.9816868  0.9816868  0.9913253  0.9746988  0.9893976  0.98313254
 0.97566265 0.97927713 0.97493976 0.9881928  0.99445784]
2022-01-19 19:20:11,127 - INFO - Epoch time: 391.19479489326477
2022-01-19 19:20:11,127 - INFO - 
Epoch: 37
2022-01-19 19:20:11,127 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:21:01,569 - INFO - [Step=31000]	Loss=0.8329	257.9 examples/second
2022-01-19 19:22:57,124 - INFO - [Step=31250]	Loss=0.8130	276.9 examples/second
2022-01-19 19:24:52,611 - INFO - [Step=31500]	Loss=0.8204	277.1 examples/second
2022-01-19 19:26:46,179 - INFO - Test Loss=0.8380, Test top-1 acc=0.7935
2022-01-19 19:26:46,180 - INFO - Group Accuracy:

2022-01-19 19:26:46,180 - INFO - [0.98024094 0.9898795  0.9838554  0.993253   0.9826506  0.9951807
 0.9804819  0.9826506  0.9898795  0.97638553 0.9893976  0.9821687
 0.97566265 0.9804819  0.97518075 0.98746985 0.99493974]
2022-01-19 19:26:46,181 - INFO - Saving...
2022-01-19 19:26:46,433 - INFO - Epoch time: 395.3056480884552
2022-01-19 19:26:46,433 - INFO - 
Epoch: 38
2022-01-19 19:26:46,433 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:26:57,763 - INFO - [Step=31750]	Loss=0.8196	255.7 examples/second
2022-01-19 19:28:52,415 - INFO - [Step=32000]	Loss=0.7984	279.1 examples/second
2022-01-19 19:30:47,079 - INFO - [Step=32250]	Loss=0.8010	279.1 examples/second
2022-01-19 19:32:41,860 - INFO - [Step=32500]	Loss=0.8201	278.8 examples/second
2022-01-19 19:33:19,041 - INFO - Test Loss=0.8587, Test top-1 acc=0.7933
2022-01-19 19:33:19,042 - INFO - Group Accuracy:

2022-01-19 19:33:19,042 - INFO - [0.97951806 0.9893976  0.9848193  0.9922892  0.9826506  0.9954217
 0.97927713 0.9812048  0.9901205  0.97542167 0.9893976  0.9826506
 0.9746988  0.97951806 0.97614455 0.98746985 0.99493974]
2022-01-19 19:33:19,043 - INFO - Epoch time: 392.60947704315186
2022-01-19 19:33:19,043 - INFO - 
Epoch: 39
2022-01-19 19:33:19,043 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:34:46,088 - INFO - [Step=32750]	Loss=0.8030	257.6 examples/second
2022-01-19 19:36:41,057 - INFO - [Step=33000]	Loss=0.8022	278.3 examples/second
2022-01-19 19:38:36,380 - INFO - [Step=33250]	Loss=0.7874	277.5 examples/second
2022-01-19 19:39:52,940 - INFO - Test Loss=0.8491, Test top-1 acc=0.7913
2022-01-19 19:39:52,940 - INFO - Group Accuracy:

2022-01-19 19:39:52,940 - INFO - [0.9787952  0.9901205  0.9845783  0.9913253  0.9845783  0.99421686
 0.9814458  0.9819277  0.99060243 0.97445786 0.9898795  0.9850602
 0.97566265 0.98024094 0.97493976 0.98722893 0.9956626 ]
2022-01-19 19:39:52,941 - INFO - Epoch time: 393.8981659412384
2022-01-19 19:39:52,941 - INFO - 
Epoch: 40
2022-01-19 19:39:52,941 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:40:40,891 - INFO - [Step=33500]	Loss=0.7960	257.0 examples/second
2022-01-19 19:42:36,238 - INFO - [Step=33750]	Loss=0.7745	277.4 examples/second
2022-01-19 19:44:31,595 - INFO - [Step=34000]	Loss=0.7824	277.4 examples/second
2022-01-19 19:46:27,133 - INFO - Test Loss=0.8906, Test top-1 acc=0.7913
2022-01-19 19:46:27,134 - INFO - Group Accuracy:

2022-01-19 19:46:27,134 - INFO - [0.97951806 0.9898795  0.9840964  0.9918072  0.9809638  0.99373496
 0.9804819  0.9826506  0.9901205  0.97566265 0.99036145 0.9816868
 0.97638553 0.97927713 0.9778313  0.98771083 0.9959036 ]
2022-01-19 19:46:27,135 - INFO - Epoch time: 394.1941978931427
2022-01-19 19:46:27,135 - INFO - 
Epoch: 41
2022-01-19 19:46:27,136 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:46:35,928 - INFO - [Step=34250]	Loss=0.7892	257.4 examples/second
2022-01-19 19:48:31,219 - INFO - [Step=34500]	Loss=0.7694	277.6 examples/second
2022-01-19 19:50:26,653 - INFO - [Step=34750]	Loss=0.7859	277.2 examples/second
2022-01-19 19:52:22,457 - INFO - [Step=35000]	Loss=0.7787	276.3 examples/second
2022-01-19 19:53:02,323 - INFO - Test Loss=0.8626, Test top-1 acc=0.7899
2022-01-19 19:53:02,324 - INFO - Group Accuracy:

2022-01-19 19:53:02,324 - INFO - [0.97831327 0.9898795  0.98578316 0.993253   0.98240966 0.99373496
 0.9816868  0.9814458  0.9889157  0.9746988  0.9881928  0.9826506
 0.97542167 0.9804819  0.97301203 0.98698795 0.99493974]
2022-01-19 19:53:02,324 - INFO - Epoch time: 395.18901443481445
2022-01-19 19:53:02,325 - INFO - 
Epoch: 42
2022-01-19 19:53:02,325 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:54:27,490 - INFO - [Step=35250]	Loss=0.7593	255.9 examples/second
2022-01-19 19:56:22,927 - INFO - [Step=35500]	Loss=0.7700	277.2 examples/second
2022-01-19 19:58:18,296 - INFO - [Step=35750]	Loss=0.7831	277.4 examples/second
2022-01-19 19:59:37,219 - INFO - Test Loss=0.8750, Test top-1 acc=0.7892
2022-01-19 19:59:37,219 - INFO - Group Accuracy:

2022-01-19 19:59:37,219 - INFO - [0.9766265  0.99036145 0.9840964  0.9927711  0.9816868  0.99421686
 0.9809638  0.9814458  0.9898795  0.97590363 0.9913253  0.9821687
 0.97638553 0.97903615 0.97590363 0.9879518  0.9951807 ]
2022-01-19 19:59:37,221 - INFO - Epoch time: 394.89638471603394
2022-01-19 19:59:37,221 - INFO - 
Epoch: 43
2022-01-19 19:59:37,221 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:00:22,717 - INFO - [Step=36000]	Loss=0.7430	257.2 examples/second
2022-01-19 20:02:17,457 - INFO - [Step=36250]	Loss=0.7515	278.9 examples/second
2022-01-19 20:04:12,440 - INFO - [Step=36500]	Loss=0.7665	278.3 examples/second
2022-01-19 20:06:10,085 - INFO - Test Loss=0.8544, Test top-1 acc=0.7945
2022-01-19 20:06:10,086 - INFO - Group Accuracy:

2022-01-19 20:06:10,086 - INFO - [0.9787952  0.99084336 0.98433733 0.9925301  0.9819277  0.99445784
 0.97975904 0.9814458  0.99060243 0.97566265 0.99036145 0.98433733
 0.97518075 0.97951806 0.97590363 0.9879518  0.9951807 ]
2022-01-19 20:06:10,086 - INFO - Saving...
2022-01-19 20:06:10,342 - INFO - Epoch time: 393.1212708950043
2022-01-19 20:06:10,343 - INFO - 
Epoch: 44
2022-01-19 20:06:10,343 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:06:16,836 - INFO - [Step=36750]	Loss=0.7503	257.2 examples/second
2022-01-19 20:08:11,665 - INFO - [Step=37000]	Loss=0.7343	278.7 examples/second
2022-01-19 20:10:06,759 - INFO - [Step=37250]	Loss=0.7558	278.0 examples/second
2022-01-19 20:12:01,597 - INFO - [Step=37500]	Loss=0.7586	278.7 examples/second
2022-01-19 20:12:43,291 - INFO - Test Loss=0.8499, Test top-1 acc=0.7945
2022-01-19 20:12:43,291 - INFO - Group Accuracy:

2022-01-19 20:12:43,291 - INFO - [0.97831327 0.9891566  0.9838554  0.9939759  0.98289156 0.9946988
 0.97927713 0.98289156 0.99036145 0.9742169  0.9918072  0.9840964
 0.9771084  0.9809638  0.97614455 0.98698795 0.9951807 ]
2022-01-19 20:12:43,292 - INFO - Epoch time: 392.94986963272095
2022-01-19 20:12:43,293 - INFO - 
Epoch: 45
2022-01-19 20:12:43,293 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:14:05,919 - INFO - [Step=37750]	Loss=0.7301	257.4 examples/second
2022-01-19 20:16:01,239 - INFO - [Step=38000]	Loss=0.7450	277.5 examples/second
2022-01-19 20:17:56,807 - INFO - [Step=38250]	Loss=0.7521	276.9 examples/second
2022-01-19 20:19:18,122 - INFO - Test Loss=0.8494, Test top-1 acc=0.7928
2022-01-19 20:19:18,122 - INFO - Group Accuracy:

2022-01-19 20:19:18,122 - INFO - [0.9771084  0.98963857 0.98289156 0.9925301  0.9814458  0.99373496
 0.9812048  0.98313254 0.99084336 0.97518075 0.99084336 0.9845783
 0.97590363 0.97903615 0.9766265  0.98771083 0.9956626 ]
2022-01-19 20:19:18,123 - INFO - Epoch time: 394.8307843208313
2022-01-19 20:19:18,123 - INFO - 
Epoch: 46
2022-01-19 20:19:18,123 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:20:01,938 - INFO - [Step=38500]	Loss=0.7357	255.7 examples/second
2022-01-19 20:21:57,368 - INFO - [Step=38750]	Loss=0.7353	277.2 examples/second
2022-01-19 20:23:52,732 - INFO - [Step=39000]	Loss=0.7215	277.4 examples/second
2022-01-19 20:25:53,612 - INFO - Test Loss=0.8663, Test top-1 acc=0.7990
2022-01-19 20:25:53,613 - INFO - Group Accuracy:

2022-01-19 20:25:53,613 - INFO - [0.9812048  0.9898795  0.9833735  0.9927711  0.9812048  0.99445784
 0.9809638  0.98361444 0.99156624 0.97542167 0.9893976  0.98289156
 0.9766265  0.9804819  0.97831327 0.9886747  0.99493974]
2022-01-19 20:25:53,614 - INFO - Saving...
2022-01-19 20:25:53,871 - INFO - Epoch time: 395.74708461761475
2022-01-19 20:25:53,871 - INFO - 
Epoch: 47
2022-01-19 20:25:53,871 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:25:58,175 - INFO - [Step=39250]	Loss=0.7278	255.1 examples/second
2022-01-19 20:27:53,476 - INFO - [Step=39500]	Loss=0.7276	277.5 examples/second
2022-01-19 20:29:48,731 - INFO - [Step=39750]	Loss=0.7296	277.6 examples/second
2022-01-19 20:31:44,150 - INFO - [Step=40000]	Loss=0.7284	277.3 examples/second
2022-01-19 20:32:28,553 - INFO - Test Loss=0.8526, Test top-1 acc=0.7945
2022-01-19 20:32:28,553 - INFO - Group Accuracy:

2022-01-19 20:32:28,553 - INFO - [0.9785542  0.9898795  0.9853012  0.9927711  0.9826506  0.99445784
 0.9807229  0.9816868  0.9901205  0.9768675  0.9898795  0.9838554
 0.9766265  0.97927713 0.97518075 0.98771083 0.9954217 ]
2022-01-19 20:32:28,554 - INFO - Epoch time: 394.68368887901306
2022-01-19 20:32:28,555 - INFO - 
Epoch: 48
2022-01-19 20:32:28,555 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:33:49,309 - INFO - [Step=40250]	Loss=0.7125	255.7 examples/second
2022-01-19 20:35:44,952 - INFO - [Step=40500]	Loss=0.7293	276.7 examples/second
2022-01-19 20:37:40,974 - INFO - [Step=40750]	Loss=0.7122	275.8 examples/second
2022-01-19 20:39:04,830 - INFO - Test Loss=0.8634, Test top-1 acc=0.7928
2022-01-19 20:39:04,831 - INFO - Group Accuracy:

2022-01-19 20:39:04,831 - INFO - [0.97903615 0.9893976  0.9838554  0.9922892  0.9816868  0.9946988
 0.97927713 0.9819277  0.9898795  0.97614455 0.99036145 0.9850602
 0.9766265  0.98024094 0.97566265 0.9879518  0.9946988 ]
2022-01-19 20:39:04,832 - INFO - Epoch time: 396.276976108551
2022-01-19 20:39:04,832 - INFO - 
Epoch: 49
2022-01-19 20:39:04,832 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:39:45,959 - INFO - [Step=41000]	Loss=0.7069	256.0 examples/second
2022-01-19 20:41:41,153 - INFO - [Step=41250]	Loss=0.7068	277.8 examples/second
2022-01-19 20:43:36,738 - INFO - [Step=41500]	Loss=0.7135	276.9 examples/second
2022-01-19 20:45:32,294 - INFO - [Step=41750]	Loss=0.7176	276.9 examples/second
2022-01-19 20:45:40,336 - INFO - Test Loss=0.8704, Test top-1 acc=0.7889
2022-01-19 20:45:40,336 - INFO - Group Accuracy:

2022-01-19 20:45:40,336 - INFO - [0.9771084  0.99060243 0.9838554  0.99156624 0.9816868  0.9930121
 0.9778313  0.9814458  0.99036145 0.9771084  0.98771083 0.9848193
 0.97638553 0.9804819  0.9778313  0.98698795 0.99493974]
2022-01-19 20:45:40,337 - INFO - Epoch time: 395.5057632923126
2022-01-19 20:45:40,337 - INFO - 
Epoch: 50
2022-01-19 20:45:40,337 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:47:37,538 - INFO - [Step=42000]	Loss=0.7034	255.5 examples/second
2022-01-19 20:49:33,021 - INFO - [Step=42250]	Loss=0.7050	277.1 examples/second
2022-01-19 20:51:28,277 - INFO - [Step=42500]	Loss=0.7312	277.6 examples/second
2022-01-19 20:52:14,738 - INFO - Test Loss=0.8628, Test top-1 acc=0.7954
2022-01-19 20:52:14,739 - INFO - Group Accuracy:

2022-01-19 20:52:14,739 - INFO - [0.9787952  0.9893976  0.9848193  0.993494   0.9814458  0.99373496
 0.97903615 0.9812048  0.98963857 0.9778313  0.99156624 0.9838554
 0.97590363 0.97951806 0.9775904  0.98746985 0.99493974]
2022-01-19 20:52:14,740 - INFO - Epoch time: 394.4028241634369
2022-01-19 20:52:14,740 - INFO - 
Epoch: 51
2022-01-19 20:52:14,741 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:53:32,567 - INFO - [Step=42750]	Loss=0.6869	257.5 examples/second
2022-01-19 20:55:27,779 - INFO - [Step=43000]	Loss=0.6994	277.7 examples/second
2022-01-19 20:57:23,227 - INFO - [Step=43250]	Loss=0.7045	277.2 examples/second
2022-01-19 20:58:49,102 - INFO - Test Loss=0.8839, Test top-1 acc=0.7892
2022-01-19 20:58:49,102 - INFO - Group Accuracy:

2022-01-19 20:58:49,102 - INFO - [0.97927713 0.9889157  0.9840964  0.9925301  0.9804819  0.99445784
 0.97975904 0.9819277  0.9886747  0.97614455 0.9901205  0.98289156
 0.97614455 0.97831327 0.97518075 0.98674697 0.9959036 ]
2022-01-19 20:58:49,103 - INFO - Epoch time: 394.3625543117523
2022-01-19 20:58:49,103 - INFO - 
Epoch: 52
2022-01-19 20:58:49,103 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:59:27,982 - INFO - [Step=43500]	Loss=0.7146	256.5 examples/second
2022-01-19 21:01:23,059 - INFO - [Step=43750]	Loss=0.6890	278.1 examples/second
2022-01-19 21:03:18,255 - INFO - [Step=44000]	Loss=0.7248	277.8 examples/second
2022-01-19 21:05:13,551 - INFO - [Step=44250]	Loss=0.6921	277.5 examples/second
2022-01-19 21:05:23,639 - INFO - Test Loss=0.8749, Test top-1 acc=0.7916
2022-01-19 21:05:23,640 - INFO - Group Accuracy:

2022-01-19 21:05:23,640 - INFO - [0.9775904  0.99084336 0.98313254 0.99373496 0.98       0.99421686
 0.97975904 0.9833735  0.9891566  0.9766265  0.99036145 0.9833735
 0.97493976 0.97975904 0.97614455 0.98698795 0.9959036 ]
2022-01-19 21:05:23,641 - INFO - Epoch time: 394.53748774528503
2022-01-19 21:05:23,641 - INFO - 
Epoch: 53
2022-01-19 21:05:23,641 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:07:18,931 - INFO - [Step=44500]	Loss=0.6754	255.2 examples/second
2022-01-19 21:09:14,502 - INFO - [Step=44750]	Loss=0.6888	276.9 examples/second
2022-01-19 21:11:09,774 - INFO - [Step=45000]	Loss=0.6962	277.6 examples/second
2022-01-19 21:11:58,764 - INFO - Test Loss=0.9220, Test top-1 acc=0.7805
2022-01-19 21:11:58,764 - INFO - Group Accuracy:

2022-01-19 21:11:58,764 - INFO - [0.97493976 0.9889157  0.9833735  0.9922892  0.9809638  0.993253
 0.9771084  0.9819277  0.98746985 0.97566265 0.9901205  0.9804819
 0.9737349  0.9812048  0.97493976 0.98722893 0.99493974]
2022-01-19 21:11:58,765 - INFO - Epoch time: 395.1247854232788
2022-01-19 21:11:58,765 - INFO - 
Epoch: 54
2022-01-19 21:11:58,766 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:13:14,798 - INFO - [Step=45250]	Loss=0.6781	256.0 examples/second
2022-01-19 21:15:10,381 - INFO - [Step=45500]	Loss=0.6764	276.9 examples/second
2022-01-19 21:17:05,984 - INFO - [Step=45750]	Loss=0.6941	276.8 examples/second
2022-01-19 21:18:34,076 - INFO - Test Loss=0.8729, Test top-1 acc=0.7928
2022-01-19 21:18:34,077 - INFO - Group Accuracy:

2022-01-19 21:18:34,077 - INFO - [0.98       0.9893976  0.98361444 0.9925301  0.98433733 0.99421686
 0.9787952  0.9838554  0.9893976  0.9766265  0.9881928  0.98361444
 0.9771084  0.9809638  0.9773494  0.98698795 0.99445784]
2022-01-19 21:18:34,078 - INFO - Epoch time: 395.3123052120209
2022-01-19 21:18:34,078 - INFO - 
Epoch: 55
2022-01-19 21:18:34,078 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:19:10,571 - INFO - [Step=46000]	Loss=0.6843	256.8 examples/second
2022-01-19 21:21:05,678 - INFO - [Step=46250]	Loss=0.6665	278.0 examples/second
2022-01-19 21:23:00,909 - INFO - [Step=46500]	Loss=0.6953	277.7 examples/second
2022-01-19 21:24:56,100 - INFO - [Step=46750]	Loss=0.6880	277.8 examples/second
2022-01-19 21:25:08,066 - INFO - Test Loss=0.8751, Test top-1 acc=0.7935
2022-01-19 21:25:08,066 - INFO - Group Accuracy:

2022-01-19 21:25:08,066 - INFO - [0.97927713 0.9898795  0.9833735  0.9925301  0.9845783  0.9939759
 0.98024094 0.9838554  0.9893976  0.9766265  0.9886747  0.9821687
 0.9780723  0.9780723  0.9766265  0.9884337  0.9961446 ]
2022-01-19 21:25:08,067 - INFO - Epoch time: 393.9891929626465
2022-01-19 21:25:08,067 - INFO - 
Epoch: 56
2022-01-19 21:25:08,067 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:27:00,362 - INFO - [Step=47000]	Loss=0.6568	257.5 examples/second
2022-01-19 21:28:54,908 - INFO - [Step=47250]	Loss=0.6643	279.4 examples/second
2022-01-19 21:30:49,745 - INFO - [Step=47500]	Loss=0.6839	278.7 examples/second
2022-01-19 21:31:41,159 - INFO - Test Loss=0.8857, Test top-1 acc=0.7906
2022-01-19 21:31:41,159 - INFO - Group Accuracy:

2022-01-19 21:31:41,159 - INFO - [0.9775904  0.9898795  0.9848193  0.9925301  0.9807229  0.99421686
 0.9819277  0.9816868  0.9889157  0.97590363 0.9901205  0.9838554
 0.97542167 0.9809638  0.9742169  0.9848193  0.9954217 ]
2022-01-19 21:31:41,160 - INFO - Epoch time: 393.0926697254181
2022-01-19 21:31:41,160 - INFO - 
Epoch: 57
2022-01-19 21:31:41,160 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:32:54,588 - INFO - [Step=47750]	Loss=0.6607	256.3 examples/second
2022-01-19 21:34:50,191 - INFO - [Step=48000]	Loss=0.6557	276.8 examples/second
2022-01-19 21:36:45,610 - INFO - [Step=48250]	Loss=0.6772	277.3 examples/second
2022-01-19 21:38:15,959 - INFO - Test Loss=0.8753, Test top-1 acc=0.7908
2022-01-19 21:38:15,959 - INFO - Group Accuracy:

2022-01-19 21:38:15,959 - INFO - [0.9807229  0.9886747  0.98240966 0.993253   0.98313254 0.99421686
 0.9814458  0.9833735  0.9889157  0.97445786 0.98963857 0.9850602
 0.97445786 0.97927713 0.97590363 0.98626506 0.99493974]
2022-01-19 21:38:15,960 - INFO - Epoch time: 394.80026507377625
2022-01-19 21:38:15,960 - INFO - 
Epoch: 58
2022-01-19 21:38:15,960 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:38:50,394 - INFO - [Step=48500]	Loss=0.6769	256.4 examples/second
2022-01-19 21:40:45,937 - INFO - [Step=48750]	Loss=0.6785	277.0 examples/second
2022-01-19 21:42:41,556 - INFO - [Step=49000]	Loss=0.6606	276.8 examples/second
2022-01-19 21:44:37,601 - INFO - [Step=49250]	Loss=0.6712	275.8 examples/second
2022-01-19 21:44:52,240 - INFO - Test Loss=0.9035, Test top-1 acc=0.7899
2022-01-19 21:44:52,240 - INFO - Group Accuracy:

2022-01-19 21:44:52,240 - INFO - [0.97903615 0.9889157  0.9838554  0.9930121  0.9826506  0.993253
 0.98024094 0.9826506  0.9893976  0.97590363 0.9893976  0.9826506
 0.97542167 0.97831327 0.97518075 0.98626506 0.9951807 ]
2022-01-19 21:44:52,241 - INFO - Epoch time: 396.2802939414978
2022-01-19 21:44:52,241 - INFO - 
Epoch: 59
2022-01-19 21:44:52,241 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:46:42,339 - INFO - [Step=49500]	Loss=0.6226	256.5 examples/second
2022-01-19 21:48:37,127 - INFO - [Step=49750]	Loss=0.5956	278.8 examples/second
2022-01-19 21:50:31,963 - INFO - [Step=50000]	Loss=0.5786	278.7 examples/second
2022-01-19 21:51:25,237 - INFO - Test Loss=0.8176, Test top-1 acc=0.8046
2022-01-19 21:51:25,237 - INFO - Group Accuracy:

2022-01-19 21:51:25,237 - INFO - [0.9804819  0.99060243 0.9840964  0.99421686 0.98433733 0.99421686
 0.98240966 0.98313254 0.9901205  0.9780723  0.99108434 0.9848193
 0.9771084  0.9816868  0.9775904  0.9886747  0.9956626 ]
2022-01-19 21:51:25,238 - INFO - Saving...
2022-01-19 21:51:25,424 - INFO - Epoch time: 393.1836314201355
2022-01-19 21:51:25,424 - INFO - 
Epoch: 60
2022-01-19 21:51:25,425 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:52:36,477 - INFO - [Step=50250]	Loss=0.5706	257.0 examples/second
2022-01-19 21:54:31,462 - INFO - [Step=50500]	Loss=0.5678	278.3 examples/second
2022-01-19 21:56:26,503 - INFO - [Step=50750]	Loss=0.5560	278.2 examples/second
2022-01-19 21:57:59,017 - INFO - Test Loss=0.8124, Test top-1 acc=0.8048
2022-01-19 21:57:59,017 - INFO - Group Accuracy:

2022-01-19 21:57:59,017 - INFO - [0.98024094 0.99036145 0.9850602  0.99421686 0.98433733 0.99373496
 0.98289156 0.98289156 0.9898795  0.9778313  0.99108434 0.98433733
 0.97831327 0.9814458  0.9787952  0.9881928  0.9961446 ]
2022-01-19 21:57:59,018 - INFO - Saving...
2022-01-19 21:57:59,294 - INFO - Epoch time: 393.86920189857483
2022-01-19 21:57:59,294 - INFO - 
Epoch: 61
2022-01-19 21:57:59,294 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:58:31,158 - INFO - [Step=51000]	Loss=0.5694	256.7 examples/second
2022-01-19 22:00:25,646 - INFO - [Step=51250]	Loss=0.5684	279.5 examples/second
2022-01-19 22:02:20,117 - INFO - [Step=51500]	Loss=0.5595	279.5 examples/second
2022-01-19 22:04:14,711 - INFO - [Step=51750]	Loss=0.5586	279.2 examples/second
2022-01-19 22:04:31,690 - INFO - Test Loss=0.8068, Test top-1 acc=0.8065
2022-01-19 22:04:31,690 - INFO - Group Accuracy:

2022-01-19 22:04:31,690 - INFO - [0.97975904 0.9898795  0.9860241  0.99445784 0.9845783  0.9939759
 0.98240966 0.98313254 0.98963857 0.9780723  0.9913253  0.9848193
 0.9766265  0.98240966 0.97831327 0.9889157  0.9959036 ]
2022-01-19 22:04:31,691 - INFO - Saving...
2022-01-19 22:04:31,958 - INFO - Epoch time: 392.6643087863922
2022-01-19 22:04:31,958 - INFO - 
Epoch: 62
2022-01-19 22:04:31,959 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:06:20,222 - INFO - [Step=52000]	Loss=0.5601	255.0 examples/second
2022-01-19 22:08:15,795 - INFO - [Step=52250]	Loss=0.5395	276.9 examples/second
2022-01-19 22:10:11,445 - INFO - [Step=52500]	Loss=0.5446	276.7 examples/second
2022-01-19 22:11:07,524 - INFO - Test Loss=0.8058, Test top-1 acc=0.8017
2022-01-19 22:11:07,524 - INFO - Group Accuracy:

2022-01-19 22:11:07,524 - INFO - [0.97975904 0.99060243 0.9853012  0.9939759  0.9845783  0.99421686
 0.9821687  0.9821687  0.98963857 0.9773494  0.99060243 0.9840964
 0.9768675  0.9816868  0.97903615 0.9879518  0.9961446 ]
2022-01-19 22:11:07,525 - INFO - Epoch time: 395.56684970855713
2022-01-19 22:11:07,525 - INFO - 
Epoch: 63
2022-01-19 22:11:07,525 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:12:16,449 - INFO - [Step=52750]	Loss=0.5479	256.0 examples/second
2022-01-19 22:14:11,550 - INFO - [Step=53000]	Loss=0.5430	278.0 examples/second
2022-01-19 22:16:06,884 - INFO - [Step=53250]	Loss=0.5548	277.5 examples/second
2022-01-19 22:17:42,415 - INFO - Test Loss=0.8100, Test top-1 acc=0.8072
2022-01-19 22:17:42,416 - INFO - Group Accuracy:

2022-01-19 22:17:42,416 - INFO - [0.9804819  0.99084336 0.9845783  0.99445784 0.9855422  0.99445784
 0.98289156 0.98289156 0.9898795  0.9780723  0.99108434 0.9848193
 0.9768675  0.98240966 0.97903615 0.9884337  0.9959036 ]
2022-01-19 22:17:42,417 - INFO - Saving...
2022-01-19 22:17:42,682 - INFO - Epoch time: 395.15691089630127
2022-01-19 22:17:42,683 - INFO - 
Epoch: 64
2022-01-19 22:17:42,683 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:18:12,522 - INFO - [Step=53500]	Loss=0.5530	254.7 examples/second
2022-01-19 22:20:09,133 - INFO - [Step=53750]	Loss=0.5455	274.4 examples/second
2022-01-19 22:22:05,851 - INFO - [Step=54000]	Loss=0.5347	274.2 examples/second
2022-01-19 22:24:02,290 - INFO - [Step=54250]	Loss=0.5481	274.8 examples/second
2022-01-19 22:24:21,676 - INFO - Test Loss=0.8064, Test top-1 acc=0.8055
2022-01-19 22:24:21,676 - INFO - Group Accuracy:

2022-01-19 22:24:21,676 - INFO - [0.98       0.99060243 0.9848193  0.993494   0.98578316 0.99445784
 0.98289156 0.9814458  0.98963857 0.9778313  0.99060243 0.98433733
 0.9768675  0.98240966 0.97831327 0.9893976  0.9961446 ]
2022-01-19 22:24:21,677 - INFO - Epoch time: 398.99469923973083
2022-01-19 22:24:21,677 - INFO - 
Epoch: 65
2022-01-19 22:24:21,677 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:26:07,443 - INFO - [Step=54500]	Loss=0.5492	255.7 examples/second
2022-01-19 22:28:02,564 - INFO - [Step=54750]	Loss=0.5358	278.0 examples/second
2022-01-19 22:29:58,092 - INFO - [Step=55000]	Loss=0.5330	277.0 examples/second
2022-01-19 22:30:56,542 - INFO - Test Loss=0.8075, Test top-1 acc=0.8060
2022-01-19 22:30:56,542 - INFO - Group Accuracy:

2022-01-19 22:30:56,542 - INFO - [0.9804819  0.99036145 0.9848193  0.993253   0.9855422  0.99445784
 0.9816868  0.98313254 0.9891566  0.9771084  0.99156624 0.98433733
 0.9773494  0.9819277  0.97903615 0.9886747  0.9963855 ]
2022-01-19 22:30:56,544 - INFO - Epoch time: 394.86643743515015
2022-01-19 22:30:56,544 - INFO - 
Epoch: 66
2022-01-19 22:30:56,544 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:32:03,063 - INFO - [Step=55250]	Loss=0.5395	256.1 examples/second
2022-01-19 22:33:57,676 - INFO - [Step=55500]	Loss=0.5280	279.2 examples/second
2022-01-19 22:35:52,377 - INFO - [Step=55750]	Loss=0.5409	279.0 examples/second
2022-01-19 22:37:29,484 - INFO - Test Loss=0.8097, Test top-1 acc=0.8065
2022-01-19 22:37:29,484 - INFO - Group Accuracy:

2022-01-19 22:37:29,484 - INFO - [0.97975904 0.9898795  0.98433733 0.99373496 0.98626506 0.9946988
 0.9826506  0.9826506  0.99036145 0.9780723  0.99084336 0.98289156
 0.9778313  0.9838554  0.97831327 0.9884337  0.9961446 ]
2022-01-19 22:37:29,485 - INFO - Epoch time: 392.9411268234253
2022-01-19 22:37:29,485 - INFO - 
Epoch: 67
2022-01-19 22:37:29,485 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:37:56,945 - INFO - [Step=56000]	Loss=0.5282	256.9 examples/second
2022-01-19 22:39:52,048 - INFO - [Step=56250]	Loss=0.5244	278.0 examples/second
2022-01-19 22:41:46,388 - INFO - [Step=56500]	Loss=0.5216	279.9 examples/second
2022-01-19 22:43:41,029 - INFO - [Step=56750]	Loss=0.5399	279.1 examples/second
2022-01-19 22:44:02,200 - INFO - Test Loss=0.8110, Test top-1 acc=0.8046
2022-01-19 22:44:02,200 - INFO - Group Accuracy:

2022-01-19 22:44:02,200 - INFO - [0.9804819  0.99108434 0.9855422  0.9930121  0.9845783  0.9946988
 0.98240966 0.9826506  0.9898795  0.97638553 0.99036145 0.98361444
 0.9771084  0.9826506  0.97831327 0.9891566  0.9961446 ]
2022-01-19 22:44:02,201 - INFO - Epoch time: 392.7156138420105
2022-01-19 22:44:02,201 - INFO - 
Epoch: 68
2022-01-19 22:44:02,201 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:45:45,697 - INFO - [Step=57000]	Loss=0.5188	256.7 examples/second
2022-01-19 22:47:41,067 - INFO - [Step=57250]	Loss=0.5287	277.4 examples/second
2022-01-19 22:49:36,809 - INFO - [Step=57500]	Loss=0.5327	276.5 examples/second
2022-01-19 22:50:37,526 - INFO - Test Loss=0.8141, Test top-1 acc=0.8108
2022-01-19 22:50:37,526 - INFO - Group Accuracy:

2022-01-19 22:50:37,526 - INFO - [0.9816868  0.99060243 0.9850602  0.99421686 0.98578316 0.99445784
 0.9819277  0.98361444 0.98963857 0.9778313  0.99084336 0.9853012
 0.9775904  0.9826506  0.9785542  0.9881928  0.9961446 ]
2022-01-19 22:50:37,527 - INFO - Saving...
2022-01-19 22:50:37,801 - INFO - Epoch time: 395.59978914260864
2022-01-19 22:50:37,801 - INFO - 
Epoch: 69
2022-01-19 22:50:37,801 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:51:41,937 - INFO - [Step=57750]	Loss=0.5361	255.7 examples/second
2022-01-19 22:53:36,986 - INFO - [Step=58000]	Loss=0.5207	278.1 examples/second
2022-01-19 22:55:32,059 - INFO - [Step=58250]	Loss=0.5268	278.1 examples/second
2022-01-19 22:57:11,527 - INFO - Test Loss=0.8133, Test top-1 acc=0.8092
2022-01-19 22:57:11,527 - INFO - Group Accuracy:

2022-01-19 22:57:11,527 - INFO - [0.9809638  0.9898795  0.9855422  0.9930121  0.9850602  0.9946988
 0.98289156 0.98313254 0.9898795  0.9775904  0.99108434 0.9850602
 0.9771084  0.9826506  0.9780723  0.9886747  0.9959036 ]
2022-01-19 22:57:11,529 - INFO - Epoch time: 393.7277615070343
2022-01-19 22:57:11,529 - INFO - 
Epoch: 70
2022-01-19 22:57:11,529 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:57:36,963 - INFO - [Step=58500]	Loss=0.5246	256.2 examples/second
2022-01-19 22:59:31,990 - INFO - [Step=58750]	Loss=0.5192	278.2 examples/second
2022-01-19 23:01:27,001 - INFO - [Step=59000]	Loss=0.5343	278.2 examples/second
2022-01-19 23:03:22,095 - INFO - [Step=59250]	Loss=0.5311	278.0 examples/second
2022-01-19 23:03:45,616 - INFO - Test Loss=0.8183, Test top-1 acc=0.8067
2022-01-19 23:03:45,616 - INFO - Group Accuracy:

2022-01-19 23:03:45,616 - INFO - [0.9814458  0.99036145 0.9860241  0.993253   0.9850602  0.99445784
 0.9826506  0.98313254 0.9893976  0.9775904  0.9918072  0.9838554
 0.9766265  0.98240966 0.9785542  0.9884337  0.9959036 ]
2022-01-19 23:03:45,617 - INFO - Epoch time: 394.0884475708008
2022-01-19 23:03:45,617 - INFO - 
Epoch: 71
2022-01-19 23:03:45,617 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:05:26,645 - INFO - [Step=59500]	Loss=0.5235	256.9 examples/second
2022-01-19 23:07:21,540 - INFO - [Step=59750]	Loss=0.5256	278.5 examples/second
2022-01-19 23:09:16,428 - INFO - [Step=60000]	Loss=0.5170	278.5 examples/second
2022-01-19 23:10:19,234 - INFO - Test Loss=0.8109, Test top-1 acc=0.8111
2022-01-19 23:10:19,235 - INFO - Group Accuracy:

2022-01-19 23:10:19,235 - INFO - [0.9812048  0.99060243 0.9850602  0.993253   0.98578316 0.99445784
 0.9826506  0.9833735  0.9898795  0.9778313  0.9930121  0.98578316
 0.9773494  0.98289156 0.9775904  0.9886747  0.9961446 ]
2022-01-19 23:10:19,237 - INFO - Saving...
2022-01-19 23:10:19,432 - INFO - Epoch time: 393.81493520736694
2022-01-19 23:10:19,432 - INFO - 
Epoch: 72
2022-01-19 23:10:19,433 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:11:21,322 - INFO - [Step=60250]	Loss=0.5206	256.2 examples/second
2022-01-19 23:13:16,114 - INFO - [Step=60500]	Loss=0.5223	278.8 examples/second
2022-01-19 23:15:10,931 - INFO - [Step=60750]	Loss=0.5197	278.7 examples/second
2022-01-19 23:16:52,759 - INFO - Test Loss=0.8134, Test top-1 acc=0.8099
2022-01-19 23:16:52,759 - INFO - Group Accuracy:

2022-01-19 23:16:52,759 - INFO - [0.9804819  0.99060243 0.98626506 0.993494   0.98578316 0.99421686
 0.98313254 0.98289156 0.9891566  0.9771084  0.9918072  0.9855422
 0.9768675  0.9819277  0.9785542  0.9884337  0.9963855 ]
2022-01-19 23:16:52,760 - INFO - Epoch time: 393.32758617401123
2022-01-19 23:16:52,760 - INFO - 
Epoch: 73
2022-01-19 23:16:52,760 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:17:15,587 - INFO - [Step=61000]	Loss=0.5190	256.7 examples/second
2022-01-19 23:19:10,750 - INFO - [Step=61250]	Loss=0.5167	277.9 examples/second
2022-01-19 23:21:05,789 - INFO - [Step=61500]	Loss=0.5154	278.2 examples/second
2022-01-19 23:23:00,658 - INFO - [Step=61750]	Loss=0.5264	278.6 examples/second
2022-01-19 23:23:26,588 - INFO - Test Loss=0.8141, Test top-1 acc=0.8087
2022-01-19 23:23:26,589 - INFO - Group Accuracy:

2022-01-19 23:23:26,589 - INFO - [0.9816868  0.98963857 0.98578316 0.99373496 0.98626506 0.99445784
 0.9826506  0.9821687  0.9893976  0.9773494  0.99156624 0.9845783
 0.97590363 0.98289156 0.9785542  0.98963857 0.9963855 ]
2022-01-19 23:23:26,590 - INFO - Epoch time: 393.82975149154663
2022-01-19 23:23:26,590 - INFO - 
Epoch: 74
2022-01-19 23:23:26,590 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:25:04,789 - INFO - [Step=62000]	Loss=0.5050	257.8 examples/second
2022-01-19 23:26:59,221 - INFO - [Step=62250]	Loss=0.5165	279.6 examples/second
2022-01-19 23:28:53,731 - INFO - [Step=62500]	Loss=0.5066	279.5 examples/second
2022-01-19 23:29:59,181 - INFO - Test Loss=0.8164, Test top-1 acc=0.8101
2022-01-19 23:29:59,182 - INFO - Group Accuracy:

2022-01-19 23:29:59,182 - INFO - [0.9804819  0.9913253  0.9850602  0.9930121  0.9850602  0.99445784
 0.98240966 0.98313254 0.98963857 0.9787952  0.9920482  0.9853012
 0.97638553 0.98289156 0.9785542  0.9886747  0.9963855 ]
2022-01-19 23:29:59,182 - INFO - Epoch time: 392.5924701690674
2022-01-19 23:29:59,183 - INFO - 
Epoch: 75
2022-01-19 23:29:59,183 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:30:59,234 - INFO - [Step=62750]	Loss=0.5108	255.0 examples/second
2022-01-19 23:32:55,016 - INFO - [Step=63000]	Loss=0.5068	276.4 examples/second
2022-01-19 23:34:50,875 - INFO - [Step=63250]	Loss=0.5027	276.2 examples/second
2022-01-19 23:36:35,769 - INFO - Test Loss=0.8234, Test top-1 acc=0.8065
2022-01-19 23:36:35,769 - INFO - Group Accuracy:

2022-01-19 23:36:35,769 - INFO - [0.9812048  0.99060243 0.9853012  0.993494   0.9853012  0.9946988
 0.98289156 0.9826506  0.9898795  0.9768675  0.9925301  0.9845783
 0.97638553 0.9816868  0.9785542  0.9886747  0.9959036 ]
2022-01-19 23:36:35,770 - INFO - Epoch time: 396.5875754356384
2022-01-19 23:36:35,770 - INFO - 
Epoch: 76
2022-01-19 23:36:35,770 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:36:56,314 - INFO - [Step=63500]	Loss=0.5205	255.1 examples/second
2022-01-19 23:38:50,683 - INFO - [Step=63750]	Loss=0.5069	279.8 examples/second
2022-01-19 23:40:45,069 - INFO - [Step=64000]	Loss=0.5070	279.8 examples/second
2022-01-19 23:42:39,528 - INFO - [Step=64250]	Loss=0.5124	279.6 examples/second
2022-01-19 23:43:07,931 - INFO - Test Loss=0.8115, Test top-1 acc=0.8099
2022-01-19 23:43:07,932 - INFO - Group Accuracy:

2022-01-19 23:43:07,932 - INFO - [0.9814458  0.99084336 0.9848193  0.9927711  0.9855422  0.9946988
 0.98289156 0.9840964  0.9891566  0.9780723  0.9918072  0.98433733
 0.97590363 0.98240966 0.9785542  0.9884337  0.9961446 ]
2022-01-19 23:43:07,933 - INFO - Epoch time: 392.16279888153076
2022-01-19 23:43:07,933 - INFO - 
Epoch: 77
2022-01-19 23:43:07,933 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:44:44,336 - INFO - [Step=64500]	Loss=0.5052	256.4 examples/second
2022-01-19 23:46:38,963 - INFO - [Step=64750]	Loss=0.4945	279.2 examples/second
2022-01-19 23:48:33,619 - INFO - [Step=65000]	Loss=0.5158	279.1 examples/second
2022-01-19 23:49:40,844 - INFO - Test Loss=0.8194, Test top-1 acc=0.8075
2022-01-19 23:49:40,845 - INFO - Group Accuracy:

2022-01-19 23:49:40,854 - INFO - [0.9809638  0.99084336 0.9860241  0.99373496 0.9850602  0.99445784
 0.9821687  0.9833735  0.9891566  0.9780723  0.99108434 0.98433733
 0.9771084  0.9826506  0.9780723  0.9886747  0.9961446 ]
2022-01-19 23:49:40,855 - INFO - Epoch time: 392.9214713573456
2022-01-19 23:49:40,855 - INFO - 
Epoch: 78
2022-01-19 23:49:40,855 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:50:38,331 - INFO - [Step=65250]	Loss=0.5089	256.6 examples/second
2022-01-19 23:52:33,956 - INFO - [Step=65500]	Loss=0.5111	276.8 examples/second
2022-01-19 23:54:29,505 - INFO - [Step=65750]	Loss=0.5082	276.9 examples/second
2022-01-19 23:56:16,149 - INFO - Test Loss=0.8170, Test top-1 acc=0.8096
2022-01-19 23:56:16,150 - INFO - Group Accuracy:

2022-01-19 23:56:16,150 - INFO - [0.9807229  0.99084336 0.9850602  0.9930121  0.9860241  0.9946988
 0.98313254 0.9826506  0.9891566  0.9775904  0.99108434 0.9845783
 0.97614455 0.9826506  0.97831327 0.9886747  0.9961446 ]
2022-01-19 23:56:16,151 - INFO - Epoch time: 395.29591250419617
2022-01-19 23:56:16,151 - INFO - 
Epoch: 79
2022-01-19 23:56:16,151 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:56:34,184 - INFO - [Step=66000]	Loss=0.5235	256.7 examples/second
2022-01-19 23:58:28,934 - INFO - [Step=66250]	Loss=0.5037	278.9 examples/second
2022-01-20 00:00:23,749 - INFO - [Step=66500]	Loss=0.5047	278.7 examples/second
2022-01-20 00:02:18,588 - INFO - [Step=66750]	Loss=0.5134	278.7 examples/second
2022-01-20 00:02:48,985 - INFO - Test Loss=0.8208, Test top-1 acc=0.8063
2022-01-20 00:02:48,985 - INFO - Group Accuracy:

2022-01-20 00:02:48,986 - INFO - [0.9814458  0.9901205  0.98626506 0.9939759  0.98626506 0.9946988
 0.9816868  0.9819277  0.9891566  0.9773494  0.9918072  0.9853012
 0.97638553 0.98240966 0.9775904  0.9889157  0.9961446 ]
2022-01-20 00:02:48,987 - INFO - Epoch time: 392.8361871242523
2022-01-20 00:02:48,987 - INFO - 
Epoch: 80
2022-01-20 00:02:48,987 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:04:23,202 - INFO - [Step=67000]	Loss=0.4904	256.8 examples/second
2022-01-20 00:06:18,004 - INFO - [Step=67250]	Loss=0.5072	278.7 examples/second
2022-01-20 00:08:12,865 - INFO - [Step=67500]	Loss=0.4927	278.6 examples/second
2022-01-20 00:09:22,561 - INFO - Test Loss=0.8272, Test top-1 acc=0.8099
2022-01-20 00:09:22,561 - INFO - Group Accuracy:

2022-01-20 00:09:22,561 - INFO - [0.9809638  0.99156624 0.9855422  0.993494   0.9860241  0.9946988
 0.9812048  0.98361444 0.98963857 0.9778313  0.9920482  0.9850602
 0.97590363 0.98313254 0.9787952  0.9881928  0.9963855 ]
2022-01-20 00:09:22,562 - INFO - Epoch time: 393.5749912261963
2022-01-20 00:09:22,562 - INFO - 
Epoch: 81
2022-01-20 00:09:22,562 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:10:17,824 - INFO - [Step=67750]	Loss=0.4974	256.1 examples/second
2022-01-20 00:12:12,583 - INFO - [Step=68000]	Loss=0.5035	278.8 examples/second
2022-01-20 00:14:07,473 - INFO - [Step=68250]	Loss=0.5008	278.5 examples/second
2022-01-20 00:15:56,316 - INFO - Test Loss=0.8336, Test top-1 acc=0.8055
2022-01-20 00:15:56,316 - INFO - Group Accuracy:

2022-01-20 00:15:56,317 - INFO - [0.9807229  0.9913253  0.9855422  0.9930121  0.9850602  0.99493974
 0.9809638  0.9821687  0.9889157  0.9775904  0.99060243 0.9840964
 0.97542167 0.9826506  0.9768675  0.9891566  0.9961446 ]
2022-01-20 00:15:56,317 - INFO - Epoch time: 393.7555034160614
2022-01-20 00:15:56,318 - INFO - 
Epoch: 82
2022-01-20 00:15:56,318 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:16:12,241 - INFO - [Step=68500]	Loss=0.4977	256.5 examples/second
2022-01-20 00:18:08,707 - INFO - [Step=68750]	Loss=0.4907	274.8 examples/second
2022-01-20 00:20:05,659 - INFO - [Step=69000]	Loss=0.4906	273.6 examples/second
2022-01-20 00:22:02,838 - INFO - [Step=69250]	Loss=0.4984	273.1 examples/second
2022-01-20 00:22:36,317 - INFO - Test Loss=0.8265, Test top-1 acc=0.8072
2022-01-20 00:22:36,318 - INFO - Group Accuracy:

2022-01-20 00:22:36,318 - INFO - [0.98024094 0.9913253  0.98578316 0.99373496 0.98578316 0.9946988
 0.9819277  0.98289156 0.98963857 0.9780723  0.99060243 0.9845783
 0.97590363 0.9833735  0.9775904  0.9889157  0.9961446 ]
2022-01-20 00:22:36,319 - INFO - Epoch time: 400.00122237205505
2022-01-20 00:22:36,319 - INFO - 
Epoch: 83
2022-01-20 00:22:36,319 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:24:08,985 - INFO - [Step=69500]	Loss=0.4923	253.7 examples/second
2022-01-20 00:26:04,469 - INFO - [Step=69750]	Loss=0.4932	277.1 examples/second
2022-01-20 00:28:00,102 - INFO - [Step=70000]	Loss=0.5018	276.7 examples/second
2022-01-20 00:29:12,411 - INFO - Test Loss=0.8233, Test top-1 acc=0.8082
2022-01-20 00:29:12,411 - INFO - Group Accuracy:

2022-01-20 00:29:12,411 - INFO - [0.9809638  0.9898795  0.9860241  0.99421686 0.9855422  0.9946988
 0.9812048  0.9816868  0.9898795  0.9775904  0.99156624 0.9848193
 0.9768675  0.9826506  0.9775904  0.9893976  0.9963855 ]
2022-01-20 00:29:12,413 - INFO - Epoch time: 396.0941364765167
2022-01-20 00:29:12,413 - INFO - 
Epoch: 84
2022-01-20 00:29:12,413 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:30:05,609 - INFO - [Step=70250]	Loss=0.4957	255.0 examples/second
2022-01-20 00:32:01,584 - INFO - [Step=70500]	Loss=0.4823	275.9 examples/second
2022-01-20 00:33:57,628 - INFO - [Step=70750]	Loss=0.4810	275.8 examples/second
2022-01-20 00:35:49,344 - INFO - Test Loss=0.8303, Test top-1 acc=0.8084
2022-01-20 00:35:49,345 - INFO - Group Accuracy:

2022-01-20 00:35:49,345 - INFO - [0.9809638  0.99156624 0.9855422  0.993494   0.9845783  0.99493974
 0.9807229  0.9826506  0.98963857 0.9775904  0.9920482  0.9855422
 0.9773494  0.98240966 0.9773494  0.9886747  0.9959036 ]
2022-01-20 00:35:49,346 - INFO - Epoch time: 396.93239760398865
2022-01-20 00:35:49,346 - INFO - 
Epoch: 85
2022-01-20 00:35:49,346 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:36:02,838 - INFO - [Step=71000]	Loss=0.4905	255.6 examples/second
2022-01-20 00:37:57,614 - INFO - [Step=71250]	Loss=0.4850	278.8 examples/second
2022-01-20 00:39:52,427 - INFO - [Step=71500]	Loss=0.4795	278.7 examples/second
2022-01-20 00:41:47,377 - INFO - [Step=71750]	Loss=0.4930	278.4 examples/second
2022-01-20 00:42:22,711 - INFO - Test Loss=0.8237, Test top-1 acc=0.8128
2022-01-20 00:42:22,712 - INFO - Group Accuracy:

2022-01-20 00:42:22,712 - INFO - [0.9809638  0.9925301  0.98626506 0.9930121  0.9848193  0.9951807
 0.98240966 0.98313254 0.9898795  0.9780723  0.99156624 0.9853012
 0.9773494  0.9826506  0.9773494  0.9889157  0.9966265 ]
2022-01-20 00:42:22,712 - INFO - Saving...
2022-01-20 00:42:22,946 - INFO - Epoch time: 393.60048508644104
2022-01-20 00:42:22,946 - INFO - 
Epoch: 86
2022-01-20 00:42:22,946 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:43:52,489 - INFO - [Step=72000]	Loss=0.4839	255.8 examples/second
2022-01-20 00:45:47,021 - INFO - [Step=72250]	Loss=0.4820	279.4 examples/second
2022-01-20 00:47:41,451 - INFO - [Step=72500]	Loss=0.4879	279.6 examples/second
2022-01-20 00:48:55,425 - INFO - Test Loss=0.8323, Test top-1 acc=0.8060
2022-01-20 00:48:55,425 - INFO - Group Accuracy:

2022-01-20 00:48:55,425 - INFO - [0.9816868  0.99036145 0.9860241  0.993494   0.9860241  0.99493974
 0.9812048  0.9821687  0.9893976  0.9787952  0.99108434 0.9845783
 0.97590363 0.98361444 0.9780723  0.9889157  0.9961446 ]
2022-01-20 00:48:55,427 - INFO - Epoch time: 392.4801516532898
2022-01-20 00:48:55,427 - INFO - 
Epoch: 87
2022-01-20 00:48:55,427 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:49:46,107 - INFO - [Step=72750]	Loss=0.4886	256.7 examples/second
2022-01-20 00:51:40,827 - INFO - [Step=73000]	Loss=0.4922	278.9 examples/second
2022-01-20 00:53:35,564 - INFO - [Step=73250]	Loss=0.4871	278.9 examples/second
2022-01-20 00:55:28,327 - INFO - Test Loss=0.8310, Test top-1 acc=0.8077
2022-01-20 00:55:28,328 - INFO - Group Accuracy:

2022-01-20 00:55:28,328 - INFO - [0.9816868  0.9913253  0.9833735  0.993494   0.9848193  0.99445784
 0.98240966 0.9833735  0.9893976  0.9787952  0.9913253  0.9840964
 0.9766265  0.98313254 0.9778313  0.9886747  0.9963855 ]
2022-01-20 00:55:28,329 - INFO - Epoch time: 392.90215969085693
2022-01-20 00:55:28,329 - INFO - 
Epoch: 88
2022-01-20 00:55:28,329 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:55:39,688 - INFO - [Step=73500]	Loss=0.4737	257.8 examples/second
2022-01-20 00:57:35,196 - INFO - [Step=73750]	Loss=0.4777	277.0 examples/second
2022-01-20 00:59:30,876 - INFO - [Step=74000]	Loss=0.4783	276.6 examples/second
2022-01-20 01:01:26,709 - INFO - [Step=74250]	Loss=0.4831	276.3 examples/second
2022-01-20 01:02:04,434 - INFO - Test Loss=0.8253, Test top-1 acc=0.8077
2022-01-20 01:02:04,434 - INFO - Group Accuracy:

2022-01-20 01:02:04,434 - INFO - [0.9812048  0.99060243 0.98433733 0.993494   0.9855422  0.9954217
 0.9812048  0.98361444 0.9893976  0.9785542  0.99156624 0.9850602
 0.97614455 0.9838554  0.9778313  0.9898795  0.9956626 ]
2022-01-20 01:02:04,435 - INFO - Epoch time: 396.1057322025299
2022-01-20 01:02:04,435 - INFO - 
Epoch: 89
2022-01-20 01:02:04,435 - INFO - 
Learning Rate: 0.0010
2022-01-20 01:03:33,024 - INFO - [Step=74500]	Loss=0.4784	253.3 examples/second
2022-01-20 01:05:29,752 - INFO - [Step=74750]	Loss=0.4772	274.1 examples/second
2022-01-20 01:07:26,833 - INFO - [Step=75000]	Loss=0.4894	273.3 examples/second
2022-01-20 01:08:44,619 - INFO - Test Loss=0.8355, Test top-1 acc=0.8094
2022-01-20 01:08:44,620 - INFO - Group Accuracy:

2022-01-20 01:08:44,620 - INFO - [0.9804819  0.9913253  0.9853012  0.993494   0.9848193  0.99445784
 0.9816868  0.9838554  0.9898795  0.97831327 0.9913253  0.98433733
 0.97614455 0.98240966 0.9778313  0.9889157  0.9963855 ]
2022-01-20 01:08:44,621 - INFO - Epoch time: 400.18665623664856
2022-01-20 01:08:56,532 - INFO - Computing OOD Statistics...
2022-01-20 01:08:56,540 - INFO - 	Baseline.          AUROC: 0.3702. TNR@95TPR: 0.0306. AUPR OUT: 0.1310
2022-01-20 01:08:56,545 - INFO - 	ODIN (T=1000).     AUROC: 0.8779. TNR@95TPR: 0.4165. AUPR OUT: 0.5671
2022-01-20 01:08:56,545 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-20 01:08:56,545 - INFO - Top 1 Accuracy:  Min: 0.8128; Max: 0.8128; Avg: 0.8128; Std: 0.0000; Len: 1
2022-01-20 01:08:56,545 - INFO - Top 5 Accuracy:  Min: 0.9862; Max: 0.9862; Avg: 0.9862; Std: 0.0000; Len: 1
2022-01-20 01:08:56,545 - INFO - **********************************************************************
2022-01-20 01:08:56,545 - INFO - 	MSP (auroc): [0.37016725726435157] Min: 0.3702; Max: 0.3702; Avg: 0.3702; Std: 0.0000; Len: 1
2022-01-20 01:08:56,546 - INFO - 	MSP (tnr): [0.030588235294117694] Min: 0.0306; Max: 0.0306; Avg: 0.0306; Std: 0.0000; Len: 1
2022-01-20 01:08:56,546 - INFO - 	MSP (aupr): [0.1309591700041596] Min: 0.1310; Max: 0.1310; Avg: 0.1310; Std: 0.0000; Len: 1
2022-01-20 01:08:56,546 - INFO - 	ODIN (auroc): [0.8779217576187102] Min: 0.8779; Max: 0.8779; Avg: 0.8779; Std: 0.0000; Len: 1
2022-01-20 01:08:56,546 - INFO - 	ODIN (tnr): [0.41647058823529415] Min: 0.4165; Max: 0.4165; Avg: 0.4165; Std: 0.0000; Len: 1
2022-01-20 01:08:56,546 - INFO - 	ODIN (aupr): [0.5670784928049755] Min: 0.5671; Max: 0.5671; Avg: 0.5671; Std: 0.0000; Len: 1

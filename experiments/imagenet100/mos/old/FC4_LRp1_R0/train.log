2022-01-19 15:16:05,790 - INFO - ==> Preparing data..
2022-01-19 15:16:06,147 - INFO - checkpoint filename: experiments/coarse/mos/FC4_LRp1_R0/checkpoint.pt
2022-01-19 15:16:06,147 - INFO - log filename: experiments/coarse/mos/FC4_LRp1_R0/train.log
2022-01-19 15:16:06,147 - INFO - ********************************************************
2022-01-19 15:16:06,147 - INFO - Starting Iter: 0 / 1
2022-01-19 15:16:06,147 - INFO - ********************************************************
2022-01-19 15:16:09,303 - INFO - cuda
2022-01-19 15:16:09,332 - INFO - 
Epoch: 0
2022-01-19 15:16:09,332 - INFO - 
Learning Rate: 0.0100
2022-01-19 15:18:05,704 - INFO - [Step=250]	Loss=7.1868	275.0 examples/second
2022-01-19 15:19:59,494 - INFO - [Step=500]	Loss=5.4085	281.2 examples/second
2022-01-19 15:21:53,398 - INFO - [Step=750]	Loss=5.2824	280.9 examples/second
2022-01-19 15:22:39,454 - INFO - Test Loss=5.2015, Test top-1 acc=0.0489
2022-01-19 15:22:39,455 - INFO - Group Accuracy:

2022-01-19 15:22:39,455 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-19 15:22:39,456 - INFO - Saving...
2022-01-19 15:22:39,613 - INFO - Epoch time: 390.2809717655182
2022-01-19 15:22:39,613 - INFO - 
Epoch: 1
2022-01-19 15:22:39,613 - INFO - 
Learning Rate: 0.0280
2022-01-19 15:23:57,528 - INFO - [Step=1000]	Loss=5.1760	257.8 examples/second
2022-01-19 15:25:52,470 - INFO - [Step=1250]	Loss=4.9728	278.4 examples/second
2022-01-19 15:27:47,355 - INFO - [Step=1500]	Loss=4.8577	278.5 examples/second
2022-01-19 15:29:12,681 - INFO - Test Loss=4.7637, Test top-1 acc=0.1190
2022-01-19 15:29:12,682 - INFO - Group Accuracy:

2022-01-19 15:29:12,682 - INFO - [0.939759   0.939759   0.939759   0.94144577 0.939759   0.940241
 0.939759   0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.9395181  0.9518072 ]
2022-01-19 15:29:12,683 - INFO - Saving...
2022-01-19 15:29:12,948 - INFO - Epoch time: 393.3348059654236
2022-01-19 15:29:12,948 - INFO - 
Epoch: 2
2022-01-19 15:29:12,948 - INFO - 
Learning Rate: 0.0460
2022-01-19 15:29:51,784 - INFO - [Step=1750]	Loss=4.7245	257.2 examples/second
2022-01-19 15:31:47,231 - INFO - [Step=2000]	Loss=4.6110	277.2 examples/second
2022-01-19 15:33:42,066 - INFO - [Step=2250]	Loss=4.4340	278.7 examples/second
2022-01-19 15:35:36,771 - INFO - [Step=2500]	Loss=4.2608	279.0 examples/second
2022-01-19 15:35:46,308 - INFO - Test Loss=4.0703, Test top-1 acc=0.2123
2022-01-19 15:35:46,308 - INFO - Group Accuracy:

2022-01-19 15:35:46,308 - INFO - [0.9395181  0.9448193  0.9407229  0.94578314 0.939759   0.946506
 0.9407229  0.94192773 0.94289154 0.939759   0.95301205 0.940241
 0.94       0.939759   0.939759   0.93903613 0.95373493]
2022-01-19 15:35:46,309 - INFO - Saving...
2022-01-19 15:35:46,572 - INFO - Epoch time: 393.624196767807
2022-01-19 15:35:46,573 - INFO - 
Epoch: 3
2022-01-19 15:35:46,573 - INFO - 
Learning Rate: 0.0640
2022-01-19 15:37:41,364 - INFO - [Step=2750]	Loss=4.1914	256.8 examples/second
2022-01-19 15:39:36,071 - INFO - [Step=3000]	Loss=4.0248	279.0 examples/second
2022-01-19 15:41:30,936 - INFO - [Step=3250]	Loss=3.8358	278.6 examples/second
2022-01-19 15:42:19,616 - INFO - Test Loss=4.0001, Test top-1 acc=0.2831
2022-01-19 15:42:19,616 - INFO - Group Accuracy:

2022-01-19 15:42:19,616 - INFO - [0.94240963 0.9501205  0.94144577 0.95277107 0.9433735  0.95686746
 0.94240963 0.9472289  0.9460241  0.94144577 0.9520482  0.939759
 0.94120485 0.94144577 0.940241   0.94289154 0.9544578 ]
2022-01-19 15:42:19,617 - INFO - Saving...
2022-01-19 15:42:19,876 - INFO - Epoch time: 393.3037497997284
2022-01-19 15:42:19,877 - INFO - 
Epoch: 4
2022-01-19 15:42:19,877 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:43:36,136 - INFO - [Step=3500]	Loss=3.7755	255.6 examples/second
2022-01-19 15:45:31,222 - INFO - [Step=3750]	Loss=3.7792	278.1 examples/second
2022-01-19 15:47:26,029 - INFO - [Step=4000]	Loss=3.5746	278.7 examples/second
2022-01-19 15:48:53,474 - INFO - Test Loss=3.4057, Test top-1 acc=0.3258
2022-01-19 15:48:53,475 - INFO - Group Accuracy:

2022-01-19 15:48:53,475 - INFO - [0.9469879  0.94915664 0.9436145  0.9612048  0.94578314 0.9631325
 0.93759036 0.9474699  0.9479518  0.94240963 0.9520482  0.94216865
 0.9395181  0.94216865 0.9436145  0.94578314 0.9662651 ]
2022-01-19 15:48:53,476 - INFO - Saving...
2022-01-19 15:48:53,730 - INFO - Epoch time: 393.8537781238556
2022-01-19 15:48:53,731 - INFO - 
Epoch: 5
2022-01-19 15:48:53,731 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:49:30,175 - INFO - [Step=4250]	Loss=3.4274	257.8 examples/second
2022-01-19 15:51:25,559 - INFO - [Step=4500]	Loss=3.2689	277.3 examples/second
2022-01-19 15:53:20,819 - INFO - [Step=4750]	Loss=3.1822	277.6 examples/second
2022-01-19 15:55:15,951 - INFO - [Step=5000]	Loss=3.0749	277.9 examples/second
2022-01-19 15:55:27,775 - INFO - Test Loss=3.1147, Test top-1 acc=0.3735
2022-01-19 15:55:27,775 - INFO - Group Accuracy:

2022-01-19 15:55:27,775 - INFO - [0.9481928  0.9498795  0.94506025 0.94891566 0.94506025 0.9660241
 0.94578314 0.9436145  0.9587952  0.9477109  0.9592771  0.9472289
 0.94120485 0.9436145  0.9431325  0.9539759  0.9708434 ]
2022-01-19 15:55:27,777 - INFO - Saving...
2022-01-19 15:55:28,010 - INFO - Epoch time: 394.2791163921356
2022-01-19 15:55:28,010 - INFO - 
Epoch: 6
2022-01-19 15:55:28,010 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:57:21,113 - INFO - [Step=5250]	Loss=2.9862	255.7 examples/second
2022-01-19 15:59:17,012 - INFO - [Step=5500]	Loss=2.8948	276.1 examples/second
2022-01-19 16:01:12,930 - INFO - [Step=5750]	Loss=2.8439	276.1 examples/second
2022-01-19 16:02:04,179 - INFO - Test Loss=2.9083, Test top-1 acc=0.4376
2022-01-19 16:02:04,179 - INFO - Group Accuracy:

2022-01-19 16:02:04,180 - INFO - [0.94963855 0.9578313  0.94843376 0.9703615  0.9498795  0.9773494
 0.94216865 0.95662653 0.9628916  0.9501205  0.96048194 0.9486747
 0.9395181  0.9436145  0.946747   0.9520482  0.9739759 ]
2022-01-19 16:02:04,181 - INFO - Saving...
2022-01-19 16:02:04,415 - INFO - Epoch time: 396.4044985771179
2022-01-19 16:02:04,415 - INFO - 
Epoch: 7
2022-01-19 16:02:04,415 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:03:17,752 - INFO - [Step=6000]	Loss=2.7409	256.4 examples/second
2022-01-19 16:05:12,424 - INFO - [Step=6250]	Loss=2.6676	279.1 examples/second
2022-01-19 16:07:07,016 - INFO - [Step=6500]	Loss=2.6290	279.3 examples/second
2022-01-19 16:08:36,766 - INFO - Test Loss=2.4937, Test top-1 acc=0.4752
2022-01-19 16:08:36,767 - INFO - Group Accuracy:

2022-01-19 16:08:36,767 - INFO - [0.95566267 0.9578313  0.9501205  0.973253   0.9498795  0.9725301
 0.94891566 0.94963855 0.9653012  0.9585542  0.96771085 0.9539759
 0.9407229  0.946506   0.9486747  0.9592771  0.9821687 ]
2022-01-19 16:08:36,767 - INFO - Saving...
2022-01-19 16:08:37,002 - INFO - Epoch time: 392.58715534210205
2022-01-19 16:08:37,002 - INFO - 
Epoch: 8
2022-01-19 16:08:37,002 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:09:11,225 - INFO - [Step=6750]	Loss=2.5478	257.6 examples/second
2022-01-19 16:11:06,086 - INFO - [Step=7000]	Loss=2.4894	278.6 examples/second
2022-01-19 16:13:00,641 - INFO - [Step=7250]	Loss=2.4555	279.3 examples/second
2022-01-19 16:14:55,101 - INFO - [Step=7500]	Loss=2.4176	279.6 examples/second
2022-01-19 16:15:09,147 - INFO - Test Loss=2.3756, Test top-1 acc=0.4983
2022-01-19 16:15:09,148 - INFO - Group Accuracy:

2022-01-19 16:15:09,148 - INFO - [0.95662653 0.96048194 0.95373493 0.9739759  0.94578314 0.97975904
 0.95686746 0.9549398  0.9746988  0.95373493 0.966506   0.94891566
 0.94626504 0.94891566 0.9510843  0.96072286 0.9787952 ]
2022-01-19 16:15:09,149 - INFO - Saving...
2022-01-19 16:15:09,418 - INFO - Epoch time: 392.4159469604492
2022-01-19 16:15:09,418 - INFO - 
Epoch: 9
2022-01-19 16:15:09,419 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:16:59,771 - INFO - [Step=7750]	Loss=2.3245	256.7 examples/second
2022-01-19 16:18:55,421 - INFO - [Step=8000]	Loss=2.3115	276.7 examples/second
2022-01-19 16:20:50,972 - INFO - [Step=8250]	Loss=2.2698	276.9 examples/second
2022-01-19 16:21:44,904 - INFO - Test Loss=2.1883, Test top-1 acc=0.5318
2022-01-19 16:21:44,905 - INFO - Group Accuracy:

2022-01-19 16:21:44,905 - INFO - [0.9578313  0.96409637 0.9551807  0.9773494  0.9612048  0.9821687
 0.95421684 0.96433735 0.9653012  0.95710844 0.9696385  0.96048194
 0.94578314 0.9486747  0.9520482  0.9655422  0.98313254]
2022-01-19 16:21:44,906 - INFO - Saving...
2022-01-19 16:21:45,172 - INFO - Epoch time: 395.7536292076111
2022-01-19 16:21:45,172 - INFO - 
Epoch: 10
2022-01-19 16:21:45,172 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:22:56,722 - INFO - [Step=8500]	Loss=2.1997	254.5 examples/second
2022-01-19 16:24:53,126 - INFO - [Step=8750]	Loss=2.1877	274.9 examples/second
2022-01-19 16:26:49,324 - INFO - [Step=9000]	Loss=2.1543	275.4 examples/second
2022-01-19 16:28:22,617 - INFO - Test Loss=2.2790, Test top-1 acc=0.5376
2022-01-19 16:28:22,617 - INFO - Group Accuracy:

2022-01-19 16:28:22,617 - INFO - [0.95759034 0.9727711  0.9585542  0.9698795  0.9583132  0.9812048
 0.95566267 0.9612048  0.9698795  0.95421684 0.96433735 0.9510843
 0.9445783  0.946747   0.9551807  0.966506   0.98289156]
2022-01-19 16:28:22,619 - INFO - Saving...
2022-01-19 16:28:22,864 - INFO - Epoch time: 397.69144225120544
2022-01-19 16:28:22,864 - INFO - 
Epoch: 11
2022-01-19 16:28:22,864 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:28:55,093 - INFO - [Step=9250]	Loss=2.1382	254.4 examples/second
2022-01-19 16:30:51,054 - INFO - [Step=9500]	Loss=2.1018	276.0 examples/second
2022-01-19 16:32:46,223 - INFO - [Step=9750]	Loss=2.0522	277.9 examples/second
2022-01-19 16:34:41,603 - INFO - [Step=10000]	Loss=2.0391	277.3 examples/second
2022-01-19 16:34:58,004 - INFO - Test Loss=1.9826, Test top-1 acc=0.5761
2022-01-19 16:34:58,004 - INFO - Group Accuracy:

2022-01-19 16:34:58,004 - INFO - [0.96409637 0.9686747  0.95277107 0.9775904  0.96457833 0.9807229
 0.9544578  0.96361446 0.9778313  0.9674699  0.9725301  0.96819276
 0.9513253  0.9513253  0.95373493 0.9703615  0.9833735 ]
2022-01-19 16:34:58,005 - INFO - Saving...
2022-01-19 16:34:58,249 - INFO - Epoch time: 395.38481616973877
2022-01-19 16:34:58,249 - INFO - 
Epoch: 12
2022-01-19 16:34:58,249 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:36:45,971 - INFO - [Step=10250]	Loss=1.9848	257.3 examples/second
2022-01-19 16:38:41,397 - INFO - [Step=10500]	Loss=1.9974	277.2 examples/second
2022-01-19 16:40:36,637 - INFO - [Step=10750]	Loss=1.9567	277.7 examples/second
2022-01-19 16:41:32,334 - INFO - Test Loss=1.9399, Test top-1 acc=0.5976
2022-01-19 16:41:32,334 - INFO - Group Accuracy:

2022-01-19 16:41:32,334 - INFO - [0.9614458  0.9691566  0.9544578  0.9814458  0.96048194 0.9845783
 0.96072286 0.96457833 0.9778313  0.9657831  0.9746988  0.96819276
 0.9546988  0.9469879  0.96096385 0.96433735 0.9845783 ]
2022-01-19 16:41:32,335 - INFO - Saving...
2022-01-19 16:41:32,572 - INFO - Epoch time: 394.32254338264465
2022-01-19 16:41:32,572 - INFO - 
Epoch: 13
2022-01-19 16:41:32,572 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:42:41,206 - INFO - [Step=11000]	Loss=1.9209	256.9 examples/second
2022-01-19 16:44:37,241 - INFO - [Step=11250]	Loss=1.9203	275.8 examples/second
2022-01-19 16:46:33,490 - INFO - [Step=11500]	Loss=1.8983	275.3 examples/second
2022-01-19 16:48:09,452 - INFO - Test Loss=1.8586, Test top-1 acc=0.6041
2022-01-19 16:48:09,453 - INFO - Group Accuracy:

2022-01-19 16:48:09,453 - INFO - [0.9619277  0.97614455 0.9590362  0.98289156 0.9614458  0.9804819
 0.9520482  0.9706024  0.97927713 0.96433735 0.97638553 0.9628916
 0.9549398  0.9580723  0.95975906 0.9703615  0.9845783 ]
2022-01-19 16:48:09,454 - INFO - Saving...
2022-01-19 16:48:09,689 - INFO - Epoch time: 397.11692476272583
2022-01-19 16:48:09,689 - INFO - 
Epoch: 14
2022-01-19 16:48:09,689 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:48:39,637 - INFO - [Step=11750]	Loss=1.8727	253.7 examples/second
2022-01-19 16:50:35,453 - INFO - [Step=12000]	Loss=1.8259	276.3 examples/second
2022-01-19 16:52:30,554 - INFO - [Step=12250]	Loss=1.8279	278.0 examples/second
2022-01-19 16:54:25,787 - INFO - [Step=12500]	Loss=1.8221	277.7 examples/second
2022-01-19 16:54:44,637 - INFO - Test Loss=1.8761, Test top-1 acc=0.6084
2022-01-19 16:54:44,637 - INFO - Group Accuracy:

2022-01-19 16:54:44,637 - INFO - [0.9612048  0.97445786 0.9592771  0.9812048  0.96506023 0.98771083
 0.9592771  0.96819276 0.9804819  0.9621687  0.97301203 0.9561446
 0.95566267 0.9549398  0.9592771  0.9706024  0.98626506]
2022-01-19 16:54:44,638 - INFO - Saving...
2022-01-19 16:54:44,807 - INFO - Epoch time: 395.1181695461273
2022-01-19 16:54:44,807 - INFO - 
Epoch: 15
2022-01-19 16:54:44,808 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:56:30,172 - INFO - [Step=12750]	Loss=1.7742	257.3 examples/second
2022-01-19 16:58:25,044 - INFO - [Step=13000]	Loss=1.7623	278.6 examples/second
2022-01-19 17:00:19,727 - INFO - [Step=13250]	Loss=1.7656	279.0 examples/second
2022-01-19 17:01:17,716 - INFO - Test Loss=2.0003, Test top-1 acc=0.5966
2022-01-19 17:01:17,716 - INFO - Group Accuracy:

2022-01-19 17:01:17,716 - INFO - [0.96481925 0.9778313  0.96       0.9821687  0.96385545 0.98578316
 0.96168673 0.9653012  0.9706024  0.96096385 0.97108436 0.9662651
 0.9438554  0.9587952  0.95686746 0.97108436 0.9838554 ]
2022-01-19 17:01:17,717 - INFO - Epoch time: 392.9096050262451
2022-01-19 17:01:17,717 - INFO - 
Epoch: 16
2022-01-19 17:01:17,717 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:02:24,295 - INFO - [Step=13500]	Loss=1.7693	256.9 examples/second
2022-01-19 17:04:20,339 - INFO - [Step=13750]	Loss=1.7103	275.8 examples/second
2022-01-19 17:06:16,195 - INFO - [Step=14000]	Loss=1.7342	276.2 examples/second
2022-01-19 17:07:54,538 - INFO - Test Loss=1.7282, Test top-1 acc=0.6219
2022-01-19 17:07:54,539 - INFO - Group Accuracy:

2022-01-19 17:07:54,539 - INFO - [0.95975906 0.9701205  0.95710844 0.9821687  0.9674699  0.9879518
 0.9551807  0.97108436 0.98024094 0.96433735 0.973494   0.9653012
 0.9614458  0.9592771  0.9626506  0.97156626 0.9879518 ]
2022-01-19 17:07:54,540 - INFO - Saving...
2022-01-19 17:07:54,721 - INFO - Epoch time: 397.00381088256836
2022-01-19 17:07:54,721 - INFO - 
Epoch: 17
2022-01-19 17:07:54,721 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:08:22,349 - INFO - [Step=14250]	Loss=1.7081	253.7 examples/second
2022-01-19 17:10:18,322 - INFO - [Step=14500]	Loss=1.6584	275.9 examples/second
2022-01-19 17:12:13,426 - INFO - [Step=14750]	Loss=1.6672	278.0 examples/second
2022-01-19 17:14:08,483 - INFO - [Step=15000]	Loss=1.6896	278.1 examples/second
2022-01-19 17:14:29,640 - INFO - Test Loss=1.6676, Test top-1 acc=0.6463
2022-01-19 17:14:29,641 - INFO - Group Accuracy:

2022-01-19 17:14:29,641 - INFO - [0.96843374 0.97493976 0.96891564 0.9838554  0.96795183 0.98578316
 0.9633735  0.966506   0.97903615 0.96843374 0.973494   0.97180724
 0.95228916 0.9595181  0.9595181  0.9771084  0.9855422 ]
2022-01-19 17:14:29,642 - INFO - Saving...
2022-01-19 17:14:29,815 - INFO - Epoch time: 395.0940842628479
2022-01-19 17:14:29,815 - INFO - 
Epoch: 18
2022-01-19 17:14:29,816 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:16:13,235 - INFO - [Step=15250]	Loss=1.6221	256.5 examples/second
2022-01-19 17:18:08,992 - INFO - [Step=15500]	Loss=1.6315	276.4 examples/second
2022-01-19 17:20:04,508 - INFO - [Step=15750]	Loss=1.6393	277.0 examples/second
2022-01-19 17:21:04,853 - INFO - Test Loss=1.5950, Test top-1 acc=0.6441
2022-01-19 17:21:04,854 - INFO - Group Accuracy:

2022-01-19 17:21:04,854 - INFO - [0.96409637 0.9809638  0.96698797 0.98746985 0.9708434  0.99060243
 0.96409637 0.9621687  0.9780723  0.9708434  0.9698795  0.9653012
 0.96409637 0.9674699  0.9614458  0.96771085 0.9891566 ]
2022-01-19 17:21:04,855 - INFO - Epoch time: 395.03929376602173
2022-01-19 17:21:04,855 - INFO - 
Epoch: 19
2022-01-19 17:21:04,855 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:22:09,167 - INFO - [Step=16000]	Loss=1.5941	256.7 examples/second
2022-01-19 17:24:04,601 - INFO - [Step=16250]	Loss=1.6121	277.2 examples/second
2022-01-19 17:25:59,882 - INFO - [Step=16500]	Loss=1.5957	277.6 examples/second
2022-01-19 17:27:39,502 - INFO - Test Loss=1.5386, Test top-1 acc=0.6494
2022-01-19 17:27:39,502 - INFO - Group Accuracy:

2022-01-19 17:27:39,502 - INFO - [0.9691566  0.97445786 0.9708434  0.98289156 0.9653012  0.9881928
 0.966747   0.96698797 0.97903615 0.9691566  0.9775904  0.9713253
 0.95975906 0.96457833 0.9624096  0.97445786 0.98722893]
2022-01-19 17:27:39,503 - INFO - Saving...
2022-01-19 17:27:39,775 - INFO - Epoch time: 394.9204251766205
2022-01-19 17:27:39,776 - INFO - 
Epoch: 20
2022-01-19 17:27:39,776 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:28:04,618 - INFO - [Step=16750]	Loss=1.5939	256.5 examples/second
2022-01-19 17:29:59,657 - INFO - [Step=17000]	Loss=1.5616	278.2 examples/second
2022-01-19 17:31:54,762 - INFO - [Step=17250]	Loss=1.5614	278.0 examples/second
2022-01-19 17:33:50,021 - INFO - [Step=17500]	Loss=1.5782	277.6 examples/second
2022-01-19 17:34:13,445 - INFO - Test Loss=1.5927, Test top-1 acc=0.6487
2022-01-19 17:34:13,446 - INFO - Group Accuracy:

2022-01-19 17:34:13,446 - INFO - [0.9621687  0.9819277  0.9706024  0.98313254 0.96843374 0.9889157
 0.96409637 0.9660241  0.97927713 0.966506   0.9780723  0.97228914
 0.9626506  0.9619277  0.9595181  0.97566265 0.98313254]
2022-01-19 17:34:13,446 - INFO - Epoch time: 393.6708233356476
2022-01-19 17:34:13,447 - INFO - 
Epoch: 21
2022-01-19 17:34:13,447 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:35:54,240 - INFO - [Step=17750]	Loss=1.5243	257.6 examples/second
2022-01-19 17:37:49,214 - INFO - [Step=18000]	Loss=1.5389	278.3 examples/second
2022-01-19 17:39:44,219 - INFO - [Step=18250]	Loss=1.5463	278.3 examples/second
2022-01-19 17:40:46,706 - INFO - Test Loss=1.7220, Test top-1 acc=0.6316
2022-01-19 17:40:46,706 - INFO - Group Accuracy:

2022-01-19 17:40:46,707 - INFO - [0.96433735 0.97518075 0.9592771  0.9821687  0.96481925 0.9881928
 0.9628916  0.9696385  0.97975904 0.9585542  0.973253   0.9713253
 0.9554217  0.96506023 0.9619277  0.9737349  0.9893976 ]
2022-01-19 17:40:46,707 - INFO - Epoch time: 393.260769367218
2022-01-19 17:40:46,707 - INFO - 
Epoch: 22
2022-01-19 17:40:46,707 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:41:48,616 - INFO - [Step=18500]	Loss=1.5186	257.2 examples/second
2022-01-19 17:43:43,894 - INFO - [Step=18750]	Loss=1.4957	277.6 examples/second
2022-01-19 17:45:39,032 - INFO - [Step=19000]	Loss=1.5081	277.9 examples/second
2022-01-19 17:47:20,799 - INFO - Test Loss=1.5613, Test top-1 acc=0.6487
2022-01-19 17:47:20,799 - INFO - Group Accuracy:

2022-01-19 17:47:20,799 - INFO - [0.966747   0.9739759  0.9662651  0.9845783  0.97204816 0.9893976
 0.966506   0.9708434  0.9787952  0.9691566  0.9737349  0.9701205
 0.95710844 0.96457833 0.9614458  0.97518075 0.9901205 ]
2022-01-19 17:47:20,800 - INFO - Epoch time: 394.0926432609558
2022-01-19 17:47:20,800 - INFO - 
Epoch: 23
2022-01-19 17:47:20,800 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:47:43,169 - INFO - [Step=19250]	Loss=1.5200	257.8 examples/second
2022-01-19 17:49:38,400 - INFO - [Step=19500]	Loss=1.4961	277.7 examples/second
2022-01-19 17:51:33,654 - INFO - [Step=19750]	Loss=1.4951	277.7 examples/second
2022-01-19 17:53:28,799 - INFO - [Step=20000]	Loss=1.4966	277.9 examples/second
2022-01-19 17:53:54,379 - INFO - Test Loss=1.5272, Test top-1 acc=0.6675
2022-01-19 17:53:54,380 - INFO - Group Accuracy:

2022-01-19 17:53:54,380 - INFO - [0.96698797 0.98       0.97156626 0.98771083 0.97204816 0.9860241
 0.96843374 0.9706024  0.9819277  0.9725301  0.97542167 0.9713253
 0.9619277  0.9626506  0.9551807  0.9771084  0.98771083]
2022-01-19 17:53:54,381 - INFO - Saving...
2022-01-19 17:53:54,565 - INFO - Epoch time: 393.76513934135437
2022-01-19 17:53:54,565 - INFO - 
Epoch: 24
2022-01-19 17:53:54,565 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:55:33,636 - INFO - [Step=20250]	Loss=1.4567	256.3 examples/second
2022-01-19 17:57:29,863 - INFO - [Step=20500]	Loss=1.4606	275.3 examples/second
2022-01-19 17:59:25,995 - INFO - [Step=20750]	Loss=1.4681	275.5 examples/second
2022-01-19 18:00:31,585 - INFO - Test Loss=1.5345, Test top-1 acc=0.6639
2022-01-19 18:00:31,586 - INFO - Group Accuracy:

2022-01-19 18:00:31,586 - INFO - [0.9696385  0.9742169  0.97228914 0.98313254 0.9708434  0.9881928
 0.9628916  0.9739759  0.9807229  0.9696385  0.9816868  0.97204816
 0.9590362  0.9631325  0.9655422  0.9737349  0.9881928 ]
2022-01-19 18:00:31,587 - INFO - Epoch time: 397.0219147205353
2022-01-19 18:00:31,587 - INFO - 
Epoch: 25
2022-01-19 18:00:31,588 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:01:31,770 - INFO - [Step=21000]	Loss=1.4558	254.4 examples/second
2022-01-19 18:03:27,668 - INFO - [Step=21250]	Loss=1.4398	276.1 examples/second
2022-01-19 18:05:23,641 - INFO - [Step=21500]	Loss=1.4476	275.9 examples/second
2022-01-19 18:07:08,701 - INFO - Test Loss=1.9649, Test top-1 acc=0.6084
2022-01-19 18:07:08,702 - INFO - Group Accuracy:

2022-01-19 18:07:08,702 - INFO - [0.96795183 0.9727711  0.93084335 0.9819277  0.96698797 0.9848193
 0.9621687  0.96024096 0.9838554  0.96361446 0.97614455 0.9737349
 0.9595181  0.9585542  0.9583132  0.96795183 0.98771083]
2022-01-19 18:07:08,703 - INFO - Epoch time: 397.11532330513
2022-01-19 18:07:08,703 - INFO - 
Epoch: 26
2022-01-19 18:07:08,703 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:07:29,370 - INFO - [Step=21750]	Loss=1.4529	254.5 examples/second
2022-01-19 18:09:25,026 - INFO - [Step=22000]	Loss=1.4218	276.7 examples/second
2022-01-19 18:11:20,467 - INFO - [Step=22250]	Loss=1.4520	277.2 examples/second
2022-01-19 18:13:15,671 - INFO - [Step=22500]	Loss=1.4300	277.8 examples/second
2022-01-19 18:13:43,742 - INFO - Test Loss=1.4257, Test top-1 acc=0.6848
2022-01-19 18:13:43,743 - INFO - Group Accuracy:

2022-01-19 18:13:43,743 - INFO - [0.9713253  0.97927713 0.96457833 0.9855422  0.96506023 0.9886747
 0.9674699  0.97493976 0.98433733 0.96506023 0.9814458  0.9703615
 0.9672289  0.9698795  0.9660241  0.9746988  0.98722893]
2022-01-19 18:13:43,744 - INFO - Saving...
2022-01-19 18:13:43,930 - INFO - Epoch time: 395.2272267341614
2022-01-19 18:13:43,930 - INFO - 
Epoch: 27
2022-01-19 18:13:43,930 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:15:20,495 - INFO - [Step=22750]	Loss=1.3957	256.4 examples/second
2022-01-19 18:17:16,158 - INFO - [Step=23000]	Loss=1.4251	276.7 examples/second
2022-01-19 18:19:11,880 - INFO - [Step=23250]	Loss=1.4123	276.5 examples/second
2022-01-19 18:20:19,346 - INFO - Test Loss=1.5237, Test top-1 acc=0.6578
2022-01-19 18:20:19,346 - INFO - Group Accuracy:

2022-01-19 18:20:19,346 - INFO - [0.96361446 0.97638553 0.97228914 0.9855422  0.9725301  0.98722893
 0.9674699  0.9693976  0.98433733 0.96795183 0.9771084  0.9727711
 0.95710844 0.966506   0.96361446 0.97638553 0.98771083]
2022-01-19 18:20:19,347 - INFO - Epoch time: 395.4169728755951
2022-01-19 18:20:19,347 - INFO - 
Epoch: 28
2022-01-19 18:20:19,347 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:21:16,958 - INFO - [Step=23500]	Loss=1.4001	255.8 examples/second
2022-01-19 18:23:12,472 - INFO - [Step=23750]	Loss=1.3862	277.0 examples/second
2022-01-19 18:25:07,884 - INFO - [Step=24000]	Loss=1.3863	277.3 examples/second
2022-01-19 18:26:54,188 - INFO - Test Loss=1.4990, Test top-1 acc=0.6696
2022-01-19 18:26:54,188 - INFO - Group Accuracy:

2022-01-19 18:26:54,189 - INFO - [0.9701205  0.98289156 0.97301203 0.9853012  0.96409637 0.9848193
 0.9619277  0.97156626 0.9821687  0.97228914 0.97590363 0.9725301
 0.9626506  0.96457833 0.9628916  0.9780723  0.99084336]
2022-01-19 18:26:54,190 - INFO - Epoch time: 394.8422875404358
2022-01-19 18:26:54,190 - INFO - 
Epoch: 29
2022-01-19 18:26:54,190 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:27:12,188 - INFO - [Step=24250]	Loss=1.3833	257.4 examples/second
2022-01-19 18:29:07,906 - INFO - [Step=24500]	Loss=1.0738	276.5 examples/second
2022-01-19 18:31:03,726 - INFO - [Step=24750]	Loss=1.0204	276.3 examples/second
2022-01-19 18:32:59,539 - INFO - [Step=25000]	Loss=1.0003	276.3 examples/second
2022-01-19 18:33:30,325 - INFO - Test Loss=0.9201, Test top-1 acc=0.7778
2022-01-19 18:33:30,325 - INFO - Group Accuracy:

2022-01-19 18:33:30,325 - INFO - [0.97566265 0.9884337  0.9826506  0.9918072  0.9821687  0.9927711
 0.9780723  0.9812048  0.9898795  0.97614455 0.98722893 0.98289156
 0.97590363 0.9778313  0.97301203 0.9853012  0.9939759 ]
2022-01-19 18:33:30,326 - INFO - Saving...
2022-01-19 18:33:30,583 - INFO - Epoch time: 396.3934414386749
2022-01-19 18:33:30,583 - INFO - 
Epoch: 30
2022-01-19 18:33:30,583 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:35:05,137 - INFO - [Step=25250]	Loss=0.9665	254.8 examples/second
2022-01-19 18:37:00,615 - INFO - [Step=25500]	Loss=0.9562	277.1 examples/second
2022-01-19 18:38:55,447 - INFO - [Step=25750]	Loss=0.9370	278.7 examples/second
2022-01-19 18:40:04,566 - INFO - Test Loss=0.8901, Test top-1 acc=0.7810
2022-01-19 18:40:04,567 - INFO - Group Accuracy:

2022-01-19 18:40:04,567 - INFO - [0.97831327 0.9886747  0.9826506  0.9920482  0.9814458  0.9925301
 0.97951806 0.9809638  0.99060243 0.97614455 0.9884337  0.9833735
 0.97518075 0.9780723  0.97445786 0.9860241  0.99421686]
2022-01-19 18:40:04,567 - INFO - Saving...
2022-01-19 18:40:04,740 - INFO - Epoch time: 394.15684628486633
2022-01-19 18:40:04,740 - INFO - 
Epoch: 31
2022-01-19 18:40:04,740 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:40:59,547 - INFO - [Step=26000]	Loss=0.9213	257.9 examples/second
2022-01-19 18:42:55,029 - INFO - [Step=26250]	Loss=0.8984	277.1 examples/second
2022-01-19 18:44:50,631 - INFO - [Step=26500]	Loss=0.9135	276.8 examples/second
2022-01-19 18:46:40,139 - INFO - Test Loss=0.8668, Test top-1 acc=0.7877
2022-01-19 18:46:40,140 - INFO - Group Accuracy:

2022-01-19 18:46:40,140 - INFO - [0.9809638  0.9893976  0.98313254 0.9913253  0.98361444 0.993494
 0.97927713 0.97975904 0.99084336 0.97542167 0.9901205  0.98289156
 0.97590363 0.97903615 0.97542167 0.98674697 0.99421686]
2022-01-19 18:46:40,141 - INFO - Saving...
2022-01-19 18:46:40,316 - INFO - Epoch time: 395.57510638237
2022-01-19 18:46:40,316 - INFO - 
Epoch: 32
2022-01-19 18:46:40,316 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:46:56,219 - INFO - [Step=26750]	Loss=0.9179	254.8 examples/second
2022-01-19 18:48:52,357 - INFO - [Step=27000]	Loss=0.8922	275.5 examples/second
2022-01-19 18:50:48,590 - INFO - [Step=27250]	Loss=0.8786	275.3 examples/second
2022-01-19 18:52:44,463 - INFO - [Step=27500]	Loss=0.8640	276.2 examples/second
2022-01-19 18:53:17,457 - INFO - Test Loss=0.8541, Test top-1 acc=0.7899
2022-01-19 18:53:17,457 - INFO - Group Accuracy:

2022-01-19 18:53:17,457 - INFO - [0.97903615 0.9901205  0.98313254 0.9930121  0.9816868  0.99445784
 0.97951806 0.9804819  0.99084336 0.97590363 0.9898795  0.9850602
 0.9768675  0.9785542  0.9742169  0.98698795 0.9951807 ]
2022-01-19 18:53:17,459 - INFO - Saving...
2022-01-19 18:53:17,660 - INFO - Epoch time: 397.3441433906555
2022-01-19 18:53:17,660 - INFO - 
Epoch: 33
2022-01-19 18:53:17,660 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:54:50,086 - INFO - [Step=27750]	Loss=0.8555	254.7 examples/second
2022-01-19 18:56:45,985 - INFO - [Step=28000]	Loss=0.8555	276.1 examples/second
2022-01-19 18:58:42,039 - INFO - [Step=28250]	Loss=0.8804	275.7 examples/second
2022-01-19 18:59:54,573 - INFO - Test Loss=0.8605, Test top-1 acc=0.7901
2022-01-19 18:59:54,573 - INFO - Group Accuracy:

2022-01-19 18:59:54,573 - INFO - [0.97951806 0.9889157  0.98433733 0.9927711  0.9826506  0.9939759
 0.9807229  0.9804819  0.99036145 0.9775904  0.9901205  0.98433733
 0.97614455 0.97903615 0.973494   0.9881928  0.99493974]
2022-01-19 18:59:54,575 - INFO - Saving...
2022-01-19 18:59:54,859 - INFO - Epoch time: 397.1988136768341
2022-01-19 18:59:54,859 - INFO - 
Epoch: 34
2022-01-19 18:59:54,859 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:00:48,046 - INFO - [Step=28500]	Loss=0.8571	254.0 examples/second
2022-01-19 19:02:43,831 - INFO - [Step=28750]	Loss=0.8565	276.4 examples/second
2022-01-19 19:04:39,710 - INFO - [Step=29000]	Loss=0.8499	276.2 examples/second
2022-01-19 19:06:31,433 - INFO - Test Loss=0.8626, Test top-1 acc=0.7882
2022-01-19 19:06:31,433 - INFO - Group Accuracy:

2022-01-19 19:06:31,433 - INFO - [0.9807229  0.9886747  0.9833735  0.9920482  0.9826506  0.99421686
 0.97975904 0.9812048  0.99108434 0.9766265  0.9884337  0.98433733
 0.9771084  0.97831327 0.97445786 0.9886747  0.9954217 ]
2022-01-19 19:06:31,434 - INFO - Epoch time: 396.57472491264343
2022-01-19 19:06:31,434 - INFO - 
Epoch: 35
2022-01-19 19:06:31,434 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:06:45,022 - INFO - [Step=29250]	Loss=0.8489	255.4 examples/second
2022-01-19 19:08:40,900 - INFO - [Step=29500]	Loss=0.8229	276.2 examples/second
2022-01-19 19:10:36,773 - INFO - [Step=29750]	Loss=0.8210	276.2 examples/second
2022-01-19 19:12:32,702 - INFO - [Step=30000]	Loss=0.8356	276.0 examples/second
2022-01-19 19:13:08,263 - INFO - Test Loss=0.8434, Test top-1 acc=0.7904
2022-01-19 19:13:08,263 - INFO - Group Accuracy:

2022-01-19 19:13:08,263 - INFO - [0.98024094 0.9879518  0.9838554  0.9922892  0.9840964  0.99445784
 0.9804819  0.9809638  0.99084336 0.97638553 0.9891566  0.9845783
 0.97542167 0.97903615 0.97542167 0.98771083 0.9951807 ]
2022-01-19 19:13:08,264 - INFO - Saving...
2022-01-19 19:13:08,517 - INFO - Epoch time: 397.08329153060913
2022-01-19 19:13:08,517 - INFO - 
Epoch: 36
2022-01-19 19:13:08,518 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:14:39,203 - INFO - [Step=30250]	Loss=0.8201	253.0 examples/second
2022-01-19 19:16:35,056 - INFO - [Step=30500]	Loss=0.8224	276.2 examples/second
2022-01-19 19:18:31,059 - INFO - [Step=30750]	Loss=0.8211	275.9 examples/second
2022-01-19 19:19:45,767 - INFO - Test Loss=0.8417, Test top-1 acc=0.7908
2022-01-19 19:19:45,767 - INFO - Group Accuracy:

2022-01-19 19:19:45,767 - INFO - [0.98024094 0.9891566  0.98240966 0.99373496 0.9816868  0.9946988
 0.98       0.9812048  0.9913253  0.9768675  0.9901205  0.9850602
 0.9771084  0.9787952  0.97614455 0.98963857 0.9951807 ]
2022-01-19 19:19:45,768 - INFO - Saving...
2022-01-19 19:19:46,025 - INFO - Epoch time: 397.50776863098145
2022-01-19 19:19:46,026 - INFO - 
Epoch: 37
2022-01-19 19:19:46,026 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:20:36,837 - INFO - [Step=31000]	Loss=0.8129	254.4 examples/second
2022-01-19 19:22:32,588 - INFO - [Step=31250]	Loss=0.7855	276.5 examples/second
2022-01-19 19:24:28,433 - INFO - [Step=31500]	Loss=0.8163	276.2 examples/second
2022-01-19 19:26:22,373 - INFO - Test Loss=0.8439, Test top-1 acc=0.7928
2022-01-19 19:26:22,374 - INFO - Group Accuracy:

2022-01-19 19:26:22,374 - INFO - [0.97903615 0.99036145 0.9840964  0.9920482  0.9838554  0.993494
 0.9812048  0.9809638  0.99084336 0.97614455 0.9891566  0.9848193
 0.9768675  0.98       0.97638553 0.9884337  0.99445784]
2022-01-19 19:26:22,375 - INFO - Saving...
2022-01-19 19:26:22,623 - INFO - Epoch time: 396.59718203544617
2022-01-19 19:26:22,623 - INFO - 
Epoch: 38
2022-01-19 19:26:22,623 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:26:33,991 - INFO - [Step=31750]	Loss=0.7967	254.9 examples/second
2022-01-19 19:28:30,055 - INFO - [Step=32000]	Loss=0.7952	275.7 examples/second
2022-01-19 19:30:26,128 - INFO - [Step=32250]	Loss=0.7979	275.7 examples/second
2022-01-19 19:32:21,859 - INFO - [Step=32500]	Loss=0.7927	276.5 examples/second
2022-01-19 19:32:59,387 - INFO - Test Loss=0.8323, Test top-1 acc=0.7933
2022-01-19 19:32:59,388 - INFO - Group Accuracy:

2022-01-19 19:32:59,397 - INFO - [0.97927713 0.9893976  0.9838554  0.9922892  0.9838554  0.9939759
 0.9809638  0.9821687  0.99036145 0.9773494  0.9898795  0.98361444
 0.97518075 0.97975904 0.97614455 0.9886747  0.99445784]
2022-01-19 19:32:59,398 - INFO - Saving...
2022-01-19 19:32:59,567 - INFO - Epoch time: 396.94361877441406
2022-01-19 19:32:59,567 - INFO - 
Epoch: 39
2022-01-19 19:32:59,567 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:34:27,506 - INFO - [Step=32750]	Loss=0.7827	254.7 examples/second
2022-01-19 19:36:22,952 - INFO - [Step=33000]	Loss=0.7817	277.2 examples/second
2022-01-19 19:38:18,457 - INFO - [Step=33250]	Loss=0.7955	277.0 examples/second
2022-01-19 19:39:35,184 - INFO - Test Loss=0.8342, Test top-1 acc=0.7942
2022-01-19 19:39:35,184 - INFO - Group Accuracy:

2022-01-19 19:39:35,184 - INFO - [0.9787952  0.9901205  0.98433733 0.9925301  0.98289156 0.99445784
 0.9814458  0.9821687  0.99084336 0.9773494  0.99036145 0.9850602
 0.97518075 0.9775904  0.97518075 0.9884337  0.9951807 ]
2022-01-19 19:39:35,185 - INFO - Saving...
2022-01-19 19:39:35,440 - INFO - Epoch time: 395.87288880348206
2022-01-19 19:39:35,440 - INFO - 
Epoch: 40
2022-01-19 19:39:35,440 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:40:24,031 - INFO - [Step=33500]	Loss=0.7713	254.8 examples/second
2022-01-19 19:42:20,621 - INFO - [Step=33750]	Loss=0.7711	274.5 examples/second
2022-01-19 19:44:17,346 - INFO - [Step=34000]	Loss=0.7780	274.2 examples/second
2022-01-19 19:46:14,514 - INFO - Test Loss=0.8411, Test top-1 acc=0.7916
2022-01-19 19:46:14,515 - INFO - Group Accuracy:

2022-01-19 19:46:14,515 - INFO - [0.9807229  0.9884337  0.9838554  0.99156624 0.9826506  0.99373496
 0.9804819  0.9807229  0.9898795  0.9768675  0.9901205  0.98433733
 0.9766265  0.98024094 0.97566265 0.9881928  0.9946988 ]
2022-01-19 19:46:14,516 - INFO - Epoch time: 399.0764813423157
2022-01-19 19:46:14,516 - INFO - 
Epoch: 41
2022-01-19 19:46:14,517 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:46:23,629 - INFO - [Step=34250]	Loss=0.7745	253.4 examples/second
2022-01-19 19:48:18,827 - INFO - [Step=34500]	Loss=0.7665	277.8 examples/second
2022-01-19 19:50:14,028 - INFO - [Step=34750]	Loss=0.7711	277.8 examples/second
2022-01-19 19:52:09,641 - INFO - [Step=35000]	Loss=0.7583	276.8 examples/second
2022-01-19 19:52:49,253 - INFO - Test Loss=0.8481, Test top-1 acc=0.7923
2022-01-19 19:52:49,253 - INFO - Group Accuracy:

2022-01-19 19:52:49,253 - INFO - [0.97903615 0.98963857 0.9845783  0.9925301  0.98240966 0.99493974
 0.9804819  0.9812048  0.9898795  0.9771084  0.9891566  0.9833735
 0.9773494  0.98024094 0.97542167 0.98963857 0.99493974]
2022-01-19 19:52:49,255 - INFO - Epoch time: 394.7381503582001
2022-01-19 19:52:49,255 - INFO - 
Epoch: 42
2022-01-19 19:52:49,255 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:54:14,539 - INFO - [Step=35250]	Loss=0.7513	256.2 examples/second
2022-01-19 19:56:09,985 - INFO - [Step=35500]	Loss=0.7538	277.2 examples/second
2022-01-19 19:58:05,370 - INFO - [Step=35750]	Loss=0.7578	277.3 examples/second
2022-01-19 19:59:24,278 - INFO - Test Loss=1.3736, Test top-1 acc=0.7798
2022-01-19 19:59:24,279 - INFO - Group Accuracy:

2022-01-19 19:59:24,279 - INFO - [0.97614455 0.9884337  0.9807229  0.9925301  0.98240966 0.9946988
 0.97975904 0.9787952  0.99036145 0.973494   0.98963857 0.9840964
 0.97614455 0.97927713 0.97518075 0.98674697 0.99421686]
2022-01-19 19:59:24,279 - INFO - Epoch time: 395.0246629714966
2022-01-19 19:59:24,279 - INFO - 
Epoch: 43
2022-01-19 19:59:24,279 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:00:10,099 - INFO - [Step=36000]	Loss=0.7500	256.6 examples/second
2022-01-19 20:02:05,687 - INFO - [Step=36250]	Loss=0.7366	276.8 examples/second
2022-01-19 20:04:01,400 - INFO - [Step=36500]	Loss=0.7435	276.5 examples/second
2022-01-19 20:05:59,475 - INFO - Test Loss=0.8579, Test top-1 acc=0.7923
2022-01-19 20:05:59,476 - INFO - Group Accuracy:

2022-01-19 20:05:59,476 - INFO - [0.97975904 0.99036145 0.98433733 0.9927711  0.98240966 0.9930121
 0.9809638  0.9809638  0.98963857 0.9766265  0.99060243 0.9821687
 0.9778313  0.9807229  0.97542167 0.98771083 0.99493974]
2022-01-19 20:05:59,477 - INFO - Epoch time: 395.1971592903137
2022-01-19 20:05:59,477 - INFO - 
Epoch: 44
2022-01-19 20:05:59,477 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:06:06,155 - INFO - [Step=36750]	Loss=0.7454	256.5 examples/second
2022-01-19 20:08:00,999 - INFO - [Step=37000]	Loss=0.7256	278.6 examples/second
2022-01-19 20:09:55,850 - INFO - [Step=37250]	Loss=0.7347	278.6 examples/second
2022-01-19 20:11:50,556 - INFO - [Step=37500]	Loss=0.7520	279.0 examples/second
2022-01-19 20:12:32,118 - INFO - Test Loss=0.8328, Test top-1 acc=0.7935
2022-01-19 20:12:32,118 - INFO - Group Accuracy:

2022-01-19 20:12:32,118 - INFO - [0.9785542  0.98963857 0.9853012  0.9927711  0.98240966 0.9951807
 0.98       0.9821687  0.9898795  0.9766265  0.9881928  0.9845783
 0.9771084  0.9775904  0.9766265  0.9884337  0.9946988 ]
2022-01-19 20:12:32,119 - INFO - Epoch time: 392.64253187179565
2022-01-19 20:12:32,119 - INFO - 
Epoch: 45
2022-01-19 20:12:32,119 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:13:54,741 - INFO - [Step=37750]	Loss=0.7313	257.7 examples/second
2022-01-19 20:15:50,068 - INFO - [Step=38000]	Loss=0.7333	277.5 examples/second
2022-01-19 20:17:45,632 - INFO - [Step=38250]	Loss=0.7336	276.9 examples/second
2022-01-19 20:19:07,420 - INFO - Test Loss=0.8840, Test top-1 acc=0.7949
2022-01-19 20:19:07,421 - INFO - Group Accuracy:

2022-01-19 20:19:07,421 - INFO - [0.97903615 0.9901205  0.9848193  0.9922892  0.98313254 0.993494
 0.9768675  0.9816868  0.98963857 0.97518075 0.99036145 0.9845783
 0.9773494  0.9812048  0.9768675  0.9879518  0.9954217 ]
2022-01-19 20:19:07,422 - INFO - Saving...
2022-01-19 20:19:07,702 - INFO - Epoch time: 395.58299469947815
2022-01-19 20:19:07,703 - INFO - 
Epoch: 46
2022-01-19 20:19:07,703 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:19:51,582 - INFO - [Step=38500]	Loss=0.7293	254.1 examples/second
2022-01-19 20:21:47,663 - INFO - [Step=38750]	Loss=0.7056	275.7 examples/second
2022-01-19 20:23:43,696 - INFO - [Step=39000]	Loss=0.7294	275.8 examples/second
2022-01-19 20:25:44,904 - INFO - Test Loss=0.8380, Test top-1 acc=0.7930
2022-01-19 20:25:44,904 - INFO - Group Accuracy:

2022-01-19 20:25:44,904 - INFO - [0.97831327 0.9898795  0.9853012  0.9930121  0.98289156 0.99373496
 0.9807229  0.98240966 0.9891566  0.97542167 0.9891566  0.98289156
 0.9768675  0.9819277  0.97493976 0.98771083 0.9939759 ]
2022-01-19 20:25:44,905 - INFO - Epoch time: 397.2022602558136
2022-01-19 20:25:44,905 - INFO - 
Epoch: 47
2022-01-19 20:25:44,905 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:25:49,551 - INFO - [Step=39250]	Loss=0.7421	254.3 examples/second
2022-01-19 20:27:44,975 - INFO - [Step=39500]	Loss=0.6926	277.2 examples/second
2022-01-19 20:29:40,393 - INFO - [Step=39750]	Loss=0.7196	277.3 examples/second
2022-01-19 20:31:35,827 - INFO - [Step=40000]	Loss=0.7211	277.2 examples/second
2022-01-19 20:32:20,085 - INFO - Test Loss=0.8481, Test top-1 acc=0.7942
2022-01-19 20:32:20,085 - INFO - Group Accuracy:

2022-01-19 20:32:20,085 - INFO - [0.97951806 0.9891566  0.9840964  0.9927711  0.9833735  0.99421686
 0.98       0.9814458  0.9901205  0.9773494  0.9881928  0.9838554
 0.97831327 0.97951806 0.97638553 0.9881928  0.9954217 ]
2022-01-19 20:32:20,086 - INFO - Epoch time: 395.1811981201172
2022-01-19 20:32:20,086 - INFO - 
Epoch: 48
2022-01-19 20:32:20,086 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:33:40,238 - INFO - [Step=40250]	Loss=0.7029	257.2 examples/second
2022-01-19 20:35:35,312 - INFO - [Step=40500]	Loss=0.7168	278.1 examples/second
2022-01-19 20:37:30,558 - INFO - [Step=40750]	Loss=0.7139	277.7 examples/second
2022-01-19 20:38:54,061 - INFO - Test Loss=0.8216, Test top-1 acc=0.7995
2022-01-19 20:38:54,062 - INFO - Group Accuracy:

2022-01-19 20:38:54,062 - INFO - [0.97831327 0.98963857 0.9840964  0.9930121  0.98313254 0.99421686
 0.98       0.98240966 0.9889157  0.9773494  0.9918072  0.9845783
 0.9768675  0.9819277  0.97614455 0.9879518  0.9963855 ]
2022-01-19 20:38:54,063 - INFO - Saving...
2022-01-19 20:38:54,314 - INFO - Epoch time: 394.2273814678192
2022-01-19 20:38:54,314 - INFO - 
Epoch: 49
2022-01-19 20:38:54,314 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:39:35,975 - INFO - [Step=41000]	Loss=0.7236	255.2 examples/second
2022-01-19 20:41:31,955 - INFO - [Step=41250]	Loss=0.6907	275.9 examples/second
2022-01-19 20:43:28,052 - INFO - [Step=41500]	Loss=0.6954	275.6 examples/second
2022-01-19 20:45:24,059 - INFO - [Step=41750]	Loss=0.7213	275.8 examples/second
2022-01-19 20:45:31,741 - INFO - Test Loss=0.8364, Test top-1 acc=0.8055
2022-01-19 20:45:31,742 - INFO - Group Accuracy:

2022-01-19 20:45:31,742 - INFO - [0.9814458  0.9901205  0.98240966 0.9927711  0.9838554  0.99421686
 0.9809638  0.98240966 0.99036145 0.9773494  0.99108434 0.98361444
 0.9780723  0.9812048  0.9775904  0.98771083 0.9946988 ]
2022-01-19 20:45:31,743 - INFO - Saving...
2022-01-19 20:45:31,912 - INFO - Epoch time: 397.59821224212646
2022-01-19 20:45:31,912 - INFO - 
Epoch: 50
2022-01-19 20:45:31,912 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:47:30,427 - INFO - [Step=42000]	Loss=0.6899	253.2 examples/second
2022-01-19 20:49:26,204 - INFO - [Step=42250]	Loss=0.6963	276.4 examples/second
2022-01-19 20:51:22,141 - INFO - [Step=42500]	Loss=0.7078	276.0 examples/second
2022-01-19 20:52:09,307 - INFO - Test Loss=0.8292, Test top-1 acc=0.7966
2022-01-19 20:52:09,307 - INFO - Group Accuracy:

2022-01-19 20:52:09,307 - INFO - [0.97951806 0.99036145 0.98289156 0.9939759  0.9855422  0.99421686
 0.9821687  0.9840964  0.9893976  0.9780723  0.98771083 0.98361444
 0.97542167 0.97951806 0.9746988  0.9879518  0.9939759 ]
2022-01-19 20:52:09,308 - INFO - Epoch time: 397.3954699039459
2022-01-19 20:52:09,308 - INFO - 
Epoch: 51
2022-01-19 20:52:09,308 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:53:27,984 - INFO - [Step=42750]	Loss=0.6843	254.3 examples/second
2022-01-19 20:55:23,228 - INFO - [Step=43000]	Loss=0.6830	277.7 examples/second
2022-01-19 20:57:18,545 - INFO - [Step=43250]	Loss=0.7153	277.5 examples/second
2022-01-19 20:58:44,602 - INFO - Test Loss=0.8401, Test top-1 acc=0.7993
2022-01-19 20:58:44,602 - INFO - Group Accuracy:

2022-01-19 20:58:44,602 - INFO - [0.98       0.9898795  0.9853012  0.9927711  0.9853012  0.9930121
 0.9814458  0.9809638  0.9913253  0.97590363 0.99060243 0.98240966
 0.9775904  0.9819277  0.97566265 0.9893976  0.9961446 ]
2022-01-19 20:58:44,603 - INFO - Epoch time: 395.2952673435211
2022-01-19 20:58:44,603 - INFO - 
Epoch: 52
2022-01-19 20:58:44,603 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:59:23,453 - INFO - [Step=43500]	Loss=0.7117	256.2 examples/second
2022-01-19 21:01:18,302 - INFO - [Step=43750]	Loss=0.6703	278.6 examples/second
2022-01-19 21:03:12,920 - INFO - [Step=44000]	Loss=0.6858	279.2 examples/second
2022-01-19 21:05:07,441 - INFO - [Step=44250]	Loss=0.6949	279.4 examples/second
2022-01-19 21:05:17,108 - INFO - Test Loss=0.8458, Test top-1 acc=0.8024
2022-01-19 21:05:17,108 - INFO - Group Accuracy:

2022-01-19 21:05:17,108 - INFO - [0.9826506  0.9891566  0.98289156 0.99373496 0.98361444 0.99445784
 0.9809638  0.98313254 0.9901205  0.97831327 0.9891566  0.98361444
 0.9773494  0.9821687  0.97614455 0.9884337  0.9954217 ]
2022-01-19 21:05:17,109 - INFO - Epoch time: 392.5059766769409
2022-01-19 21:05:17,109 - INFO - 
Epoch: 53
2022-01-19 21:05:17,109 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:07:11,620 - INFO - [Step=44500]	Loss=0.6735	257.7 examples/second
2022-01-19 21:09:06,314 - INFO - [Step=44750]	Loss=0.6793	279.0 examples/second
2022-01-19 21:11:01,137 - INFO - [Step=45000]	Loss=0.6982	278.7 examples/second
2022-01-19 21:11:49,578 - INFO - Test Loss=0.8507, Test top-1 acc=0.7988
2022-01-19 21:11:49,578 - INFO - Group Accuracy:

2022-01-19 21:11:49,578 - INFO - [0.97927713 0.99084336 0.9853012  0.9927711  0.98361444 0.99445784
 0.9775904  0.9814458  0.99036145 0.9766265  0.9913253  0.98722893
 0.9768675  0.9807229  0.97638553 0.98626506 0.9961446 ]
2022-01-19 21:11:49,580 - INFO - Epoch time: 392.47041964530945
2022-01-19 21:11:49,580 - INFO - 
Epoch: 54
2022-01-19 21:11:49,580 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:13:05,107 - INFO - [Step=45250]	Loss=0.6851	258.1 examples/second
2022-01-19 21:14:59,631 - INFO - [Step=45500]	Loss=0.6688	279.4 examples/second
2022-01-19 21:16:54,243 - INFO - [Step=45750]	Loss=0.6855	279.2 examples/second
2022-01-19 21:18:21,678 - INFO - Test Loss=0.8594, Test top-1 acc=0.7925
2022-01-19 21:18:21,679 - INFO - Group Accuracy:

2022-01-19 21:18:21,679 - INFO - [0.9809638  0.98963857 0.98240966 0.9922892  0.9821687  0.99445784
 0.97951806 0.9814458  0.9889157  0.9771084  0.9886747  0.9819277
 0.97638553 0.9807229  0.97614455 0.9881928  0.99445784]
2022-01-19 21:18:21,680 - INFO - Epoch time: 392.1001718044281
2022-01-19 21:18:21,680 - INFO - 
Epoch: 55
2022-01-19 21:18:21,680 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:18:58,244 - INFO - [Step=46000]	Loss=0.6901	258.1 examples/second
2022-01-19 21:20:52,477 - INFO - [Step=46250]	Loss=0.6561	280.1 examples/second
2022-01-19 21:22:46,862 - INFO - [Step=46500]	Loss=0.6643	279.8 examples/second
2022-01-19 21:24:41,147 - INFO - [Step=46750]	Loss=0.6890	280.0 examples/second
2022-01-19 21:24:53,105 - INFO - Test Loss=0.8503, Test top-1 acc=0.7978
2022-01-19 21:24:53,105 - INFO - Group Accuracy:

2022-01-19 21:24:53,105 - INFO - [0.9814458  0.9898795  0.9838554  0.9927711  0.98313254 0.99493974
 0.9804819  0.9838554  0.9891566  0.97638553 0.99060243 0.9840964
 0.97614455 0.9807229  0.97445786 0.9893976  0.99445784]
2022-01-19 21:24:53,106 - INFO - Epoch time: 391.4258587360382
2022-01-19 21:24:53,106 - INFO - 
Epoch: 56
2022-01-19 21:24:53,106 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:26:45,174 - INFO - [Step=47000]	Loss=0.6526	258.0 examples/second
2022-01-19 21:28:39,624 - INFO - [Step=47250]	Loss=0.6709	279.6 examples/second
2022-01-19 21:30:34,161 - INFO - [Step=47500]	Loss=0.6682	279.4 examples/second
2022-01-19 21:31:24,968 - INFO - Test Loss=0.8594, Test top-1 acc=0.7961
2022-01-19 21:31:24,968 - INFO - Group Accuracy:

2022-01-19 21:31:24,968 - INFO - [0.9775904  0.99108434 0.9860241  0.9930121  0.9850602  0.9939759
 0.97975904 0.97951806 0.99108434 0.9766265  0.9898795  0.98433733
 0.9785542  0.97951806 0.97638553 0.98771083 0.99421686]
2022-01-19 21:31:24,969 - INFO - Epoch time: 391.86353039741516
2022-01-19 21:31:24,969 - INFO - 
Epoch: 57
2022-01-19 21:31:24,969 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:32:39,027 - INFO - [Step=47750]	Loss=0.6600	256.3 examples/second
2022-01-19 21:34:35,573 - INFO - [Step=48000]	Loss=0.6692	274.6 examples/second
2022-01-19 21:36:32,472 - INFO - [Step=48250]	Loss=0.6588	273.7 examples/second
2022-01-19 21:38:03,870 - INFO - Test Loss=0.8023, Test top-1 acc=0.8014
2022-01-19 21:38:03,871 - INFO - Group Accuracy:

2022-01-19 21:38:03,871 - INFO - [0.98024094 0.99036145 0.9850602  0.993494   0.9845783  0.99421686
 0.9787952  0.9819277  0.9898795  0.9778313  0.9889157  0.9845783
 0.9773494  0.98240966 0.97590363 0.98746985 0.9951807 ]
2022-01-19 21:38:03,872 - INFO - Epoch time: 398.902147769928
2022-01-19 21:38:03,872 - INFO - 
Epoch: 58
2022-01-19 21:38:03,872 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:38:38,006 - INFO - [Step=48500]	Loss=0.6628	254.9 examples/second
2022-01-19 21:40:33,450 - INFO - [Step=48750]	Loss=0.6462	277.2 examples/second
2022-01-19 21:42:29,162 - INFO - [Step=49000]	Loss=0.6491	276.5 examples/second
2022-01-19 21:44:25,095 - INFO - [Step=49250]	Loss=0.6621	276.0 examples/second
2022-01-19 21:44:39,340 - INFO - Test Loss=0.8479, Test top-1 acc=0.8027
2022-01-19 21:44:39,340 - INFO - Group Accuracy:

2022-01-19 21:44:39,340 - INFO - [0.9804819  0.99060243 0.9853012  0.993253   0.9853012  0.993494
 0.97927713 0.9804819  0.99084336 0.9785542  0.9889157  0.9838554
 0.9780723  0.9807229  0.97614455 0.9901205  0.9946988 ]
2022-01-19 21:44:39,341 - INFO - Epoch time: 395.4690272808075
2022-01-19 21:44:39,341 - INFO - 
Epoch: 59
2022-01-19 21:44:39,341 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:46:30,250 - INFO - [Step=49500]	Loss=0.6171	255.7 examples/second
2022-01-19 21:48:25,999 - INFO - [Step=49750]	Loss=0.5843	276.5 examples/second
2022-01-19 21:50:21,528 - INFO - [Step=50000]	Loss=0.5653	277.0 examples/second
2022-01-19 21:51:15,026 - INFO - Test Loss=0.7861, Test top-1 acc=0.8128
2022-01-19 21:51:15,026 - INFO - Group Accuracy:

2022-01-19 21:51:15,026 - INFO - [0.9819277  0.99084336 0.98626506 0.9930121  0.98698795 0.9939759
 0.9821687  0.9816868  0.99084336 0.9785542  0.9901205  0.98433733
 0.98       0.9819277  0.9785542  0.9901205  0.9951807 ]
2022-01-19 21:51:15,027 - INFO - Saving...
2022-01-19 21:51:15,305 - INFO - Epoch time: 395.96401143074036
2022-01-19 21:51:15,305 - INFO - 
Epoch: 60
2022-01-19 21:51:15,305 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:52:26,367 - INFO - [Step=50250]	Loss=0.5630	256.3 examples/second
2022-01-19 21:54:21,286 - INFO - [Step=50500]	Loss=0.5740	278.5 examples/second
2022-01-19 21:56:16,218 - INFO - [Step=50750]	Loss=0.5624	278.4 examples/second
2022-01-19 21:57:48,355 - INFO - Test Loss=0.7774, Test top-1 acc=0.8135
2022-01-19 21:57:48,356 - INFO - Group Accuracy:

2022-01-19 21:57:48,356 - INFO - [0.98313254 0.9922892  0.9860241  0.993494   0.98626506 0.9939759
 0.9809638  0.9826506  0.99084336 0.9787952  0.99108434 0.98626506
 0.9787952  0.98240966 0.9778313  0.99060243 0.9951807 ]
2022-01-19 21:57:48,357 - INFO - Saving...
2022-01-19 21:57:48,616 - INFO - Epoch time: 393.3114297389984
2022-01-19 21:57:48,617 - INFO - 
Epoch: 61
2022-01-19 21:57:48,617 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:58:20,406 - INFO - [Step=51000]	Loss=0.5548	257.7 examples/second
2022-01-19 22:00:15,905 - INFO - [Step=51250]	Loss=0.5477	277.1 examples/second
2022-01-19 22:02:11,412 - INFO - [Step=51500]	Loss=0.5522	277.0 examples/second
2022-01-19 22:04:06,962 - INFO - [Step=51750]	Loss=0.5538	276.9 examples/second
2022-01-19 22:04:23,617 - INFO - Test Loss=0.7717, Test top-1 acc=0.8147
2022-01-19 22:04:23,617 - INFO - Group Accuracy:

2022-01-19 22:04:23,617 - INFO - [0.98240966 0.9918072  0.98650604 0.993494   0.9860241  0.99421686
 0.9816868  0.98289156 0.9913253  0.9778313  0.99060243 0.9853012
 0.9787952  0.9821687  0.97903615 0.9898795  0.9951807 ]
2022-01-19 22:04:23,618 - INFO - Saving...
2022-01-19 22:04:23,879 - INFO - Epoch time: 395.2624385356903
2022-01-19 22:04:23,879 - INFO - 
Epoch: 62
2022-01-19 22:04:23,879 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:06:11,660 - INFO - [Step=52000]	Loss=0.5573	256.6 examples/second
2022-01-19 22:08:06,314 - INFO - [Step=52250]	Loss=0.5513	279.1 examples/second
2022-01-19 22:10:01,221 - INFO - [Step=52500]	Loss=0.5345	278.5 examples/second
2022-01-19 22:10:56,681 - INFO - Test Loss=0.7712, Test top-1 acc=0.8130
2022-01-19 22:10:56,681 - INFO - Group Accuracy:

2022-01-19 22:10:56,681 - INFO - [0.98289156 0.99156624 0.98650604 0.9930121  0.9860241  0.9939759
 0.9816868  0.98240966 0.99060243 0.9785542  0.9901205  0.9845783
 0.97903615 0.98313254 0.9780723  0.99108434 0.99493974]
2022-01-19 22:10:56,682 - INFO - Epoch time: 392.8026850223541
2022-01-19 22:10:56,682 - INFO - 
Epoch: 63
2022-01-19 22:10:56,682 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:12:05,157 - INFO - [Step=52750]	Loss=0.5434	258.2 examples/second
2022-01-19 22:13:59,875 - INFO - [Step=53000]	Loss=0.5399	278.9 examples/second
2022-01-19 22:15:54,500 - INFO - [Step=53250]	Loss=0.5318	279.2 examples/second
2022-01-19 22:17:29,667 - INFO - Test Loss=0.7671, Test top-1 acc=0.8169
2022-01-19 22:17:29,668 - INFO - Group Accuracy:

2022-01-19 22:17:29,668 - INFO - [0.9826506  0.9920482  0.9860241  0.993253   0.98650604 0.99421686
 0.9816868  0.98240966 0.99108434 0.9785542  0.9913253  0.9850602
 0.97927713 0.9833735  0.97927713 0.99036145 0.9954217 ]
2022-01-19 22:17:29,669 - INFO - Saving...
2022-01-19 22:17:29,928 - INFO - Epoch time: 393.2460958957672
2022-01-19 22:17:29,928 - INFO - 
Epoch: 64
2022-01-19 22:17:29,929 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:17:59,457 - INFO - [Step=53500]	Loss=0.5293	256.1 examples/second
2022-01-19 22:19:54,063 - INFO - [Step=53750]	Loss=0.5408	279.2 examples/second
2022-01-19 22:21:48,556 - INFO - [Step=54000]	Loss=0.5284	279.5 examples/second
2022-01-19 22:23:43,387 - INFO - [Step=54250]	Loss=0.5357	278.7 examples/second
2022-01-19 22:24:02,468 - INFO - Test Loss=0.7687, Test top-1 acc=0.8186
2022-01-19 22:24:02,469 - INFO - Group Accuracy:

2022-01-19 22:24:02,469 - INFO - [0.9833735  0.9918072  0.98626506 0.9930121  0.98650604 0.99445784
 0.98240966 0.98313254 0.99036145 0.97903615 0.99108434 0.9848193
 0.97951806 0.98433733 0.97951806 0.99084336 0.9954217 ]
2022-01-19 22:24:02,470 - INFO - Saving...
2022-01-19 22:24:02,716 - INFO - Epoch time: 392.78790259361267
2022-01-19 22:24:02,717 - INFO - 
Epoch: 65
2022-01-19 22:24:02,717 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:25:48,012 - INFO - [Step=54500]	Loss=0.5284	256.8 examples/second
2022-01-19 22:27:42,523 - INFO - [Step=54750]	Loss=0.5253	279.5 examples/second
2022-01-19 22:29:37,179 - INFO - [Step=55000]	Loss=0.5361	279.1 examples/second
2022-01-19 22:30:34,924 - INFO - Test Loss=0.7733, Test top-1 acc=0.8152
2022-01-19 22:30:34,925 - INFO - Group Accuracy:

2022-01-19 22:30:34,936 - INFO - [0.98289156 0.9918072  0.98650604 0.993253   0.98626506 0.99445784
 0.98024094 0.9821687  0.9913253  0.9778313  0.99084336 0.9848193
 0.97951806 0.9833735  0.97903615 0.99060243 0.9959036 ]
2022-01-19 22:30:34,937 - INFO - Epoch time: 392.2208049297333
2022-01-19 22:30:34,938 - INFO - 
Epoch: 66
2022-01-19 22:30:34,938 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:31:41,943 - INFO - [Step=55250]	Loss=0.5279	256.5 examples/second
2022-01-19 22:33:37,808 - INFO - [Step=55500]	Loss=0.5332	276.2 examples/second
2022-01-19 22:35:33,446 - INFO - [Step=55750]	Loss=0.5257	276.7 examples/second
2022-01-19 22:37:11,081 - INFO - Test Loss=0.7733, Test top-1 acc=0.8161
2022-01-19 22:37:11,081 - INFO - Group Accuracy:

2022-01-19 22:37:11,081 - INFO - [0.98313254 0.99108434 0.98674697 0.9927711  0.98626506 0.99445784
 0.9816868  0.9826506  0.99060243 0.9785542  0.9901205  0.9860241
 0.9787952  0.9838554  0.97831327 0.9898795  0.9954217 ]
2022-01-19 22:37:11,091 - INFO - Epoch time: 396.15344619750977
2022-01-19 22:37:11,091 - INFO - 
Epoch: 67
2022-01-19 22:37:11,091 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:37:38,443 - INFO - [Step=56000]	Loss=0.5269	256.0 examples/second
2022-01-19 22:39:32,788 - INFO - [Step=56250]	Loss=0.5090	279.9 examples/second
2022-01-19 22:41:27,060 - INFO - [Step=56500]	Loss=0.5310	280.0 examples/second
2022-01-19 22:43:21,714 - INFO - [Step=56750]	Loss=0.5211	279.1 examples/second
2022-01-19 22:43:43,032 - INFO - Test Loss=0.7717, Test top-1 acc=0.8133
2022-01-19 22:43:43,032 - INFO - Group Accuracy:

2022-01-19 22:43:43,032 - INFO - [0.9821687  0.99156624 0.98650604 0.993253   0.98626506 0.99421686
 0.9809638  0.9821687  0.99060243 0.97831327 0.9918072  0.9850602
 0.9787952  0.9833735  0.97975904 0.99036145 0.99445784]
2022-01-19 22:43:43,033 - INFO - Epoch time: 391.9416723251343
2022-01-19 22:43:43,033 - INFO - 
Epoch: 68
2022-01-19 22:43:43,033 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:45:26,467 - INFO - [Step=57000]	Loss=0.5278	256.5 examples/second
2022-01-19 22:47:21,592 - INFO - [Step=57250]	Loss=0.5250	278.0 examples/second
2022-01-19 22:49:16,674 - INFO - [Step=57500]	Loss=0.5210	278.1 examples/second
2022-01-19 22:50:17,111 - INFO - Test Loss=0.7794, Test top-1 acc=0.8145
2022-01-19 22:50:17,111 - INFO - Group Accuracy:

2022-01-19 22:50:17,111 - INFO - [0.98361444 0.9925301  0.98746985 0.9927711  0.98650604 0.99445784
 0.9819277  0.9821687  0.9901205  0.97831327 0.99084336 0.9853012
 0.9785542  0.98361444 0.97975904 0.9901205  0.99493974]
2022-01-19 22:50:17,112 - INFO - Epoch time: 394.0794634819031
2022-01-19 22:50:17,113 - INFO - 
Epoch: 69
2022-01-19 22:50:17,113 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:51:21,437 - INFO - [Step=57750]	Loss=0.5340	256.5 examples/second
2022-01-19 22:53:16,200 - INFO - [Step=58000]	Loss=0.5206	278.8 examples/second
2022-01-19 22:55:10,959 - INFO - [Step=58250]	Loss=0.5223	278.8 examples/second
2022-01-19 22:56:50,154 - INFO - Test Loss=0.7693, Test top-1 acc=0.8159
2022-01-19 22:56:50,154 - INFO - Group Accuracy:

2022-01-19 22:56:50,155 - INFO - [0.98240966 0.99084336 0.98674697 0.9925301  0.98578316 0.99445784
 0.9812048  0.9816868  0.99060243 0.9785542  0.9898795  0.9855422
 0.97951806 0.98313254 0.97903615 0.99060243 0.9954217 ]
2022-01-19 22:56:50,156 - INFO - Epoch time: 393.0437066555023
2022-01-19 22:56:50,156 - INFO - 
Epoch: 70
2022-01-19 22:56:50,156 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:57:14,929 - INFO - [Step=58500]	Loss=0.5038	258.1 examples/second
2022-01-19 22:59:09,519 - INFO - [Step=58750]	Loss=0.5111	279.3 examples/second
2022-01-19 23:01:03,898 - INFO - [Step=59000]	Loss=0.5171	279.8 examples/second
2022-01-19 23:02:58,519 - INFO - [Step=59250]	Loss=0.5170	279.2 examples/second
2022-01-19 23:03:22,286 - INFO - Test Loss=0.7793, Test top-1 acc=0.8176
2022-01-19 23:03:22,286 - INFO - Group Accuracy:

2022-01-19 23:03:22,286 - INFO - [0.9845783  0.9920482  0.98578316 0.9930121  0.9853012  0.99445784
 0.9819277  0.9819277  0.99084336 0.9775904  0.99108434 0.9850602
 0.97903615 0.9833735  0.97903615 0.99108434 0.99445784]
2022-01-19 23:03:22,286 - INFO - Epoch time: 392.13009691238403
2022-01-19 23:03:22,287 - INFO - 
Epoch: 71
2022-01-19 23:03:22,287 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:05:03,011 - INFO - [Step=59500]	Loss=0.5193	257.0 examples/second
2022-01-19 23:06:57,512 - INFO - [Step=59750]	Loss=0.5102	279.5 examples/second
2022-01-19 23:08:52,150 - INFO - [Step=60000]	Loss=0.5063	279.1 examples/second
2022-01-19 23:09:54,676 - INFO - Test Loss=0.7719, Test top-1 acc=0.8171
2022-01-19 23:09:54,676 - INFO - Group Accuracy:

2022-01-19 23:09:54,683 - INFO - [0.9826506  0.9913253  0.98626506 0.9927711  0.98578316 0.99421686
 0.9826506  0.9819277  0.99036145 0.9780723  0.99108434 0.9850602
 0.98024094 0.9826506  0.97975904 0.99036145 0.9959036 ]
2022-01-19 23:09:54,684 - INFO - Epoch time: 392.3971447944641
2022-01-19 23:09:54,684 - INFO - 
Epoch: 72
2022-01-19 23:09:54,684 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:10:56,292 - INFO - [Step=60250]	Loss=0.5156	257.8 examples/second
2022-01-19 23:12:50,864 - INFO - [Step=60500]	Loss=0.5142	279.3 examples/second
2022-01-19 23:14:45,411 - INFO - [Step=60750]	Loss=0.5080	279.4 examples/second
2022-01-19 23:16:26,786 - INFO - Test Loss=0.7719, Test top-1 acc=0.8128
2022-01-19 23:16:26,787 - INFO - Group Accuracy:

2022-01-19 23:16:26,787 - INFO - [0.9821687  0.99156624 0.98771083 0.9930121  0.98626506 0.99445784
 0.9809638  0.9819277  0.99084336 0.9780723  0.9891566  0.9853012
 0.97903615 0.98361444 0.9780723  0.99084336 0.9954217 ]
2022-01-19 23:16:26,787 - INFO - Epoch time: 392.10367703437805
2022-01-19 23:16:26,787 - INFO - 
Epoch: 73
2022-01-19 23:16:26,788 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:16:49,548 - INFO - [Step=61000]	Loss=0.5174	257.8 examples/second
2022-01-19 23:18:44,143 - INFO - [Step=61250]	Loss=0.5031	279.2 examples/second
2022-01-19 23:20:38,561 - INFO - [Step=61500]	Loss=0.5179	279.7 examples/second
2022-01-19 23:22:32,954 - INFO - [Step=61750]	Loss=0.5069	279.7 examples/second
2022-01-19 23:22:58,614 - INFO - Test Loss=0.7806, Test top-1 acc=0.8123
2022-01-19 23:22:58,614 - INFO - Group Accuracy:

2022-01-19 23:22:58,624 - INFO - [0.9826506  0.9913253  0.98746985 0.9925301  0.98650604 0.99445784
 0.9807229  0.9826506  0.9898795  0.9778313  0.99084336 0.9840964
 0.97951806 0.9833735  0.9785542  0.99108434 0.9951807 ]
2022-01-19 23:22:58,625 - INFO - Epoch time: 391.8374996185303
2022-01-19 23:22:58,625 - INFO - 
Epoch: 74
2022-01-19 23:22:58,625 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:24:38,017 - INFO - [Step=62000]	Loss=0.5211	255.9 examples/second
2022-01-19 23:26:33,734 - INFO - [Step=62250]	Loss=0.4967	276.5 examples/second
2022-01-19 23:28:29,481 - INFO - [Step=62500]	Loss=0.5073	276.5 examples/second
2022-01-19 23:29:34,632 - INFO - Test Loss=0.7837, Test top-1 acc=0.8193
2022-01-19 23:29:34,633 - INFO - Group Accuracy:

2022-01-19 23:29:34,633 - INFO - [0.9840964  0.9913253  0.98674697 0.9925301  0.98746985 0.99445784
 0.9814458  0.9833735  0.99084336 0.97903615 0.99156624 0.9860241
 0.97831327 0.9838554  0.97951806 0.9901205  0.9954217 ]
2022-01-19 23:29:34,633 - INFO - Saving...
2022-01-19 23:29:34,904 - INFO - Epoch time: 396.27912044525146
2022-01-19 23:29:34,904 - INFO - 
Epoch: 75
2022-01-19 23:29:34,904 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:30:34,781 - INFO - [Step=62750]	Loss=0.5097	255.4 examples/second
2022-01-19 23:32:30,566 - INFO - [Step=63000]	Loss=0.4969	276.4 examples/second
2022-01-19 23:34:26,367 - INFO - [Step=63250]	Loss=0.5148	276.3 examples/second
2022-01-19 23:36:10,971 - INFO - Test Loss=0.7776, Test top-1 acc=0.8166
2022-01-19 23:36:10,971 - INFO - Group Accuracy:

2022-01-19 23:36:10,981 - INFO - [0.9826506  0.98963857 0.98698795 0.9930121  0.98650604 0.9946988
 0.9807229  0.9826506  0.99060243 0.9773494  0.99156624 0.9855422
 0.9787952  0.9833735  0.97831327 0.99108434 0.9959036 ]
2022-01-19 23:36:10,981 - INFO - Epoch time: 396.0770902633667
2022-01-19 23:36:10,982 - INFO - 
Epoch: 76
2022-01-19 23:36:10,982 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:36:31,300 - INFO - [Step=63500]	Loss=0.5133	256.1 examples/second
2022-01-19 23:38:27,253 - INFO - [Step=63750]	Loss=0.4941	276.0 examples/second
2022-01-19 23:40:22,974 - INFO - [Step=64000]	Loss=0.5067	276.5 examples/second
2022-01-19 23:42:18,622 - INFO - [Step=64250]	Loss=0.4912	276.7 examples/second
2022-01-19 23:42:46,705 - INFO - Test Loss=0.7816, Test top-1 acc=0.8159
2022-01-19 23:42:46,705 - INFO - Group Accuracy:

2022-01-19 23:42:46,705 - INFO - [0.9838554  0.99060243 0.9879518  0.9930121  0.98698795 0.9946988
 0.9819277  0.98240966 0.99084336 0.97903615 0.9918072  0.9845783
 0.97831327 0.9838554  0.97927713 0.9898795  0.99493974]
2022-01-19 23:42:46,706 - INFO - Epoch time: 395.72407054901123
2022-01-19 23:42:46,706 - INFO - 
Epoch: 77
2022-01-19 23:42:46,706 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:44:22,723 - INFO - [Step=64500]	Loss=0.4929	257.9 examples/second
2022-01-19 23:46:17,338 - INFO - [Step=64750]	Loss=0.5044	279.2 examples/second
2022-01-19 23:48:12,042 - INFO - [Step=65000]	Loss=0.4863	279.0 examples/second
2022-01-19 23:49:18,902 - INFO - Test Loss=0.7803, Test top-1 acc=0.8173
2022-01-19 23:49:18,902 - INFO - Group Accuracy:

2022-01-19 23:49:18,902 - INFO - [0.9838554  0.99108434 0.98698795 0.9927711  0.98626506 0.99445784
 0.9812048  0.9819277  0.99036145 0.9778313  0.99108434 0.9848193
 0.97831327 0.98313254 0.97927713 0.99108434 0.9954217 ]
2022-01-19 23:49:18,903 - INFO - Epoch time: 392.1973900794983
2022-01-19 23:49:18,903 - INFO - 
Epoch: 78
2022-01-19 23:49:18,903 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:50:16,014 - INFO - [Step=65250]	Loss=0.4914	258.1 examples/second
2022-01-19 23:52:11,128 - INFO - [Step=65500]	Loss=0.5080	278.0 examples/second
2022-01-19 23:54:06,203 - INFO - [Step=65750]	Loss=0.4890	278.1 examples/second
2022-01-19 23:55:52,590 - INFO - Test Loss=0.7798, Test top-1 acc=0.8176
2022-01-19 23:55:52,591 - INFO - Group Accuracy:

2022-01-19 23:55:52,591 - INFO - [0.9838554  0.9901205  0.9879518  0.993253   0.9853012  0.99421686
 0.98289156 0.98240966 0.99084336 0.9785542  0.99060243 0.9850602
 0.9780723  0.98361444 0.97903615 0.99036145 0.9968675 ]
2022-01-19 23:55:52,591 - INFO - Epoch time: 393.68812251091003
2022-01-19 23:55:52,591 - INFO - 
Epoch: 79
2022-01-19 23:55:52,591 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:56:10,649 - INFO - [Step=66000]	Loss=0.4993	257.1 examples/second
2022-01-19 23:58:06,185 - INFO - [Step=66250]	Loss=0.4862	277.0 examples/second
2022-01-20 00:00:01,629 - INFO - [Step=66500]	Loss=0.4956	277.2 examples/second
2022-01-20 00:01:56,978 - INFO - [Step=66750]	Loss=0.5082	277.4 examples/second
2022-01-20 00:02:27,555 - INFO - Test Loss=0.7819, Test top-1 acc=0.8181
2022-01-20 00:02:27,556 - INFO - Group Accuracy:

2022-01-20 00:02:27,556 - INFO - [0.98313254 0.9920482  0.98698795 0.99373496 0.98626506 0.99445784
 0.9812048  0.9826506  0.99084336 0.9775904  0.99060243 0.9850602
 0.9780723  0.98313254 0.97927713 0.99060243 0.9961446 ]
2022-01-20 00:02:27,557 - INFO - Epoch time: 394.9655225276947
2022-01-20 00:02:27,557 - INFO - 
Epoch: 80
2022-01-20 00:02:27,557 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:04:02,178 - INFO - [Step=67000]	Loss=0.4962	255.6 examples/second
2022-01-20 00:05:57,681 - INFO - [Step=67250]	Loss=0.4837	277.1 examples/second
2022-01-20 00:07:53,240 - INFO - [Step=67500]	Loss=0.4925	276.9 examples/second
2022-01-20 00:09:02,903 - INFO - Test Loss=0.7838, Test top-1 acc=0.8164
2022-01-20 00:09:02,903 - INFO - Group Accuracy:

2022-01-20 00:09:02,904 - INFO - [0.98289156 0.9922892  0.9860241  0.9930121  0.98578316 0.99445784
 0.9814458  0.9826506  0.99036145 0.97831327 0.9901205  0.9853012
 0.97951806 0.98240966 0.97903615 0.9898795  0.9951807 ]
2022-01-20 00:09:02,905 - INFO - Epoch time: 395.3478150367737
2022-01-20 00:09:02,905 - INFO - 
Epoch: 81
2022-01-20 00:09:02,905 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:09:58,018 - INFO - [Step=67750]	Loss=0.4900	256.5 examples/second
2022-01-20 00:11:52,667 - INFO - [Step=68000]	Loss=0.4924	279.1 examples/second
2022-01-20 00:13:47,335 - INFO - [Step=68250]	Loss=0.4851	279.1 examples/second
2022-01-20 00:15:35,710 - INFO - Test Loss=0.7830, Test top-1 acc=0.8198
2022-01-20 00:15:35,710 - INFO - Group Accuracy:

2022-01-20 00:15:35,710 - INFO - [0.9838554  0.9918072  0.98698795 0.9927711  0.98578316 0.99445784
 0.98240966 0.9821687  0.9898795  0.9785542  0.9918072  0.9850602
 0.9785542  0.98289156 0.97951806 0.98963857 0.9961446 ]
2022-01-20 00:15:35,711 - INFO - Saving...
2022-01-20 00:15:35,961 - INFO - Epoch time: 393.0561888217926
2022-01-20 00:15:35,962 - INFO - 
Epoch: 82
2022-01-20 00:15:35,962 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:15:51,710 - INFO - [Step=68500]	Loss=0.4896	257.3 examples/second
2022-01-20 00:17:47,338 - INFO - [Step=68750]	Loss=0.4902	276.8 examples/second
2022-01-20 00:19:42,800 - INFO - [Step=69000]	Loss=0.4806	277.1 examples/second
2022-01-20 00:21:38,016 - INFO - [Step=69250]	Loss=0.4885	277.7 examples/second
2022-01-20 00:22:10,907 - INFO - Test Loss=0.7823, Test top-1 acc=0.8198
2022-01-20 00:22:10,908 - INFO - Group Accuracy:

2022-01-20 00:22:10,908 - INFO - [0.9821687  0.99084336 0.9881928  0.9927711  0.9860241  0.99445784
 0.98240966 0.9814458  0.9891566  0.97831327 0.99156624 0.9855422
 0.9787952  0.9850602  0.97927713 0.98963857 0.9951807 ]
2022-01-20 00:22:10,908 - INFO - Epoch time: 394.9469847679138
2022-01-20 00:22:10,909 - INFO - 
Epoch: 83
2022-01-20 00:22:10,909 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:23:42,958 - INFO - [Step=69500]	Loss=0.4721	256.1 examples/second
2022-01-20 00:25:38,227 - INFO - [Step=69750]	Loss=0.4916	277.6 examples/second
2022-01-20 00:27:33,561 - INFO - [Step=70000]	Loss=0.4878	277.5 examples/second
2022-01-20 00:28:45,426 - INFO - Test Loss=0.7908, Test top-1 acc=0.8183
2022-01-20 00:28:45,426 - INFO - Group Accuracy:

2022-01-20 00:28:45,426 - INFO - [0.98313254 0.99108434 0.9881928  0.9927711  0.9853012  0.99445784
 0.98313254 0.9814458  0.9901205  0.9785542  0.99060243 0.9850602
 0.9780723  0.98313254 0.9804819  0.99036145 0.9959036 ]
2022-01-20 00:28:45,427 - INFO - Epoch time: 394.51873779296875
2022-01-20 00:28:45,427 - INFO - 
Epoch: 84
2022-01-20 00:28:45,427 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:29:38,161 - INFO - [Step=70250]	Loss=0.4880	256.8 examples/second
2022-01-20 00:31:32,826 - INFO - [Step=70500]	Loss=0.4866	279.1 examples/second
2022-01-20 00:33:27,500 - INFO - [Step=70750]	Loss=0.4887	279.1 examples/second
2022-01-20 00:35:18,267 - INFO - Test Loss=0.7839, Test top-1 acc=0.8178
2022-01-20 00:35:18,268 - INFO - Group Accuracy:

2022-01-20 00:35:18,268 - INFO - [0.9840964  0.99060243 0.98771083 0.993253   0.9853012  0.99445784
 0.9816868  0.98313254 0.99060243 0.9785542  0.9918072  0.98433733
 0.9785542  0.9838554  0.9785542  0.9913253  0.9966265 ]
2022-01-20 00:35:18,268 - INFO - Epoch time: 392.8410484790802
2022-01-20 00:35:18,269 - INFO - 
Epoch: 85
2022-01-20 00:35:18,269 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:35:31,973 - INFO - [Step=71000]	Loss=0.4838	257.1 examples/second
2022-01-20 00:37:26,767 - INFO - [Step=71250]	Loss=0.4811	278.8 examples/second
2022-01-20 00:39:21,487 - INFO - [Step=71500]	Loss=0.4875	278.9 examples/second
2022-01-20 00:41:16,382 - INFO - [Step=71750]	Loss=0.4837	278.5 examples/second
2022-01-20 00:41:51,388 - INFO - Test Loss=0.7971, Test top-1 acc=0.8173
2022-01-20 00:41:51,388 - INFO - Group Accuracy:

2022-01-20 00:41:51,388 - INFO - [0.9833735  0.99060243 0.98722893 0.99373496 0.98578316 0.99445784
 0.9819277  0.98240966 0.99060243 0.9780723  0.99060243 0.9853012
 0.97927713 0.9833735  0.9787952  0.9901205  0.9959036 ]
2022-01-20 00:41:51,389 - INFO - Epoch time: 393.1203091144562
2022-01-20 00:41:51,389 - INFO - 
Epoch: 86
2022-01-20 00:41:51,389 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:43:20,999 - INFO - [Step=72000]	Loss=0.4958	256.8 examples/second
2022-01-20 00:45:16,027 - INFO - [Step=72250]	Loss=0.4846	278.2 examples/second
2022-01-20 00:47:11,400 - INFO - [Step=72500]	Loss=0.4822	277.4 examples/second
2022-01-20 00:48:25,651 - INFO - Test Loss=0.7906, Test top-1 acc=0.8183
2022-01-20 00:48:25,651 - INFO - Group Accuracy:

2022-01-20 00:48:25,651 - INFO - [0.98361444 0.99156624 0.98771083 0.99421686 0.9853012  0.99421686
 0.98240966 0.98240966 0.9901205  0.9787952  0.9913253  0.9850602
 0.97975904 0.98361444 0.97903615 0.9898795  0.9959036 ]
2022-01-20 00:48:25,652 - INFO - Epoch time: 394.2628891468048
2022-01-20 00:48:25,652 - INFO - 
Epoch: 87
2022-01-20 00:48:25,652 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:49:15,878 - INFO - [Step=72750]	Loss=0.4841	257.1 examples/second
2022-01-20 00:51:10,767 - INFO - [Step=73000]	Loss=0.4837	278.5 examples/second
2022-01-20 00:53:05,582 - INFO - [Step=73250]	Loss=0.4716	278.7 examples/second
2022-01-20 00:54:58,329 - INFO - Test Loss=0.7947, Test top-1 acc=0.8178
2022-01-20 00:54:58,330 - INFO - Group Accuracy:

2022-01-20 00:54:58,330 - INFO - [0.9848193  0.99036145 0.98722893 0.99373496 0.9848193  0.9946988
 0.98240966 0.9819277  0.9901205  0.9778313  0.99156624 0.9850602
 0.97927713 0.98313254 0.9785542  0.9913253  0.9956626 ]
2022-01-20 00:54:58,331 - INFO - Epoch time: 392.6788456439972
2022-01-20 00:54:58,331 - INFO - 
Epoch: 88
2022-01-20 00:54:58,331 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:55:09,791 - INFO - [Step=73500]	Loss=0.4851	257.6 examples/second
2022-01-20 00:57:05,283 - INFO - [Step=73750]	Loss=0.4822	277.1 examples/second
2022-01-20 00:59:00,856 - INFO - [Step=74000]	Loss=0.4822	276.9 examples/second
2022-01-20 01:00:56,900 - INFO - [Step=74250]	Loss=0.4769	275.8 examples/second
2022-01-20 01:01:34,620 - INFO - Test Loss=0.8018, Test top-1 acc=0.8173
2022-01-20 01:01:34,620 - INFO - Group Accuracy:

2022-01-20 01:01:34,621 - INFO - [0.98361444 0.99084336 0.98674697 0.9927711  0.9845783  0.9939759
 0.9819277  0.9826506  0.9898795  0.97831327 0.9913253  0.9853012
 0.97975904 0.98240966 0.97903615 0.99084336 0.9959036 ]
2022-01-20 01:01:34,621 - INFO - Epoch time: 396.29043102264404
2022-01-20 01:01:34,621 - INFO - 
Epoch: 89
2022-01-20 01:01:34,621 - INFO - 
Learning Rate: 0.0010
2022-01-20 01:03:01,540 - INFO - [Step=74500]	Loss=0.4804	256.7 examples/second
2022-01-20 01:04:56,297 - INFO - [Step=74750]	Loss=0.4785	278.9 examples/second
2022-01-20 01:06:51,300 - INFO - [Step=75000]	Loss=0.4717	278.3 examples/second
2022-01-20 01:08:07,564 - INFO - Test Loss=0.7991, Test top-1 acc=0.8128
2022-01-20 01:08:07,564 - INFO - Group Accuracy:

2022-01-20 01:08:07,565 - INFO - [0.98289156 0.99156624 0.98650604 0.9927711  0.98578316 0.9946988
 0.98313254 0.9814458  0.99036145 0.97831327 0.9901205  0.9853012
 0.97903615 0.9833735  0.9787952  0.98963857 0.9961446 ]
2022-01-20 01:08:07,566 - INFO - Epoch time: 392.94453954696655
2022-01-20 01:08:17,648 - INFO - Computing OOD Statistics...
2022-01-20 01:08:17,659 - INFO - 	Baseline.          AUROC: 0.3262. TNR@95TPR: 0.0235. AUPR OUT: 0.1218
2022-01-20 01:08:17,664 - INFO - 	ODIN (T=1000).     AUROC: 0.8841. TNR@95TPR: 0.4918. AUPR OUT: 0.6056
2022-01-20 01:08:17,664 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-20 01:08:17,664 - INFO - Top 1 Accuracy:  Min: 0.8198; Max: 0.8198; Avg: 0.8198; Std: 0.0000; Len: 1
2022-01-20 01:08:17,664 - INFO - Top 5 Accuracy:  Min: 0.9866; Max: 0.9866; Avg: 0.9866; Std: 0.0000; Len: 1
2022-01-20 01:08:17,664 - INFO - **********************************************************************
2022-01-20 01:08:17,664 - INFO - 	MSP (auroc): [0.32620240963855424] Min: 0.3262; Max: 0.3262; Avg: 0.3262; Std: 0.0000; Len: 1
2022-01-20 01:08:17,664 - INFO - 	MSP (tnr): [0.02352941176470591] Min: 0.0235; Max: 0.0235; Avg: 0.0235; Std: 0.0000; Len: 1
2022-01-20 01:08:17,664 - INFO - 	MSP (aupr): [0.1218410360277009] Min: 0.1218; Max: 0.1218; Avg: 0.1218; Std: 0.0000; Len: 1
2022-01-20 01:08:17,664 - INFO - 	ODIN (auroc): [0.8840583982990786] Min: 0.8841; Max: 0.8841; Avg: 0.8841; Std: 0.0000; Len: 1
2022-01-20 01:08:17,665 - INFO - 	ODIN (tnr): [0.491764705882353] Min: 0.4918; Max: 0.4918; Avg: 0.4918; Std: 0.0000; Len: 1
2022-01-20 01:08:17,665 - INFO - 	ODIN (aupr): [0.6055898213219708] Min: 0.6056; Max: 0.6056; Avg: 0.6056; Std: 0.0000; Len: 1

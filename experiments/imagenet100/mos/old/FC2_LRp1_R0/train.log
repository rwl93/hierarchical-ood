2022-01-18 17:08:14,652 - INFO - ==> Preparing data..
2022-01-18 17:08:15,032 - INFO - checkpoint filename: experiments/coarse/mos/FC2_LRp1_R0/checkpoint.pt
2022-01-18 17:08:15,032 - INFO - log filename: experiments/coarse/mos/FC2_LRp1_R0/train.log
2022-01-18 17:08:15,032 - INFO - ********************************************************
2022-01-18 17:08:15,032 - INFO - Starting Iter: 0 / 1
2022-01-18 17:08:15,032 - INFO - ********************************************************
2022-01-18 17:08:18,121 - INFO - cuda
2022-01-18 17:08:18,160 - INFO - 
Epoch: 0
2022-01-18 17:08:18,160 - INFO - 
Learning Rate: 0.0100
2022-01-18 17:10:15,825 - INFO - [Step=250]	Loss=7.5002	272.0 examples/second
2022-01-18 17:12:11,035 - INFO - [Step=500]	Loss=5.4148	277.8 examples/second
2022-01-18 17:14:06,741 - INFO - [Step=750]	Loss=5.3194	276.6 examples/second
2022-01-18 17:14:53,301 - INFO - Test Loss=5.1983, Test top-1 acc=0.0441
2022-01-18 17:14:53,301 - INFO - Group Accuracy:

2022-01-18 17:14:53,301 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.9395181 0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-18 17:14:53,302 - INFO - Saving...
2022-01-18 17:14:53,451 - INFO - Epoch time: 395.29046058654785
2022-01-18 17:14:53,451 - INFO - 
Epoch: 1
2022-01-18 17:14:53,451 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:16:11,629 - INFO - [Step=1000]	Loss=5.2575	256.2 examples/second
2022-01-18 17:18:07,435 - INFO - [Step=1250]	Loss=5.0071	276.3 examples/second
2022-01-18 17:20:03,157 - INFO - [Step=1500]	Loss=4.8197	276.5 examples/second
2022-01-18 17:21:29,101 - INFO - Test Loss=4.6539, Test top-1 acc=0.1181
2022-01-18 17:21:29,102 - INFO - Group Accuracy:

2022-01-18 17:21:29,102 - INFO - [0.939759   0.94       0.939759   0.94192773 0.939759   0.940241
 0.9395181  0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.940241   0.9395181  0.9518072 ]
2022-01-18 17:21:29,102 - INFO - Saving...
2022-01-18 17:21:29,357 - INFO - Epoch time: 395.90585064888
2022-01-18 17:21:29,357 - INFO - 
Epoch: 2
2022-01-18 17:21:29,357 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:22:08,136 - INFO - [Step=1750]	Loss=4.6795	256.0 examples/second
2022-01-18 17:24:03,390 - INFO - [Step=2000]	Loss=4.5563	277.6 examples/second
2022-01-18 17:25:58,808 - INFO - [Step=2250]	Loss=4.3938	277.3 examples/second
2022-01-18 17:27:54,229 - INFO - [Step=2500]	Loss=4.2153	277.2 examples/second
2022-01-18 17:28:03,539 - INFO - Test Loss=4.2072, Test top-1 acc=0.2133
2022-01-18 17:28:03,539 - INFO - Group Accuracy:

2022-01-18 17:28:03,539 - INFO - [0.940241   0.9453012  0.939759   0.9460241  0.939759   0.9469879
 0.94192773 0.9436145  0.94289154 0.939759   0.95228916 0.9404819
 0.939759   0.939759   0.94       0.940241   0.9518072 ]
2022-01-18 17:28:03,541 - INFO - Saving...
2022-01-18 17:28:03,815 - INFO - Epoch time: 394.4577498435974
2022-01-18 17:28:03,815 - INFO - 
Epoch: 3
2022-01-18 17:28:03,815 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:29:57,977 - INFO - [Step=2750]	Loss=4.1390	258.6 examples/second
2022-01-18 17:31:52,635 - INFO - [Step=3000]	Loss=3.9752	279.1 examples/second
2022-01-18 17:33:47,480 - INFO - [Step=3250]	Loss=3.8373	278.6 examples/second
2022-01-18 17:34:36,060 - INFO - Test Loss=3.6356, Test top-1 acc=0.2824
2022-01-18 17:34:36,061 - INFO - Group Accuracy:

2022-01-18 17:34:36,061 - INFO - [0.9440964  0.9472289  0.94168675 0.95638555 0.9431325  0.95373493
 0.9436145  0.946747   0.9513253  0.94433737 0.95349395 0.9426506
 0.940241   0.940241   0.940241   0.9433735  0.9578313 ]
2022-01-18 17:34:36,062 - INFO - Saving...
2022-01-18 17:34:36,309 - INFO - Epoch time: 392.4943165779114
2022-01-18 17:34:36,309 - INFO - 
Epoch: 4
2022-01-18 17:34:36,309 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:35:52,866 - INFO - [Step=3500]	Loss=3.7960	255.2 examples/second
2022-01-18 17:37:48,909 - INFO - [Step=3750]	Loss=3.6934	275.8 examples/second
2022-01-18 17:39:45,124 - INFO - [Step=4000]	Loss=3.5564	275.4 examples/second
2022-01-18 17:41:13,846 - INFO - Test Loss=3.3475, Test top-1 acc=0.3359
2022-01-18 17:41:13,846 - INFO - Group Accuracy:

2022-01-18 17:41:13,846 - INFO - [0.946506   0.94939756 0.94120485 0.9595181  0.9445783  0.96433735
 0.9339759  0.95301205 0.9510843  0.94096386 0.95228916 0.94120485
 0.94096386 0.9436145  0.94144577 0.9498795  0.966747  ]
2022-01-18 17:41:13,847 - INFO - Saving...
2022-01-18 17:41:14,106 - INFO - Epoch time: 397.7961177825928
2022-01-18 17:41:14,106 - INFO - 
Epoch: 5
2022-01-18 17:41:14,106 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:41:50,460 - INFO - [Step=4250]	Loss=3.4171	255.3 examples/second
2022-01-18 17:43:45,443 - INFO - [Step=4500]	Loss=3.2704	278.3 examples/second
2022-01-18 17:45:40,422 - INFO - [Step=4750]	Loss=3.1967	278.3 examples/second
2022-01-18 17:47:35,947 - INFO - [Step=5000]	Loss=3.0773	277.0 examples/second
2022-01-18 17:47:48,086 - INFO - Test Loss=3.1788, Test top-1 acc=0.3600
2022-01-18 17:47:48,087 - INFO - Group Accuracy:

2022-01-18 17:47:48,087 - INFO - [0.9469879  0.94915664 0.94289154 0.9621687  0.94433737 0.96385545
 0.933253   0.9498795  0.9551807  0.9472289  0.95759034 0.94120485
 0.939759   0.9385542  0.94554216 0.946506   0.97180724]
2022-01-18 17:47:48,087 - INFO - Saving...
2022-01-18 17:47:48,340 - INFO - Epoch time: 394.2337942123413
2022-01-18 17:47:48,340 - INFO - 
Epoch: 6
2022-01-18 17:47:48,340 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:49:40,116 - INFO - [Step=5250]	Loss=3.0010	257.7 examples/second
2022-01-18 17:51:34,373 - INFO - [Step=5500]	Loss=2.9121	280.1 examples/second
2022-01-18 17:53:29,650 - INFO - [Step=5750]	Loss=2.8724	277.6 examples/second
2022-01-18 17:54:21,274 - INFO - Test Loss=2.9328, Test top-1 acc=0.4019
2022-01-18 17:54:21,274 - INFO - Group Accuracy:

2022-01-18 17:54:21,274 - INFO - [0.9472289  0.9518072  0.9472289  0.96385545 0.9486747  0.9708434
 0.9387952  0.9520482  0.9657831  0.9472289  0.9585542  0.9460241
 0.9445783  0.940241   0.9445783  0.9539759  0.97301203]
2022-01-18 17:54:21,275 - INFO - Saving...
2022-01-18 17:54:21,541 - INFO - Epoch time: 393.20108675956726
2022-01-18 17:54:21,541 - INFO - 
Epoch: 7
2022-01-18 17:54:21,541 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:55:35,551 - INFO - [Step=6000]	Loss=2.7634	254.2 examples/second
2022-01-18 17:57:30,730 - INFO - [Step=6250]	Loss=2.6975	277.8 examples/second
2022-01-18 17:59:25,884 - INFO - [Step=6500]	Loss=2.6565	277.9 examples/second
2022-01-18 18:00:55,964 - INFO - Test Loss=2.4043, Test top-1 acc=0.4952
2022-01-18 18:00:55,965 - INFO - Group Accuracy:

2022-01-18 18:00:55,965 - INFO - [0.9539759  0.9621687  0.9469879  0.97180724 0.9515663  0.97518075
 0.94963855 0.95686746 0.9706024  0.9573494  0.9633735  0.9561446
 0.94506025 0.9448193  0.94843376 0.96048194 0.97951806]
2022-01-18 18:00:55,966 - INFO - Saving...
2022-01-18 18:00:56,201 - INFO - Epoch time: 394.6596448421478
2022-01-18 18:00:56,201 - INFO - 
Epoch: 8
2022-01-18 18:00:56,201 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:01:30,277 - INFO - [Step=6750]	Loss=2.5729	257.2 examples/second
2022-01-18 18:03:24,404 - INFO - [Step=7000]	Loss=2.5294	280.4 examples/second
2022-01-18 18:05:19,050 - INFO - [Step=7250]	Loss=2.4799	279.1 examples/second
2022-01-18 18:07:13,344 - INFO - [Step=7500]	Loss=2.4431	280.0 examples/second
2022-01-18 18:07:27,231 - INFO - Test Loss=2.2387, Test top-1 acc=0.5267
2022-01-18 18:07:27,231 - INFO - Group Accuracy:

2022-01-18 18:07:27,231 - INFO - [0.96048194 0.9621687  0.9508434  0.9780723  0.9472289  0.9804819
 0.9561446  0.95975906 0.9703615  0.95638555 0.96771085 0.95566267
 0.9481928  0.95036143 0.9508434  0.9621687  0.9804819 ]
2022-01-18 18:07:27,232 - INFO - Saving...
2022-01-18 18:07:27,424 - INFO - Epoch time: 391.223345041275
2022-01-18 18:07:27,425 - INFO - 
Epoch: 9
2022-01-18 18:07:27,425 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:09:16,771 - INFO - [Step=7750]	Loss=2.3592	259.3 examples/second
2022-01-18 18:11:11,105 - INFO - [Step=8000]	Loss=2.3341	279.9 examples/second
2022-01-18 18:13:05,330 - INFO - [Step=8250]	Loss=2.2942	280.2 examples/second
2022-01-18 18:13:58,312 - INFO - Test Loss=2.6176, Test top-1 acc=0.4918
2022-01-18 18:13:58,312 - INFO - Group Accuracy:

2022-01-18 18:13:58,312 - INFO - [0.9583132  0.9672289  0.94963855 0.9746988  0.95566267 0.97228914
 0.9561446  0.9546988  0.9624096  0.95686746 0.9585542  0.95349395
 0.9481928  0.9474699  0.94843376 0.96168673 0.9737349 ]
2022-01-18 18:13:58,313 - INFO - Epoch time: 390.888658285141
2022-01-18 18:13:58,313 - INFO - 
Epoch: 10
2022-01-18 18:13:58,313 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:15:08,755 - INFO - [Step=8500]	Loss=2.2265	259.3 examples/second
2022-01-18 18:17:02,932 - INFO - [Step=8750]	Loss=2.2258	280.3 examples/second
2022-01-18 18:18:57,244 - INFO - [Step=9000]	Loss=2.1665	279.9 examples/second
2022-01-18 18:20:28,968 - INFO - Test Loss=2.1514, Test top-1 acc=0.5528
2022-01-18 18:20:28,969 - INFO - Group Accuracy:

2022-01-18 18:20:28,969 - INFO - [0.9595181  0.966747   0.9595181  0.97493976 0.96096385 0.9814458
 0.9578313  0.96024096 0.973253   0.9551807  0.9706024  0.9628916
 0.9510843  0.94915664 0.9469879  0.966506   0.9787952 ]
2022-01-18 18:20:28,969 - INFO - Saving...
2022-01-18 18:20:29,240 - INFO - Epoch time: 390.926944732666
2022-01-18 18:20:29,241 - INFO - 
Epoch: 11
2022-01-18 18:20:29,241 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:21:00,758 - INFO - [Step=9250]	Loss=2.1677	259.1 examples/second
2022-01-18 18:22:54,846 - INFO - [Step=9500]	Loss=2.1126	280.5 examples/second
2022-01-18 18:24:48,946 - INFO - [Step=9750]	Loss=2.0833	280.5 examples/second
2022-01-18 18:26:43,041 - INFO - [Step=10000]	Loss=2.0694	280.5 examples/second
2022-01-18 18:26:59,363 - INFO - Test Loss=1.9829, Test top-1 acc=0.5783
2022-01-18 18:26:59,364 - INFO - Group Accuracy:

2022-01-18 18:26:59,364 - INFO - [0.9614458  0.97228914 0.9551807  0.9773494  0.96072286 0.97831327
 0.9518072  0.9631325  0.9696385  0.96433735 0.9727711  0.9662651
 0.95277107 0.9554217  0.9554217  0.9703615  0.9848193 ]
2022-01-18 18:26:59,365 - INFO - Saving...
2022-01-18 18:26:59,632 - INFO - Epoch time: 390.39148473739624
2022-01-18 18:26:59,632 - INFO - 
Epoch: 12
2022-01-18 18:26:59,633 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:28:46,738 - INFO - [Step=10250]	Loss=1.9930	258.7 examples/second
2022-01-18 18:30:40,718 - INFO - [Step=10500]	Loss=2.0089	280.8 examples/second
2022-01-18 18:32:34,788 - INFO - [Step=10750]	Loss=1.9830	280.5 examples/second
2022-01-18 18:33:29,743 - INFO - Test Loss=2.2131, Test top-1 acc=0.5504
2022-01-18 18:33:29,744 - INFO - Group Accuracy:

2022-01-18 18:33:29,744 - INFO - [0.9624096  0.96385545 0.9551807  0.9742169  0.9590362  0.97831327
 0.9580723  0.95710844 0.9807229  0.9619277  0.9691566  0.9631325
 0.94843376 0.9440964  0.95373493 0.9653012  0.9821687 ]
2022-01-18 18:33:29,745 - INFO - Epoch time: 390.1127464771271
2022-01-18 18:33:29,745 - INFO - 
Epoch: 13
2022-01-18 18:33:29,745 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:34:38,127 - INFO - [Step=11000]	Loss=1.9327	259.4 examples/second
2022-01-18 18:36:33,009 - INFO - [Step=11250]	Loss=1.9335	278.5 examples/second
2022-01-18 18:38:27,991 - INFO - [Step=11500]	Loss=1.9123	278.3 examples/second
2022-01-18 18:40:02,923 - INFO - Test Loss=1.9124, Test top-1 acc=0.6065
2022-01-18 18:40:02,923 - INFO - Group Accuracy:

2022-01-18 18:40:02,923 - INFO - [0.96361446 0.97638553 0.9612048  0.98433733 0.9583132  0.9819277
 0.95638555 0.9686747  0.97542167 0.96048194 0.9727711  0.96409637
 0.95421684 0.9554217  0.96       0.9691566  0.9833735 ]
2022-01-18 18:40:02,924 - INFO - Saving...
2022-01-18 18:40:03,188 - INFO - Epoch time: 393.44259309768677
2022-01-18 18:40:03,188 - INFO - 
Epoch: 14
2022-01-18 18:40:03,188 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:40:32,562 - INFO - [Step=11750]	Loss=1.9018	256.9 examples/second
2022-01-18 18:42:27,604 - INFO - [Step=12000]	Loss=1.8491	278.2 examples/second
2022-01-18 18:44:22,795 - INFO - [Step=12250]	Loss=1.8453	277.8 examples/second
2022-01-18 18:46:17,766 - INFO - [Step=12500]	Loss=1.8467	278.3 examples/second
2022-01-18 18:46:36,383 - INFO - Test Loss=1.9213, Test top-1 acc=0.6041
2022-01-18 18:46:36,383 - INFO - Group Accuracy:

2022-01-18 18:46:36,383 - INFO - [0.96096385 0.97108436 0.96       0.9773494  0.9655422  0.98433733
 0.96       0.9686747  0.97566265 0.96409637 0.9691566  0.966747
 0.9549398  0.9546988  0.96       0.9698795  0.9848193 ]
2022-01-18 18:46:36,384 - INFO - Epoch time: 393.1963255405426
2022-01-18 18:46:36,385 - INFO - 
Epoch: 15
2022-01-18 18:46:36,385 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:48:21,157 - INFO - [Step=12750]	Loss=1.7941	259.3 examples/second
2022-01-18 18:50:15,350 - INFO - [Step=13000]	Loss=1.7847	280.2 examples/second
2022-01-18 18:52:09,702 - INFO - [Step=13250]	Loss=1.7777	279.8 examples/second
2022-01-18 18:53:07,262 - INFO - Test Loss=1.9764, Test top-1 acc=0.5764
2022-01-18 18:53:07,262 - INFO - Group Accuracy:

2022-01-18 18:53:07,262 - INFO - [0.96168673 0.9713253  0.9633735  0.9819277  0.9624096  0.98361444
 0.9549398  0.96168673 0.96843374 0.966747   0.97228914 0.96409637
 0.9385542  0.95686746 0.9559036  0.96891564 0.9860241 ]
2022-01-18 18:53:07,263 - INFO - Epoch time: 390.8779134750366
2022-01-18 18:53:07,263 - INFO - 
Epoch: 16
2022-01-18 18:53:07,263 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:54:13,006 - INFO - [Step=13500]	Loss=1.7775	259.5 examples/second
2022-01-18 18:56:07,092 - INFO - [Step=13750]	Loss=1.7291	280.5 examples/second
2022-01-18 18:58:01,261 - INFO - [Step=14000]	Loss=1.7503	280.3 examples/second
2022-01-18 18:59:37,535 - INFO - Test Loss=1.7090, Test top-1 acc=0.6337
2022-01-18 18:59:37,536 - INFO - Group Accuracy:

2022-01-18 18:59:37,536 - INFO - [0.96481925 0.97638553 0.96048194 0.98433733 0.96795183 0.9855422
 0.9583132  0.97108436 0.97927713 0.96891564 0.97831327 0.966747
 0.95710844 0.9580723  0.9614458  0.97156626 0.98650604]
2022-01-18 18:59:37,537 - INFO - Saving...
2022-01-18 18:59:37,786 - INFO - Epoch time: 390.5234754085541
2022-01-18 18:59:37,786 - INFO - 
Epoch: 17
2022-01-18 18:59:37,786 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:00:04,917 - INFO - [Step=14250]	Loss=1.7100	258.8 examples/second
2022-01-18 19:02:00,157 - INFO - [Step=14500]	Loss=1.6818	277.7 examples/second
2022-01-18 19:03:55,201 - INFO - [Step=14750]	Loss=1.6846	278.2 examples/second
2022-01-18 19:05:50,239 - INFO - [Step=15000]	Loss=1.6862	278.2 examples/second
2022-01-18 19:06:11,138 - INFO - Test Loss=1.6051, Test top-1 acc=0.6419
2022-01-18 19:06:11,139 - INFO - Group Accuracy:

2022-01-18 19:06:11,139 - INFO - [0.96698797 0.97493976 0.9655422  0.9826506  0.9698795  0.98771083
 0.96506023 0.9686747  0.97975904 0.96698797 0.9768675  0.97108436
 0.95759034 0.9580723  0.9624096  0.97542167 0.98746985]
2022-01-18 19:06:11,140 - INFO - Saving...
2022-01-18 19:06:11,375 - INFO - Epoch time: 393.58847427368164
2022-01-18 19:06:11,375 - INFO - 
Epoch: 18
2022-01-18 19:06:11,375 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:07:54,506 - INFO - [Step=15250]	Loss=1.6359	257.5 examples/second
2022-01-18 19:09:49,950 - INFO - [Step=15500]	Loss=1.6578	277.2 examples/second
2022-01-18 19:11:45,368 - INFO - [Step=15750]	Loss=1.6489	277.3 examples/second
2022-01-18 19:12:45,640 - INFO - Test Loss=1.7177, Test top-1 acc=0.6234
2022-01-18 19:12:45,641 - INFO - Group Accuracy:

2022-01-18 19:12:45,641 - INFO - [0.9631325  0.9812048  0.9621687  0.98313254 0.9672289  0.98024094
 0.9628916  0.9674699  0.97566265 0.96795183 0.97204816 0.96
 0.9592771  0.96409637 0.9633735  0.9706024  0.98361444]
2022-01-18 19:12:45,642 - INFO - Epoch time: 394.2666735649109
2022-01-18 19:12:45,642 - INFO - 
Epoch: 19
2022-01-18 19:12:45,642 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:13:49,646 - INFO - [Step=16000]	Loss=1.6053	257.5 examples/second
2022-01-18 19:15:44,346 - INFO - [Step=16250]	Loss=1.6168	279.0 examples/second
2022-01-18 19:17:38,880 - INFO - [Step=16500]	Loss=1.6083	279.4 examples/second
2022-01-18 19:19:17,875 - INFO - Test Loss=1.4896, Test top-1 acc=0.6619
2022-01-18 19:19:17,875 - INFO - Group Accuracy:

2022-01-18 19:19:17,875 - INFO - [0.96891564 0.9816868  0.96891564 0.98626506 0.96795183 0.98674697
 0.9660241  0.96795183 0.9826506  0.96795183 0.9766265  0.97301203
 0.9585542  0.96048194 0.9590362  0.9778313  0.98698795]
2022-01-18 19:19:17,876 - INFO - Saving...
2022-01-18 19:19:18,124 - INFO - Epoch time: 392.4817051887512
2022-01-18 19:19:18,124 - INFO - 
Epoch: 20
2022-01-18 19:19:18,124 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:19:42,706 - INFO - [Step=16750]	Loss=1.6097	258.4 examples/second
2022-01-18 19:21:37,847 - INFO - [Step=17000]	Loss=1.5683	277.9 examples/second
2022-01-18 19:23:32,875 - INFO - [Step=17250]	Loss=1.5818	278.2 examples/second
2022-01-18 19:25:28,143 - INFO - [Step=17500]	Loss=1.5864	277.6 examples/second
2022-01-18 19:25:51,516 - INFO - Test Loss=1.5879, Test top-1 acc=0.6492
2022-01-18 19:25:51,517 - INFO - Group Accuracy:

2022-01-18 19:25:51,517 - INFO - [0.96457833 0.97903615 0.9701205  0.9860241  0.96819276 0.9891566
 0.9612048  0.96481925 0.97975904 0.9691566  0.98       0.9713253
 0.9592771  0.9633735  0.95710844 0.973253   0.98722893]
2022-01-18 19:25:51,517 - INFO - Epoch time: 393.3937439918518
2022-01-18 19:25:51,518 - INFO - 
Epoch: 21
2022-01-18 19:25:51,518 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:27:33,440 - INFO - [Step=17750]	Loss=1.5423	255.4 examples/second
2022-01-18 19:29:30,189 - INFO - [Step=18000]	Loss=1.5391	274.1 examples/second
2022-01-18 19:31:26,764 - INFO - [Step=18250]	Loss=1.5572	274.5 examples/second
2022-01-18 19:32:29,663 - INFO - Test Loss=2.1402, Test top-1 acc=0.5877
2022-01-18 19:32:29,663 - INFO - Group Accuracy:

2022-01-18 19:32:29,673 - INFO - [0.9612048  0.9739759  0.91566265 0.9746988  0.96843374 0.9879518
 0.9621687  0.96843374 0.97493976 0.94554216 0.9691566  0.9614458
 0.95036143 0.9619277  0.9587952  0.9686747  0.98698795]
2022-01-18 19:32:29,674 - INFO - Epoch time: 398.1564419269562
2022-01-18 19:32:29,674 - INFO - 
Epoch: 22
2022-01-18 19:32:29,674 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:33:31,161 - INFO - [Step=18500]	Loss=1.5238	257.2 examples/second
2022-01-18 19:35:25,932 - INFO - [Step=18750]	Loss=1.5116	278.8 examples/second
2022-01-18 19:37:20,740 - INFO - [Step=19000]	Loss=1.5149	278.7 examples/second
2022-01-18 19:39:01,973 - INFO - Test Loss=1.9725, Test top-1 acc=0.5949
2022-01-18 19:39:01,974 - INFO - Group Accuracy:

2022-01-18 19:39:01,974 - INFO - [0.9544578  0.9445783  0.9508434  0.9812048  0.96698797 0.98746985
 0.96168673 0.9628916  0.9809638  0.9624096  0.9657831  0.9653012
 0.96433735 0.96048194 0.96024096 0.9725301  0.98674697]
2022-01-18 19:39:01,974 - INFO - Epoch time: 392.30038714408875
2022-01-18 19:39:01,975 - INFO - 
Epoch: 23
2022-01-18 19:39:01,975 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:39:24,267 - INFO - [Step=19250]	Loss=1.5235	259.1 examples/second
2022-01-18 19:41:18,465 - INFO - [Step=19500]	Loss=1.4922	280.2 examples/second
2022-01-18 19:43:12,526 - INFO - [Step=19750]	Loss=1.5085	280.6 examples/second
2022-01-18 19:45:06,636 - INFO - [Step=20000]	Loss=1.5127	280.4 examples/second
2022-01-18 19:45:32,008 - INFO - Test Loss=1.9644, Test top-1 acc=0.5925
2022-01-18 19:45:32,009 - INFO - Group Accuracy:

2022-01-18 19:45:32,009 - INFO - [0.9580723  0.9508434  0.96048194 0.9816868  0.9686747  0.98674697
 0.95662653 0.96795183 0.97975904 0.96433735 0.96843374 0.96819276
 0.9583132  0.96096385 0.9624096  0.9691566  0.98433733]
2022-01-18 19:45:32,010 - INFO - Epoch time: 390.03515362739563
2022-01-18 19:45:32,010 - INFO - 
Epoch: 24
2022-01-18 19:45:32,010 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:47:10,577 - INFO - [Step=20250]	Loss=1.4596	258.2 examples/second
2022-01-18 19:49:05,746 - INFO - [Step=20500]	Loss=1.4718	277.9 examples/second
2022-01-18 19:51:00,966 - INFO - [Step=20750]	Loss=1.4804	277.7 examples/second
2022-01-18 19:52:05,910 - INFO - Test Loss=1.4779, Test top-1 acc=0.6728
2022-01-18 19:52:05,910 - INFO - Group Accuracy:

2022-01-18 19:52:05,910 - INFO - [0.97204816 0.9804819  0.9746988  0.9804819  0.9672289  0.9884337
 0.96024096 0.97228914 0.98289156 0.9696385  0.9814458  0.9739759
 0.9621687  0.9662651  0.96385545 0.9746988  0.98650604]
2022-01-18 19:52:05,911 - INFO - Saving...
2022-01-18 19:52:06,097 - INFO - Epoch time: 394.0870580673218
2022-01-18 19:52:06,097 - INFO - 
Epoch: 25
2022-01-18 19:52:06,097 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:53:05,337 - INFO - [Step=21000]	Loss=1.4734	257.3 examples/second
2022-01-18 19:54:59,824 - INFO - [Step=21250]	Loss=1.4541	279.5 examples/second
2022-01-18 19:56:54,123 - INFO - [Step=21500]	Loss=1.4741	280.0 examples/second
2022-01-18 19:58:37,113 - INFO - Test Loss=1.5879, Test top-1 acc=0.6547
2022-01-18 19:58:37,114 - INFO - Group Accuracy:

2022-01-18 19:58:37,114 - INFO - [0.9655422  0.9727711  0.97156626 0.9826506  0.9713253  0.9850602
 0.96771085 0.97156626 0.98650604 0.96891564 0.97903615 0.9742169
 0.96048194 0.9539759  0.96361446 0.9672289  0.9893976 ]
2022-01-18 19:58:37,114 - INFO - Epoch time: 391.01725912094116
2022-01-18 19:58:37,114 - INFO - 
Epoch: 26
2022-01-18 19:58:37,114 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:58:57,302 - INFO - [Step=21750]	Loss=1.4552	259.8 examples/second
2022-01-18 20:00:51,374 - INFO - [Step=22000]	Loss=1.4373	280.5 examples/second
2022-01-18 20:02:45,378 - INFO - [Step=22250]	Loss=1.4590	280.7 examples/second
2022-01-18 20:04:39,543 - INFO - [Step=22500]	Loss=1.4509	280.3 examples/second
2022-01-18 20:05:07,640 - INFO - Test Loss=1.5949, Test top-1 acc=0.6607
2022-01-18 20:05:07,641 - INFO - Group Accuracy:

2022-01-18 20:05:07,641 - INFO - [0.96843374 0.98289156 0.9587952  0.9850602  0.9713253  0.9893976
 0.966747   0.9672289  0.97951806 0.9660241  0.97445786 0.96698797
 0.9614458  0.96361446 0.96457833 0.9780723  0.98963857]
2022-01-18 20:05:07,642 - INFO - Epoch time: 390.52723813056946
2022-01-18 20:05:07,642 - INFO - 
Epoch: 27
2022-01-18 20:05:07,642 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:06:44,331 - INFO - [Step=22750]	Loss=1.3989	256.4 examples/second
2022-01-18 20:08:39,955 - INFO - [Step=23000]	Loss=1.4390	276.8 examples/second
2022-01-18 20:10:35,438 - INFO - [Step=23250]	Loss=1.4298	277.1 examples/second
2022-01-18 20:11:43,027 - INFO - Test Loss=1.6133, Test top-1 acc=0.6465
2022-01-18 20:11:43,027 - INFO - Group Accuracy:

2022-01-18 20:11:43,027 - INFO - [0.96698797 0.98240966 0.9698795  0.9812048  0.97228914 0.9891566
 0.95759034 0.97180724 0.9807229  0.96698797 0.9819277  0.97180724
 0.9356626  0.9612048  0.96168673 0.97638553 0.98746985]
2022-01-18 20:11:43,028 - INFO - Epoch time: 395.38652420043945
2022-01-18 20:11:43,028 - INFO - 
Epoch: 28
2022-01-18 20:11:43,028 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:12:39,885 - INFO - [Step=23500]	Loss=1.4112	257.1 examples/second
2022-01-18 20:14:34,586 - INFO - [Step=23750]	Loss=1.4043	279.0 examples/second
2022-01-18 20:16:29,080 - INFO - [Step=24000]	Loss=1.4012	279.5 examples/second
2022-01-18 20:18:14,568 - INFO - Test Loss=1.9933, Test top-1 acc=0.5957
2022-01-18 20:18:14,568 - INFO - Group Accuracy:

2022-01-18 20:18:14,568 - INFO - [0.9624096  0.9739759  0.93831325 0.9706024  0.96361446 0.9840964
 0.9655422  0.97301203 0.9804819  0.9660241  0.9628916  0.9551807
 0.9614458  0.96481925 0.9585542  0.9633735  0.9889157 ]
2022-01-18 20:18:14,569 - INFO - Epoch time: 391.5408217906952
2022-01-18 20:18:14,569 - INFO - 
Epoch: 29
2022-01-18 20:18:14,569 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:18:32,678 - INFO - [Step=24250]	Loss=1.3858	258.9 examples/second
2022-01-18 20:20:27,014 - INFO - [Step=24500]	Loss=1.0874	279.9 examples/second
2022-01-18 20:22:21,215 - INFO - [Step=24750]	Loss=1.0332	280.2 examples/second
2022-01-18 20:24:15,444 - INFO - [Step=25000]	Loss=1.0174	280.1 examples/second
2022-01-18 20:24:45,424 - INFO - Test Loss=0.9309, Test top-1 acc=0.7759
2022-01-18 20:24:45,424 - INFO - Group Accuracy:

2022-01-18 20:24:45,424 - INFO - [0.97590363 0.99036145 0.98289156 0.9920482  0.9809638  0.993494
 0.97831327 0.97975904 0.9891566  0.9737349  0.98722893 0.9838554
 0.9739759  0.9768675  0.9742169  0.9855422  0.99373496]
2022-01-18 20:24:45,425 - INFO - Saving...
2022-01-18 20:24:45,665 - INFO - Epoch time: 391.09571504592896
2022-01-18 20:24:45,665 - INFO - 
Epoch: 30
2022-01-18 20:24:45,665 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:26:19,712 - INFO - [Step=25250]	Loss=0.9713	257.5 examples/second
2022-01-18 20:28:14,966 - INFO - [Step=25500]	Loss=0.9703	277.6 examples/second
2022-01-18 20:30:10,163 - INFO - [Step=25750]	Loss=0.9480	277.8 examples/second
2022-01-18 20:31:19,999 - INFO - Test Loss=0.9106, Test top-1 acc=0.7831
2022-01-18 20:31:20,000 - INFO - Group Accuracy:

2022-01-18 20:31:20,000 - INFO - [0.9773494  0.9891566  0.9821687  0.9922892  0.9804819  0.993494
 0.97903615 0.9819277  0.98963857 0.9746988  0.98722893 0.9826506
 0.97445786 0.9768675  0.97590363 0.98722893 0.993253  ]
2022-01-18 20:31:20,001 - INFO - Saving...
2022-01-18 20:31:20,241 - INFO - Epoch time: 394.5762414932251
2022-01-18 20:31:20,242 - INFO - 
Epoch: 31
2022-01-18 20:31:20,242 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:32:14,833 - INFO - [Step=26000]	Loss=0.9353	256.7 examples/second
2022-01-18 20:34:09,813 - INFO - [Step=26250]	Loss=0.9119	278.3 examples/second
2022-01-18 20:36:04,711 - INFO - [Step=26500]	Loss=0.9244	278.5 examples/second
2022-01-18 20:37:53,317 - INFO - Test Loss=0.8756, Test top-1 acc=0.7887
2022-01-18 20:37:53,317 - INFO - Group Accuracy:

2022-01-18 20:37:53,317 - INFO - [0.9778313  0.9898795  0.9845783  0.9930121  0.9809638  0.99373496
 0.97927713 0.9807229  0.9891566  0.97590363 0.9891566  0.9838554
 0.9766265  0.97903615 0.9766265  0.9855422  0.993494  ]
2022-01-18 20:37:53,318 - INFO - Saving...
2022-01-18 20:37:53,569 - INFO - Epoch time: 393.3276083469391
2022-01-18 20:37:53,570 - INFO - 
Epoch: 32
2022-01-18 20:37:53,570 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:38:09,531 - INFO - [Step=26750]	Loss=0.9225	256.4 examples/second
2022-01-18 20:40:04,077 - INFO - [Step=27000]	Loss=0.9041	279.4 examples/second
2022-01-18 20:41:58,242 - INFO - [Step=27250]	Loss=0.8924	280.3 examples/second
2022-01-18 20:43:52,355 - INFO - [Step=27500]	Loss=0.8768	280.4 examples/second
2022-01-18 20:44:25,110 - INFO - Test Loss=0.8836, Test top-1 acc=0.7872
2022-01-18 20:44:25,110 - INFO - Group Accuracy:

2022-01-18 20:44:25,110 - INFO - [0.9775904  0.99036145 0.9848193  0.9930121  0.9819277  0.99421686
 0.97951806 0.9814458  0.9891566  0.9739759  0.9886747  0.9838554
 0.97566265 0.97831327 0.9737349  0.98722893 0.993253  ]
2022-01-18 20:44:25,111 - INFO - Epoch time: 391.5417249202728
2022-01-18 20:44:25,111 - INFO - 
Epoch: 33
2022-01-18 20:44:25,111 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:45:57,191 - INFO - [Step=27750]	Loss=0.8684	256.3 examples/second
2022-01-18 20:47:52,598 - INFO - [Step=28000]	Loss=0.8637	277.3 examples/second
2022-01-18 20:49:48,017 - INFO - [Step=28250]	Loss=0.8936	277.3 examples/second
2022-01-18 20:50:59,799 - INFO - Test Loss=0.8670, Test top-1 acc=0.7896
2022-01-18 20:50:59,799 - INFO - Group Accuracy:

2022-01-18 20:50:59,799 - INFO - [0.9787952  0.99084336 0.9848193  0.9920482  0.98240966 0.99421686
 0.9773494  0.98289156 0.9891566  0.97614455 0.9881928  0.98313254
 0.9768675  0.9785542  0.9746988  0.9879518  0.99373496]
2022-01-18 20:50:59,800 - INFO - Saving...
2022-01-18 20:50:59,984 - INFO - Epoch time: 394.8724048137665
2022-01-18 20:50:59,984 - INFO - 
Epoch: 34
2022-01-18 20:50:59,984 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:51:52,354 - INFO - [Step=28500]	Loss=0.8672	257.4 examples/second
2022-01-18 20:53:46,439 - INFO - [Step=28750]	Loss=0.8728	280.5 examples/second
2022-01-18 20:55:40,658 - INFO - [Step=29000]	Loss=0.8598	280.2 examples/second
2022-01-18 20:57:30,809 - INFO - Test Loss=0.8637, Test top-1 acc=0.7928
2022-01-18 20:57:30,809 - INFO - Group Accuracy:

2022-01-18 20:57:30,810 - INFO - [0.97951806 0.99060243 0.98289156 0.9920482  0.9821687  0.9946988
 0.98024094 0.9826506  0.98963857 0.97518075 0.99060243 0.9860241
 0.9768675  0.97831327 0.97518075 0.98746985 0.993494  ]
2022-01-18 20:57:30,810 - INFO - Saving...
2022-01-18 20:57:31,015 - INFO - Epoch time: 391.030592918396
2022-01-18 20:57:31,015 - INFO - 
Epoch: 35
2022-01-18 20:57:31,015 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:57:44,592 - INFO - [Step=29250]	Loss=0.8532	258.2 examples/second
2022-01-18 20:59:38,935 - INFO - [Step=29500]	Loss=0.8332	279.9 examples/second
2022-01-18 21:01:33,271 - INFO - [Step=29750]	Loss=0.8264	279.9 examples/second
2022-01-18 21:03:27,636 - INFO - [Step=30000]	Loss=0.8452	279.8 examples/second
2022-01-18 21:04:02,627 - INFO - Test Loss=0.8581, Test top-1 acc=0.7904
2022-01-18 21:04:02,628 - INFO - Group Accuracy:

2022-01-18 21:04:02,628 - INFO - [0.98024094 0.99060243 0.9840964  0.9925301  0.98289156 0.99421686
 0.98024094 0.9821687  0.9898795  0.97493976 0.9884337  0.9845783
 0.97566265 0.98024094 0.9773494  0.98771083 0.99445784]
2022-01-18 21:04:02,629 - INFO - Epoch time: 391.61405634880066
2022-01-18 21:04:02,629 - INFO - 
Epoch: 36
2022-01-18 21:04:02,629 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:05:31,827 - INFO - [Step=30250]	Loss=0.8295	257.7 examples/second
2022-01-18 21:07:26,035 - INFO - [Step=30500]	Loss=0.8328	280.2 examples/second
2022-01-18 21:09:20,263 - INFO - [Step=30750]	Loss=0.8412	280.1 examples/second
2022-01-18 21:10:34,057 - INFO - Test Loss=0.8526, Test top-1 acc=0.7935
2022-01-18 21:10:34,057 - INFO - Group Accuracy:

2022-01-18 21:10:34,057 - INFO - [0.9809638  0.99084336 0.98361444 0.9927711  0.9812048  0.9939759
 0.9804819  0.98289156 0.9891566  0.97518075 0.9889157  0.9850602
 0.9768675  0.97927713 0.9766265  0.98698795 0.9930121 ]
2022-01-18 21:10:34,058 - INFO - Saving...
2022-01-18 21:10:34,315 - INFO - Epoch time: 391.68649673461914
2022-01-18 21:10:34,316 - INFO - 
Epoch: 37
2022-01-18 21:10:34,316 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:11:24,396 - INFO - [Step=31000]	Loss=0.8170	257.8 examples/second
2022-01-18 21:13:18,728 - INFO - [Step=31250]	Loss=0.7952	279.9 examples/second
2022-01-18 21:15:13,122 - INFO - [Step=31500]	Loss=0.8288	279.7 examples/second
2022-01-18 21:17:05,854 - INFO - Test Loss=0.8466, Test top-1 acc=0.7969
2022-01-18 21:17:05,855 - INFO - Group Accuracy:

2022-01-18 21:17:05,855 - INFO - [0.97927713 0.99156624 0.9840964  0.993494   0.9838554  0.99421686
 0.9819277  0.98361444 0.9893976  0.97614455 0.9884337  0.9848193
 0.9771084  0.9785542  0.97638553 0.98771083 0.9930121 ]
2022-01-18 21:17:05,856 - INFO - Saving...
2022-01-18 21:17:06,128 - INFO - Epoch time: 391.81228160858154
2022-01-18 21:17:06,128 - INFO - 
Epoch: 38
2022-01-18 21:17:06,128 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:17:17,536 - INFO - [Step=31750]	Loss=0.8118	257.2 examples/second
2022-01-18 21:19:12,287 - INFO - [Step=32000]	Loss=0.8045	278.9 examples/second
2022-01-18 21:21:06,802 - INFO - [Step=32250]	Loss=0.8086	279.4 examples/second
2022-01-18 21:23:01,301 - INFO - [Step=32500]	Loss=0.7970	279.5 examples/second
2022-01-18 21:23:38,303 - INFO - Test Loss=0.8472, Test top-1 acc=0.7935
2022-01-18 21:23:38,303 - INFO - Group Accuracy:

2022-01-18 21:23:38,303 - INFO - [0.9787952  0.99036145 0.98240966 0.9925301  0.9816868  0.9939759
 0.98       0.9833735  0.9898795  0.97590363 0.9891566  0.98433733
 0.9773494  0.97927713 0.97590363 0.98771083 0.9927711 ]
2022-01-18 21:23:38,304 - INFO - Epoch time: 392.1756520271301
2022-01-18 21:23:38,304 - INFO - 
Epoch: 39
2022-01-18 21:23:38,304 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:25:05,046 - INFO - [Step=32750]	Loss=0.7971	258.6 examples/second
2022-01-18 21:26:59,482 - INFO - [Step=33000]	Loss=0.7970	279.6 examples/second
2022-01-18 21:28:53,614 - INFO - [Step=33250]	Loss=0.8052	280.4 examples/second
2022-01-18 21:30:09,673 - INFO - Test Loss=0.8371, Test top-1 acc=0.7928
2022-01-18 21:30:09,674 - INFO - Group Accuracy:

2022-01-18 21:30:09,674 - INFO - [0.97951806 0.99108434 0.98361444 0.9930121  0.98313254 0.9939759
 0.9787952  0.9838554  0.9891566  0.97638553 0.99156624 0.98650604
 0.97301203 0.97903615 0.97542167 0.98746985 0.99493974]
2022-01-18 21:30:09,675 - INFO - Epoch time: 391.37130975723267
2022-01-18 21:30:09,675 - INFO - 
Epoch: 40
2022-01-18 21:30:09,675 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:30:57,489 - INFO - [Step=33500]	Loss=0.7844	258.3 examples/second
2022-01-18 21:32:51,995 - INFO - [Step=33750]	Loss=0.7784	279.5 examples/second
2022-01-18 21:34:46,631 - INFO - [Step=34000]	Loss=0.7844	279.1 examples/second
2022-01-18 21:36:42,361 - INFO - Test Loss=0.8408, Test top-1 acc=0.7973
2022-01-18 21:36:42,361 - INFO - Group Accuracy:

2022-01-18 21:36:42,361 - INFO - [0.97975904 0.99036145 0.98313254 0.99156624 0.9838554  0.99421686
 0.9816868  0.9826506  0.9898795  0.97614455 0.98963857 0.9853012
 0.97590363 0.9804819  0.97518075 0.98722893 0.99493974]
2022-01-18 21:36:42,362 - INFO - Saving...
2022-01-18 21:36:42,592 - INFO - Epoch time: 392.9161288738251
2022-01-18 21:36:42,592 - INFO - 
Epoch: 41
2022-01-18 21:36:42,592 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:36:51,217 - INFO - [Step=34250]	Loss=0.7888	256.9 examples/second
2022-01-18 21:38:46,137 - INFO - [Step=34500]	Loss=0.7787	278.5 examples/second
2022-01-18 21:40:41,256 - INFO - [Step=34750]	Loss=0.7788	278.0 examples/second
2022-01-18 21:42:36,020 - INFO - [Step=35000]	Loss=0.7733	278.8 examples/second
2022-01-18 21:43:15,374 - INFO - Test Loss=0.8537, Test top-1 acc=0.7942
2022-01-18 21:43:15,374 - INFO - Group Accuracy:

2022-01-18 21:43:15,374 - INFO - [0.9787952  0.9913253  0.9833735  0.993253   0.9814458  0.99445784
 0.98024094 0.98240966 0.9893976  0.9766265  0.9879518  0.9855422
 0.97493976 0.97975904 0.97542167 0.9881928  0.99373496]
2022-01-18 21:43:15,375 - INFO - Epoch time: 392.78322768211365
2022-01-18 21:43:15,375 - INFO - 
Epoch: 42
2022-01-18 21:43:15,375 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:44:41,583 - INFO - [Step=35250]	Loss=0.7632	254.9 examples/second
2022-01-18 21:46:38,593 - INFO - [Step=35500]	Loss=0.7631	273.5 examples/second
2022-01-18 21:48:35,417 - INFO - [Step=35750]	Loss=0.7680	273.9 examples/second
2022-01-18 21:49:55,253 - INFO - Test Loss=0.8775, Test top-1 acc=0.7923
2022-01-18 21:49:55,253 - INFO - Group Accuracy:

2022-01-18 21:49:55,253 - INFO - [0.98       0.9913253  0.98289156 0.993253   0.9814458  0.99421686
 0.98       0.9814458  0.9884337  0.97590363 0.98626506 0.9848193
 0.97614455 0.97975904 0.97638553 0.98674697 0.99373496]
2022-01-18 21:49:55,254 - INFO - Epoch time: 399.878874540329
2022-01-18 21:49:55,254 - INFO - 
Epoch: 43
2022-01-18 21:49:55,254 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:50:41,763 - INFO - [Step=36000]	Loss=0.7598	253.3 examples/second
2022-01-18 21:52:37,833 - INFO - [Step=36250]	Loss=0.7501	275.7 examples/second
2022-01-18 21:54:34,092 - INFO - [Step=36500]	Loss=0.7541	275.2 examples/second
2022-01-18 21:56:33,017 - INFO - Test Loss=0.8492, Test top-1 acc=0.7971
2022-01-18 21:56:33,017 - INFO - Group Accuracy:

2022-01-18 21:56:33,017 - INFO - [0.97951806 0.99036145 0.9816868  0.9927711  0.9821687  0.99421686
 0.97975904 0.9833735  0.9893976  0.97614455 0.99060243 0.9838554
 0.97831327 0.98       0.9780723  0.98771083 0.9939759 ]
2022-01-18 21:56:33,018 - INFO - Epoch time: 397.76373171806335
2022-01-18 21:56:33,018 - INFO - 
Epoch: 44
2022-01-18 21:56:33,018 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:56:39,732 - INFO - [Step=36750]	Loss=0.7561	254.7 examples/second
2022-01-18 21:58:36,218 - INFO - [Step=37000]	Loss=0.7440	274.7 examples/second
2022-01-18 22:00:33,243 - INFO - [Step=37250]	Loss=0.7420	273.4 examples/second
2022-01-18 22:02:30,293 - INFO - [Step=37500]	Loss=0.7625	273.4 examples/second
2022-01-18 22:03:12,778 - INFO - Test Loss=0.8465, Test top-1 acc=0.7940
2022-01-18 22:03:12,778 - INFO - Group Accuracy:

2022-01-18 22:03:12,778 - INFO - [0.98       0.99108434 0.98313254 0.99373496 0.98289156 0.993494
 0.9809638  0.98240966 0.9893976  0.9771084  0.9879518  0.9845783
 0.97518075 0.9787952  0.97590363 0.98674697 0.99493974]
2022-01-18 22:03:12,780 - INFO - Epoch time: 399.7620816230774
2022-01-18 22:03:12,780 - INFO - 
Epoch: 45
2022-01-18 22:03:12,780 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:04:35,658 - INFO - [Step=37750]	Loss=0.7437	255.3 examples/second
2022-01-18 22:06:31,972 - INFO - [Step=38000]	Loss=0.7444	275.1 examples/second
2022-01-18 22:08:27,773 - INFO - [Step=38250]	Loss=0.7444	276.3 examples/second
2022-01-18 22:09:49,461 - INFO - Test Loss=0.8363, Test top-1 acc=0.7966
2022-01-18 22:09:49,461 - INFO - Group Accuracy:

2022-01-18 22:09:49,461 - INFO - [0.97975904 0.98963857 0.98313254 0.9925301  0.9838554  0.99373496
 0.9804819  0.98361444 0.9889157  0.97590363 0.9891566  0.9848193
 0.97542167 0.9807229  0.9771084  0.98650604 0.99493974]
2022-01-18 22:09:49,462 - INFO - Epoch time: 396.6821074485779
2022-01-18 22:09:49,462 - INFO - 
Epoch: 46
2022-01-18 22:09:49,462 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:10:33,270 - INFO - [Step=38500]	Loss=0.7388	255.0 examples/second
2022-01-18 22:12:29,653 - INFO - [Step=38750]	Loss=0.7188	275.0 examples/second
2022-01-18 22:14:26,111 - INFO - [Step=39000]	Loss=0.7446	274.8 examples/second
2022-01-18 22:16:27,452 - INFO - Test Loss=0.8478, Test top-1 acc=0.7964
2022-01-18 22:16:27,453 - INFO - Group Accuracy:

2022-01-18 22:16:27,462 - INFO - [0.9809638  0.99156624 0.9840964  0.9927711  0.98289156 0.99445784
 0.97975904 0.98313254 0.9901205  0.9746988  0.9889157  0.9860241
 0.97614455 0.97951806 0.97614455 0.9881928  0.9946988 ]
2022-01-18 22:16:27,463 - INFO - Epoch time: 398.00091648101807
2022-01-18 22:16:27,463 - INFO - 
Epoch: 47
2022-01-18 22:16:27,463 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:16:31,613 - INFO - [Step=39250]	Loss=0.7606	255.0 examples/second
2022-01-18 22:18:28,025 - INFO - [Step=39500]	Loss=0.7030	274.9 examples/second
2022-01-18 22:20:24,276 - INFO - [Step=39750]	Loss=0.7293	275.3 examples/second
2022-01-18 22:22:20,478 - INFO - [Step=40000]	Loss=0.7378	275.4 examples/second
2022-01-18 22:23:04,772 - INFO - Test Loss=0.8710, Test top-1 acc=0.7940
2022-01-18 22:23:04,772 - INFO - Group Accuracy:

2022-01-18 22:23:04,782 - INFO - [0.97975904 0.99036145 0.98289156 0.9927711  0.9826506  0.993494
 0.98024094 0.9819277  0.9901205  0.9771084  0.9886747  0.9853012
 0.9766265  0.97542167 0.9778313  0.98746985 0.9951807 ]
2022-01-18 22:23:04,783 - INFO - Epoch time: 397.3193824291229
2022-01-18 22:23:04,783 - INFO - 
Epoch: 48
2022-01-18 22:23:04,783 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:24:24,689 - INFO - [Step=40250]	Loss=0.7145	257.6 examples/second
2022-01-18 22:26:19,664 - INFO - [Step=40500]	Loss=0.7290	278.3 examples/second
2022-01-18 22:28:14,437 - INFO - [Step=40750]	Loss=0.7282	278.8 examples/second
2022-01-18 22:29:37,487 - INFO - Test Loss=0.8439, Test top-1 acc=0.7940
2022-01-18 22:29:37,487 - INFO - Group Accuracy:

2022-01-18 22:29:37,488 - INFO - [0.98024094 0.99036145 0.9850602  0.99373496 0.98240966 0.993494
 0.97831327 0.9838554  0.98963857 0.9746988  0.98963857 0.98433733
 0.97542167 0.97927713 0.97566265 0.98698795 0.99421686]
2022-01-18 22:29:37,489 - INFO - Epoch time: 392.7058506011963
2022-01-18 22:29:37,489 - INFO - 
Epoch: 49
2022-01-18 22:29:37,489 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:30:18,621 - INFO - [Step=41000]	Loss=0.7349	257.7 examples/second
2022-01-18 22:32:14,306 - INFO - [Step=41250]	Loss=0.6990	276.6 examples/second
2022-01-18 22:34:09,959 - INFO - [Step=41500]	Loss=0.7150	276.7 examples/second
2022-01-18 22:36:05,600 - INFO - [Step=41750]	Loss=0.7336	276.7 examples/second
2022-01-18 22:36:12,798 - INFO - Test Loss=0.8582, Test top-1 acc=0.7937
2022-01-18 22:36:12,799 - INFO - Group Accuracy:

2022-01-18 22:36:12,799 - INFO - [0.98       0.9922892  0.98289156 0.9918072  0.9848193  0.9939759
 0.9785542  0.9809638  0.9898795  0.97542167 0.9913253  0.9855422
 0.97614455 0.9821687  0.9778313  0.9879518  0.99421686]
2022-01-18 22:36:12,800 - INFO - Epoch time: 395.31092166900635
2022-01-18 22:36:12,800 - INFO - 
Epoch: 50
2022-01-18 22:36:12,800 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:38:10,528 - INFO - [Step=42000]	Loss=0.7081	256.1 examples/second
2022-01-18 22:40:06,180 - INFO - [Step=42250]	Loss=0.7084	276.7 examples/second
2022-01-18 22:42:01,636 - INFO - [Step=42500]	Loss=0.7168	277.2 examples/second
2022-01-18 22:42:48,472 - INFO - Test Loss=0.8463, Test top-1 acc=0.7961
2022-01-18 22:42:48,472 - INFO - Group Accuracy:

2022-01-18 22:42:48,472 - INFO - [0.9787952  0.99084336 0.98313254 0.99373496 0.9814458  0.993253
 0.9809638  0.9814458  0.9891566  0.97590363 0.9879518  0.98361444
 0.97638553 0.9804819  0.9785542  0.98746985 0.9961446 ]
2022-01-18 22:42:48,473 - INFO - Epoch time: 395.67347979545593
2022-01-18 22:42:48,473 - INFO - 
Epoch: 51
2022-01-18 22:42:48,473 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:44:06,071 - INFO - [Step=42750]	Loss=0.6996	257.2 examples/second
2022-01-18 22:46:00,724 - INFO - [Step=43000]	Loss=0.6949	279.1 examples/second
2022-01-18 22:47:55,339 - INFO - [Step=43250]	Loss=0.7224	279.2 examples/second
2022-01-18 22:49:20,503 - INFO - Test Loss=0.8748, Test top-1 acc=0.8002
2022-01-18 22:49:20,503 - INFO - Group Accuracy:

2022-01-18 22:49:20,503 - INFO - [0.9785542  0.9918072  0.98313254 0.9927711  0.98289156 0.99421686
 0.9826506  0.9819277  0.98963857 0.97566265 0.99084336 0.9826506
 0.9768675  0.98       0.97542167 0.98771083 0.99373496]
2022-01-18 22:49:20,504 - INFO - Saving...
2022-01-18 22:49:20,730 - INFO - Epoch time: 392.2570538520813
2022-01-18 22:49:20,731 - INFO - 
Epoch: 52
2022-01-18 22:49:20,731 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:49:59,379 - INFO - [Step=43500]	Loss=0.7248	258.0 examples/second
2022-01-18 22:51:53,710 - INFO - [Step=43750]	Loss=0.6829	279.9 examples/second
2022-01-18 22:53:48,306 - INFO - [Step=44000]	Loss=0.6920	279.2 examples/second
2022-01-18 22:55:42,701 - INFO - [Step=44250]	Loss=0.7027	279.7 examples/second
2022-01-18 22:55:52,410 - INFO - Test Loss=0.8691, Test top-1 acc=0.7973
2022-01-18 22:55:52,410 - INFO - Group Accuracy:

2022-01-18 22:55:52,410 - INFO - [0.98       0.9918072  0.9816868  0.9927711  0.9838554  0.9939759
 0.97975904 0.9840964  0.9901205  0.9766265  0.9913253  0.9840964
 0.97614455 0.97903615 0.9773494  0.98722893 0.993494  ]
2022-01-18 22:55:52,411 - INFO - Epoch time: 391.680118560791
2022-01-18 22:55:52,411 - INFO - 
Epoch: 53
2022-01-18 22:55:52,411 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:57:46,810 - INFO - [Step=44500]	Loss=0.6833	257.8 examples/second
2022-01-18 22:59:41,232 - INFO - [Step=44750]	Loss=0.6987	279.7 examples/second
2022-01-18 23:01:35,839 - INFO - [Step=45000]	Loss=0.7047	279.2 examples/second
2022-01-18 23:02:24,382 - INFO - Test Loss=0.8422, Test top-1 acc=0.7993
2022-01-18 23:02:24,382 - INFO - Group Accuracy:

2022-01-18 23:02:24,382 - INFO - [0.98024094 0.99060243 0.98578316 0.993253   0.9848193  0.993494
 0.9780723  0.9816868  0.99108434 0.9727711  0.9913253  0.9853012
 0.9785542  0.9807229  0.9766265  0.98626506 0.9946988 ]
2022-01-18 23:02:24,383 - INFO - Epoch time: 391.97241497039795
2022-01-18 23:02:24,383 - INFO - 
Epoch: 54
2022-01-18 23:02:24,383 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:03:39,990 - INFO - [Step=45250]	Loss=0.6953	257.8 examples/second
2022-01-18 23:05:34,797 - INFO - [Step=45500]	Loss=0.6684	278.7 examples/second
2022-01-18 23:07:29,458 - INFO - [Step=45750]	Loss=0.6957	279.1 examples/second
2022-01-18 23:08:56,925 - INFO - Test Loss=0.8474, Test top-1 acc=0.7983
2022-01-18 23:08:56,926 - INFO - Group Accuracy:

2022-01-18 23:08:56,926 - INFO - [0.9819277  0.9893976  0.98361444 0.9927711  0.9814458  0.9939759
 0.9804819  0.9819277  0.9886747  0.9766265  0.9891566  0.9848193
 0.9768675  0.98       0.97518075 0.9886747  0.9946988 ]
2022-01-18 23:08:56,926 - INFO - Epoch time: 392.5431909561157
2022-01-18 23:08:56,926 - INFO - 
Epoch: 55
2022-01-18 23:08:56,926 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:09:33,451 - INFO - [Step=46000]	Loss=0.7066	258.1 examples/second
2022-01-18 23:11:27,895 - INFO - [Step=46250]	Loss=0.6726	279.6 examples/second
2022-01-18 23:13:22,652 - INFO - [Step=46500]	Loss=0.6749	278.9 examples/second
2022-01-18 23:15:16,951 - INFO - [Step=46750]	Loss=0.6920	280.0 examples/second
2022-01-18 23:15:29,138 - INFO - Test Loss=0.8759, Test top-1 acc=0.7889
2022-01-18 23:15:29,138 - INFO - Group Accuracy:

2022-01-18 23:15:29,138 - INFO - [0.98       0.9893976  0.98313254 0.9920482  0.9807229  0.993494
 0.97903615 0.9826506  0.9898795  0.97493976 0.9893976  0.9840964
 0.9746988  0.97951806 0.97445786 0.9891566  0.99445784]
2022-01-18 23:15:29,139 - INFO - Epoch time: 392.2127161026001
2022-01-18 23:15:29,139 - INFO - 
Epoch: 56
2022-01-18 23:15:29,139 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:17:21,170 - INFO - [Step=47000]	Loss=0.6599	257.6 examples/second
2022-01-18 23:19:15,651 - INFO - [Step=47250]	Loss=0.6772	279.5 examples/second
2022-01-18 23:21:10,011 - INFO - [Step=47500]	Loss=0.6814	279.8 examples/second
2022-01-18 23:22:00,854 - INFO - Test Loss=0.8752, Test top-1 acc=0.7966
2022-01-18 23:22:00,854 - INFO - Group Accuracy:

2022-01-18 23:22:00,854 - INFO - [0.9816868  0.99108434 0.9838554  0.993494   0.9833735  0.9930121
 0.98       0.9787952  0.99084336 0.9742169  0.9901205  0.98578316
 0.97638553 0.9807229  0.9742169  0.98698795 0.9946988 ]
2022-01-18 23:22:00,855 - INFO - Epoch time: 391.7155680656433
2022-01-18 23:22:00,855 - INFO - 
Epoch: 57
2022-01-18 23:22:00,855 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:23:14,563 - INFO - [Step=47750]	Loss=0.6720	256.9 examples/second
2022-01-18 23:25:10,368 - INFO - [Step=48000]	Loss=0.6743	276.3 examples/second
2022-01-18 23:27:05,928 - INFO - [Step=48250]	Loss=0.6693	276.9 examples/second
2022-01-18 23:28:36,598 - INFO - Test Loss=0.8550, Test top-1 acc=0.7920
2022-01-18 23:28:36,598 - INFO - Group Accuracy:

2022-01-18 23:28:36,598 - INFO - [0.9780723  0.99036145 0.9838554  0.9922892  0.98313254 0.9927711
 0.9807229  0.9807229  0.9879518  0.9737349  0.9901205  0.98313254
 0.9773494  0.98024094 0.97566265 0.9889157  0.9951807 ]
2022-01-18 23:28:36,600 - INFO - Epoch time: 395.7447772026062
2022-01-18 23:28:36,600 - INFO - 
Epoch: 58
2022-01-18 23:28:36,600 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:29:10,668 - INFO - [Step=48500]	Loss=0.6755	256.5 examples/second
2022-01-18 23:31:05,390 - INFO - [Step=48750]	Loss=0.6544	278.9 examples/second
2022-01-18 23:32:59,811 - INFO - [Step=49000]	Loss=0.6695	279.7 examples/second
2022-01-18 23:34:54,229 - INFO - [Step=49250]	Loss=0.6790	279.7 examples/second
2022-01-18 23:35:08,645 - INFO - Test Loss=0.8833, Test top-1 acc=0.7918
2022-01-18 23:35:08,645 - INFO - Group Accuracy:

2022-01-18 23:35:08,645 - INFO - [0.98024094 0.9879518  0.9833735  0.9920482  0.9814458  0.99373496
 0.9807229  0.9807229  0.9891566  0.9742169  0.9889157  0.9833735
 0.9768675  0.9814458  0.97590363 0.98722893 0.99493974]
2022-01-18 23:35:08,647 - INFO - Epoch time: 392.0469138622284
2022-01-18 23:35:08,647 - INFO - 
Epoch: 59
2022-01-18 23:35:08,647 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:36:58,595 - INFO - [Step=49500]	Loss=0.6283	257.3 examples/second
2022-01-18 23:38:53,458 - INFO - [Step=49750]	Loss=0.5977	278.6 examples/second
2022-01-18 23:40:48,367 - INFO - [Step=50000]	Loss=0.5771	278.5 examples/second
2022-01-18 23:41:41,697 - INFO - Test Loss=0.7912, Test top-1 acc=0.8067
2022-01-18 23:41:41,697 - INFO - Group Accuracy:

2022-01-18 23:41:41,698 - INFO - [0.9814458  0.99084336 0.98626506 0.9925301  0.9853012  0.99445784
 0.9821687  0.9838554  0.9901205  0.9766265  0.9898795  0.9848193
 0.9773494  0.9821687  0.9766265  0.9898795  0.99493974]
2022-01-18 23:41:41,698 - INFO - Saving...
2022-01-18 23:41:41,959 - INFO - Epoch time: 393.3117814064026
2022-01-18 23:41:41,959 - INFO - 
Epoch: 60
2022-01-18 23:41:41,959 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:42:53,139 - INFO - [Step=50250]	Loss=0.5774	256.5 examples/second
2022-01-18 23:44:47,778 - INFO - [Step=50500]	Loss=0.5839	279.1 examples/second
2022-01-18 23:46:42,342 - INFO - [Step=50750]	Loss=0.5784	279.3 examples/second
2022-01-18 23:48:14,785 - INFO - Test Loss=0.7879, Test top-1 acc=0.8070
2022-01-18 23:48:14,785 - INFO - Group Accuracy:

2022-01-18 23:48:14,785 - INFO - [0.9809638  0.9913253  0.98578316 0.993253   0.98361444 0.9939759
 0.98240966 0.98313254 0.98963857 0.9766265  0.99036145 0.9850602
 0.9785542  0.9821687  0.9780723  0.98963857 0.99493974]
2022-01-18 23:48:14,786 - INFO - Saving...
2022-01-18 23:48:15,051 - INFO - Epoch time: 393.09174609184265
2022-01-18 23:48:15,051 - INFO - 
Epoch: 61
2022-01-18 23:48:15,051 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:48:46,979 - INFO - [Step=51000]	Loss=0.5652	256.7 examples/second
2022-01-18 23:50:42,697 - INFO - [Step=51250]	Loss=0.5542	276.5 examples/second
2022-01-18 23:52:38,119 - INFO - [Step=51500]	Loss=0.5615	277.2 examples/second
2022-01-18 23:54:33,587 - INFO - [Step=51750]	Loss=0.5680	277.1 examples/second
2022-01-18 23:54:50,222 - INFO - Test Loss=0.7775, Test top-1 acc=0.8087
2022-01-18 23:54:50,223 - INFO - Group Accuracy:

2022-01-18 23:54:50,232 - INFO - [0.9814458  0.9930121  0.98626506 0.9925301  0.98433733 0.99445784
 0.9833735  0.98289156 0.9901205  0.97638553 0.99084336 0.9855422
 0.9780723  0.9819277  0.9773494  0.9898795  0.9951807 ]
2022-01-18 23:54:50,233 - INFO - Saving...
2022-01-18 23:54:50,484 - INFO - Epoch time: 395.43289065361023
2022-01-18 23:54:50,484 - INFO - 
Epoch: 62
2022-01-18 23:54:50,484 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:56:37,642 - INFO - [Step=52000]	Loss=0.5668	258.0 examples/second
2022-01-18 23:58:32,112 - INFO - [Step=52250]	Loss=0.5595	279.6 examples/second
2022-01-19 00:00:26,474 - INFO - [Step=52500]	Loss=0.5499	279.8 examples/second
2022-01-19 00:01:21,975 - INFO - Test Loss=0.7759, Test top-1 acc=0.8096
2022-01-19 00:01:21,975 - INFO - Group Accuracy:

2022-01-19 00:01:21,975 - INFO - [0.9819277  0.9927711  0.9855422  0.993253   0.9845783  0.9946988
 0.98361444 0.98361444 0.9898795  0.97542167 0.9913253  0.98578316
 0.9787952  0.98240966 0.9773494  0.9898795  0.99493974]
2022-01-19 00:01:21,976 - INFO - Saving...
2022-01-19 00:01:22,234 - INFO - Epoch time: 391.7499508857727
2022-01-19 00:01:22,234 - INFO - 
Epoch: 63
2022-01-19 00:01:22,234 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:02:30,808 - INFO - [Step=52750]	Loss=0.5552	257.4 examples/second
2022-01-19 00:04:25,996 - INFO - [Step=53000]	Loss=0.5526	277.8 examples/second
2022-01-19 00:06:21,215 - INFO - [Step=53250]	Loss=0.5439	277.7 examples/second
2022-01-19 00:07:56,069 - INFO - Test Loss=0.7782, Test top-1 acc=0.8058
2022-01-19 00:07:56,069 - INFO - Group Accuracy:

2022-01-19 00:07:56,069 - INFO - [0.9807229  0.9925301  0.9850602  0.993253   0.9840964  0.99373496
 0.9819277  0.9826506  0.98963857 0.97566265 0.9913253  0.9853012
 0.97951806 0.98289156 0.97638553 0.9898795  0.9951807 ]
2022-01-19 00:07:56,070 - INFO - Epoch time: 393.8356387615204
2022-01-19 00:07:56,070 - INFO - 
Epoch: 64
2022-01-19 00:07:56,070 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:08:25,470 - INFO - [Step=53500]	Loss=0.5444	257.5 examples/second
2022-01-19 00:10:20,322 - INFO - [Step=53750]	Loss=0.5517	278.6 examples/second
2022-01-19 00:12:15,034 - INFO - [Step=54000]	Loss=0.5378	279.0 examples/second
2022-01-19 00:14:09,457 - INFO - [Step=54250]	Loss=0.5554	279.7 examples/second
2022-01-19 00:14:28,722 - INFO - Test Loss=0.7800, Test top-1 acc=0.8072
2022-01-19 00:14:28,722 - INFO - Group Accuracy:

2022-01-19 00:14:28,722 - INFO - [0.9812048  0.9925301  0.9848193  0.9930121  0.9855422  0.99421686
 0.9821687  0.98289156 0.98963857 0.9766265  0.99036145 0.98578316
 0.9787952  0.9816868  0.9785542  0.9898795  0.99493974]
2022-01-19 00:14:28,724 - INFO - Epoch time: 392.6537322998047
2022-01-19 00:14:28,724 - INFO - 
Epoch: 65
2022-01-19 00:14:28,724 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:16:13,681 - INFO - [Step=54500]	Loss=0.5362	257.6 examples/second
2022-01-19 00:18:08,175 - INFO - [Step=54750]	Loss=0.5379	279.5 examples/second
2022-01-19 00:20:02,667 - INFO - [Step=55000]	Loss=0.5489	279.5 examples/second
2022-01-19 00:21:00,564 - INFO - Test Loss=0.7774, Test top-1 acc=0.8092
2022-01-19 00:21:00,565 - INFO - Group Accuracy:

2022-01-19 00:21:00,565 - INFO - [0.9821687  0.9920482  0.98722893 0.9930121  0.9853012  0.99445784
 0.9821687  0.98313254 0.9891566  0.9768675  0.99108434 0.9853012
 0.9775904  0.9821687  0.9780723  0.9898795  0.9951807 ]
2022-01-19 00:21:00,566 - INFO - Epoch time: 391.84220838546753
2022-01-19 00:21:00,566 - INFO - 
Epoch: 66
2022-01-19 00:21:00,566 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:22:06,769 - INFO - [Step=55250]	Loss=0.5354	257.9 examples/second
2022-01-19 00:24:01,807 - INFO - [Step=55500]	Loss=0.5433	278.2 examples/second
2022-01-19 00:25:58,607 - INFO - [Step=55750]	Loss=0.5410	274.0 examples/second
2022-01-19 00:27:36,367 - INFO - Test Loss=0.7842, Test top-1 acc=0.8070
2022-01-19 00:27:36,368 - INFO - Group Accuracy:

2022-01-19 00:27:36,368 - INFO - [0.9814458  0.9927711  0.98722893 0.9925301  0.9848193  0.99493974
 0.9826506  0.9821687  0.98963857 0.9766265  0.99060243 0.98433733
 0.9785542  0.98289156 0.9773494  0.9889157  0.9946988 ]
2022-01-19 00:27:36,368 - INFO - Epoch time: 395.8024311065674
2022-01-19 00:27:36,368 - INFO - 
Epoch: 67
2022-01-19 00:27:36,369 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:28:03,963 - INFO - [Step=56000]	Loss=0.5390	255.3 examples/second
2022-01-19 00:29:58,531 - INFO - [Step=56250]	Loss=0.5229	279.3 examples/second
2022-01-19 00:31:52,858 - INFO - [Step=56500]	Loss=0.5386	279.9 examples/second
2022-01-19 00:33:47,115 - INFO - [Step=56750]	Loss=0.5266	280.1 examples/second
2022-01-19 00:34:08,486 - INFO - Test Loss=0.7754, Test top-1 acc=0.8111
2022-01-19 00:34:08,486 - INFO - Group Accuracy:

2022-01-19 00:34:08,486 - INFO - [0.9807229  0.9925301  0.98698795 0.9930121  0.9848193  0.99445784
 0.98240966 0.9826506  0.9893976  0.9766265  0.9913253  0.9850602
 0.9778313  0.9833735  0.9785542  0.9898795  0.9951807 ]
2022-01-19 00:34:08,487 - INFO - Saving...
2022-01-19 00:34:08,676 - INFO - Epoch time: 392.30721974372864
2022-01-19 00:34:08,676 - INFO - 
Epoch: 68
2022-01-19 00:34:08,676 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:35:51,878 - INFO - [Step=57000]	Loss=0.5392	256.5 examples/second
2022-01-19 00:37:47,443 - INFO - [Step=57250]	Loss=0.5342	276.9 examples/second
2022-01-19 00:39:42,574 - INFO - [Step=57500]	Loss=0.5299	277.9 examples/second
2022-01-19 00:40:42,737 - INFO - Test Loss=0.7828, Test top-1 acc=0.8072
2022-01-19 00:40:42,737 - INFO - Group Accuracy:

2022-01-19 00:40:42,737 - INFO - [0.9804819  0.9925301  0.9853012  0.9927711  0.9860241  0.99445784
 0.9833735  0.98313254 0.9891566  0.97638553 0.9920482  0.9853012
 0.9778313  0.9819277  0.9773494  0.9891566  0.9954217 ]
2022-01-19 00:40:42,738 - INFO - Epoch time: 394.06180715560913
2022-01-19 00:40:42,738 - INFO - 
Epoch: 69
2022-01-19 00:40:42,738 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:41:47,033 - INFO - [Step=57750]	Loss=0.5456	257.1 examples/second
2022-01-19 00:43:41,855 - INFO - [Step=58000]	Loss=0.5324	278.7 examples/second
2022-01-19 00:45:36,401 - INFO - [Step=58250]	Loss=0.5344	279.4 examples/second
2022-01-19 00:47:15,869 - INFO - Test Loss=0.7772, Test top-1 acc=0.8070
2022-01-19 00:47:15,869 - INFO - Group Accuracy:

2022-01-19 00:47:15,869 - INFO - [0.9809638  0.9920482  0.9860241  0.993253   0.9845783  0.99445784
 0.98240966 0.98313254 0.9893976  0.97614455 0.99084336 0.9850602
 0.9787952  0.9819277  0.9778313  0.9893976  0.9951807 ]
2022-01-19 00:47:15,870 - INFO - Epoch time: 393.1322295665741
2022-01-19 00:47:15,870 - INFO - 
Epoch: 70
2022-01-19 00:47:15,870 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:47:40,755 - INFO - [Step=58500]	Loss=0.5208	257.3 examples/second
2022-01-19 00:49:35,347 - INFO - [Step=58750]	Loss=0.5236	279.3 examples/second
2022-01-19 00:51:29,628 - INFO - [Step=59000]	Loss=0.5208	280.0 examples/second
2022-01-19 00:53:23,939 - INFO - [Step=59250]	Loss=0.5304	279.9 examples/second
2022-01-19 00:53:47,012 - INFO - Test Loss=0.7848, Test top-1 acc=0.8101
2022-01-19 00:53:47,013 - INFO - Group Accuracy:

2022-01-19 00:53:47,013 - INFO - [0.9809638  0.9927711  0.9860241  0.9930121  0.98674697 0.99445784
 0.98313254 0.98313254 0.98963857 0.9766265  0.99108434 0.98433733
 0.9785542  0.9819277  0.9773494  0.9898795  0.99493974]
2022-01-19 00:53:47,014 - INFO - Epoch time: 391.14343643188477
2022-01-19 00:53:47,014 - INFO - 
Epoch: 71
2022-01-19 00:53:47,014 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:55:28,351 - INFO - [Step=59500]	Loss=0.5262	257.2 examples/second
2022-01-19 00:57:23,997 - INFO - [Step=59750]	Loss=0.5218	276.7 examples/second
2022-01-19 00:59:19,687 - INFO - [Step=60000]	Loss=0.5221	276.6 examples/second
2022-01-19 01:00:22,738 - INFO - Test Loss=0.7771, Test top-1 acc=0.8125
2022-01-19 01:00:22,738 - INFO - Group Accuracy:

2022-01-19 01:00:22,738 - INFO - [0.9814458  0.9925301  0.98650604 0.9922892  0.9848193  0.99445784
 0.98313254 0.98361444 0.9893976  0.9771084  0.9918072  0.9848193
 0.97903615 0.9814458  0.9775904  0.98963857 0.9951807 ]
2022-01-19 01:00:22,739 - INFO - Saving...
2022-01-19 01:00:22,926 - INFO - Epoch time: 395.91188192367554
2022-01-19 01:00:22,926 - INFO - 
Epoch: 72
2022-01-19 01:00:22,926 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:01:24,870 - INFO - [Step=60250]	Loss=0.5202	255.6 examples/second
2022-01-19 01:03:20,605 - INFO - [Step=60500]	Loss=0.5263	276.5 examples/second
2022-01-19 01:05:16,407 - INFO - [Step=60750]	Loss=0.5223	276.3 examples/second
2022-01-19 01:06:58,622 - INFO - Test Loss=0.7844, Test top-1 acc=0.8092
2022-01-19 01:06:58,622 - INFO - Group Accuracy:

2022-01-19 01:06:58,622 - INFO - [0.9812048  0.9925301  0.9853012  0.9930121  0.98626506 0.99445784
 0.9819277  0.9833735  0.9893976  0.9768675  0.99036145 0.98578316
 0.9780723  0.98313254 0.9768675  0.98963857 0.9946988 ]
2022-01-19 01:06:58,623 - INFO - Epoch time: 395.6975383758545
2022-01-19 01:06:58,623 - INFO - 
Epoch: 73
2022-01-19 01:06:58,623 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:07:21,782 - INFO - [Step=61000]	Loss=0.5306	255.2 examples/second
2022-01-19 01:09:16,198 - INFO - [Step=61250]	Loss=0.5140	279.7 examples/second
2022-01-19 01:11:10,820 - INFO - [Step=61500]	Loss=0.5254	279.2 examples/second
2022-01-19 01:13:05,562 - INFO - [Step=61750]	Loss=0.5190	278.9 examples/second
2022-01-19 01:13:30,924 - INFO - Test Loss=0.7868, Test top-1 acc=0.8082
2022-01-19 01:13:30,924 - INFO - Group Accuracy:

2022-01-19 01:13:30,924 - INFO - [0.9821687  0.9920482  0.9860241  0.99373496 0.9855422  0.9946988
 0.9814458  0.98313254 0.9898795  0.9768675  0.99108434 0.9845783
 0.9785542  0.98289156 0.9775904  0.9891566  0.99493974]
2022-01-19 01:13:30,925 - INFO - Epoch time: 392.30149698257446
2022-01-19 01:13:30,925 - INFO - 
Epoch: 74
2022-01-19 01:13:30,925 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:15:09,671 - INFO - [Step=62000]	Loss=0.5286	257.8 examples/second
2022-01-19 01:17:05,514 - INFO - [Step=62250]	Loss=0.5082	276.2 examples/second
2022-01-19 01:19:01,293 - INFO - [Step=62500]	Loss=0.5139	276.4 examples/second
2022-01-19 01:20:06,444 - INFO - Test Loss=0.7921, Test top-1 acc=0.8055
2022-01-19 01:20:06,445 - INFO - Group Accuracy:

2022-01-19 01:20:06,445 - INFO - [0.9819277  0.9925301  0.98578316 0.993494   0.98578316 0.9939759
 0.9816868  0.98289156 0.9893976  0.97542167 0.99108434 0.9853012
 0.97831327 0.9814458  0.9768675  0.9891566  0.9951807 ]
2022-01-19 01:20:06,446 - INFO - Epoch time: 395.5208921432495
2022-01-19 01:20:06,446 - INFO - 
Epoch: 75
2022-01-19 01:20:06,446 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:21:05,675 - INFO - [Step=62750]	Loss=0.5171	257.3 examples/second
2022-01-19 01:23:00,055 - INFO - [Step=63000]	Loss=0.5141	279.8 examples/second
2022-01-19 01:24:54,445 - INFO - [Step=63250]	Loss=0.5298	279.7 examples/second
2022-01-19 01:26:37,643 - INFO - Test Loss=0.7874, Test top-1 acc=0.8087
2022-01-19 01:26:37,644 - INFO - Group Accuracy:

2022-01-19 01:26:37,644 - INFO - [0.9814458  0.9930121  0.98578316 0.993494   0.9853012  0.99421686
 0.9819277  0.9833735  0.9891566  0.9766265  0.9920482  0.9840964
 0.9775904  0.98240966 0.9778313  0.98963857 0.9961446 ]
2022-01-19 01:26:37,645 - INFO - Epoch time: 391.19921350479126
2022-01-19 01:26:37,645 - INFO - 
Epoch: 76
2022-01-19 01:26:37,645 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:26:57,983 - INFO - [Step=63500]	Loss=0.5191	259.0 examples/second
2022-01-19 01:28:52,699 - INFO - [Step=63750]	Loss=0.5077	279.0 examples/second
2022-01-19 01:30:47,317 - INFO - [Step=64000]	Loss=0.5224	279.2 examples/second
2022-01-19 01:32:41,992 - INFO - [Step=64250]	Loss=0.5012	279.1 examples/second
2022-01-19 01:33:09,609 - INFO - Test Loss=0.7890, Test top-1 acc=0.8072
2022-01-19 01:33:09,609 - INFO - Group Accuracy:

2022-01-19 01:33:09,609 - INFO - [0.9807229  0.9920482  0.9853012  0.993494   0.98626506 0.9939759
 0.9816868  0.9838554  0.9893976  0.97590363 0.9913253  0.9848193
 0.97903615 0.98289156 0.9775904  0.9893976  0.99493974]
2022-01-19 01:33:09,610 - INFO - Epoch time: 391.9646461009979
2022-01-19 01:33:09,610 - INFO - 
Epoch: 77
2022-01-19 01:33:09,610 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:34:46,038 - INFO - [Step=64500]	Loss=0.5062	258.0 examples/second
2022-01-19 01:36:41,537 - INFO - [Step=64750]	Loss=0.5183	277.1 examples/second
2022-01-19 01:38:36,635 - INFO - [Step=65000]	Loss=0.4931	278.0 examples/second
2022-01-19 01:39:44,149 - INFO - Test Loss=0.7915, Test top-1 acc=0.8082
2022-01-19 01:39:44,150 - INFO - Group Accuracy:

2022-01-19 01:39:44,150 - INFO - [0.9816868  0.9927711  0.9853012  0.99373496 0.9855422  0.99493974
 0.9819277  0.9838554  0.9898795  0.9766265  0.9918072  0.9848193
 0.9785542  0.9819277  0.9780723  0.9893976  0.9946988 ]
2022-01-19 01:39:44,151 - INFO - Epoch time: 394.54070019721985
2022-01-19 01:39:44,151 - INFO - 
Epoch: 78
2022-01-19 01:39:44,151 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:40:41,400 - INFO - [Step=65250]	Loss=0.5033	256.5 examples/second
2022-01-19 01:42:36,432 - INFO - [Step=65500]	Loss=0.5196	278.2 examples/second
2022-01-19 01:44:31,078 - INFO - [Step=65750]	Loss=0.5005	279.1 examples/second
2022-01-19 01:46:17,547 - INFO - Test Loss=0.7991, Test top-1 acc=0.8070
2022-01-19 01:46:17,548 - INFO - Group Accuracy:

2022-01-19 01:46:17,548 - INFO - [0.98       0.9927711  0.9848193  0.993494   0.9848193  0.99445784
 0.9819277  0.98433733 0.9898795  0.97566265 0.9913253  0.9855422
 0.9780723  0.98240966 0.9778313  0.9889157  0.9951807 ]
2022-01-19 01:46:17,549 - INFO - Epoch time: 393.3977518081665
2022-01-19 01:46:17,549 - INFO - 
Epoch: 79
2022-01-19 01:46:17,549 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:46:35,448 - INFO - [Step=66000]	Loss=0.5115	257.3 examples/second
2022-01-19 01:48:29,876 - INFO - [Step=66250]	Loss=0.4948	279.7 examples/second
2022-01-19 01:50:24,570 - INFO - [Step=66500]	Loss=0.5063	279.0 examples/second
2022-01-19 01:52:19,423 - INFO - [Step=66750]	Loss=0.5111	278.6 examples/second
2022-01-19 01:52:49,447 - INFO - Test Loss=0.8046, Test top-1 acc=0.8106
2022-01-19 01:52:49,447 - INFO - Group Accuracy:

2022-01-19 01:52:49,447 - INFO - [0.9809638  0.993253   0.9848193  0.9930121  0.9840964  0.99445784
 0.9819277  0.9833735  0.98963857 0.9775904  0.99156624 0.9853012
 0.9787952  0.98240966 0.97831327 0.9893976  0.9954217 ]
2022-01-19 01:52:49,448 - INFO - Epoch time: 391.89942955970764
2022-01-19 01:52:49,448 - INFO - 
Epoch: 80
2022-01-19 01:52:49,448 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:54:24,370 - INFO - [Step=67000]	Loss=0.5038	256.1 examples/second
2022-01-19 01:56:20,210 - INFO - [Step=67250]	Loss=0.4995	276.2 examples/second
2022-01-19 01:58:16,016 - INFO - [Step=67500]	Loss=0.4949	276.3 examples/second
2022-01-19 01:59:25,808 - INFO - Test Loss=0.7946, Test top-1 acc=0.8092
2022-01-19 01:59:25,809 - INFO - Group Accuracy:

2022-01-19 01:59:25,809 - INFO - [0.9816868  0.9927711  0.9855422  0.9939759  0.9848193  0.99445784
 0.98313254 0.98313254 0.9893976  0.9768675  0.99084336 0.98433733
 0.97831327 0.98313254 0.9778313  0.9893976  0.9951807 ]
2022-01-19 01:59:25,810 - INFO - Epoch time: 396.3614454269409
2022-01-19 01:59:25,810 - INFO - 
Epoch: 81
2022-01-19 01:59:25,810 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:00:20,922 - INFO - [Step=67750]	Loss=0.5048	256.2 examples/second
2022-01-19 02:02:16,411 - INFO - [Step=68000]	Loss=0.5000	277.1 examples/second
2022-01-19 02:04:11,727 - INFO - [Step=68250]	Loss=0.4962	277.5 examples/second
2022-01-19 02:06:00,535 - INFO - Test Loss=0.7989, Test top-1 acc=0.8104
2022-01-19 02:06:00,535 - INFO - Group Accuracy:

2022-01-19 02:06:00,535 - INFO - [0.9814458  0.9922892  0.9855422  0.99373496 0.98433733 0.99421686
 0.9814458  0.98289156 0.9901205  0.9766265  0.9918072  0.9845783
 0.97975904 0.9816868  0.9787952  0.9891566  0.9959036 ]
2022-01-19 02:06:00,536 - INFO - Epoch time: 394.7263517379761
2022-01-19 02:06:00,536 - INFO - 
Epoch: 82
2022-01-19 02:06:00,536 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:06:16,449 - INFO - [Step=68500]	Loss=0.5014	256.6 examples/second
2022-01-19 02:08:10,630 - INFO - [Step=68750]	Loss=0.4992	280.3 examples/second
2022-01-19 02:10:05,165 - INFO - [Step=69000]	Loss=0.4985	279.4 examples/second
2022-01-19 02:11:59,686 - INFO - [Step=69250]	Loss=0.4943	279.4 examples/second
2022-01-19 02:12:32,346 - INFO - Test Loss=0.7871, Test top-1 acc=0.8118
2022-01-19 02:12:32,346 - INFO - Group Accuracy:

2022-01-19 02:12:32,346 - INFO - [0.9812048  0.99373496 0.9848193  0.99373496 0.9855422  0.9946988
 0.9819277  0.9840964  0.9891566  0.9766265  0.99156624 0.9853012
 0.9787952  0.98240966 0.9780723  0.9898795  0.99493974]
2022-01-19 02:12:32,347 - INFO - Epoch time: 391.81092286109924
2022-01-19 02:12:32,347 - INFO - 
Epoch: 83
2022-01-19 02:12:32,347 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:14:03,650 - INFO - [Step=69500]	Loss=0.4858	258.1 examples/second
2022-01-19 02:15:58,265 - INFO - [Step=69750]	Loss=0.5041	279.2 examples/second
2022-01-19 02:17:52,645 - INFO - [Step=70000]	Loss=0.4963	279.8 examples/second
2022-01-19 02:19:04,337 - INFO - Test Loss=0.8006, Test top-1 acc=0.8089
2022-01-19 02:19:04,337 - INFO - Group Accuracy:

2022-01-19 02:19:04,338 - INFO - [0.9814458  0.993253   0.9848193  0.99373496 0.9838554  0.99421686
 0.98240966 0.98361444 0.98963857 0.97614455 0.99156624 0.98578316
 0.9780723  0.9814458  0.9768675  0.98963857 0.99445784]
2022-01-19 02:19:04,338 - INFO - Epoch time: 391.99124026298523
2022-01-19 02:19:04,338 - INFO - 
Epoch: 84
2022-01-19 02:19:04,338 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:19:56,630 - INFO - [Step=70250]	Loss=0.4975	258.1 examples/second
2022-01-19 02:21:51,099 - INFO - [Step=70500]	Loss=0.4997	279.6 examples/second
2022-01-19 02:23:45,381 - INFO - [Step=70750]	Loss=0.5012	280.0 examples/second
2022-01-19 02:25:35,224 - INFO - Test Loss=0.7969, Test top-1 acc=0.8084
2022-01-19 02:25:35,225 - INFO - Group Accuracy:

2022-01-19 02:25:35,225 - INFO - [0.9804819  0.9930121  0.9850602  0.9930121  0.9853012  0.99445784
 0.9814458  0.9833735  0.9889157  0.9771084  0.99108434 0.98578316
 0.9780723  0.9816868  0.9775904  0.9889157  0.9946988 ]
2022-01-19 02:25:35,226 - INFO - Epoch time: 390.8872957229614
2022-01-19 02:25:35,226 - INFO - 
Epoch: 85
2022-01-19 02:25:35,226 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:25:48,896 - INFO - [Step=71000]	Loss=0.4949	259.1 examples/second
2022-01-19 02:27:44,588 - INFO - [Step=71250]	Loss=0.4879	276.6 examples/second
2022-01-19 02:29:40,100 - INFO - [Step=71500]	Loss=0.4919	277.0 examples/second
2022-01-19 02:31:35,788 - INFO - [Step=71750]	Loss=0.4894	276.6 examples/second
2022-01-19 02:32:11,392 - INFO - Test Loss=0.8124, Test top-1 acc=0.8101
2022-01-19 02:32:11,392 - INFO - Group Accuracy:

2022-01-19 02:32:11,392 - INFO - [0.9816868  0.9920482  0.98578316 0.99373496 0.9853012  0.9946988
 0.9814458  0.9838554  0.9893976  0.9746988  0.9920482  0.9850602
 0.97831327 0.9812048  0.97831327 0.9889157  0.9946988 ]
2022-01-19 02:32:11,393 - INFO - Epoch time: 396.1676323413849
2022-01-19 02:32:11,393 - INFO - 
Epoch: 86
2022-01-19 02:32:11,393 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:33:40,554 - INFO - [Step=72000]	Loss=0.5061	256.5 examples/second
2022-01-19 02:35:35,526 - INFO - [Step=72250]	Loss=0.4922	278.3 examples/second
2022-01-19 02:37:30,434 - INFO - [Step=72500]	Loss=0.4917	278.5 examples/second
2022-01-19 02:38:44,966 - INFO - Test Loss=0.8030, Test top-1 acc=0.8084
2022-01-19 02:38:44,966 - INFO - Group Accuracy:

2022-01-19 02:38:44,966 - INFO - [0.9807229  0.9927711  0.98578316 0.99373496 0.98433733 0.9946988
 0.9816868  0.98313254 0.9891566  0.9768675  0.9920482  0.9850602
 0.97903615 0.98240966 0.9773494  0.9891566  0.9946988 ]
2022-01-19 02:38:44,966 - INFO - Epoch time: 393.57304644584656
2022-01-19 02:38:44,967 - INFO - 
Epoch: 87
2022-01-19 02:38:44,967 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:39:34,967 - INFO - [Step=72750]	Loss=0.4939	257.0 examples/second
2022-01-19 02:41:29,323 - INFO - [Step=73000]	Loss=0.4938	279.8 examples/second
2022-01-19 02:43:23,849 - INFO - [Step=73250]	Loss=0.4869	279.4 examples/second
2022-01-19 02:45:16,571 - INFO - Test Loss=0.8050, Test top-1 acc=0.8099
2022-01-19 02:45:16,572 - INFO - Group Accuracy:

2022-01-19 02:45:16,572 - INFO - [0.9819277  0.9920482  0.98578316 0.9930121  0.9853012  0.99421686
 0.9814458  0.9821687  0.9891566  0.9766265  0.9925301  0.9860241
 0.9775904  0.9821687  0.9778313  0.9898795  0.99445784]
2022-01-19 02:45:16,573 - INFO - Epoch time: 391.6065626144409
2022-01-19 02:45:16,573 - INFO - 
Epoch: 88
2022-01-19 02:45:16,573 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:45:27,840 - INFO - [Step=73500]	Loss=0.4993	258.1 examples/second
2022-01-19 02:47:23,148 - INFO - [Step=73750]	Loss=0.4966	277.5 examples/second
2022-01-19 02:49:18,782 - INFO - [Step=74000]	Loss=0.4908	276.7 examples/second
2022-01-19 02:51:13,937 - INFO - [Step=74250]	Loss=0.4909	277.9 examples/second
2022-01-19 02:51:51,163 - INFO - Test Loss=0.8145, Test top-1 acc=0.8063
2022-01-19 02:51:51,163 - INFO - Group Accuracy:

2022-01-19 02:51:51,163 - INFO - [0.9814458  0.9925301  0.9855422  0.99373496 0.9850602  0.99373496
 0.9819277  0.9821687  0.9898795  0.9768675  0.99084336 0.9853012
 0.9778313  0.9816868  0.97831327 0.9891566  0.9951807 ]
2022-01-19 02:51:51,164 - INFO - Epoch time: 394.59039068222046
2022-01-19 02:51:51,164 - INFO - 
Epoch: 89
2022-01-19 02:51:51,164 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:53:18,632 - INFO - [Step=74500]	Loss=0.4914	256.6 examples/second
2022-01-19 02:55:14,144 - INFO - [Step=74750]	Loss=0.4930	277.0 examples/second
2022-01-19 02:57:09,447 - INFO - [Step=75000]	Loss=0.4786	277.5 examples/second
2022-01-19 02:58:25,650 - INFO - Test Loss=0.8305, Test top-1 acc=0.8089
2022-01-19 02:58:25,651 - INFO - Group Accuracy:

2022-01-19 02:58:25,651 - INFO - [0.9816868  0.993253   0.9853012  0.993494   0.9848193  0.9939759
 0.9812048  0.9826506  0.9898795  0.97638553 0.99060243 0.9850602
 0.9775904  0.9814458  0.97831327 0.9891566  0.9939759 ]
2022-01-19 02:58:25,651 - INFO - Epoch time: 394.4877738952637
2022-01-19 02:58:35,280 - INFO - Computing OOD Statistics...
2022-01-19 02:58:35,292 - INFO - 	Baseline.          AUROC: 0.3626. TNR@95TPR: 0.0247. AUPR OUT: 0.1293
2022-01-19 02:58:35,297 - INFO - 	ODIN (T=1000).     AUROC: 0.8910. TNR@95TPR: 0.4647. AUPR OUT: 0.6183
2022-01-19 02:58:35,297 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 02:58:35,297 - INFO - Top 1 Accuracy:  Min: 0.8125; Max: 0.8125; Avg: 0.8125; Std: 0.0000; Len: 1
2022-01-19 02:58:35,297 - INFO - Top 5 Accuracy:  Min: 0.9862; Max: 0.9862; Avg: 0.9862; Std: 0.0000; Len: 1
2022-01-19 02:58:35,297 - INFO - **********************************************************************
2022-01-19 02:58:35,298 - INFO - 	MSP (auroc): [0.362608929836995] Min: 0.3626; Max: 0.3626; Avg: 0.3626; Std: 0.0000; Len: 1
2022-01-19 02:58:35,298 - INFO - 	MSP (tnr): [0.024705882352941133] Min: 0.0247; Max: 0.0247; Avg: 0.0247; Std: 0.0000; Len: 1
2022-01-19 02:58:35,298 - INFO - 	MSP (aupr): [0.1292962340994715] Min: 0.1293; Max: 0.1293; Avg: 0.1293; Std: 0.0000; Len: 1
2022-01-19 02:58:35,298 - INFO - 	ODIN (auroc): [0.8910284904323176] Min: 0.8910; Max: 0.8910; Avg: 0.8910; Std: 0.0000; Len: 1
2022-01-19 02:58:35,298 - INFO - 	ODIN (tnr): [0.4647058823529412] Min: 0.4647; Max: 0.4647; Avg: 0.4647; Std: 0.0000; Len: 1
2022-01-19 02:58:35,298 - INFO - 	ODIN (aupr): [0.618329976073459] Min: 0.6183; Max: 0.6183; Avg: 0.6183; Std: 0.0000; Len: 1

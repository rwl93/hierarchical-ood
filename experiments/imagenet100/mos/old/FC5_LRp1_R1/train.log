2022-01-18 16:54:31,028 - INFO - ==> Preparing data..
2022-01-18 16:54:31,394 - INFO - checkpoint filename: experiments/coarse/mos/FC5_LRp1_R1/checkpoint.pt
2022-01-18 16:54:31,394 - INFO - log filename: experiments/coarse/mos/FC5_LRp1_R1/train.log
2022-01-18 16:54:31,394 - INFO - ********************************************************
2022-01-18 16:54:31,394 - INFO - Starting Iter: 0 / 1
2022-01-18 16:54:31,394 - INFO - ********************************************************
2022-01-18 16:54:34,496 - INFO - cuda
2022-01-18 16:54:34,551 - INFO - 
Epoch: 0
2022-01-18 16:54:34,551 - INFO - 
Learning Rate: 0.0100
2022-01-18 16:56:32,167 - INFO - [Step=250]	Loss=7.3042	272.1 examples/second
2022-01-18 16:58:26,940 - INFO - [Step=500]	Loss=5.4043	278.8 examples/second
2022-01-18 17:00:22,074 - INFO - [Step=750]	Loss=5.2030	277.9 examples/second
2022-01-18 17:01:08,355 - INFO - Test Loss=5.1400, Test top-1 acc=0.0675
2022-01-18 17:01:08,356 - INFO - Group Accuracy:

2022-01-18 17:01:08,356 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9460241]
2022-01-18 17:01:08,356 - INFO - Saving...
2022-01-18 17:01:08,577 - INFO - Epoch time: 394.0260531902313
2022-01-18 17:01:08,577 - INFO - 
Epoch: 1
2022-01-18 17:01:08,577 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:02:26,317 - INFO - [Step=1000]	Loss=5.0458	257.6 examples/second
2022-01-18 17:04:21,526 - INFO - [Step=1250]	Loss=4.8719	277.8 examples/second
2022-01-18 17:06:16,726 - INFO - [Step=1500]	Loss=4.7228	277.8 examples/second
2022-01-18 17:07:42,285 - INFO - Test Loss=4.5593, Test top-1 acc=0.1687
2022-01-18 17:07:42,285 - INFO - Group Accuracy:

2022-01-18 17:07:42,285 - INFO - [0.939759   0.94120485 0.939759   0.9445783  0.939759   0.9438554
 0.939759   0.939759   0.9392771  0.939759   0.9518072  0.939759
 0.939759   0.939759   0.94       0.939759   0.9549398 ]
2022-01-18 17:07:42,286 - INFO - Saving...
2022-01-18 17:07:42,541 - INFO - Epoch time: 393.9640619754791
2022-01-18 17:07:42,542 - INFO - 
Epoch: 2
2022-01-18 17:07:42,542 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:08:22,020 - INFO - [Step=1750]	Loss=4.5998	255.4 examples/second
2022-01-18 17:10:18,127 - INFO - [Step=2000]	Loss=4.4815	275.6 examples/second
2022-01-18 17:12:14,608 - INFO - [Step=2250]	Loss=4.3039	274.7 examples/second
2022-01-18 17:14:09,876 - INFO - [Step=2500]	Loss=4.1770	277.6 examples/second
2022-01-18 17:14:19,389 - INFO - Test Loss=4.6323, Test top-1 acc=0.2390
2022-01-18 17:14:19,389 - INFO - Group Accuracy:

2022-01-18 17:14:19,389 - INFO - [0.9404819  0.94289154 0.94       0.9520482  0.94096386 0.95349395
 0.940241   0.9448193  0.9440964  0.939759   0.95421684 0.940241
 0.939759   0.939759   0.939759   0.939759   0.9559036 ]
2022-01-18 17:14:19,390 - INFO - Saving...
2022-01-18 17:14:19,663 - INFO - Epoch time: 397.1212751865387
2022-01-18 17:14:19,663 - INFO - 
Epoch: 3
2022-01-18 17:14:19,663 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:16:14,357 - INFO - [Step=2750]	Loss=4.1206	257.1 examples/second
2022-01-18 17:18:09,622 - INFO - [Step=3000]	Loss=3.9563	277.6 examples/second
2022-01-18 17:20:05,078 - INFO - [Step=3250]	Loss=3.8146	277.2 examples/second
2022-01-18 17:20:53,866 - INFO - Test Loss=3.6383, Test top-1 acc=0.3130
2022-01-18 17:20:53,866 - INFO - Group Accuracy:

2022-01-18 17:20:53,866 - INFO - [0.9426506  0.946506   0.94289154 0.96096385 0.94168675 0.96168673
 0.9445783  0.946506   0.94626504 0.94289154 0.95325303 0.94144577
 0.94120485 0.9404819  0.94240963 0.94506025 0.96      ]
2022-01-18 17:20:53,867 - INFO - Saving...
2022-01-18 17:20:54,104 - INFO - Epoch time: 394.440890789032
2022-01-18 17:20:54,104 - INFO - 
Epoch: 4
2022-01-18 17:20:54,104 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:22:10,112 - INFO - [Step=3500]	Loss=3.7591	255.9 examples/second
2022-01-18 17:24:05,948 - INFO - [Step=3750]	Loss=3.6568	276.3 examples/second
2022-01-18 17:26:01,854 - INFO - [Step=4000]	Loss=3.5207	276.1 examples/second
2022-01-18 17:27:30,185 - INFO - Test Loss=3.2425, Test top-1 acc=0.3448
2022-01-18 17:27:30,186 - INFO - Group Accuracy:

2022-01-18 17:27:30,186 - INFO - [0.9431325  0.9481928  0.94216865 0.9583132  0.9426506  0.96433735
 0.946506   0.9508434  0.9592771  0.9440964  0.95301205 0.94433737
 0.939759   0.94168675 0.94433737 0.94963855 0.96457833]
2022-01-18 17:27:30,186 - INFO - Saving...
2022-01-18 17:27:30,429 - INFO - Epoch time: 396.3243103027344
2022-01-18 17:27:30,429 - INFO - 
Epoch: 5
2022-01-18 17:27:30,429 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:28:07,047 - INFO - [Step=4250]	Loss=3.3910	255.6 examples/second
2022-01-18 17:30:03,066 - INFO - [Step=4500]	Loss=3.2887	275.8 examples/second
2022-01-18 17:31:58,902 - INFO - [Step=4750]	Loss=3.1900	276.3 examples/second
2022-01-18 17:33:54,709 - INFO - [Step=5000]	Loss=3.1111	276.3 examples/second
2022-01-18 17:34:06,628 - INFO - Test Loss=3.0468, Test top-1 acc=0.3843
2022-01-18 17:34:06,628 - INFO - Group Accuracy:

2022-01-18 17:34:06,628 - INFO - [0.9472289  0.9559036  0.94240963 0.9626506  0.94096386 0.9653012
 0.9448193  0.9539759  0.9595181  0.946747   0.95301205 0.946506
 0.9407229  0.9438554  0.9373494  0.9479518  0.9703615 ]
2022-01-18 17:34:06,629 - INFO - Saving...
2022-01-18 17:34:06,818 - INFO - Epoch time: 396.38872623443604
2022-01-18 17:34:06,818 - INFO - 
Epoch: 6
2022-01-18 17:34:06,818 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:35:59,899 - INFO - [Step=5250]	Loss=3.0266	255.6 examples/second
2022-01-18 17:37:55,186 - INFO - [Step=5500]	Loss=2.9419	277.6 examples/second
2022-01-18 17:39:50,438 - INFO - [Step=5750]	Loss=2.8886	277.7 examples/second
2022-01-18 17:40:41,308 - INFO - Test Loss=2.9754, Test top-1 acc=0.3933
2022-01-18 17:40:41,308 - INFO - Group Accuracy:

2022-01-18 17:40:41,309 - INFO - [0.94216865 0.95228916 0.9472289  0.96168673 0.94843376 0.9655422
 0.9498795  0.95373493 0.96481925 0.9433735  0.95662653 0.9498795
 0.94       0.94096386 0.9431325  0.95253015 0.9708434 ]
2022-01-18 17:40:41,310 - INFO - Saving...
2022-01-18 17:40:41,570 - INFO - Epoch time: 394.7517418861389
2022-01-18 17:40:41,570 - INFO - 
Epoch: 7
2022-01-18 17:40:41,570 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:41:55,276 - INFO - [Step=6000]	Loss=2.7927	256.3 examples/second
2022-01-18 17:43:50,754 - INFO - [Step=6250]	Loss=2.7442	277.1 examples/second
2022-01-18 17:45:46,470 - INFO - [Step=6500]	Loss=2.6947	276.5 examples/second
2022-01-18 17:47:16,864 - INFO - Test Loss=2.6248, Test top-1 acc=0.4694
2022-01-18 17:47:16,865 - INFO - Group Accuracy:

2022-01-18 17:47:16,865 - INFO - [0.9518072  0.95566267 0.9520482  0.9727711  0.9477109  0.9778313
 0.9498795  0.9559036  0.97108436 0.9440964  0.96698797 0.95710844
 0.9445783  0.9440964  0.94626504 0.9438554  0.97301203]
2022-01-18 17:47:16,866 - INFO - Saving...
2022-01-18 17:47:17,111 - INFO - Epoch time: 395.5411412715912
2022-01-18 17:47:17,111 - INFO - 
Epoch: 8
2022-01-18 17:47:17,111 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:47:51,239 - INFO - [Step=6750]	Loss=2.6169	256.5 examples/second
2022-01-18 17:49:46,104 - INFO - [Step=7000]	Loss=2.5596	278.6 examples/second
2022-01-18 17:51:41,005 - INFO - [Step=7250]	Loss=2.5336	278.5 examples/second
2022-01-18 17:53:37,372 - INFO - [Step=7500]	Loss=2.4972	275.0 examples/second
2022-01-18 17:53:51,668 - INFO - Test Loss=2.3552, Test top-1 acc=0.5108
2022-01-18 17:53:51,669 - INFO - Group Accuracy:

2022-01-18 17:53:51,669 - INFO - [0.95301205 0.9657831  0.9573494  0.9742169  0.95421684 0.9773494
 0.9554217  0.9621687  0.9701205  0.9515663  0.9633735  0.96024096
 0.9448193  0.9477109  0.9501205  0.9614458  0.97903615]
2022-01-18 17:53:51,670 - INFO - Saving...
2022-01-18 17:53:51,939 - INFO - Epoch time: 394.82813334465027
2022-01-18 17:53:51,939 - INFO - 
Epoch: 9
2022-01-18 17:53:51,940 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:55:43,236 - INFO - [Step=7750]	Loss=2.4151	254.2 examples/second
2022-01-18 17:57:39,602 - INFO - [Step=8000]	Loss=2.4022	275.0 examples/second
2022-01-18 17:59:36,218 - INFO - [Step=8250]	Loss=2.3677	274.4 examples/second
2022-01-18 18:00:30,352 - INFO - Test Loss=2.6178, Test top-1 acc=0.4622
2022-01-18 18:00:30,353 - INFO - Group Accuracy:

2022-01-18 18:00:30,353 - INFO - [0.9518072  0.9561446  0.9498795  0.96385545 0.95253015 0.9739759
 0.95036143 0.9590362  0.96795183 0.95277107 0.96168673 0.9554217
 0.9426506  0.9407229  0.9501205  0.9583132  0.9706024 ]
2022-01-18 18:00:30,354 - INFO - Epoch time: 398.414427280426
2022-01-18 18:00:30,354 - INFO - 
Epoch: 10
2022-01-18 18:00:30,354 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:01:42,154 - INFO - [Step=8500]	Loss=2.3535	254.1 examples/second
2022-01-18 18:03:38,964 - INFO - [Step=8750]	Loss=2.2757	274.0 examples/second
2022-01-18 18:05:35,566 - INFO - [Step=9000]	Loss=2.2572	274.4 examples/second
2022-01-18 18:07:08,930 - INFO - Test Loss=2.3863, Test top-1 acc=0.5217
2022-01-18 18:07:08,931 - INFO - Group Accuracy:

2022-01-18 18:07:08,931 - INFO - [0.95759034 0.9672289  0.95373493 0.9773494  0.95301205 0.97975904
 0.9559036  0.95638555 0.96409637 0.9614458  0.96819276 0.9592771
 0.94144577 0.94843376 0.9518072  0.9614458  0.98024094]
2022-01-18 18:07:08,932 - INFO - Saving...
2022-01-18 18:07:09,196 - INFO - Epoch time: 398.8424291610718
2022-01-18 18:07:09,197 - INFO - 
Epoch: 11
2022-01-18 18:07:09,197 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:07:41,260 - INFO - [Step=9250]	Loss=2.2240	254.6 examples/second
2022-01-18 18:09:37,703 - INFO - [Step=9500]	Loss=2.1985	274.8 examples/second
2022-01-18 18:11:33,834 - INFO - [Step=9750]	Loss=2.1824	275.6 examples/second
2022-01-18 18:13:30,319 - INFO - [Step=10000]	Loss=2.1453	274.7 examples/second
2022-01-18 18:13:46,940 - INFO - Test Loss=2.2958, Test top-1 acc=0.5607
2022-01-18 18:13:46,940 - INFO - Group Accuracy:

2022-01-18 18:13:46,940 - INFO - [0.95759034 0.96385545 0.95373493 0.97927713 0.95759034 0.98313254
 0.9580723  0.96361446 0.9766265  0.96361446 0.9693976  0.9633735
 0.946747   0.9513253  0.9549398  0.9657831  0.98361444]
2022-01-18 18:13:46,941 - INFO - Saving...
2022-01-18 18:13:47,186 - INFO - Epoch time: 397.9895374774933
2022-01-18 18:13:47,186 - INFO - 
Epoch: 12
2022-01-18 18:13:47,186 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:15:36,388 - INFO - [Step=10250]	Loss=2.0871	253.8 examples/second
2022-01-18 18:17:33,106 - INFO - [Step=10500]	Loss=2.0937	274.2 examples/second
2022-01-18 18:19:29,886 - INFO - [Step=10750]	Loss=2.0728	274.0 examples/second
2022-01-18 18:20:26,167 - INFO - Test Loss=2.1918, Test top-1 acc=0.5807
2022-01-18 18:20:26,167 - INFO - Group Accuracy:

2022-01-18 18:20:26,167 - INFO - [0.96433735 0.96795183 0.9633735  0.97590363 0.96361446 0.9812048
 0.95566267 0.96481925 0.97228914 0.96433735 0.97180724 0.9621687
 0.9469879  0.95373493 0.95566267 0.9662651  0.9812048 ]
2022-01-18 18:20:26,169 - INFO - Saving...
2022-01-18 18:20:26,434 - INFO - Epoch time: 399.24763321876526
2022-01-18 18:20:26,434 - INFO - 
Epoch: 13
2022-01-18 18:20:26,434 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:21:36,112 - INFO - [Step=11000]	Loss=2.0514	253.5 examples/second
2022-01-18 18:23:32,733 - INFO - [Step=11250]	Loss=1.9916	274.4 examples/second
2022-01-18 18:25:29,344 - INFO - [Step=11500]	Loss=2.0106	274.4 examples/second
2022-01-18 18:27:05,272 - INFO - Test Loss=2.1930, Test top-1 acc=0.5904
2022-01-18 18:27:05,272 - INFO - Group Accuracy:

2022-01-18 18:27:05,273 - INFO - [0.9628916  0.9742169  0.96481925 0.97301203 0.9626506  0.9814458
 0.96096385 0.966747   0.96843374 0.9633735  0.97493976 0.9660241
 0.95228916 0.9561446  0.9578313  0.96096385 0.9860241 ]
2022-01-18 18:27:05,273 - INFO - Saving...
2022-01-18 18:27:05,548 - INFO - Epoch time: 399.1139485836029
2022-01-18 18:27:05,548 - INFO - 
Epoch: 14
2022-01-18 18:27:05,549 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:27:35,372 - INFO - [Step=11750]	Loss=1.9918	253.9 examples/second
2022-01-18 18:29:31,942 - INFO - [Step=12000]	Loss=1.9569	274.5 examples/second
2022-01-18 18:31:28,472 - INFO - [Step=12250]	Loss=1.9568	274.6 examples/second
2022-01-18 18:33:25,104 - INFO - [Step=12500]	Loss=1.9386	274.4 examples/second
2022-01-18 18:33:44,106 - INFO - Test Loss=2.2210, Test top-1 acc=0.5684
2022-01-18 18:33:44,106 - INFO - Group Accuracy:

2022-01-18 18:33:44,107 - INFO - [0.9595181  0.97180724 0.9624096  0.97542167 0.9583132  0.9860241
 0.9549398  0.9686747  0.9713253  0.96361446 0.97108436 0.95975906
 0.95036143 0.9445783  0.95253015 0.96891564 0.9838554 ]
2022-01-18 18:33:44,107 - INFO - Epoch time: 398.5588011741638
2022-01-18 18:33:44,107 - INFO - 
Epoch: 15
2022-01-18 18:33:44,107 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:35:30,469 - INFO - [Step=12750]	Loss=1.8791	255.3 examples/second
2022-01-18 18:37:26,162 - INFO - [Step=13000]	Loss=1.8924	276.6 examples/second
2022-01-18 18:39:22,139 - INFO - [Step=13250]	Loss=1.8687	275.9 examples/second
2022-01-18 18:40:20,560 - INFO - Test Loss=2.1266, Test top-1 acc=0.5812
2022-01-18 18:40:20,560 - INFO - Group Accuracy:

2022-01-18 18:40:20,560 - INFO - [0.96072286 0.9696385  0.9672289  0.9780723  0.9631325  0.9850602
 0.9587952  0.9696385  0.97831327 0.9633735  0.96795183 0.9708434
 0.9539759  0.9549398  0.9539759  0.95759034 0.9809638 ]
2022-01-18 18:40:20,561 - INFO - Epoch time: 396.45350670814514
2022-01-18 18:40:20,561 - INFO - 
Epoch: 16
2022-01-18 18:40:20,561 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:41:27,607 - INFO - [Step=13500]	Loss=1.8662	255.0 examples/second
2022-01-18 18:43:24,089 - INFO - [Step=13750]	Loss=1.8514	274.7 examples/second
2022-01-18 18:45:20,497 - INFO - [Step=14000]	Loss=1.8485	274.9 examples/second
2022-01-18 18:46:58,280 - INFO - Test Loss=1.8069, Test top-1 acc=0.6186
2022-01-18 18:46:58,281 - INFO - Group Accuracy:

2022-01-18 18:46:58,281 - INFO - [0.9612048  0.973253   0.9691566  0.97951806 0.96819276 0.9850602
 0.9587952  0.96843374 0.97927713 0.9660241  0.9691566  0.9633735
 0.9578313  0.95975906 0.96024096 0.973253   0.98698795]
2022-01-18 18:46:58,282 - INFO - Saving...
2022-01-18 18:46:58,521 - INFO - Epoch time: 397.9597897529602
2022-01-18 18:46:58,521 - INFO - 
Epoch: 17
2022-01-18 18:46:58,521 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:47:25,598 - INFO - [Step=14250]	Loss=1.8056	255.8 examples/second
2022-01-18 18:49:20,717 - INFO - [Step=14500]	Loss=1.8192	278.0 examples/second
2022-01-18 18:51:15,778 - INFO - [Step=14750]	Loss=1.7798	278.1 examples/second
2022-01-18 18:53:11,220 - INFO - [Step=15000]	Loss=1.7750	277.2 examples/second
2022-01-18 18:53:32,146 - INFO - Test Loss=2.4632, Test top-1 acc=0.5716
2022-01-18 18:53:32,146 - INFO - Group Accuracy:

2022-01-18 18:53:32,147 - INFO - [0.95759034 0.9703615  0.92650604 0.9768675  0.96795183 0.98289156
 0.96096385 0.96361446 0.97903615 0.96481925 0.966506   0.966747
 0.95349395 0.9614458  0.95253015 0.96168673 0.98289156]
2022-01-18 18:53:32,147 - INFO - Epoch time: 393.62606620788574
2022-01-18 18:53:32,147 - INFO - 
Epoch: 18
2022-01-18 18:53:32,147 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:55:16,420 - INFO - [Step=15250]	Loss=1.7591	255.6 examples/second
2022-01-18 18:57:13,314 - INFO - [Step=15500]	Loss=1.7513	273.8 examples/second
2022-01-18 18:59:10,287 - INFO - [Step=15750]	Loss=1.7527	273.6 examples/second
2022-01-18 19:00:11,558 - INFO - Test Loss=1.9346, Test top-1 acc=0.6031
2022-01-18 19:00:11,558 - INFO - Group Accuracy:

2022-01-18 19:00:11,558 - INFO - [0.96481925 0.97542167 0.96506023 0.9838554  0.9590362  0.9881928
 0.95662653 0.9693976  0.9713253  0.9614458  0.97180724 0.966747
 0.9583132  0.9587952  0.9592771  0.95686746 0.9850602 ]
2022-01-18 19:00:11,559 - INFO - Epoch time: 399.41215682029724
2022-01-18 19:00:11,559 - INFO - 
Epoch: 19
2022-01-18 19:00:11,559 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:01:16,234 - INFO - [Step=16000]	Loss=1.7297	254.1 examples/second
2022-01-18 19:03:12,596 - INFO - [Step=16250]	Loss=1.7295	275.0 examples/second
2022-01-18 19:05:09,086 - INFO - [Step=16500]	Loss=1.7106	274.7 examples/second
2022-01-18 19:06:49,828 - INFO - Test Loss=1.7765, Test top-1 acc=0.6284
2022-01-18 19:06:49,828 - INFO - Group Accuracy:

2022-01-18 19:06:49,828 - INFO - [0.96481925 0.9787952  0.96385545 0.9804819  0.966747   0.9860241
 0.9626506  0.9626506  0.9773494  0.966506   0.9766265  0.9696385
 0.9554217  0.9554217  0.9583132  0.973253   0.9814458 ]
2022-01-18 19:06:49,829 - INFO - Saving...
2022-01-18 19:06:50,091 - INFO - Epoch time: 398.53105330467224
2022-01-18 19:06:50,091 - INFO - 
Epoch: 20
2022-01-18 19:06:50,091 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:07:15,342 - INFO - [Step=16750]	Loss=1.7085	253.5 examples/second
2022-01-18 19:09:12,027 - INFO - [Step=17000]	Loss=1.6775	274.2 examples/second
2022-01-18 19:11:08,655 - INFO - [Step=17250]	Loss=1.6973	274.4 examples/second
2022-01-18 19:13:05,451 - INFO - [Step=17500]	Loss=1.6951	274.0 examples/second
2022-01-18 19:13:29,058 - INFO - Test Loss=1.6372, Test top-1 acc=0.6371
2022-01-18 19:13:29,059 - INFO - Group Accuracy:

2022-01-18 19:13:29,059 - INFO - [0.97301203 0.9742169  0.96698797 0.98433733 0.9660241  0.98674697
 0.9674699  0.9713253  0.9775904  0.9655422  0.97542167 0.9696385
 0.9551807  0.9590362  0.95686746 0.96891564 0.98626506]
2022-01-18 19:13:29,059 - INFO - Saving...
2022-01-18 19:13:29,250 - INFO - Epoch time: 399.15881395339966
2022-01-18 19:13:29,250 - INFO - 
Epoch: 21
2022-01-18 19:13:29,250 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:15:11,442 - INFO - [Step=17750]	Loss=1.6474	254.0 examples/second
2022-01-18 19:17:07,909 - INFO - [Step=18000]	Loss=1.6636	274.8 examples/second
2022-01-18 19:19:04,419 - INFO - [Step=18250]	Loss=1.6513	274.7 examples/second
2022-01-18 19:20:07,758 - INFO - Test Loss=1.7144, Test top-1 acc=0.6253
2022-01-18 19:20:07,758 - INFO - Group Accuracy:

2022-01-18 19:20:07,758 - INFO - [0.96361446 0.9693976  0.96819276 0.9840964  0.9703615  0.98626506
 0.9653012  0.97108436 0.9706024  0.9655422  0.97180724 0.9693976
 0.9554217  0.95975906 0.9631325  0.973253   0.98626506]
2022-01-18 19:20:07,759 - INFO - Epoch time: 398.50942301750183
2022-01-18 19:20:07,759 - INFO - 
Epoch: 22
2022-01-18 19:20:07,759 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:21:10,043 - INFO - [Step=18500]	Loss=1.6423	254.7 examples/second
2022-01-18 19:23:06,366 - INFO - [Step=18750]	Loss=1.6191	275.1 examples/second
2022-01-18 19:25:02,764 - INFO - [Step=19000]	Loss=1.6433	274.9 examples/second
2022-01-18 19:26:46,003 - INFO - Test Loss=1.7282, Test top-1 acc=0.6255
2022-01-18 19:26:46,003 - INFO - Group Accuracy:

2022-01-18 19:26:46,003 - INFO - [0.9662651  0.97542167 0.96843374 0.9821687  0.96771085 0.98650604
 0.96072286 0.9624096  0.9778313  0.96506023 0.96819276 0.97156626
 0.9626506  0.9544578  0.96433735 0.9672289  0.9889157 ]
2022-01-18 19:26:46,004 - INFO - Epoch time: 398.24483919143677
2022-01-18 19:26:46,004 - INFO - 
Epoch: 23
2022-01-18 19:26:46,004 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:27:08,804 - INFO - [Step=19250]	Loss=1.6268	253.9 examples/second
2022-01-18 19:29:05,073 - INFO - [Step=19500]	Loss=1.5859	275.2 examples/second
2022-01-18 19:31:01,899 - INFO - [Step=19750]	Loss=1.6017	273.9 examples/second
2022-01-18 19:32:58,728 - INFO - [Step=20000]	Loss=1.6011	273.9 examples/second
2022-01-18 19:33:25,046 - INFO - Test Loss=1.7271, Test top-1 acc=0.6253
2022-01-18 19:33:25,047 - INFO - Group Accuracy:

2022-01-18 19:33:25,047 - INFO - [0.96457833 0.9612048  0.9713253  0.98650604 0.9672289  0.9845783
 0.9621687  0.96891564 0.97638553 0.9628916  0.9768675  0.9691566
 0.96096385 0.9583132  0.96048194 0.9727711  0.98674697]
2022-01-18 19:33:25,047 - INFO - Epoch time: 399.0432929992676
2022-01-18 19:33:25,048 - INFO - 
Epoch: 24
2022-01-18 19:33:25,048 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:35:05,050 - INFO - [Step=20250]	Loss=1.5618	253.3 examples/second
2022-01-18 19:37:01,578 - INFO - [Step=20500]	Loss=1.5608	274.6 examples/second
2022-01-18 19:38:58,056 - INFO - [Step=20750]	Loss=1.5870	274.7 examples/second
2022-01-18 19:40:03,726 - INFO - Test Loss=1.7371, Test top-1 acc=0.6405
2022-01-18 19:40:03,727 - INFO - Group Accuracy:

2022-01-18 19:40:03,727 - INFO - [0.9660241  0.97903615 0.96698797 0.9804819  0.96771085 0.9886747
 0.9539759  0.9691566  0.9826506  0.96891564 0.97180724 0.9703615
 0.9587952  0.96024096 0.9506024  0.9713253  0.9879518 ]
2022-01-18 19:40:03,728 - INFO - Saving...
2022-01-18 19:40:03,961 - INFO - Epoch time: 398.91345977783203
2022-01-18 19:40:03,961 - INFO - 
Epoch: 25
2022-01-18 19:40:03,961 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:41:04,208 - INFO - [Step=21000]	Loss=1.5585	253.7 examples/second
2022-01-18 19:43:00,745 - INFO - [Step=21250]	Loss=1.5491	274.6 examples/second
2022-01-18 19:44:57,500 - INFO - [Step=21500]	Loss=1.5777	274.1 examples/second
2022-01-18 19:46:42,877 - INFO - Test Loss=2.0947, Test top-1 acc=0.5846
2022-01-18 19:46:42,877 - INFO - Group Accuracy:

2022-01-18 19:46:42,877 - INFO - [0.9660241  0.97204816 0.9544578  0.9785542  0.9498795  0.9826506
 0.94554216 0.96       0.97614455 0.9515663  0.9746988  0.9614458
 0.9549398  0.95759034 0.9595181  0.9701205  0.98433733]
2022-01-18 19:46:42,879 - INFO - Epoch time: 398.91756987571716
2022-01-18 19:46:42,879 - INFO - 
Epoch: 26
2022-01-18 19:46:42,879 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:47:03,411 - INFO - [Step=21750]	Loss=1.5378	254.1 examples/second
2022-01-18 19:49:00,246 - INFO - [Step=22000]	Loss=1.5374	273.9 examples/second
2022-01-18 19:50:57,029 - INFO - [Step=22250]	Loss=1.5254	274.0 examples/second
2022-01-18 19:52:53,988 - INFO - [Step=22500]	Loss=1.5480	273.6 examples/second
2022-01-18 19:53:22,401 - INFO - Test Loss=1.8702, Test top-1 acc=0.6145
2022-01-18 19:53:22,402 - INFO - Group Accuracy:

2022-01-18 19:53:22,402 - INFO - [0.9657831  0.97228914 0.9686747  0.97566265 0.9628916  0.9855422
 0.9626506  0.966506   0.9804819  0.9660241  0.9727711  0.9706024
 0.9436145  0.95975906 0.9561446  0.9713253  0.9889157 ]
2022-01-18 19:53:22,403 - INFO - Epoch time: 399.52389430999756
2022-01-18 19:53:22,403 - INFO - 
Epoch: 27
2022-01-18 19:53:22,403 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:54:59,882 - INFO - [Step=22750]	Loss=1.4821	254.2 examples/second
2022-01-18 19:56:56,433 - INFO - [Step=23000]	Loss=1.5068	274.6 examples/second
2022-01-18 19:58:53,127 - INFO - [Step=23250]	Loss=1.5094	274.2 examples/second
2022-01-18 20:00:01,742 - INFO - Test Loss=1.7503, Test top-1 acc=0.6340
2022-01-18 20:00:01,742 - INFO - Group Accuracy:

2022-01-18 20:00:01,742 - INFO - [0.96457833 0.9768675  0.9662651  0.9853012  0.9657831  0.98722893
 0.966506   0.97204816 0.97566265 0.96024096 0.973253   0.96698797
 0.95710844 0.9580723  0.9587952  0.96771085 0.9889157 ]
2022-01-18 20:00:01,743 - INFO - Epoch time: 399.34037232398987
2022-01-18 20:00:01,743 - INFO - 
Epoch: 28
2022-01-18 20:00:01,743 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:00:59,712 - INFO - [Step=23500]	Loss=1.5004	252.8 examples/second
2022-01-18 20:02:56,528 - INFO - [Step=23750]	Loss=1.4764	273.9 examples/second
2022-01-18 20:04:53,372 - INFO - [Step=24000]	Loss=1.5085	273.9 examples/second
2022-01-18 20:06:41,238 - INFO - Test Loss=1.6693, Test top-1 acc=0.6492
2022-01-18 20:06:41,238 - INFO - Group Accuracy:

2022-01-18 20:06:41,238 - INFO - [0.9672289  0.9746988  0.9628916  0.9773494  0.9706024  0.9838554
 0.9660241  0.97228914 0.9807229  0.96409637 0.97180724 0.9739759
 0.9578313  0.9624096  0.9621687  0.9696385  0.9889157 ]
2022-01-18 20:06:41,239 - INFO - Saving...
2022-01-18 20:06:41,502 - INFO - Epoch time: 399.7585186958313
2022-01-18 20:06:41,502 - INFO - 
Epoch: 29
2022-01-18 20:06:41,502 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:06:59,601 - INFO - [Step=24250]	Loss=1.4630	253.5 examples/second
2022-01-18 20:08:56,171 - INFO - [Step=24500]	Loss=1.1722	274.5 examples/second
2022-01-18 20:10:52,825 - INFO - [Step=24750]	Loss=1.0966	274.3 examples/second
2022-01-18 20:12:49,450 - INFO - [Step=25000]	Loss=1.0734	274.4 examples/second
2022-01-18 20:13:20,106 - INFO - Test Loss=1.0057, Test top-1 acc=0.7605
2022-01-18 20:13:20,106 - INFO - Group Accuracy:

2022-01-18 20:13:20,107 - INFO - [0.9780723  0.98746985 0.9821687  0.9898795  0.9787952  0.993253
 0.9773494  0.9814458  0.9884337  0.97445786 0.98771083 0.9807229
 0.97156626 0.97590363 0.97156626 0.9838554  0.9918072 ]
2022-01-18 20:13:20,108 - INFO - Saving...
2022-01-18 20:13:20,363 - INFO - Epoch time: 398.8606939315796
2022-01-18 20:13:20,363 - INFO - 
Epoch: 30
2022-01-18 20:13:20,363 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:14:55,470 - INFO - [Step=25250]	Loss=1.0233	253.9 examples/second
2022-01-18 20:16:52,135 - INFO - [Step=25500]	Loss=1.0194	274.3 examples/second
2022-01-18 20:18:48,920 - INFO - [Step=25750]	Loss=1.0087	274.0 examples/second
2022-01-18 20:19:59,237 - INFO - Test Loss=0.9785, Test top-1 acc=0.7716
2022-01-18 20:19:59,238 - INFO - Group Accuracy:

2022-01-18 20:19:59,238 - INFO - [0.9778313  0.9860241  0.9812048  0.99060243 0.9807229  0.9954217
 0.9804819  0.9826506  0.9884337  0.97542167 0.98722893 0.9838554
 0.97228914 0.97638553 0.973253   0.9853012  0.99373496]
2022-01-18 20:19:59,239 - INFO - Saving...
2022-01-18 20:19:59,484 - INFO - Epoch time: 399.12098479270935
2022-01-18 20:19:59,484 - INFO - 
Epoch: 31
2022-01-18 20:19:59,484 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:20:54,925 - INFO - [Step=26000]	Loss=1.0104	254.0 examples/second
2022-01-18 20:22:51,628 - INFO - [Step=26250]	Loss=0.9768	274.2 examples/second
2022-01-18 20:24:48,514 - INFO - [Step=26500]	Loss=0.9839	273.8 examples/second
2022-01-18 20:26:38,754 - INFO - Test Loss=0.9618, Test top-1 acc=0.7706
2022-01-18 20:26:38,755 - INFO - Group Accuracy:

2022-01-18 20:26:38,755 - INFO - [0.9773494  0.9886747  0.9821687  0.99084336 0.9807229  0.9946988
 0.9787952  0.98240966 0.9884337  0.97566265 0.9893976  0.9833735
 0.97180724 0.97638553 0.9737349  0.9855422  0.993253  ]
2022-01-18 20:26:38,755 - INFO - Epoch time: 399.2710621356964
2022-01-18 20:26:38,755 - INFO - 
Epoch: 32
2022-01-18 20:26:38,755 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:26:54,625 - INFO - [Step=26750]	Loss=0.9733	253.7 examples/second
2022-01-18 20:28:50,816 - INFO - [Step=27000]	Loss=0.9531	275.4 examples/second
2022-01-18 20:30:46,896 - INFO - [Step=27250]	Loss=0.9611	275.7 examples/second
2022-01-18 20:32:43,446 - INFO - [Step=27500]	Loss=0.9483	274.6 examples/second
2022-01-18 20:33:16,713 - INFO - Test Loss=0.9612, Test top-1 acc=0.7757
2022-01-18 20:33:16,714 - INFO - Group Accuracy:

2022-01-18 20:33:16,714 - INFO - [0.9771084  0.9879518  0.9826506  0.99156624 0.98240966 0.99373496
 0.97975904 0.98289156 0.9889157  0.9771084  0.98746985 0.9845783
 0.97204816 0.9780723  0.97493976 0.98650604 0.9930121 ]
2022-01-18 20:33:16,716 - INFO - Saving...
2022-01-18 20:33:16,973 - INFO - Epoch time: 398.2170760631561
2022-01-18 20:33:16,973 - INFO - 
Epoch: 33
2022-01-18 20:33:16,973 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:34:49,796 - INFO - [Step=27750]	Loss=0.9245	253.3 examples/second
2022-01-18 20:36:46,552 - INFO - [Step=28000]	Loss=0.9224	274.1 examples/second
2022-01-18 20:38:43,467 - INFO - [Step=28250]	Loss=0.9392	273.7 examples/second
2022-01-18 20:39:56,251 - INFO - Test Loss=0.9916, Test top-1 acc=0.7716
2022-01-18 20:39:56,252 - INFO - Group Accuracy:

2022-01-18 20:39:56,252 - INFO - [0.9780723  0.98722893 0.98361444 0.99060243 0.9804819  0.9951807
 0.97951806 0.9819277  0.9886747  0.97590363 0.9881928  0.9821687
 0.9737349  0.9785542  0.9742169  0.9853012  0.9927711 ]
2022-01-18 20:39:56,253 - INFO - Epoch time: 399.2802209854126
2022-01-18 20:39:56,253 - INFO - 
Epoch: 34
2022-01-18 20:39:56,253 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:40:49,289 - INFO - [Step=28500]	Loss=0.9044	254.3 examples/second
2022-01-18 20:42:45,927 - INFO - [Step=28750]	Loss=0.9041	274.4 examples/second
2022-01-18 20:44:42,743 - INFO - [Step=29000]	Loss=0.9101	273.9 examples/second
2022-01-18 20:46:35,039 - INFO - Test Loss=0.9782, Test top-1 acc=0.7769
2022-01-18 20:46:35,039 - INFO - Group Accuracy:

2022-01-18 20:46:35,039 - INFO - [0.9778313  0.9886747  0.9816868  0.9918072  0.9816868  0.9946988
 0.98       0.9838554  0.9886747  0.97566265 0.9886747  0.98361444
 0.9725301  0.9771084  0.9727711  0.98650604 0.9922892 ]
2022-01-18 20:46:35,040 - INFO - Saving...
2022-01-18 20:46:35,294 - INFO - Epoch time: 399.0406610965729
2022-01-18 20:46:35,294 - INFO - 
Epoch: 35
2022-01-18 20:46:35,294 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:46:48,536 - INFO - [Step=29250]	Loss=0.9276	254.4 examples/second
2022-01-18 20:48:45,082 - INFO - [Step=29500]	Loss=0.8959	274.6 examples/second
2022-01-18 20:50:41,510 - INFO - [Step=29750]	Loss=0.8954	274.8 examples/second
2022-01-18 20:52:38,635 - INFO - [Step=30000]	Loss=0.8961	273.2 examples/second
2022-01-18 20:53:13,949 - INFO - Test Loss=0.9571, Test top-1 acc=0.7827
2022-01-18 20:53:13,949 - INFO - Group Accuracy:

2022-01-18 20:53:13,949 - INFO - [0.97831327 0.9879518  0.98361444 0.99060243 0.98240966 0.9954217
 0.9809638  0.98240966 0.9886747  0.9768675  0.9881928  0.9840964
 0.97156626 0.9787952  0.9739759  0.98650604 0.993494  ]
2022-01-18 20:53:13,950 - INFO - Saving...
2022-01-18 20:53:14,187 - INFO - Epoch time: 398.8925931453705
2022-01-18 20:53:14,187 - INFO - 
Epoch: 36
2022-01-18 20:53:14,187 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:54:44,696 - INFO - [Step=30250]	Loss=0.8991	253.8 examples/second
2022-01-18 20:56:41,422 - INFO - [Step=30500]	Loss=0.8922	274.1 examples/second
2022-01-18 20:58:38,192 - INFO - [Step=30750]	Loss=0.8860	274.0 examples/second
2022-01-18 20:59:53,372 - INFO - Test Loss=0.9503, Test top-1 acc=0.7692
2022-01-18 20:59:53,373 - INFO - Group Accuracy:

2022-01-18 20:59:53,373 - INFO - [0.9768675  0.9884337  0.98289156 0.9920482  0.9804819  0.9939759
 0.9807229  0.98240966 0.99060243 0.97493976 0.98650604 0.98289156
 0.9742169  0.97831327 0.9727711  0.9879518  0.9927711 ]
2022-01-18 20:59:53,374 - INFO - Epoch time: 399.1868395805359
2022-01-18 20:59:53,374 - INFO - 
Epoch: 37
2022-01-18 20:59:53,374 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:00:44,427 - INFO - [Step=31000]	Loss=0.8843	253.5 examples/second
2022-01-18 21:02:41,263 - INFO - [Step=31250]	Loss=0.8594	273.9 examples/second
2022-01-18 21:04:38,179 - INFO - [Step=31500]	Loss=0.8696	273.7 examples/second
2022-01-18 21:06:33,138 - INFO - Test Loss=0.9472, Test top-1 acc=0.7834
2022-01-18 21:06:33,138 - INFO - Group Accuracy:

2022-01-18 21:06:33,138 - INFO - [0.9768675  0.98963857 0.98313254 0.9922892  0.9814458  0.99445784
 0.9814458  0.9826506  0.9889157  0.97638553 0.9886747  0.9821687
 0.9737349  0.9780723  0.97493976 0.9860241  0.9925301 ]
2022-01-18 21:06:33,139 - INFO - Saving...
2022-01-18 21:06:33,371 - INFO - Epoch time: 399.997594833374
2022-01-18 21:06:33,371 - INFO - 
Epoch: 38
2022-01-18 21:06:33,372 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:06:44,508 - INFO - [Step=31750]	Loss=0.8747	253.3 examples/second
2022-01-18 21:08:40,845 - INFO - [Step=32000]	Loss=0.8464	275.1 examples/second
2022-01-18 21:10:37,266 - INFO - [Step=32250]	Loss=0.8579	274.9 examples/second
2022-01-18 21:12:33,628 - INFO - [Step=32500]	Loss=0.8727	275.0 examples/second
2022-01-18 21:13:11,222 - INFO - Test Loss=0.9536, Test top-1 acc=0.7807
2022-01-18 21:13:11,222 - INFO - Group Accuracy:

2022-01-18 21:13:11,222 - INFO - [0.9780723  0.98650604 0.9812048  0.9930121  0.98       0.9946988
 0.98       0.98313254 0.98963857 0.9768675  0.98650604 0.98289156
 0.97445786 0.97903615 0.97445786 0.98698795 0.9930121 ]
2022-01-18 21:13:11,223 - INFO - Epoch time: 397.8517634868622
2022-01-18 21:13:11,223 - INFO - 
Epoch: 39
2022-01-18 21:13:11,223 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:14:38,298 - INFO - [Step=32750]	Loss=0.8510	256.7 examples/second
2022-01-18 21:16:33,027 - INFO - [Step=33000]	Loss=0.8548	278.9 examples/second
2022-01-18 21:18:28,198 - INFO - [Step=33250]	Loss=0.8408	277.8 examples/second
2022-01-18 21:19:44,297 - INFO - Test Loss=0.9532, Test top-1 acc=0.7831
2022-01-18 21:19:44,298 - INFO - Group Accuracy:

2022-01-18 21:19:44,298 - INFO - [0.9780723  0.9884337  0.98313254 0.9925301  0.9819277  0.99493974
 0.9819277  0.9819277  0.9893976  0.97493976 0.9879518  0.98289156
 0.973494   0.97975904 0.9739759  0.98746985 0.9930121 ]
2022-01-18 21:19:44,299 - INFO - Epoch time: 393.07534313201904
2022-01-18 21:19:44,299 - INFO - 
Epoch: 40
2022-01-18 21:19:44,299 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:20:32,352 - INFO - [Step=33500]	Loss=0.8476	257.7 examples/second
2022-01-18 21:22:28,392 - INFO - [Step=33750]	Loss=0.8290	275.8 examples/second
2022-01-18 21:24:24,728 - INFO - [Step=34000]	Loss=0.8329	275.1 examples/second
2022-01-18 21:26:21,198 - INFO - Test Loss=0.9431, Test top-1 acc=0.7769
2022-01-18 21:26:21,199 - INFO - Group Accuracy:

2022-01-18 21:26:21,199 - INFO - [0.9771084  0.9889157  0.9821687  0.9920482  0.97927713 0.9951807
 0.97951806 0.9804819  0.9891566  0.9766265  0.9879518  0.9826506
 0.973253   0.9780723  0.9742169  0.9855422  0.99373496]
2022-01-18 21:26:21,200 - INFO - Epoch time: 396.90095043182373
2022-01-18 21:26:21,200 - INFO - 
Epoch: 41
2022-01-18 21:26:21,200 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:26:30,314 - INFO - [Step=34250]	Loss=0.8435	254.8 examples/second
2022-01-18 21:28:24,970 - INFO - [Step=34500]	Loss=0.8177	279.1 examples/second
2022-01-18 21:30:19,766 - INFO - [Step=34750]	Loss=0.8242	278.8 examples/second
2022-01-18 21:32:14,961 - INFO - [Step=35000]	Loss=0.8254	277.8 examples/second
2022-01-18 21:32:54,451 - INFO - Test Loss=0.9372, Test top-1 acc=0.7836
2022-01-18 21:32:54,451 - INFO - Group Accuracy:

2022-01-18 21:32:54,451 - INFO - [0.97831327 0.9893976  0.9826506  0.9927711  0.9816868  0.99445784
 0.98240966 0.98240966 0.98963857 0.9775904  0.9889157  0.9838554
 0.97518075 0.97927713 0.973253   0.9860241  0.9930121 ]
2022-01-18 21:32:54,452 - INFO - Saving...
2022-01-18 21:32:54,648 - INFO - Epoch time: 393.44822001457214
2022-01-18 21:32:54,648 - INFO - 
Epoch: 42
2022-01-18 21:32:54,648 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:34:20,209 - INFO - [Step=35250]	Loss=0.8088	255.5 examples/second
2022-01-18 21:36:16,431 - INFO - [Step=35500]	Loss=0.8158	275.3 examples/second
2022-01-18 21:38:12,811 - INFO - [Step=35750]	Loss=0.8290	275.0 examples/second
2022-01-18 21:39:32,871 - INFO - Test Loss=0.9462, Test top-1 acc=0.7822
2022-01-18 21:39:32,872 - INFO - Group Accuracy:

2022-01-18 21:39:32,872 - INFO - [0.97542167 0.9881928  0.98313254 0.99060243 0.98289156 0.9946988
 0.98240966 0.9838554  0.98771083 0.97566265 0.9891566  0.9826506
 0.97566265 0.97975904 0.9746988  0.98722893 0.99445784]
2022-01-18 21:39:32,873 - INFO - Epoch time: 398.2243845462799
2022-01-18 21:39:32,873 - INFO - 
Epoch: 43
2022-01-18 21:39:32,873 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:40:18,709 - INFO - [Step=36000]	Loss=0.7964	254.2 examples/second
2022-01-18 21:42:13,430 - INFO - [Step=36250]	Loss=0.7944	278.9 examples/second
2022-01-18 21:44:08,574 - INFO - [Step=36500]	Loss=0.8146	277.9 examples/second
2022-01-18 21:46:06,658 - INFO - Test Loss=0.9580, Test top-1 acc=0.7795
2022-01-18 21:46:06,658 - INFO - Group Accuracy:

2022-01-18 21:46:06,658 - INFO - [0.97831327 0.9884337  0.98289156 0.9927711  0.98024094 0.99373496
 0.9807229  0.98240966 0.99084336 0.9766265  0.98771083 0.98361444
 0.9727711  0.97903615 0.97493976 0.98626506 0.99373496]
2022-01-18 21:46:06,659 - INFO - Epoch time: 393.78590631484985
2022-01-18 21:46:06,659 - INFO - 
Epoch: 44
2022-01-18 21:46:06,659 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:46:13,151 - INFO - [Step=36750]	Loss=0.8019	256.9 examples/second
2022-01-18 21:48:08,862 - INFO - [Step=37000]	Loss=0.7806	276.6 examples/second
2022-01-18 21:50:04,770 - INFO - [Step=37250]	Loss=0.7980	276.1 examples/second
2022-01-18 21:52:00,604 - INFO - [Step=37500]	Loss=0.8064	276.3 examples/second
2022-01-18 21:52:42,783 - INFO - Test Loss=0.9498, Test top-1 acc=0.7824
2022-01-18 21:52:42,783 - INFO - Group Accuracy:

2022-01-18 21:52:42,783 - INFO - [0.9787952  0.98771083 0.98240966 0.9922892  0.98240966 0.99445784
 0.98       0.98289156 0.98746985 0.9739759  0.9886747  0.98361444
 0.97493976 0.97951806 0.97445786 0.9860241  0.99373496]
2022-01-18 21:52:42,784 - INFO - Epoch time: 396.12533378601074
2022-01-18 21:52:42,784 - INFO - 
Epoch: 45
2022-01-18 21:52:42,784 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:54:05,691 - INFO - [Step=37750]	Loss=0.7785	255.8 examples/second
2022-01-18 21:56:00,786 - INFO - [Step=38000]	Loss=0.7925	278.0 examples/second
2022-01-18 21:57:56,356 - INFO - [Step=38250]	Loss=0.7999	276.9 examples/second
2022-01-18 21:59:17,887 - INFO - Test Loss=0.9372, Test top-1 acc=0.7827
2022-01-18 21:59:17,887 - INFO - Group Accuracy:

2022-01-18 21:59:17,887 - INFO - [0.97903615 0.98771083 0.9816868  0.993494   0.9819277  0.9939759
 0.97975904 0.98313254 0.99060243 0.9768675  0.99060243 0.9853012
 0.9739759  0.97927713 0.97156626 0.9848193  0.9939759 ]
2022-01-18 21:59:17,888 - INFO - Epoch time: 395.10389018058777
2022-01-18 21:59:17,888 - INFO - 
Epoch: 46
2022-01-18 21:59:17,888 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:00:01,517 - INFO - [Step=38500]	Loss=0.7869	255.7 examples/second
2022-01-18 22:01:56,680 - INFO - [Step=38750]	Loss=0.7786	277.9 examples/second
2022-01-18 22:03:51,928 - INFO - [Step=39000]	Loss=0.7626	277.7 examples/second
2022-01-18 22:05:52,434 - INFO - Test Loss=0.9620, Test top-1 acc=0.7810
2022-01-18 22:05:52,434 - INFO - Group Accuracy:

2022-01-18 22:05:52,434 - INFO - [0.9775904  0.98771083 0.9819277  0.9922892  0.9812048  0.99445784
 0.98       0.98240966 0.98963857 0.97493976 0.9886747  0.9812048
 0.9739759  0.9785542  0.9742169  0.98650604 0.99421686]
2022-01-18 22:05:52,435 - INFO - Epoch time: 394.54679012298584
2022-01-18 22:05:52,435 - INFO - 
Epoch: 47
2022-01-18 22:05:52,435 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:05:56,628 - INFO - [Step=39250]	Loss=0.7801	256.6 examples/second
2022-01-18 22:07:52,375 - INFO - [Step=39500]	Loss=0.7745	276.5 examples/second
2022-01-18 22:09:48,023 - INFO - [Step=39750]	Loss=0.7646	276.7 examples/second
2022-01-18 22:11:44,018 - INFO - [Step=40000]	Loss=0.7750	275.9 examples/second
2022-01-18 22:12:28,583 - INFO - Test Loss=0.9632, Test top-1 acc=0.7761
2022-01-18 22:12:28,583 - INFO - Group Accuracy:

2022-01-18 22:12:28,583 - INFO - [0.9771084  0.9886747  0.9833735  0.99156624 0.9809638  0.99493974
 0.97975904 0.9807229  0.9898795  0.97566265 0.9879518  0.9821687
 0.9739759  0.9778313  0.9706024  0.98698795 0.99445784]
2022-01-18 22:12:28,584 - INFO - Epoch time: 396.1488561630249
2022-01-18 22:12:28,584 - INFO - 
Epoch: 48
2022-01-18 22:12:28,584 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:13:48,978 - INFO - [Step=40250]	Loss=0.7569	256.1 examples/second
2022-01-18 22:15:44,109 - INFO - [Step=40500]	Loss=0.7660	277.9 examples/second
2022-01-18 22:17:39,012 - INFO - [Step=40750]	Loss=0.7532	278.5 examples/second
2022-01-18 22:19:02,397 - INFO - Test Loss=0.9419, Test top-1 acc=0.7836
2022-01-18 22:19:02,397 - INFO - Group Accuracy:

2022-01-18 22:19:02,397 - INFO - [0.9780723  0.9881928  0.9819277  0.9922892  0.9826506  0.99445784
 0.9785542  0.9821687  0.9898795  0.97638553 0.9889157  0.98433733
 0.97493976 0.97951806 0.973253   0.98674697 0.99421686]
2022-01-18 22:19:02,398 - INFO - Epoch time: 393.8141930103302
2022-01-18 22:19:02,398 - INFO - 
Epoch: 49
2022-01-18 22:19:02,398 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:19:43,559 - INFO - [Step=41000]	Loss=0.7422	256.9 examples/second
2022-01-18 22:21:38,591 - INFO - [Step=41250]	Loss=0.7471	278.2 examples/second
2022-01-18 22:23:33,552 - INFO - [Step=41500]	Loss=0.7524	278.4 examples/second
2022-01-18 22:25:28,618 - INFO - [Step=41750]	Loss=0.7615	278.1 examples/second
2022-01-18 22:25:36,121 - INFO - Test Loss=0.9353, Test top-1 acc=0.7889
2022-01-18 22:25:36,121 - INFO - Group Accuracy:

2022-01-18 22:25:36,121 - INFO - [0.97590363 0.9886747  0.98313254 0.9920482  0.98313254 0.9946988
 0.9809638  0.9826506  0.9898795  0.9785542  0.9891566  0.9840964
 0.97638553 0.97903615 0.9737349  0.98746985 0.99421686]
2022-01-18 22:25:36,122 - INFO - Saving...
2022-01-18 22:25:36,388 - INFO - Epoch time: 393.98944330215454
2022-01-18 22:25:36,388 - INFO - 
Epoch: 50
2022-01-18 22:25:36,388 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:27:34,404 - INFO - [Step=42000]	Loss=0.7335	254.4 examples/second
2022-01-18 22:29:30,622 - INFO - [Step=42250]	Loss=0.7440	275.3 examples/second
2022-01-18 22:31:26,873 - INFO - [Step=42500]	Loss=0.7644	275.3 examples/second
2022-01-18 22:32:13,729 - INFO - Test Loss=0.9945, Test top-1 acc=0.7827
2022-01-18 22:32:13,729 - INFO - Group Accuracy:

2022-01-18 22:32:13,729 - INFO - [0.9785542  0.9886747  0.98289156 0.993253   0.98240966 0.99421686
 0.9809638  0.9809638  0.98771083 0.97590363 0.98722893 0.9814458
 0.97614455 0.97927713 0.9737349  0.98722893 0.99373496]
2022-01-18 22:32:13,730 - INFO - Epoch time: 397.3425681591034
2022-01-18 22:32:13,731 - INFO - 
Epoch: 51
2022-01-18 22:32:13,731 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:33:32,153 - INFO - [Step=42750]	Loss=0.7258	255.4 examples/second
2022-01-18 22:35:28,463 - INFO - [Step=43000]	Loss=0.7339	275.1 examples/second
2022-01-18 22:37:24,808 - INFO - [Step=43250]	Loss=0.7462	275.0 examples/second
2022-01-18 22:38:51,308 - INFO - Test Loss=0.9704, Test top-1 acc=0.7749
2022-01-18 22:38:51,308 - INFO - Group Accuracy:

2022-01-18 22:38:51,309 - INFO - [0.9775904  0.9879518  0.9816868  0.99156624 0.9816868  0.99373496
 0.98       0.9804819  0.98771083 0.97614455 0.9893976  0.98313254
 0.97445786 0.9778313  0.9737349  0.9855422  0.99373496]
2022-01-18 22:38:51,310 - INFO - Epoch time: 397.5791220664978
2022-01-18 22:38:51,310 - INFO - 
Epoch: 52
2022-01-18 22:38:51,310 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:39:30,399 - INFO - [Step=43500]	Loss=0.7547	254.8 examples/second
2022-01-18 22:41:25,585 - INFO - [Step=43750]	Loss=0.7225	277.8 examples/second
2022-01-18 22:43:21,350 - INFO - [Step=44000]	Loss=0.7595	276.4 examples/second
2022-01-18 22:45:16,935 - INFO - [Step=44250]	Loss=0.7273	276.9 examples/second
2022-01-18 22:45:26,813 - INFO - Test Loss=0.9881, Test top-1 acc=0.7817
2022-01-18 22:45:26,814 - INFO - Group Accuracy:

2022-01-18 22:45:26,814 - INFO - [0.97927713 0.9860241  0.98240966 0.9930121  0.9812048  0.99373496
 0.9807229  0.98289156 0.9891566  0.9778313  0.98722893 0.98361444
 0.9742169  0.97638553 0.97542167 0.9853012  0.9930121 ]
2022-01-18 22:45:26,815 - INFO - Epoch time: 395.50508093833923
2022-01-18 22:45:26,815 - INFO - 
Epoch: 53
2022-01-18 22:45:26,815 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:47:21,826 - INFO - [Step=44500]	Loss=0.7227	256.2 examples/second
2022-01-18 22:49:17,102 - INFO - [Step=44750]	Loss=0.7301	277.6 examples/second
2022-01-18 22:51:12,490 - INFO - [Step=45000]	Loss=0.7350	277.3 examples/second
2022-01-18 22:52:01,372 - INFO - Test Loss=0.9819, Test top-1 acc=0.7706
2022-01-18 22:52:01,372 - INFO - Group Accuracy:

2022-01-18 22:52:01,372 - INFO - [0.97831327 0.9884337  0.9814458  0.993253   0.9819277  0.99373496
 0.97831327 0.9809638  0.9886747  0.97542167 0.9853012  0.98024094
 0.9739759  0.9785542  0.9725301  0.9860241  0.99445784]
2022-01-18 22:52:01,374 - INFO - Epoch time: 394.558798789978
2022-01-18 22:52:01,374 - INFO - 
Epoch: 54
2022-01-18 22:52:01,374 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:53:16,925 - INFO - [Step=45250]	Loss=0.7204	257.2 examples/second
2022-01-18 22:55:12,036 - INFO - [Step=45500]	Loss=0.7080	278.0 examples/second
2022-01-18 22:57:07,202 - INFO - [Step=45750]	Loss=0.7366	277.9 examples/second
2022-01-18 22:58:35,366 - INFO - Test Loss=0.9690, Test top-1 acc=0.7834
2022-01-18 22:58:35,366 - INFO - Group Accuracy:

2022-01-18 22:58:35,366 - INFO - [0.97831327 0.9879518  0.9812048  0.99108434 0.9819277  0.9939759
 0.98       0.9838554  0.98963857 0.973253   0.98674697 0.98313254
 0.9768675  0.9787952  0.9737349  0.98771083 0.993494  ]
2022-01-18 22:58:35,367 - INFO - Epoch time: 393.9928123950958
2022-01-18 22:58:35,367 - INFO - 
Epoch: 55
2022-01-18 22:58:35,367 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:59:11,931 - INFO - [Step=46000]	Loss=0.7324	256.6 examples/second
2022-01-18 23:01:07,101 - INFO - [Step=46250]	Loss=0.6987	277.9 examples/second
2022-01-18 23:03:02,623 - INFO - [Step=46500]	Loss=0.7272	277.0 examples/second
2022-01-18 23:04:57,779 - INFO - [Step=46750]	Loss=0.7271	277.9 examples/second
2022-01-18 23:05:09,804 - INFO - Test Loss=0.9905, Test top-1 acc=0.7754
2022-01-18 23:05:09,805 - INFO - Group Accuracy:

2022-01-18 23:05:09,805 - INFO - [0.9773494  0.9898795  0.9821687  0.9927711  0.98240966 0.993253
 0.9826506  0.9826506  0.9881928  0.973494   0.9881928  0.9814458
 0.97542167 0.9773494  0.97204816 0.98674697 0.9939759 ]
2022-01-18 23:05:09,806 - INFO - Epoch time: 394.43914437294006
2022-01-18 23:05:09,806 - INFO - 
Epoch: 56
2022-01-18 23:05:09,806 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:07:02,783 - INFO - [Step=47000]	Loss=0.6927	256.0 examples/second
2022-01-18 23:08:58,737 - INFO - [Step=47250]	Loss=0.6974	276.0 examples/second
2022-01-18 23:10:54,965 - INFO - [Step=47500]	Loss=0.7218	275.3 examples/second
2022-01-18 23:11:46,393 - INFO - Test Loss=1.0230, Test top-1 acc=0.7740
2022-01-18 23:11:46,393 - INFO - Group Accuracy:

2022-01-18 23:11:46,393 - INFO - [0.9773494  0.98674697 0.98240966 0.9922892  0.98024094 0.99445784
 0.97903615 0.97975904 0.9891566  0.97614455 0.98722893 0.98289156
 0.9725301  0.98       0.9739759  0.9860241  0.99493974]
2022-01-18 23:11:46,394 - INFO - Epoch time: 396.5883946418762
2022-01-18 23:11:46,394 - INFO - 
Epoch: 57
2022-01-18 23:11:46,394 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:13:00,615 - INFO - [Step=47750]	Loss=0.7044	254.7 examples/second
2022-01-18 23:14:57,803 - INFO - [Step=48000]	Loss=0.6958	273.1 examples/second
2022-01-18 23:16:55,154 - INFO - [Step=48250]	Loss=0.7144	272.7 examples/second
2022-01-18 23:18:26,961 - INFO - Test Loss=0.9591, Test top-1 acc=0.7759
2022-01-18 23:18:26,961 - INFO - Group Accuracy:

2022-01-18 23:18:26,961 - INFO - [0.97927713 0.98771083 0.9814458  0.9925301  0.9821687  0.99373496
 0.97903615 0.9814458  0.9886747  0.9746988  0.9884337  0.9816868
 0.9739759  0.97951806 0.9737349  0.9853012  0.99421686]
2022-01-18 23:18:26,962 - INFO - Epoch time: 400.5678939819336
2022-01-18 23:18:26,962 - INFO - 
Epoch: 58
2022-01-18 23:18:26,962 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:19:01,459 - INFO - [Step=48500]	Loss=0.7117	253.4 examples/second
2022-01-18 23:20:58,196 - INFO - [Step=48750]	Loss=0.7085	274.1 examples/second
2022-01-18 23:22:54,990 - INFO - [Step=49000]	Loss=0.6976	274.0 examples/second
2022-01-18 23:24:51,870 - INFO - [Step=49250]	Loss=0.7076	273.8 examples/second
2022-01-18 23:25:06,859 - INFO - Test Loss=0.9847, Test top-1 acc=0.7737
2022-01-18 23:25:06,860 - INFO - Group Accuracy:

2022-01-18 23:25:06,860 - INFO - [0.9775904  0.9881928  0.98361444 0.9930121  0.9812048  0.993494
 0.9778313  0.9809638  0.9886747  0.97614455 0.98771083 0.98024094
 0.97301203 0.9787952  0.9737349  0.98578316 0.993494  ]
2022-01-18 23:25:06,861 - INFO - Epoch time: 399.89850997924805
2022-01-18 23:25:06,861 - INFO - 
Epoch: 59
2022-01-18 23:25:06,861 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:26:58,923 - INFO - [Step=49500]	Loss=0.6557	251.9 examples/second
2022-01-18 23:28:55,852 - INFO - [Step=49750]	Loss=0.6233	273.7 examples/second
2022-01-18 23:30:52,932 - INFO - [Step=50000]	Loss=0.6035	273.3 examples/second
2022-01-18 23:31:47,328 - INFO - Test Loss=0.8985, Test top-1 acc=0.7901
2022-01-18 23:31:47,328 - INFO - Group Accuracy:

2022-01-18 23:31:47,335 - INFO - [0.9780723  0.99036145 0.9850602  0.9930121  0.9840964  0.99421686
 0.9816868  0.9819277  0.9886747  0.9773494  0.9893976  0.98433733
 0.97638553 0.97951806 0.9742169  0.98722893 0.99445784]
2022-01-18 23:31:47,336 - INFO - Saving...
2022-01-18 23:31:47,593 - INFO - Epoch time: 400.7322356700897
2022-01-18 23:31:47,593 - INFO - 
Epoch: 60
2022-01-18 23:31:47,594 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:32:59,522 - INFO - [Step=50250]	Loss=0.6032	252.8 examples/second
2022-01-18 23:34:56,312 - INFO - [Step=50500]	Loss=0.5977	274.0 examples/second
2022-01-18 23:36:53,257 - INFO - [Step=50750]	Loss=0.5879	273.6 examples/second
2022-01-18 23:38:27,130 - INFO - Test Loss=0.8842, Test top-1 acc=0.7954
2022-01-18 23:38:27,130 - INFO - Group Accuracy:

2022-01-18 23:38:27,130 - INFO - [0.9780723  0.98963857 0.9845783  0.993253   0.98361444 0.9946988
 0.98313254 0.98289156 0.9893976  0.9780723  0.9889157  0.98361444
 0.97638553 0.9809638  0.973494   0.98722893 0.99493974]
2022-01-18 23:38:27,131 - INFO - Saving...
2022-01-18 23:38:27,399 - INFO - Epoch time: 399.8050537109375
2022-01-18 23:38:27,399 - INFO - 
Epoch: 61
2022-01-18 23:38:27,399 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:38:59,539 - INFO - [Step=51000]	Loss=0.5925	253.4 examples/second
2022-01-18 23:40:56,256 - INFO - [Step=51250]	Loss=0.5896	274.2 examples/second
2022-01-18 23:42:53,114 - INFO - [Step=51500]	Loss=0.5820	273.8 examples/second
2022-01-18 23:44:50,000 - INFO - [Step=51750]	Loss=0.5941	273.8 examples/second
2022-01-18 23:45:07,111 - INFO - Test Loss=0.8793, Test top-1 acc=0.7976
2022-01-18 23:45:07,111 - INFO - Group Accuracy:

2022-01-18 23:45:07,111 - INFO - [0.97975904 0.9898795  0.9848193  0.993494   0.9840964  0.9951807
 0.98240966 0.9826506  0.9889157  0.9780723  0.99084336 0.9855422
 0.97542167 0.9816868  0.97518075 0.98722893 0.99445784]
2022-01-18 23:45:07,112 - INFO - Saving...
2022-01-18 23:45:07,308 - INFO - Epoch time: 399.9088649749756
2022-01-18 23:45:07,308 - INFO - 
Epoch: 62
2022-01-18 23:45:07,308 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:46:56,469 - INFO - [Step=52000]	Loss=0.5804	253.0 examples/second
2022-01-18 23:48:53,457 - INFO - [Step=52250]	Loss=0.5627	273.5 examples/second
2022-01-18 23:50:50,450 - INFO - [Step=52500]	Loss=0.5738	273.5 examples/second
2022-01-18 23:51:47,141 - INFO - Test Loss=0.8795, Test top-1 acc=0.7954
2022-01-18 23:51:47,141 - INFO - Group Accuracy:

2022-01-18 23:51:47,141 - INFO - [0.98024094 0.9901205  0.98433733 0.9930121  0.9833735  0.9946988
 0.9821687  0.9819277  0.9891566  0.9778313  0.99036145 0.9853012
 0.97638553 0.9812048  0.97542167 0.98771083 0.9946988 ]
2022-01-18 23:51:47,142 - INFO - Epoch time: 399.8341715335846
2022-01-18 23:51:47,142 - INFO - 
Epoch: 63
2022-01-18 23:51:47,142 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:52:56,804 - INFO - [Step=52750]	Loss=0.5702	253.3 examples/second
2022-01-18 23:54:53,703 - INFO - [Step=53000]	Loss=0.5696	273.7 examples/second
2022-01-18 23:56:50,552 - INFO - [Step=53250]	Loss=0.5794	273.9 examples/second
2022-01-18 23:58:26,882 - INFO - Test Loss=0.8827, Test top-1 acc=0.7978
2022-01-18 23:58:26,882 - INFO - Group Accuracy:

2022-01-18 23:58:26,882 - INFO - [0.9785542  0.99060243 0.9848193  0.99421686 0.98361444 0.9946988
 0.9833735  0.98289156 0.9889157  0.9787952  0.9898795  0.9845783
 0.9768675  0.9812048  0.9742169  0.98771083 0.99493974]
2022-01-18 23:58:26,884 - INFO - Saving...
2022-01-18 23:58:27,126 - INFO - Epoch time: 399.98377752304077
2022-01-18 23:58:27,126 - INFO - 
Epoch: 64
2022-01-18 23:58:27,126 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:58:57,328 - INFO - [Step=53500]	Loss=0.5769	252.4 examples/second
2022-01-19 00:00:52,984 - INFO - [Step=53750]	Loss=0.5688	276.7 examples/second
2022-01-19 00:02:48,420 - INFO - [Step=54000]	Loss=0.5548	277.2 examples/second
2022-01-19 00:04:43,937 - INFO - [Step=54250]	Loss=0.5730	277.0 examples/second
2022-01-19 00:05:02,894 - INFO - Test Loss=0.8798, Test top-1 acc=0.7971
2022-01-19 00:05:02,895 - INFO - Group Accuracy:

2022-01-19 00:05:02,895 - INFO - [0.97831327 0.99036145 0.98433733 0.99373496 0.9840964  0.99445784
 0.98361444 0.98240966 0.9889157  0.9778313  0.9891566  0.9850602
 0.9771084  0.98240966 0.9746988  0.98771083 0.9946988 ]
2022-01-19 00:05:02,896 - INFO - Epoch time: 395.7700092792511
2022-01-19 00:05:02,896 - INFO - 
Epoch: 65
2022-01-19 00:05:02,896 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:06:49,544 - INFO - [Step=54500]	Loss=0.5772	254.8 examples/second
2022-01-19 00:08:45,718 - INFO - [Step=54750]	Loss=0.5640	275.5 examples/second
2022-01-19 00:10:42,053 - INFO - [Step=55000]	Loss=0.5619	275.1 examples/second
2022-01-19 00:11:40,581 - INFO - Test Loss=0.9039, Test top-1 acc=0.7973
2022-01-19 00:11:40,581 - INFO - Group Accuracy:

2022-01-19 00:11:40,582 - INFO - [0.9778313  0.9898795  0.98433733 0.993494   0.9833735  0.99445784
 0.98289156 0.98240966 0.98963857 0.9780723  0.98963857 0.9845783
 0.9768675  0.9804819  0.97566265 0.98771083 0.9951807 ]
2022-01-19 00:11:40,582 - INFO - Epoch time: 397.6859269142151
2022-01-19 00:11:40,582 - INFO - 
Epoch: 66
2022-01-19 00:11:40,582 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:12:46,930 - INFO - [Step=55250]	Loss=0.5630	256.3 examples/second
2022-01-19 00:14:42,412 - INFO - [Step=55500]	Loss=0.5575	277.1 examples/second
2022-01-19 00:16:37,940 - INFO - [Step=55750]	Loss=0.5654	277.0 examples/second
2022-01-19 00:18:15,459 - INFO - Test Loss=0.8828, Test top-1 acc=0.7952
2022-01-19 00:18:15,459 - INFO - Group Accuracy:

2022-01-19 00:18:15,459 - INFO - [0.9780723  0.9898795  0.9838554  0.9930121  0.9845783  0.99421686
 0.9819277  0.9821687  0.9898795  0.97831327 0.98963857 0.9840964
 0.97638553 0.9816868  0.97493976 0.9881928  0.99445784]
2022-01-19 00:18:15,460 - INFO - Epoch time: 394.87741684913635
2022-01-19 00:18:15,460 - INFO - 
Epoch: 67
2022-01-19 00:18:15,460 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:18:42,638 - INFO - [Step=56000]	Loss=0.5529	256.6 examples/second
2022-01-19 00:20:37,565 - INFO - [Step=56250]	Loss=0.5511	278.4 examples/second
2022-01-19 00:22:32,649 - INFO - [Step=56500]	Loss=0.5465	278.1 examples/second
2022-01-19 00:24:28,073 - INFO - [Step=56750]	Loss=0.5560	277.2 examples/second
2022-01-19 00:24:49,068 - INFO - Test Loss=0.8856, Test top-1 acc=0.7959
2022-01-19 00:24:49,069 - INFO - Group Accuracy:

2022-01-19 00:24:49,069 - INFO - [0.97903615 0.99036145 0.9848193  0.9930121  0.9838554  0.99421686
 0.98240966 0.9819277  0.99036145 0.97831327 0.9898795  0.9840964
 0.97638553 0.9819277  0.97542167 0.9879518  0.9954217 ]
2022-01-19 00:24:49,070 - INFO - Epoch time: 393.6100420951843
2022-01-19 00:24:49,070 - INFO - 
Epoch: 68
2022-01-19 00:24:49,070 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:26:33,241 - INFO - [Step=57000]	Loss=0.5495	255.7 examples/second
2022-01-19 00:28:29,636 - INFO - [Step=57250]	Loss=0.5535	274.9 examples/second
2022-01-19 00:30:26,465 - INFO - [Step=57500]	Loss=0.5567	273.9 examples/second
2022-01-19 00:31:27,478 - INFO - Test Loss=0.9001, Test top-1 acc=0.8007
2022-01-19 00:31:27,478 - INFO - Group Accuracy:

2022-01-19 00:31:27,478 - INFO - [0.97951806 0.99036145 0.9850602  0.993253   0.98240966 0.99421686
 0.98289156 0.9826506  0.9893976  0.9773494  0.99060243 0.9855422
 0.9773494  0.9819277  0.97518075 0.9881928  0.99493974]
2022-01-19 00:31:27,479 - INFO - Saving...
2022-01-19 00:31:27,732 - INFO - Epoch time: 398.6619029045105
2022-01-19 00:31:27,732 - INFO - 
Epoch: 69
2022-01-19 00:31:27,732 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:32:32,490 - INFO - [Step=57750]	Loss=0.5607	253.9 examples/second
2022-01-19 00:34:29,647 - INFO - [Step=58000]	Loss=0.5472	273.1 examples/second
2022-01-19 00:36:27,305 - INFO - [Step=58250]	Loss=0.5524	272.0 examples/second
2022-01-19 00:38:08,370 - INFO - Test Loss=0.8891, Test top-1 acc=0.7969
2022-01-19 00:38:08,371 - INFO - Group Accuracy:

2022-01-19 00:38:08,371 - INFO - [0.97831327 0.9893976  0.98433733 0.9927711  0.98313254 0.99445784
 0.98289156 0.98240966 0.9901205  0.9778313  0.99036145 0.9850602
 0.97638553 0.9816868  0.97542167 0.98746985 0.99493974]
2022-01-19 00:38:08,372 - INFO - Epoch time: 400.63997769355774
2022-01-19 00:38:08,372 - INFO - 
Epoch: 70
2022-01-19 00:38:08,372 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:38:33,615 - INFO - [Step=58500]	Loss=0.5463	253.3 examples/second
2022-01-19 00:40:30,200 - INFO - [Step=58750]	Loss=0.5398	274.5 examples/second
2022-01-19 00:42:26,913 - INFO - [Step=59000]	Loss=0.5560	274.2 examples/second
2022-01-19 00:44:24,008 - INFO - [Step=59250]	Loss=0.5496	273.3 examples/second
2022-01-19 00:44:48,254 - INFO - Test Loss=0.8966, Test top-1 acc=0.7940
2022-01-19 00:44:48,254 - INFO - Group Accuracy:

2022-01-19 00:44:48,255 - INFO - [0.97831327 0.9893976  0.9840964  0.993253   0.9838554  0.99445784
 0.9819277  0.9814458  0.98963857 0.9780723  0.9881928  0.9853012
 0.97518075 0.9826506  0.97518075 0.98771083 0.99445784]
2022-01-19 00:44:48,255 - INFO - Epoch time: 399.8833038806915
2022-01-19 00:44:48,256 - INFO - 
Epoch: 71
2022-01-19 00:44:48,256 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:46:30,794 - INFO - [Step=59500]	Loss=0.5484	252.4 examples/second
2022-01-19 00:48:27,520 - INFO - [Step=59750]	Loss=0.5521	274.1 examples/second
2022-01-19 00:50:24,335 - INFO - [Step=60000]	Loss=0.5385	273.9 examples/second
2022-01-19 00:51:27,841 - INFO - Test Loss=0.8953, Test top-1 acc=0.7998
2022-01-19 00:51:27,841 - INFO - Group Accuracy:

2022-01-19 00:51:27,841 - INFO - [0.97831327 0.99108434 0.9840964  0.993494   0.9826506  0.99445784
 0.9819277  0.9833735  0.99036145 0.97638553 0.98963857 0.9853012
 0.97614455 0.98240966 0.97590363 0.98771083 0.99493974]
2022-01-19 00:51:27,842 - INFO - Epoch time: 399.58654403686523
2022-01-19 00:51:27,842 - INFO - 
Epoch: 72
2022-01-19 00:51:27,842 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:52:30,418 - INFO - [Step=60250]	Loss=0.5402	253.8 examples/second
2022-01-19 00:54:27,136 - INFO - [Step=60500]	Loss=0.5401	274.2 examples/second
2022-01-19 00:56:23,855 - INFO - [Step=60750]	Loss=0.5402	274.2 examples/second
2022-01-19 00:58:06,859 - INFO - Test Loss=0.8889, Test top-1 acc=0.8012
2022-01-19 00:58:06,860 - INFO - Group Accuracy:

2022-01-19 00:58:06,860 - INFO - [0.97927713 0.9898795  0.9848193  0.99493974 0.9833735  0.9946988
 0.98289156 0.98313254 0.99060243 0.9778313  0.9881928  0.98650604
 0.9771084  0.9809638  0.97445786 0.98771083 0.99493974]
2022-01-19 00:58:06,860 - INFO - Saving...
2022-01-19 00:58:07,138 - INFO - Epoch time: 399.29613637924194
2022-01-19 00:58:07,139 - INFO - 
Epoch: 73
2022-01-19 00:58:07,139 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:58:30,224 - INFO - [Step=61000]	Loss=0.5433	253.2 examples/second
2022-01-19 01:00:27,030 - INFO - [Step=61250]	Loss=0.5329	274.0 examples/second
2022-01-19 01:02:23,540 - INFO - [Step=61500]	Loss=0.5332	274.7 examples/second
2022-01-19 01:04:20,287 - INFO - [Step=61750]	Loss=0.5486	274.1 examples/second
2022-01-19 01:04:46,269 - INFO - Test Loss=0.9063, Test top-1 acc=0.7961
2022-01-19 01:04:46,269 - INFO - Group Accuracy:

2022-01-19 01:04:46,269 - INFO - [0.97975904 0.98963857 0.9845783  0.99421686 0.98433733 0.99493974
 0.9816868  0.9821687  0.9901205  0.9775904  0.9891566  0.9840964
 0.9771084  0.9816868  0.9739759  0.98771083 0.99493974]
2022-01-19 01:04:46,270 - INFO - Epoch time: 399.1314995288849
2022-01-19 01:04:46,270 - INFO - 
Epoch: 74
2022-01-19 01:04:46,270 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:06:26,141 - INFO - [Step=62000]	Loss=0.5345	254.3 examples/second
2022-01-19 01:08:22,943 - INFO - [Step=62250]	Loss=0.5415	274.0 examples/second
2022-01-19 01:10:19,935 - INFO - [Step=62500]	Loss=0.5349	273.5 examples/second
2022-01-19 01:11:26,107 - INFO - Test Loss=0.9017, Test top-1 acc=0.7998
2022-01-19 01:11:26,108 - INFO - Group Accuracy:

2022-01-19 01:11:26,108 - INFO - [0.97927713 0.9901205  0.9848193  0.993494   0.9833735  0.99445784
 0.9814458  0.9821687  0.99084336 0.9773494  0.9889157  0.9850602
 0.9775904  0.98240966 0.97566265 0.98771083 0.99493974]
2022-01-19 01:11:26,109 - INFO - Epoch time: 399.838627576828
2022-01-19 01:11:26,109 - INFO - 
Epoch: 75
2022-01-19 01:11:26,109 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:12:26,544 - INFO - [Step=62750]	Loss=0.5368	252.7 examples/second
2022-01-19 01:14:23,229 - INFO - [Step=63000]	Loss=0.5302	274.2 examples/second
2022-01-19 01:16:19,945 - INFO - [Step=63250]	Loss=0.5266	274.2 examples/second
2022-01-19 01:18:05,719 - INFO - Test Loss=0.9261, Test top-1 acc=0.7961
2022-01-19 01:18:05,719 - INFO - Group Accuracy:

2022-01-19 01:18:05,719 - INFO - [0.97903615 0.9901205  0.9850602  0.99421686 0.98433733 0.99445784
 0.9816868  0.9807229  0.9901205  0.9768675  0.98963857 0.9845783
 0.97638553 0.9809638  0.9742169  0.9879518  0.9954217 ]
2022-01-19 01:18:05,720 - INFO - Epoch time: 399.61084270477295
2022-01-19 01:18:05,720 - INFO - 
Epoch: 76
2022-01-19 01:18:05,720 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:18:26,017 - INFO - [Step=63500]	Loss=0.5420	253.8 examples/second
2022-01-19 01:20:22,882 - INFO - [Step=63750]	Loss=0.5258	273.8 examples/second
2022-01-19 01:22:20,020 - INFO - [Step=64000]	Loss=0.5287	273.2 examples/second
2022-01-19 01:24:16,832 - INFO - [Step=64250]	Loss=0.5357	273.9 examples/second
2022-01-19 01:24:45,250 - INFO - Test Loss=0.8951, Test top-1 acc=0.7976
2022-01-19 01:24:45,251 - INFO - Group Accuracy:

2022-01-19 01:24:45,251 - INFO - [0.97975904 0.9898795  0.98433733 0.9930121  0.98433733 0.99421686
 0.98024094 0.98240966 0.98963857 0.9768675  0.9898795  0.9840964
 0.97638553 0.9821687  0.9739759  0.9881928  0.9954217 ]
2022-01-19 01:24:45,253 - INFO - Epoch time: 399.5327079296112
2022-01-19 01:24:45,253 - INFO - 
Epoch: 77
2022-01-19 01:24:45,253 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:26:22,761 - INFO - [Step=64500]	Loss=0.5235	254.1 examples/second
2022-01-19 01:28:19,704 - INFO - [Step=64750]	Loss=0.5183	273.6 examples/second
2022-01-19 01:30:16,563 - INFO - [Step=65000]	Loss=0.5335	273.8 examples/second
2022-01-19 01:31:24,935 - INFO - Test Loss=0.9111, Test top-1 acc=0.7964
2022-01-19 01:31:24,935 - INFO - Group Accuracy:

2022-01-19 01:31:24,935 - INFO - [0.97975904 0.9891566  0.98433733 0.993253   0.98433733 0.99445784
 0.9807229  0.9816868  0.9891566  0.9773494  0.99084336 0.9845783
 0.9771084  0.9819277  0.973253   0.9881928  0.99493974]
2022-01-19 01:31:24,937 - INFO - Epoch time: 399.68384742736816
2022-01-19 01:31:24,937 - INFO - 
Epoch: 78
2022-01-19 01:31:24,937 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:32:23,108 - INFO - [Step=65250]	Loss=0.5253	252.9 examples/second
2022-01-19 01:34:19,874 - INFO - [Step=65500]	Loss=0.5314	274.1 examples/second
2022-01-19 01:36:16,848 - INFO - [Step=65750]	Loss=0.5244	273.6 examples/second
2022-01-19 01:38:04,790 - INFO - Test Loss=0.9142, Test top-1 acc=0.7993
2022-01-19 01:38:04,791 - INFO - Group Accuracy:

2022-01-19 01:38:04,791 - INFO - [0.9787952  0.9898795  0.9840964  0.9939759  0.98361444 0.99421686
 0.9807229  0.9804819  0.98963857 0.9780723  0.99036145 0.9848193
 0.9766265  0.98240966 0.97445786 0.98771083 0.99493974]
2022-01-19 01:38:04,792 - INFO - Epoch time: 399.85521697998047
2022-01-19 01:38:04,792 - INFO - 
Epoch: 79
2022-01-19 01:38:04,792 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:38:22,856 - INFO - [Step=66000]	Loss=0.5418	254.0 examples/second
2022-01-19 01:40:19,664 - INFO - [Step=66250]	Loss=0.5283	274.0 examples/second
2022-01-19 01:42:16,517 - INFO - [Step=66500]	Loss=0.5175	273.8 examples/second
2022-01-19 01:44:13,371 - INFO - [Step=66750]	Loss=0.5264	273.8 examples/second
2022-01-19 01:44:44,106 - INFO - Test Loss=0.9299, Test top-1 acc=0.7959
2022-01-19 01:44:44,106 - INFO - Group Accuracy:

2022-01-19 01:44:44,106 - INFO - [0.97903615 0.9893976  0.98313254 0.993494   0.98313254 0.99421686
 0.98       0.9807229  0.98963857 0.9775904  0.98963857 0.9853012
 0.9778313  0.9826506  0.97542167 0.98771083 0.99445784]
2022-01-19 01:44:44,107 - INFO - Epoch time: 399.3152189254761
2022-01-19 01:44:44,107 - INFO - 
Epoch: 80
2022-01-19 01:44:44,107 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:46:19,406 - INFO - [Step=67000]	Loss=0.5169	253.9 examples/second
2022-01-19 01:48:16,413 - INFO - [Step=67250]	Loss=0.5258	273.5 examples/second
2022-01-19 01:50:13,289 - INFO - [Step=67500]	Loss=0.5187	273.8 examples/second
2022-01-19 01:51:23,780 - INFO - Test Loss=0.9113, Test top-1 acc=0.7952
2022-01-19 01:51:23,780 - INFO - Group Accuracy:

2022-01-19 01:51:23,780 - INFO - [0.9785542  0.9898795  0.9838554  0.99373496 0.9838554  0.99421686
 0.97975904 0.9821687  0.9889157  0.9780723  0.9901205  0.98433733
 0.9775904  0.9821687  0.9746988  0.9884337  0.9956626 ]
2022-01-19 01:51:23,781 - INFO - Epoch time: 399.6736316680908
2022-01-19 01:51:23,781 - INFO - 
Epoch: 81
2022-01-19 01:51:23,781 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:52:19,746 - INFO - [Step=67750]	Loss=0.5237	253.1 examples/second
2022-01-19 01:54:16,284 - INFO - [Step=68000]	Loss=0.5183	274.6 examples/second
2022-01-19 01:56:13,076 - INFO - [Step=68250]	Loss=0.5204	274.0 examples/second
2022-01-19 01:58:03,076 - INFO - Test Loss=0.9319, Test top-1 acc=0.7969
2022-01-19 01:58:03,077 - INFO - Group Accuracy:

2022-01-19 01:58:03,077 - INFO - [0.9780723  0.9886747  0.98433733 0.9939759  0.9845783  0.9939759
 0.9804819  0.98289156 0.98963857 0.97831327 0.9891566  0.9848193
 0.97638553 0.9821687  0.9739759  0.9879518  0.9954217 ]
2022-01-19 01:58:03,078 - INFO - Epoch time: 399.2967050075531
2022-01-19 01:58:03,078 - INFO - 
Epoch: 82
2022-01-19 01:58:03,078 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:58:19,093 - INFO - [Step=68500]	Loss=0.5213	253.9 examples/second
2022-01-19 02:00:15,633 - INFO - [Step=68750]	Loss=0.5073	274.6 examples/second
2022-01-19 02:02:12,164 - INFO - [Step=69000]	Loss=0.5092	274.6 examples/second
2022-01-19 02:04:08,636 - INFO - [Step=69250]	Loss=0.5223	274.7 examples/second
2022-01-19 02:04:41,665 - INFO - Test Loss=0.9434, Test top-1 acc=0.7995
2022-01-19 02:04:41,665 - INFO - Group Accuracy:

2022-01-19 02:04:41,666 - INFO - [0.9787952  0.9893976  0.9838554  0.993494   0.9838554  0.9939759
 0.97975904 0.9821687  0.99060243 0.97831327 0.9881928  0.9850602
 0.9775904  0.9826506  0.9739759  0.9881928  0.99493974]
2022-01-19 02:04:41,667 - INFO - Epoch time: 398.58884143829346
2022-01-19 02:04:41,667 - INFO - 
Epoch: 83
2022-01-19 02:04:41,667 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:06:14,765 - INFO - [Step=69500]	Loss=0.5155	253.7 examples/second
2022-01-19 02:08:11,237 - INFO - [Step=69750]	Loss=0.5086	274.7 examples/second
2022-01-19 02:10:07,458 - INFO - [Step=70000]	Loss=0.5253	275.3 examples/second
2022-01-19 02:11:20,062 - INFO - Test Loss=0.9330, Test top-1 acc=0.7983
2022-01-19 02:11:20,063 - INFO - Group Accuracy:

2022-01-19 02:11:20,063 - INFO - [0.9778313  0.98963857 0.9855422  0.993253   0.9838554  0.9939759
 0.97927713 0.9812048  0.99060243 0.9785542  0.98963857 0.9850602
 0.9768675  0.98240966 0.97566265 0.9889157  0.9951807 ]
2022-01-19 02:11:20,064 - INFO - Epoch time: 398.39754486083984
2022-01-19 02:11:20,064 - INFO - 
Epoch: 84
2022-01-19 02:11:20,065 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:12:12,563 - INFO - [Step=70250]	Loss=0.5203	255.8 examples/second
2022-01-19 02:14:07,530 - INFO - [Step=70500]	Loss=0.5100	278.3 examples/second
2022-01-19 02:16:03,436 - INFO - [Step=70750]	Loss=0.5063	276.1 examples/second
2022-01-19 02:17:56,589 - INFO - Test Loss=0.9411, Test top-1 acc=0.7973
2022-01-19 02:17:56,589 - INFO - Group Accuracy:

2022-01-19 02:17:56,589 - INFO - [0.9787952  0.9898795  0.9853012  0.9930121  0.98313254 0.9939759
 0.98       0.9809638  0.9901205  0.97831327 0.9901205  0.9853012
 0.9771084  0.9812048  0.97566265 0.9886747  0.9956626 ]
2022-01-19 02:17:56,590 - INFO - Epoch time: 396.52544951438904
2022-01-19 02:17:56,590 - INFO - 
Epoch: 85
2022-01-19 02:17:56,590 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:18:10,164 - INFO - [Step=71000]	Loss=0.5126	252.5 examples/second
2022-01-19 02:20:06,996 - INFO - [Step=71250]	Loss=0.4997	273.9 examples/second
2022-01-19 02:22:03,915 - INFO - [Step=71500]	Loss=0.5019	273.7 examples/second
2022-01-19 02:24:00,712 - INFO - [Step=71750]	Loss=0.5135	274.0 examples/second
2022-01-19 02:24:36,232 - INFO - Test Loss=0.9404, Test top-1 acc=0.7988
2022-01-19 02:24:36,233 - INFO - Group Accuracy:

2022-01-19 02:24:36,233 - INFO - [0.9787952  0.99036145 0.98433733 0.99373496 0.9848193  0.99493974
 0.9814458  0.9816868  0.9901205  0.97831327 0.99060243 0.9840964
 0.9773494  0.9814458  0.97493976 0.9886747  0.9954217 ]
2022-01-19 02:24:36,234 - INFO - Epoch time: 399.64378571510315
2022-01-19 02:24:36,234 - INFO - 
Epoch: 86
2022-01-19 02:24:36,234 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:26:07,027 - INFO - [Step=72000]	Loss=0.5044	253.3 examples/second
2022-01-19 02:28:03,459 - INFO - [Step=72250]	Loss=0.5020	274.8 examples/second
2022-01-19 02:29:59,720 - INFO - [Step=72500]	Loss=0.5084	275.2 examples/second
2022-01-19 02:31:14,431 - INFO - Test Loss=0.9432, Test top-1 acc=0.7949
2022-01-19 02:31:14,432 - INFO - Group Accuracy:

2022-01-19 02:31:14,432 - INFO - [0.97831327 0.9886747  0.98433733 0.993494   0.9840964  0.99445784
 0.9821687  0.9807229  0.99036145 0.9778313  0.9893976  0.9838554
 0.97590363 0.9833735  0.97493976 0.9889157  0.9946988 ]
2022-01-19 02:31:14,432 - INFO - Epoch time: 398.19860768318176
2022-01-19 02:31:14,432 - INFO - 
Epoch: 87
2022-01-19 02:31:14,433 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:32:04,809 - INFO - [Step=72750]	Loss=0.5036	255.8 examples/second
2022-01-19 02:33:59,982 - INFO - [Step=73000]	Loss=0.5150	277.8 examples/second
2022-01-19 02:35:55,409 - INFO - [Step=73250]	Loss=0.5038	277.2 examples/second
2022-01-19 02:37:48,881 - INFO - Test Loss=0.9249, Test top-1 acc=0.7971
2022-01-19 02:37:48,882 - INFO - Group Accuracy:

2022-01-19 02:37:48,882 - INFO - [0.9787952  0.98963857 0.9853012  0.9939759  0.9840964  0.9951807
 0.9816868  0.9809638  0.9901205  0.9775904  0.9886747  0.98433733
 0.97638553 0.9816868  0.97445786 0.98771083 0.9954217 ]
2022-01-19 02:37:48,883 - INFO - Epoch time: 394.45100951194763
2022-01-19 02:37:48,884 - INFO - 
Epoch: 88
2022-01-19 02:37:48,884 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:38:00,027 - INFO - [Step=73500]	Loss=0.4976	256.8 examples/second
2022-01-19 02:39:55,388 - INFO - [Step=73750]	Loss=0.4962	277.4 examples/second
2022-01-19 02:41:50,914 - INFO - [Step=74000]	Loss=0.5002	277.0 examples/second
2022-01-19 02:43:46,425 - INFO - [Step=74250]	Loss=0.4990	277.0 examples/second
2022-01-19 02:44:24,032 - INFO - Test Loss=0.9221, Test top-1 acc=0.7993
2022-01-19 02:44:24,032 - INFO - Group Accuracy:

2022-01-19 02:44:24,032 - INFO - [0.97975904 0.99060243 0.9853012  0.993494   0.98433733 0.9946988
 0.9809638  0.98240966 0.99036145 0.9773494  0.9893976  0.9848193
 0.97638553 0.9814458  0.9746988  0.9884337  0.9946988 ]
2022-01-19 02:44:24,033 - INFO - Epoch time: 395.14968180656433
2022-01-19 02:44:24,033 - INFO - 
Epoch: 89
2022-01-19 02:44:24,033 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:45:51,273 - INFO - [Step=74500]	Loss=0.4966	256.3 examples/second
2022-01-19 02:47:46,549 - INFO - [Step=74750]	Loss=0.4900	277.6 examples/second
2022-01-19 02:49:41,975 - INFO - [Step=75000]	Loss=0.5062	277.2 examples/second
2022-01-19 02:50:58,280 - INFO - Test Loss=0.9569, Test top-1 acc=0.7947
2022-01-19 02:50:58,280 - INFO - Group Accuracy:

2022-01-19 02:50:58,280 - INFO - [0.9804819  0.98963857 0.98433733 0.99373496 0.98361444 0.9946988
 0.9812048  0.9816868  0.9898795  0.9775904  0.9879518  0.98361444
 0.97590363 0.9809638  0.97566265 0.9879518  0.99493974]
2022-01-19 02:50:58,281 - INFO - Epoch time: 394.2480032444
2022-01-19 02:51:08,111 - INFO - Computing OOD Statistics...
2022-01-19 02:51:08,123 - INFO - 	Baseline.          AUROC: 0.3369. TNR@95TPR: 0.0235. AUPR OUT: 0.1236
2022-01-19 02:51:08,127 - INFO - 	ODIN (T=1000).     AUROC: 0.8543. TNR@95TPR: 0.3612. AUPR OUT: 0.5168
2022-01-19 02:51:08,127 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 02:51:08,128 - INFO - Top 1 Accuracy:  Min: 0.8012; Max: 0.8012; Avg: 0.8012; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - Top 5 Accuracy:  Min: 0.9854; Max: 0.9854; Avg: 0.9854; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - **********************************************************************
2022-01-19 02:51:08,128 - INFO - 	MSP (auroc): [0.3369201984408221] Min: 0.3369; Max: 0.3369; Avg: 0.3369; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - 	MSP (tnr): [0.02352941176470591] Min: 0.0235; Max: 0.0235; Avg: 0.0235; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - 	MSP (aupr): [0.12360999103596752] Min: 0.1236; Max: 0.1236; Avg: 0.1236; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - 	ODIN (auroc): [0.8543384833451453] Min: 0.8543; Max: 0.8543; Avg: 0.8543; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - 	ODIN (tnr): [0.3611764705882353] Min: 0.3612; Max: 0.3612; Avg: 0.3612; Std: 0.0000; Len: 1
2022-01-19 02:51:08,128 - INFO - 	ODIN (aupr): [0.5168436275416616] Min: 0.5168; Max: 0.5168; Avg: 0.5168; Std: 0.0000; Len: 1

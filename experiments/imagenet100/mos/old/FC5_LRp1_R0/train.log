2022-01-18 16:52:44,635 - INFO - ==> Preparing data..
2022-01-18 16:52:44,992 - INFO - checkpoint filename: experiments/coarse/mos/FC5_LRp1_R0/checkpoint.pt
2022-01-18 16:52:44,992 - INFO - log filename: experiments/coarse/mos/FC5_LRp1_R0/train.log
2022-01-18 16:52:44,992 - INFO - ********************************************************
2022-01-18 16:52:44,992 - INFO - Starting Iter: 0 / 1
2022-01-18 16:52:44,992 - INFO - ********************************************************
2022-01-18 16:52:48,092 - INFO - cuda
2022-01-18 16:52:48,138 - INFO - 
Epoch: 0
2022-01-18 16:52:48,139 - INFO - 
Learning Rate: 0.0100
2022-01-18 16:54:46,813 - INFO - [Step=250]	Loss=7.1077	269.6 examples/second
2022-01-18 16:56:42,381 - INFO - [Step=500]	Loss=5.4788	276.9 examples/second
2022-01-18 16:58:37,672 - INFO - [Step=750]	Loss=5.3598	277.6 examples/second
2022-01-18 16:59:24,176 - INFO - Test Loss=5.5312, Test top-1 acc=0.0361
2022-01-18 16:59:24,177 - INFO - Group Accuracy:

2022-01-18 16:59:24,177 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-18 16:59:24,178 - INFO - Saving...
2022-01-18 16:59:24,414 - INFO - Epoch time: 396.27551889419556
2022-01-18 16:59:24,414 - INFO - 
Epoch: 1
2022-01-18 16:59:24,414 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:00:42,444 - INFO - [Step=1000]	Loss=5.3135	256.5 examples/second
2022-01-18 17:02:37,849 - INFO - [Step=1250]	Loss=5.1538	277.3 examples/second
2022-01-18 17:04:32,956 - INFO - [Step=1500]	Loss=4.9563	278.0 examples/second
2022-01-18 17:05:58,710 - INFO - Test Loss=4.6804, Test top-1 acc=0.1183
2022-01-18 17:05:58,710 - INFO - Group Accuracy:

2022-01-18 17:05:58,710 - INFO - [0.939759   0.9395181  0.939759   0.94       0.939759   0.939759
 0.939759   0.939759   0.939759   0.939759   0.9518072  0.939759
 0.93903613 0.939759   0.9404819  0.9395181  0.9518072 ]
2022-01-18 17:05:58,712 - INFO - Saving...
2022-01-18 17:05:58,953 - INFO - Epoch time: 394.5383608341217
2022-01-18 17:05:58,953 - INFO - 
Epoch: 2
2022-01-18 17:05:58,953 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:06:37,749 - INFO - [Step=1750]	Loss=4.7787	256.4 examples/second
2022-01-18 17:08:32,715 - INFO - [Step=2000]	Loss=4.6699	278.3 examples/second
2022-01-18 17:10:27,579 - INFO - [Step=2250]	Loss=4.4947	278.6 examples/second
2022-01-18 17:12:22,492 - INFO - [Step=2500]	Loss=4.3151	278.5 examples/second
2022-01-18 17:12:32,123 - INFO - Test Loss=4.0810, Test top-1 acc=0.2137
2022-01-18 17:12:32,123 - INFO - Group Accuracy:

2022-01-18 17:12:32,123 - INFO - [0.94144577 0.9448193  0.939759   0.94626504 0.94       0.94626504
 0.94168675 0.9433735  0.9407229  0.939759   0.95277107 0.9404819
 0.939759   0.939759   0.93783134 0.94       0.95253015]
2022-01-18 17:12:32,124 - INFO - Saving...
2022-01-18 17:12:32,395 - INFO - Epoch time: 393.4416139125824
2022-01-18 17:12:32,395 - INFO - 
Epoch: 3
2022-01-18 17:12:32,395 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:14:27,635 - INFO - [Step=2750]	Loss=4.2091	255.7 examples/second
2022-01-18 17:16:23,415 - INFO - [Step=3000]	Loss=4.0951	276.4 examples/second
2022-01-18 17:18:19,432 - INFO - [Step=3250]	Loss=3.8610	275.8 examples/second
2022-01-18 17:19:08,754 - INFO - Test Loss=3.6700, Test top-1 acc=0.2655
2022-01-18 17:19:08,754 - INFO - Group Accuracy:

2022-01-18 17:19:08,754 - INFO - [0.94096386 0.946747   0.94168675 0.9549398  0.94216865 0.95373493
 0.94216865 0.94120485 0.95036143 0.9404819  0.9520482  0.94144577
 0.9404819  0.94120485 0.94120485 0.9433735  0.9561446 ]
2022-01-18 17:19:08,755 - INFO - Saving...
2022-01-18 17:19:09,005 - INFO - Epoch time: 396.60988688468933
2022-01-18 17:19:09,005 - INFO - 
Epoch: 4
2022-01-18 17:19:09,005 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:20:25,386 - INFO - [Step=3500]	Loss=3.8017	254.1 examples/second
2022-01-18 17:22:21,713 - INFO - [Step=3750]	Loss=3.6808	275.1 examples/second
2022-01-18 17:24:17,758 - INFO - [Step=4000]	Loss=3.5392	275.8 examples/second
2022-01-18 17:25:46,405 - INFO - Test Loss=3.4488, Test top-1 acc=0.3125
2022-01-18 17:25:46,405 - INFO - Group Accuracy:

2022-01-18 17:25:46,405 - INFO - [0.94289154 0.9486747  0.940241   0.95759034 0.94626504 0.96433735
 0.93783134 0.9438554  0.9561446  0.940241   0.9518072  0.9395181
 0.9404819  0.94216865 0.9426506  0.9481928  0.96433735]
2022-01-18 17:25:46,406 - INFO - Saving...
2022-01-18 17:25:46,588 - INFO - Epoch time: 397.5827808380127
2022-01-18 17:25:46,588 - INFO - 
Epoch: 5
2022-01-18 17:25:46,588 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:26:23,349 - INFO - [Step=4250]	Loss=3.4452	254.8 examples/second
2022-01-18 17:28:19,674 - INFO - [Step=4500]	Loss=3.2550	275.1 examples/second
2022-01-18 17:30:16,115 - INFO - [Step=4750]	Loss=3.1657	274.8 examples/second
2022-01-18 17:32:12,572 - INFO - [Step=5000]	Loss=3.0772	274.8 examples/second
2022-01-18 17:32:24,607 - INFO - Test Loss=3.0292, Test top-1 acc=0.3824
2022-01-18 17:32:24,607 - INFO - Group Accuracy:

2022-01-18 17:32:24,607 - INFO - [0.94891566 0.94843376 0.94578314 0.96096385 0.946747   0.96819276
 0.94168675 0.9474699  0.96168673 0.94915664 0.9561446  0.9486747
 0.94240963 0.9392771  0.9445783  0.94891566 0.966747  ]
2022-01-18 17:32:24,609 - INFO - Saving...
2022-01-18 17:32:24,882 - INFO - Epoch time: 398.2941949367523
2022-01-18 17:32:24,882 - INFO - 
Epoch: 6
2022-01-18 17:32:24,882 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:34:18,439 - INFO - [Step=5250]	Loss=2.9640	254.2 examples/second
2022-01-18 17:36:15,353 - INFO - [Step=5500]	Loss=2.8833	273.7 examples/second
2022-01-18 17:38:12,550 - INFO - [Step=5750]	Loss=2.8268	273.0 examples/second
2022-01-18 17:39:04,742 - INFO - Test Loss=2.8277, Test top-1 acc=0.4443
2022-01-18 17:39:04,743 - INFO - Group Accuracy:

2022-01-18 17:39:04,743 - INFO - [0.94963855 0.95710844 0.94843376 0.96843374 0.9508434  0.97638553
 0.9385542  0.9585542  0.9621687  0.946506   0.96506023 0.94843376
 0.94289154 0.94240963 0.9472289  0.9561446  0.9708434 ]
2022-01-18 17:39:04,744 - INFO - Saving...
2022-01-18 17:39:05,015 - INFO - Epoch time: 400.13223910331726
2022-01-18 17:39:05,015 - INFO - 
Epoch: 7
2022-01-18 17:39:05,015 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:40:19,270 - INFO - [Step=6000]	Loss=2.7371	252.5 examples/second
2022-01-18 17:42:16,179 - INFO - [Step=6250]	Loss=2.6580	273.7 examples/second
2022-01-18 17:44:12,081 - INFO - [Step=6500]	Loss=2.6237	276.1 examples/second
2022-01-18 17:45:43,368 - INFO - Test Loss=2.5463, Test top-1 acc=0.4781
2022-01-18 17:45:43,368 - INFO - Group Accuracy:

2022-01-18 17:45:43,368 - INFO - [0.9554217  0.9518072  0.9510843  0.973253   0.95036143 0.9742169
 0.95325303 0.95710844 0.9696385  0.9510843  0.96819276 0.9561446
 0.94240963 0.946747   0.9486747  0.9633735  0.98      ]
2022-01-18 17:45:43,369 - INFO - Saving...
2022-01-18 17:45:43,609 - INFO - Epoch time: 398.59429001808167
2022-01-18 17:45:43,609 - INFO - 
Epoch: 8
2022-01-18 17:45:43,609 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:46:18,051 - INFO - [Step=6750]	Loss=2.5178	254.0 examples/second
2022-01-18 17:48:14,501 - INFO - [Step=7000]	Loss=2.4808	274.8 examples/second
2022-01-18 17:50:11,086 - INFO - [Step=7250]	Loss=2.4293	274.5 examples/second
2022-01-18 17:52:07,378 - INFO - [Step=7500]	Loss=2.3953	275.2 examples/second
2022-01-18 17:52:21,822 - INFO - Test Loss=2.2537, Test top-1 acc=0.5224
2022-01-18 17:52:21,823 - INFO - Group Accuracy:

2022-01-18 17:52:21,823 - INFO - [0.96072286 0.96072286 0.9539759  0.97590363 0.9573494  0.9780723
 0.95710844 0.96409637 0.97445786 0.9559036  0.9662651  0.9578313
 0.94554216 0.9498795  0.9510843  0.96072286 0.97975904]
2022-01-18 17:52:21,825 - INFO - Saving...
2022-01-18 17:52:22,060 - INFO - Epoch time: 398.4503855705261
2022-01-18 17:52:22,060 - INFO - 
Epoch: 9
2022-01-18 17:52:22,060 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:54:12,459 - INFO - [Step=7750]	Loss=2.3095	255.8 examples/second
2022-01-18 17:56:08,038 - INFO - [Step=8000]	Loss=2.2998	276.9 examples/second
2022-01-18 17:58:03,616 - INFO - [Step=8250]	Loss=2.2440	276.9 examples/second
2022-01-18 17:58:57,041 - INFO - Test Loss=2.1804, Test top-1 acc=0.5520
2022-01-18 17:58:57,041 - INFO - Group Accuracy:

2022-01-18 17:58:57,041 - INFO - [0.9578313  0.9672289  0.95566267 0.9766265  0.9595181  0.98024094
 0.95638555 0.96457833 0.9696385  0.96168673 0.9706024  0.96361446
 0.9501205  0.9479518  0.9539759  0.96433735 0.9845783 ]
2022-01-18 17:58:57,042 - INFO - Saving...
2022-01-18 17:58:57,283 - INFO - Epoch time: 395.22262024879456
2022-01-18 17:58:57,283 - INFO - 
Epoch: 10
2022-01-18 17:58:57,283 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:00:09,063 - INFO - [Step=8500]	Loss=2.1848	255.1 examples/second
2022-01-18 18:02:05,105 - INFO - [Step=8750]	Loss=2.1683	275.8 examples/second
2022-01-18 18:04:01,303 - INFO - [Step=9000]	Loss=2.1274	275.4 examples/second
2022-01-18 18:05:34,816 - INFO - Test Loss=2.3788, Test top-1 acc=0.5431
2022-01-18 18:05:34,817 - INFO - Group Accuracy:

2022-01-18 18:05:34,817 - INFO - [0.9595181  0.96698797 0.95566267 0.97542167 0.95662653 0.9812048
 0.9595181  0.9626506  0.9703615  0.9580723  0.9621687  0.9655422
 0.9460241  0.9460241  0.95566267 0.9578313  0.97493976]
2022-01-18 18:05:34,817 - INFO - Epoch time: 397.5345606803894
2022-01-18 18:05:34,817 - INFO - 
Epoch: 11
2022-01-18 18:05:34,818 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:06:07,156 - INFO - [Step=9250]	Loss=2.1201	254.3 examples/second
2022-01-18 18:08:03,852 - INFO - [Step=9500]	Loss=2.0671	274.2 examples/second
2022-01-18 18:09:59,988 - INFO - [Step=9750]	Loss=2.0536	275.5 examples/second
2022-01-18 18:11:56,039 - INFO - [Step=10000]	Loss=2.0344	275.7 examples/second
2022-01-18 18:12:12,787 - INFO - Test Loss=1.9737, Test top-1 acc=0.5600
2022-01-18 18:12:12,787 - INFO - Group Accuracy:

2022-01-18 18:12:12,787 - INFO - [0.9626506  0.97156626 0.95036143 0.9771084  0.9614458  0.9785542
 0.9583132  0.96457833 0.9775904  0.9633735  0.9713253  0.9662651
 0.9515663  0.94843376 0.95349395 0.966506   0.9853012 ]
2022-01-18 18:12:12,788 - INFO - Saving...
2022-01-18 18:12:12,966 - INFO - Epoch time: 398.14800095558167
2022-01-18 18:12:12,966 - INFO - 
Epoch: 12
2022-01-18 18:12:12,966 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:14:01,501 - INFO - [Step=10250]	Loss=1.9705	255.1 examples/second
2022-01-18 18:15:57,669 - INFO - [Step=10500]	Loss=1.9788	275.5 examples/second
2022-01-18 18:17:53,633 - INFO - [Step=10750]	Loss=1.9489	275.9 examples/second
2022-01-18 18:18:49,713 - INFO - Test Loss=2.0621, Test top-1 acc=0.5716
2022-01-18 18:18:49,713 - INFO - Group Accuracy:

2022-01-18 18:18:49,713 - INFO - [0.96168673 0.97301203 0.94843376 0.9787952  0.95686746 0.9845783
 0.9590362  0.9633735  0.9809638  0.9626506  0.973253   0.96361446
 0.94       0.946747   0.95373493 0.96361446 0.9848193 ]
2022-01-18 18:18:49,714 - INFO - Saving...
2022-01-18 18:18:49,892 - INFO - Epoch time: 396.92602372169495
2022-01-18 18:18:49,892 - INFO - 
Epoch: 13
2022-01-18 18:18:49,892 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:19:58,854 - INFO - [Step=11000]	Loss=1.8980	255.6 examples/second
2022-01-18 18:21:54,708 - INFO - [Step=11250]	Loss=1.9075	276.2 examples/second
2022-01-18 18:23:50,350 - INFO - [Step=11500]	Loss=1.8866	276.7 examples/second
2022-01-18 18:25:25,745 - INFO - Test Loss=2.1973, Test top-1 acc=0.5689
2022-01-18 18:25:25,746 - INFO - Group Accuracy:

2022-01-18 18:25:25,746 - INFO - [0.9619277  0.97228914 0.95662653 0.9819277  0.9580723  0.9809638
 0.9549398  0.9662651  0.97927713 0.9518072  0.9696385  0.96168673
 0.9518072  0.9549398  0.9595181  0.9693976  0.98313254]
2022-01-18 18:25:25,747 - INFO - Epoch time: 395.8546142578125
2022-01-18 18:25:25,747 - INFO - 
Epoch: 14
2022-01-18 18:25:25,747 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:25:55,446 - INFO - [Step=11750]	Loss=1.8712	255.8 examples/second
2022-01-18 18:27:51,747 - INFO - [Step=12000]	Loss=1.8385	275.2 examples/second
2022-01-18 18:29:48,284 - INFO - [Step=12250]	Loss=1.8276	274.6 examples/second
2022-01-18 18:31:44,684 - INFO - [Step=12500]	Loss=1.8230	274.9 examples/second
2022-01-18 18:32:04,128 - INFO - Test Loss=1.7488, Test top-1 acc=0.6270
2022-01-18 18:32:04,128 - INFO - Group Accuracy:

2022-01-18 18:32:04,128 - INFO - [0.9662651  0.9775904  0.96843374 0.98361444 0.9653012  0.9814458
 0.9624096  0.96795183 0.9778313  0.9674699  0.9725301  0.9612048
 0.95759034 0.9501205  0.9614458  0.9725301  0.9884337 ]
2022-01-18 18:32:04,129 - INFO - Saving...
2022-01-18 18:32:04,327 - INFO - Epoch time: 398.5802140235901
2022-01-18 18:32:04,327 - INFO - 
Epoch: 15
2022-01-18 18:32:04,327 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:33:50,790 - INFO - [Step=12750]	Loss=1.7657	253.8 examples/second
2022-01-18 18:35:46,713 - INFO - [Step=13000]	Loss=1.7723	276.0 examples/second
2022-01-18 18:37:42,430 - INFO - [Step=13250]	Loss=1.7623	276.5 examples/second
2022-01-18 18:38:40,978 - INFO - Test Loss=1.8121, Test top-1 acc=0.6051
2022-01-18 18:38:40,978 - INFO - Group Accuracy:

2022-01-18 18:38:40,978 - INFO - [0.966747   0.97614455 0.96409637 0.98024094 0.9662651  0.98674697
 0.9580723  0.9674699  0.97108436 0.96385545 0.97228914 0.9633735
 0.9559036  0.9592771  0.96024096 0.973253   0.98674697]
2022-01-18 18:38:40,979 - INFO - Epoch time: 396.65160036087036
2022-01-18 18:38:40,979 - INFO - 
Epoch: 16
2022-01-18 18:38:40,979 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:39:47,342 - INFO - [Step=13500]	Loss=1.7589	256.2 examples/second
2022-01-18 18:41:42,456 - INFO - [Step=13750]	Loss=1.7169	278.0 examples/second
2022-01-18 18:43:37,324 - INFO - [Step=14000]	Loss=1.7370	278.6 examples/second
2022-01-18 18:45:14,601 - INFO - Test Loss=1.6394, Test top-1 acc=0.6480
2022-01-18 18:45:14,602 - INFO - Group Accuracy:

2022-01-18 18:45:14,602 - INFO - [0.9672289  0.97590363 0.9674699  0.98361444 0.9626506  0.9889157
 0.9595181  0.97180724 0.9785542  0.9660241  0.97951806 0.96843374
 0.96       0.96457833 0.9612048  0.97445786 0.98722893]
2022-01-18 18:45:14,603 - INFO - Saving...
2022-01-18 18:45:14,851 - INFO - Epoch time: 393.8722505569458
2022-01-18 18:45:14,851 - INFO - 
Epoch: 17
2022-01-18 18:45:14,851 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:45:42,337 - INFO - [Step=14250]	Loss=1.6977	256.0 examples/second
2022-01-18 18:47:38,810 - INFO - [Step=14500]	Loss=1.6632	274.7 examples/second
2022-01-18 18:49:35,233 - INFO - [Step=14750]	Loss=1.6767	274.9 examples/second
2022-01-18 18:51:31,474 - INFO - [Step=15000]	Loss=1.6765	275.3 examples/second
2022-01-18 18:51:53,072 - INFO - Test Loss=1.8599, Test top-1 acc=0.6065
2022-01-18 18:51:53,072 - INFO - Group Accuracy:

2022-01-18 18:51:53,072 - INFO - [0.96795183 0.97204816 0.9590362  0.98313254 0.9657831  0.9840964
 0.95566267 0.9662651  0.97542167 0.9626506  0.9775904  0.96891564
 0.9385542  0.95686746 0.96168673 0.97301203 0.98746985]
2022-01-18 18:51:53,073 - INFO - Epoch time: 398.2221257686615
2022-01-18 18:51:53,073 - INFO - 
Epoch: 18
2022-01-18 18:51:53,074 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:53:37,180 - INFO - [Step=15250]	Loss=1.6139	254.6 examples/second
2022-01-18 18:55:33,280 - INFO - [Step=15500]	Loss=1.6431	275.6 examples/second
2022-01-18 18:57:29,328 - INFO - [Step=15750]	Loss=1.6334	275.7 examples/second
2022-01-18 18:58:30,058 - INFO - Test Loss=1.6128, Test top-1 acc=0.6400
2022-01-18 18:58:30,059 - INFO - Group Accuracy:

2022-01-18 18:58:30,059 - INFO - [0.9662651  0.9807229  0.96409637 0.98433733 0.96795183 0.9845783
 0.9614458  0.96506023 0.9787952  0.97180724 0.9739759  0.9691566
 0.9612048  0.9621687  0.96385545 0.973494   0.9860241 ]
2022-01-18 18:58:30,060 - INFO - Epoch time: 396.98673725128174
2022-01-18 18:58:30,060 - INFO - 
Epoch: 19
2022-01-18 18:58:30,060 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:59:34,425 - INFO - [Step=16000]	Loss=1.5935	255.8 examples/second
2022-01-18 19:01:30,020 - INFO - [Step=16250]	Loss=1.6171	276.8 examples/second
2022-01-18 19:03:25,532 - INFO - [Step=16500]	Loss=1.5999	277.0 examples/second
2022-01-18 19:05:05,210 - INFO - Test Loss=1.5789, Test top-1 acc=0.6434
2022-01-18 19:05:05,210 - INFO - Group Accuracy:

2022-01-18 19:05:05,210 - INFO - [0.96891564 0.9746988  0.9696385  0.9860241  0.96771085 0.9881928
 0.9628916  0.9708434  0.98       0.9686747  0.9701205  0.96771085
 0.96024096 0.96168673 0.9621687  0.973494   0.98698795]
2022-01-18 19:05:05,211 - INFO - Epoch time: 395.1505410671234
2022-01-18 19:05:05,211 - INFO - 
Epoch: 20
2022-01-18 19:05:05,211 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:05:30,368 - INFO - [Step=16750]	Loss=1.5914	256.3 examples/second
2022-01-18 19:07:26,083 - INFO - [Step=17000]	Loss=1.5575	276.5 examples/second
2022-01-18 19:09:21,764 - INFO - [Step=17250]	Loss=1.5598	276.6 examples/second
2022-01-18 19:11:17,200 - INFO - [Step=17500]	Loss=1.5675	277.2 examples/second
2022-01-18 19:11:40,906 - INFO - Test Loss=1.6681, Test top-1 acc=0.6376
2022-01-18 19:11:40,907 - INFO - Group Accuracy:

2022-01-18 19:11:40,907 - INFO - [0.96819276 0.97831327 0.9655422  0.98361444 0.96843374 0.98674697
 0.9583132  0.9693976  0.9771084  0.9662651  0.97951806 0.96795183
 0.9580723  0.96481925 0.9633735  0.9766265  0.9848193 ]
2022-01-18 19:11:40,907 - INFO - Epoch time: 395.6963679790497
2022-01-18 19:11:40,907 - INFO - 
Epoch: 21
2022-01-18 19:11:40,907 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:13:22,475 - INFO - [Step=17750]	Loss=1.5279	255.4 examples/second
2022-01-18 19:15:18,325 - INFO - [Step=18000]	Loss=1.5253	276.2 examples/second
2022-01-18 19:17:13,970 - INFO - [Step=18250]	Loss=1.5410	276.7 examples/second
2022-01-18 19:18:16,851 - INFO - Test Loss=1.6328, Test top-1 acc=0.6477
2022-01-18 19:18:16,851 - INFO - Group Accuracy:

2022-01-18 19:18:16,851 - INFO - [0.9628916  0.9766265  0.95349395 0.98433733 0.9708434  0.98650604
 0.96698797 0.9737349  0.9809638  0.9657831  0.97518075 0.9693976
 0.9549398  0.9628916  0.9595181  0.97493976 0.98963857]
2022-01-18 19:18:16,853 - INFO - Epoch time: 395.9456481933594
2022-01-18 19:18:16,853 - INFO - 
Epoch: 22
2022-01-18 19:18:16,853 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:19:19,313 - INFO - [Step=18500]	Loss=1.5243	255.3 examples/second
2022-01-18 19:21:15,559 - INFO - [Step=18750]	Loss=1.4927	275.3 examples/second
2022-01-18 19:23:11,713 - INFO - [Step=19000]	Loss=1.5037	275.5 examples/second
2022-01-18 19:24:54,245 - INFO - Test Loss=1.8847, Test top-1 acc=0.6007
2022-01-18 19:24:54,246 - INFO - Group Accuracy:

2022-01-18 19:24:54,246 - INFO - [0.9619277  0.95566267 0.9592771  0.9785542  0.9660241  0.98578316
 0.9619277  0.9660241  0.9739759  0.96698797 0.96698797 0.9693976
 0.9614458  0.96024096 0.9595181  0.9703615  0.98674697]
2022-01-18 19:24:54,247 - INFO - Epoch time: 397.39340591430664
2022-01-18 19:24:54,247 - INFO - 
Epoch: 23
2022-01-18 19:24:54,247 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:25:16,977 - INFO - [Step=19250]	Loss=1.5144	255.5 examples/second
2022-01-18 19:27:12,081 - INFO - [Step=19500]	Loss=1.4800	278.0 examples/second
2022-01-18 19:29:07,209 - INFO - [Step=19750]	Loss=1.4915	278.0 examples/second
2022-01-18 19:31:02,240 - INFO - [Step=20000]	Loss=1.4979	278.2 examples/second
2022-01-18 19:31:28,013 - INFO - Test Loss=1.6353, Test top-1 acc=0.6470
2022-01-18 19:31:28,014 - INFO - Group Accuracy:

2022-01-18 19:31:28,014 - INFO - [0.9662651  0.97445786 0.96409637 0.98626506 0.9708434  0.9855422
 0.9653012  0.9701205  0.98       0.9693976  0.9691566  0.9739759
 0.95975906 0.96409637 0.9590362  0.97301203 0.98650604]
2022-01-18 19:31:28,014 - INFO - Epoch time: 393.7677161693573
2022-01-18 19:31:28,014 - INFO - 
Epoch: 24
2022-01-18 19:31:28,014 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:33:07,861 - INFO - [Step=20250]	Loss=1.4492	254.7 examples/second
2022-01-18 19:35:04,050 - INFO - [Step=20500]	Loss=1.4683	275.4 examples/second
2022-01-18 19:37:00,077 - INFO - [Step=20750]	Loss=1.4715	275.8 examples/second
2022-01-18 19:38:05,572 - INFO - Test Loss=1.5908, Test top-1 acc=0.6554
2022-01-18 19:38:05,572 - INFO - Group Accuracy:

2022-01-18 19:38:05,572 - INFO - [0.9706024  0.9771084  0.9727711  0.97903615 0.9706024  0.98578316
 0.9551807  0.9713253  0.9809638  0.9672289  0.9804819  0.9737349
 0.96       0.9631325  0.9626506  0.9713253  0.98722893]
2022-01-18 19:38:05,573 - INFO - Saving...
2022-01-18 19:38:05,825 - INFO - Epoch time: 397.8104293346405
2022-01-18 19:38:05,825 - INFO - 
Epoch: 25
2022-01-18 19:38:05,825 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:39:06,046 - INFO - [Step=21000]	Loss=1.4554	254.0 examples/second
2022-01-18 19:41:02,261 - INFO - [Step=21250]	Loss=1.4352	275.4 examples/second
2022-01-18 19:42:58,250 - INFO - [Step=21500]	Loss=1.4600	275.9 examples/second
2022-01-18 19:44:42,929 - INFO - Test Loss=1.5981, Test top-1 acc=0.6600
2022-01-18 19:44:42,930 - INFO - Group Accuracy:

2022-01-18 19:44:42,930 - INFO - [0.9660241  0.9787952  0.9693976  0.9833735  0.97180724 0.9881928
 0.9653012  0.96361446 0.98289156 0.9696385  0.9780723  0.97204816
 0.9631325  0.9587952  0.9628916  0.97542167 0.9884337 ]
2022-01-18 19:44:42,931 - INFO - Saving...
2022-01-18 19:44:43,171 - INFO - Epoch time: 397.34588408470154
2022-01-18 19:44:43,171 - INFO - 
Epoch: 26
2022-01-18 19:44:43,171 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:45:03,790 - INFO - [Step=21750]	Loss=1.4453	254.9 examples/second
2022-01-18 19:46:59,799 - INFO - [Step=22000]	Loss=1.4153	275.8 examples/second
2022-01-18 19:48:55,361 - INFO - [Step=22250]	Loss=1.4531	276.9 examples/second
2022-01-18 19:50:51,164 - INFO - [Step=22500]	Loss=1.4360	276.3 examples/second
2022-01-18 19:51:19,743 - INFO - Test Loss=1.4374, Test top-1 acc=0.6769
2022-01-18 19:51:19,744 - INFO - Group Accuracy:

2022-01-18 19:51:19,744 - INFO - [0.9703615  0.9819277  0.97108436 0.98746985 0.9701205  0.9886747
 0.9653012  0.9708434  0.98361444 0.96891564 0.98240966 0.97180724
 0.9633735  0.96433735 0.96698797 0.97445786 0.9891566 ]
2022-01-18 19:51:19,745 - INFO - Saving...
2022-01-18 19:51:20,002 - INFO - Epoch time: 396.8303642272949
2022-01-18 19:51:20,002 - INFO - 
Epoch: 27
2022-01-18 19:51:20,002 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:52:57,545 - INFO - [Step=22750]	Loss=1.3912	253.2 examples/second
2022-01-18 19:54:53,856 - INFO - [Step=23000]	Loss=1.4199	275.1 examples/second
2022-01-18 19:56:49,822 - INFO - [Step=23250]	Loss=1.3978	275.9 examples/second
2022-01-18 19:57:57,610 - INFO - Test Loss=1.3619, Test top-1 acc=0.6863
2022-01-18 19:57:57,611 - INFO - Group Accuracy:

2022-01-18 19:57:57,611 - INFO - [0.96819276 0.98361444 0.97518075 0.98650604 0.9768675  0.9898795
 0.96481925 0.97445786 0.9812048  0.9701205  0.9804819  0.97180724
 0.96072286 0.9660241  0.9674699  0.9807229  0.9879518 ]
2022-01-18 19:57:57,612 - INFO - Saving...
2022-01-18 19:57:57,883 - INFO - Epoch time: 397.8806529045105
2022-01-18 19:57:57,883 - INFO - 
Epoch: 28
2022-01-18 19:57:57,883 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:58:55,811 - INFO - [Step=23500]	Loss=1.4005	254.0 examples/second
2022-01-18 20:00:52,385 - INFO - [Step=23750]	Loss=1.3888	274.5 examples/second
2022-01-18 20:02:48,935 - INFO - [Step=24000]	Loss=1.3875	274.6 examples/second
2022-01-18 20:04:36,522 - INFO - Test Loss=1.5634, Test top-1 acc=0.6749
2022-01-18 20:04:36,522 - INFO - Group Accuracy:

2022-01-18 20:04:36,522 - INFO - [0.96795183 0.9807229  0.9703615  0.98433733 0.9660241  0.9889157
 0.9701205  0.9713253  0.9833735  0.9706024  0.97108436 0.9701205
 0.96506023 0.96481925 0.96433735 0.9696385  0.9891566 ]
2022-01-18 20:04:36,523 - INFO - Epoch time: 398.6404414176941
2022-01-18 20:04:36,523 - INFO - 
Epoch: 29
2022-01-18 20:04:36,523 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:04:54,648 - INFO - [Step=24250]	Loss=1.3951	254.5 examples/second
2022-01-18 20:06:50,334 - INFO - [Step=24500]	Loss=1.0699	276.6 examples/second
2022-01-18 20:08:45,904 - INFO - [Step=24750]	Loss=1.0256	276.9 examples/second
2022-01-18 20:10:41,413 - INFO - [Step=25000]	Loss=1.0025	277.0 examples/second
2022-01-18 20:11:12,036 - INFO - Test Loss=0.9171, Test top-1 acc=0.7795
2022-01-18 20:11:12,036 - INFO - Group Accuracy:

2022-01-18 20:11:12,036 - INFO - [0.9773494  0.9898795  0.9833735  0.99108434 0.9812048  0.99373496
 0.9785542  0.98024094 0.98963857 0.97638553 0.98722893 0.98313254
 0.97301203 0.9773494  0.9766265  0.98698795 0.99445784]
2022-01-18 20:11:12,037 - INFO - Saving...
2022-01-18 20:11:12,214 - INFO - Epoch time: 395.6907753944397
2022-01-18 20:11:12,214 - INFO - 
Epoch: 30
2022-01-18 20:11:12,214 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:12:46,983 - INFO - [Step=25250]	Loss=0.9689	254.8 examples/second
2022-01-18 20:14:43,133 - INFO - [Step=25500]	Loss=0.9614	275.5 examples/second
2022-01-18 20:16:39,236 - INFO - [Step=25750]	Loss=0.9460	275.6 examples/second
2022-01-18 20:17:49,563 - INFO - Test Loss=0.8946, Test top-1 acc=0.7814
2022-01-18 20:17:49,564 - INFO - Group Accuracy:

2022-01-18 20:17:49,564 - INFO - [0.9768675  0.98963857 0.9833735  0.99036145 0.9821687  0.9939759
 0.97927713 0.9814458  0.9891566  0.97566265 0.9879518  0.9819277
 0.9742169  0.9775904  0.97590363 0.98674697 0.99493974]
2022-01-18 20:17:49,564 - INFO - Saving...
2022-01-18 20:17:49,822 - INFO - Epoch time: 397.60810804367065
2022-01-18 20:17:49,823 - INFO - 
Epoch: 31
2022-01-18 20:17:49,823 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:18:45,233 - INFO - [Step=26000]	Loss=0.9236	254.0 examples/second
2022-01-18 20:20:41,545 - INFO - [Step=26250]	Loss=0.9086	275.1 examples/second
2022-01-18 20:22:37,595 - INFO - [Step=26500]	Loss=0.9162	275.7 examples/second
2022-01-18 20:24:27,335 - INFO - Test Loss=0.8704, Test top-1 acc=0.7877
2022-01-18 20:24:27,335 - INFO - Group Accuracy:

2022-01-18 20:24:27,335 - INFO - [0.97831327 0.99084336 0.9850602  0.99108434 0.9809638  0.993494
 0.9807229  0.9809638  0.98963857 0.9768675  0.98746985 0.9826506
 0.97445786 0.9775904  0.9773494  0.98674697 0.9954217 ]
2022-01-18 20:24:27,336 - INFO - Saving...
2022-01-18 20:24:27,564 - INFO - Epoch time: 397.7410719394684
2022-01-18 20:24:27,564 - INFO - 
Epoch: 32
2022-01-18 20:24:27,564 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:24:43,503 - INFO - [Step=26750]	Loss=0.9138	254.2 examples/second
2022-01-18 20:26:39,769 - INFO - [Step=27000]	Loss=0.8967	275.2 examples/second
2022-01-18 20:28:35,929 - INFO - [Step=27250]	Loss=0.8822	275.5 examples/second
2022-01-18 20:30:32,047 - INFO - [Step=27500]	Loss=0.8728	275.6 examples/second
2022-01-18 20:31:05,120 - INFO - Test Loss=0.8795, Test top-1 acc=0.7865
2022-01-18 20:31:05,120 - INFO - Group Accuracy:

2022-01-18 20:31:05,120 - INFO - [0.9778313  0.98963857 0.9855422  0.99156624 0.9816868  0.99421686
 0.98024094 0.9838554  0.98963857 0.9739759  0.98674697 0.98361444
 0.97566265 0.9771084  0.97590363 0.98746985 0.9939759 ]
2022-01-18 20:31:05,122 - INFO - Epoch time: 397.55771040916443
2022-01-18 20:31:05,122 - INFO - 
Epoch: 33
2022-01-18 20:31:05,122 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:32:37,142 - INFO - [Step=27750]	Loss=0.8663	255.8 examples/second
2022-01-18 20:34:32,538 - INFO - [Step=28000]	Loss=0.8580	277.3 examples/second
2022-01-18 20:36:27,856 - INFO - [Step=28250]	Loss=0.8794	277.5 examples/second
2022-01-18 20:37:39,887 - INFO - Test Loss=0.8654, Test top-1 acc=0.7901
2022-01-18 20:37:39,887 - INFO - Group Accuracy:

2022-01-18 20:37:39,887 - INFO - [0.9780723  0.99084336 0.9853012  0.99084336 0.9816868  0.993494
 0.98024094 0.9840964  0.9898795  0.9768675  0.98722893 0.9826506
 0.97566265 0.9775904  0.97590363 0.9879518  0.99493974]
2022-01-18 20:37:39,888 - INFO - Saving...
2022-01-18 20:37:40,141 - INFO - Epoch time: 395.0188698768616
2022-01-18 20:37:40,141 - INFO - 
Epoch: 34
2022-01-18 20:37:40,141 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:38:33,507 - INFO - [Step=28500]	Loss=0.8597	254.7 examples/second
2022-01-18 20:40:30,123 - INFO - [Step=28750]	Loss=0.8571	274.4 examples/second
2022-01-18 20:42:26,769 - INFO - [Step=29000]	Loss=0.8520	274.3 examples/second
2022-01-18 20:44:19,286 - INFO - Test Loss=0.8564, Test top-1 acc=0.7875
2022-01-18 20:44:19,287 - INFO - Group Accuracy:

2022-01-18 20:44:19,287 - INFO - [0.9807229  0.9898795  0.98361444 0.99060243 0.9821687  0.99373496
 0.9807229  0.9838554  0.9901205  0.97638553 0.9889157  0.9845783
 0.9746988  0.9771084  0.97493976 0.98722893 0.9946988 ]
2022-01-18 20:44:19,287 - INFO - Epoch time: 399.14640760421753
2022-01-18 20:44:19,287 - INFO - 
Epoch: 35
2022-01-18 20:44:19,287 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:44:33,036 - INFO - [Step=29250]	Loss=0.8451	253.4 examples/second
2022-01-18 20:46:28,448 - INFO - [Step=29500]	Loss=0.8293	277.3 examples/second
2022-01-18 20:48:23,929 - INFO - [Step=29750]	Loss=0.8246	277.1 examples/second
2022-01-18 20:50:19,288 - INFO - [Step=30000]	Loss=0.8382	277.4 examples/second
2022-01-18 20:50:54,507 - INFO - Test Loss=0.8494, Test top-1 acc=0.7908
2022-01-18 20:50:54,508 - INFO - Group Accuracy:

2022-01-18 20:50:54,508 - INFO - [0.97903615 0.98963857 0.98361444 0.99108434 0.9838554  0.99421686
 0.9812048  0.9826506  0.98963857 0.9766265  0.9881928  0.98289156
 0.97566265 0.9785542  0.9766265  0.9879518  0.9951807 ]
2022-01-18 20:50:54,509 - INFO - Saving...
2022-01-18 20:50:54,787 - INFO - Epoch time: 395.4996876716614
2022-01-18 20:50:54,787 - INFO - 
Epoch: 36
2022-01-18 20:50:54,787 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:52:25,705 - INFO - [Step=30250]	Loss=0.8259	253.1 examples/second
2022-01-18 20:54:22,992 - INFO - [Step=30500]	Loss=0.8239	272.8 examples/second
2022-01-18 20:56:20,281 - INFO - [Step=30750]	Loss=0.8344	272.8 examples/second
2022-01-18 20:57:36,054 - INFO - Test Loss=0.8565, Test top-1 acc=0.7930
2022-01-18 20:57:36,054 - INFO - Group Accuracy:

2022-01-18 20:57:36,055 - INFO - [0.9785542  0.9901205  0.9850602  0.9920482  0.9804819  0.9939759
 0.9809638  0.9826506  0.9901205  0.97566265 0.9898795  0.9840964
 0.97590363 0.9780723  0.97831327 0.98722893 0.9939759 ]
2022-01-18 20:57:36,055 - INFO - Saving...
2022-01-18 20:57:36,340 - INFO - Epoch time: 401.553019285202
2022-01-18 20:57:36,341 - INFO - 
Epoch: 37
2022-01-18 20:57:36,341 - INFO - 
Learning Rate: 0.0100
2022-01-18 20:58:27,751 - INFO - [Step=31000]	Loss=0.8087	251.0 examples/second
2022-01-18 21:00:25,008 - INFO - [Step=31250]	Loss=0.7916	272.9 examples/second
2022-01-18 21:02:22,242 - INFO - [Step=31500]	Loss=0.8167	273.0 examples/second
2022-01-18 21:04:17,364 - INFO - Test Loss=0.8426, Test top-1 acc=0.7925
2022-01-18 21:04:17,364 - INFO - Group Accuracy:

2022-01-18 21:04:17,364 - INFO - [0.9778313  0.99060243 0.98650604 0.99108434 0.9821687  0.993253
 0.9804819  0.9833735  0.99036145 0.9768675  0.9881928  0.9838554
 0.97614455 0.97927713 0.9766265  0.98746985 0.9954217 ]
2022-01-18 21:04:17,365 - INFO - Epoch time: 401.0243139266968
2022-01-18 21:04:17,365 - INFO - 
Epoch: 38
2022-01-18 21:04:17,365 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:04:28,919 - INFO - [Step=31750]	Loss=0.8024	252.6 examples/second
2022-01-18 21:06:23,802 - INFO - [Step=32000]	Loss=0.7964	278.5 examples/second
2022-01-18 21:08:19,043 - INFO - [Step=32250]	Loss=0.8038	277.7 examples/second
2022-01-18 21:10:14,238 - INFO - [Step=32500]	Loss=0.7881	277.8 examples/second
2022-01-18 21:10:52,078 - INFO - Test Loss=0.8561, Test top-1 acc=0.7863
2022-01-18 21:10:52,078 - INFO - Group Accuracy:

2022-01-18 21:10:52,079 - INFO - [0.97831327 0.9901205  0.9845783  0.9918072  0.9826506  0.99373496
 0.98       0.9821687  0.9901205  0.97614455 0.9879518  0.9821687
 0.9746988  0.9778313  0.9773494  0.98771083 0.99445784]
2022-01-18 21:10:52,079 - INFO - Epoch time: 394.7143304347992
2022-01-18 21:10:52,080 - INFO - 
Epoch: 39
2022-01-18 21:10:52,080 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:12:19,471 - INFO - [Step=32750]	Loss=0.7935	255.5 examples/second
2022-01-18 21:14:14,693 - INFO - [Step=33000]	Loss=0.7872	277.7 examples/second
2022-01-18 21:16:09,789 - INFO - [Step=33250]	Loss=0.8014	278.0 examples/second
2022-01-18 21:17:27,101 - INFO - Test Loss=0.8457, Test top-1 acc=0.7942
2022-01-18 21:17:27,102 - INFO - Group Accuracy:

2022-01-18 21:17:27,102 - INFO - [0.9780723  0.99060243 0.9845783  0.9922892  0.9819277  0.9939759
 0.9809638  0.9819277  0.9898795  0.9771084  0.99036145 0.9855422
 0.9739759  0.9780723  0.9766265  0.9879518  0.9956626 ]
2022-01-18 21:17:27,102 - INFO - Saving...
2022-01-18 21:17:27,376 - INFO - Epoch time: 395.2961959838867
2022-01-18 21:17:27,376 - INFO - 
Epoch: 40
2022-01-18 21:17:27,376 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:18:15,558 - INFO - [Step=33500]	Loss=0.7780	254.4 examples/second
2022-01-18 21:20:11,002 - INFO - [Step=33750]	Loss=0.7730	277.2 examples/second
2022-01-18 21:22:06,449 - INFO - [Step=34000]	Loss=0.7816	277.2 examples/second
2022-01-18 21:24:02,489 - INFO - Test Loss=0.8449, Test top-1 acc=0.7923
2022-01-18 21:24:02,490 - INFO - Group Accuracy:

2022-01-18 21:24:02,490 - INFO - [0.97927713 0.99036145 0.98433733 0.99108434 0.9807229  0.993253
 0.97975904 0.9840964  0.9901205  0.97614455 0.9891566  0.98433733
 0.97542167 0.97903615 0.9768675  0.9891566  0.99445784]
2022-01-18 21:24:02,490 - INFO - Epoch time: 395.11436796188354
2022-01-18 21:24:02,490 - INFO - 
Epoch: 41
2022-01-18 21:24:02,490 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:24:11,494 - INFO - [Step=34250]	Loss=0.7776	255.9 examples/second
2022-01-18 21:26:06,683 - INFO - [Step=34500]	Loss=0.7710	277.8 examples/second
2022-01-18 21:28:01,813 - INFO - [Step=34750]	Loss=0.7776	277.9 examples/second
2022-01-18 21:29:56,821 - INFO - [Step=35000]	Loss=0.7680	278.2 examples/second
2022-01-18 21:30:36,914 - INFO - Test Loss=0.8326, Test top-1 acc=0.7986
2022-01-18 21:30:36,914 - INFO - Group Accuracy:

2022-01-18 21:30:36,914 - INFO - [0.9771084  0.99060243 0.9845783  0.9927711  0.9809638  0.9930121
 0.98361444 0.98313254 0.99060243 0.9766265  0.9891566  0.98361444
 0.9775904  0.9809638  0.97590363 0.98963857 0.9951807 ]
2022-01-18 21:30:36,915 - INFO - Saving...
2022-01-18 21:30:37,182 - INFO - Epoch time: 394.6918513774872
2022-01-18 21:30:37,182 - INFO - 
Epoch: 42
2022-01-18 21:30:37,183 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:32:02,642 - INFO - [Step=35250]	Loss=0.7565	254.3 examples/second
2022-01-18 21:33:58,132 - INFO - [Step=35500]	Loss=0.7585	277.1 examples/second
2022-01-18 21:35:53,544 - INFO - [Step=35750]	Loss=0.7643	277.3 examples/second
2022-01-18 21:37:13,159 - INFO - Test Loss=0.9314, Test top-1 acc=0.7913
2022-01-18 21:37:13,159 - INFO - Group Accuracy:

2022-01-18 21:37:13,159 - INFO - [0.97975904 0.99036145 0.98289156 0.9922892  0.98313254 0.99421686
 0.9804819  0.98289156 0.9901205  0.97542167 0.9881928  0.98433733
 0.97614455 0.97638553 0.97445786 0.9884337  0.9939759 ]
2022-01-18 21:37:13,167 - INFO - Epoch time: 395.9845428466797
2022-01-18 21:37:13,167 - INFO - 
Epoch: 43
2022-01-18 21:37:13,167 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:37:58,987 - INFO - [Step=36000]	Loss=0.7586	255.1 examples/second
2022-01-18 21:39:54,321 - INFO - [Step=36250]	Loss=0.7455	277.5 examples/second
2022-01-18 21:41:49,378 - INFO - [Step=36500]	Loss=0.7561	278.1 examples/second
2022-01-18 21:43:47,859 - INFO - Test Loss=0.8272, Test top-1 acc=0.7986
2022-01-18 21:43:47,859 - INFO - Group Accuracy:

2022-01-18 21:43:47,859 - INFO - [0.97951806 0.99084336 0.9860241  0.9922892  0.9833735  0.99421686
 0.9819277  0.98240966 0.9901205  0.9768675  0.9893976  0.98313254
 0.97566265 0.9804819  0.97638553 0.98722893 0.99493974]
2022-01-18 21:43:47,860 - INFO - Epoch time: 394.6929929256439
2022-01-18 21:43:47,860 - INFO - 
Epoch: 44
2022-01-18 21:43:47,860 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:43:54,627 - INFO - [Step=36750]	Loss=0.7470	255.5 examples/second
2022-01-18 21:45:50,108 - INFO - [Step=37000]	Loss=0.7356	277.1 examples/second
2022-01-18 21:47:45,511 - INFO - [Step=37250]	Loss=0.7339	277.3 examples/second
2022-01-18 21:49:40,858 - INFO - [Step=37500]	Loss=0.7573	277.4 examples/second
2022-01-18 21:50:23,074 - INFO - Test Loss=0.8391, Test top-1 acc=0.7940
2022-01-18 21:50:23,075 - INFO - Group Accuracy:

2022-01-18 21:50:23,075 - INFO - [0.97975904 0.9898795  0.9860241  0.99156624 0.98313254 0.99373496
 0.98361444 0.98361444 0.99036145 0.97566265 0.98746985 0.9838554
 0.97566265 0.98       0.9778313  0.9893976  0.9961446 ]
2022-01-18 21:50:23,076 - INFO - Epoch time: 395.21566891670227
2022-01-18 21:50:23,076 - INFO - 
Epoch: 45
2022-01-18 21:50:23,076 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:51:45,990 - INFO - [Step=37750]	Loss=0.7347	255.7 examples/second
2022-01-18 21:53:41,359 - INFO - [Step=38000]	Loss=0.7331	277.4 examples/second
2022-01-18 21:55:36,422 - INFO - [Step=38250]	Loss=0.7386	278.1 examples/second
2022-01-18 21:56:58,428 - INFO - Test Loss=0.8899, Test top-1 acc=0.7928
2022-01-18 21:56:58,428 - INFO - Group Accuracy:

2022-01-18 21:56:58,428 - INFO - [0.97975904 0.99084336 0.98433733 0.9920482  0.98289156 0.993494
 0.98       0.98240966 0.9891566  0.97590363 0.99060243 0.9838554
 0.9773494  0.97927713 0.97614455 0.9881928  0.99445784]
2022-01-18 21:56:58,429 - INFO - Epoch time: 395.3534698486328
2022-01-18 21:56:58,429 - INFO - 
Epoch: 46
2022-01-18 21:56:58,430 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:57:42,689 - INFO - [Step=38500]	Loss=0.7274	253.4 examples/second
2022-01-18 21:59:39,983 - INFO - [Step=38750]	Loss=0.7165	272.8 examples/second
2022-01-18 22:01:37,208 - INFO - [Step=39000]	Loss=0.7377	273.0 examples/second
2022-01-18 22:03:39,743 - INFO - Test Loss=0.8426, Test top-1 acc=0.7942
2022-01-18 22:03:39,743 - INFO - Group Accuracy:

2022-01-18 22:03:39,743 - INFO - [0.97951806 0.99108434 0.98433733 0.9920482  0.98361444 0.9927711
 0.98       0.98361444 0.9879518  0.97542167 0.9884337  0.9840964
 0.97566265 0.9787952  0.9773494  0.9881928  0.9956626 ]
2022-01-18 22:03:39,744 - INFO - Epoch time: 401.3146867752075
2022-01-18 22:03:39,744 - INFO - 
Epoch: 47
2022-01-18 22:03:39,744 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:03:44,026 - INFO - [Step=39250]	Loss=0.7438	252.3 examples/second
2022-01-18 22:05:41,052 - INFO - [Step=39500]	Loss=0.7001	273.4 examples/second
2022-01-18 22:07:37,861 - INFO - [Step=39750]	Loss=0.7248	274.0 examples/second
2022-01-18 22:09:34,315 - INFO - [Step=40000]	Loss=0.7287	274.8 examples/second
2022-01-18 22:10:19,404 - INFO - Test Loss=0.8690, Test top-1 acc=0.7940
2022-01-18 22:10:19,405 - INFO - Group Accuracy:

2022-01-18 22:10:19,405 - INFO - [0.9787952  0.9898795  0.98433733 0.9918072  0.9826506  0.993253
 0.98       0.9833735  0.9901205  0.97614455 0.9891566  0.9833735
 0.9768675  0.97951806 0.97614455 0.9886747  0.9959036 ]
2022-01-18 22:10:19,406 - INFO - Epoch time: 399.6614363193512
2022-01-18 22:10:19,406 - INFO - 
Epoch: 48
2022-01-18 22:10:19,406 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:11:40,869 - INFO - [Step=40250]	Loss=0.7124	252.9 examples/second
2022-01-18 22:13:37,597 - INFO - [Step=40500]	Loss=0.7171	274.1 examples/second
2022-01-18 22:15:34,119 - INFO - [Step=40750]	Loss=0.7210	274.6 examples/second
2022-01-18 22:16:58,779 - INFO - Test Loss=0.8321, Test top-1 acc=0.8055
2022-01-18 22:16:58,779 - INFO - Group Accuracy:

2022-01-18 22:16:58,780 - INFO - [0.9816868  0.9913253  0.98313254 0.9930121  0.9816868  0.9939759
 0.9821687  0.9833735  0.9893976  0.97518075 0.99084336 0.9860241
 0.9780723  0.9804819  0.97638553 0.9886747  0.9956626 ]
2022-01-18 22:16:58,781 - INFO - Saving...
2022-01-18 22:16:59,049 - INFO - Epoch time: 399.64333963394165
2022-01-18 22:16:59,049 - INFO - 
Epoch: 49
2022-01-18 22:16:59,049 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:17:40,564 - INFO - [Step=41000]	Loss=0.7232	253.1 examples/second
2022-01-18 22:19:36,982 - INFO - [Step=41250]	Loss=0.6957	274.9 examples/second
2022-01-18 22:21:33,195 - INFO - [Step=41500]	Loss=0.7073	275.4 examples/second
2022-01-18 22:23:29,267 - INFO - [Step=41750]	Loss=0.7226	275.7 examples/second
2022-01-18 22:23:36,942 - INFO - Test Loss=0.8359, Test top-1 acc=0.7986
2022-01-18 22:23:36,942 - INFO - Group Accuracy:

2022-01-18 22:23:36,942 - INFO - [0.9812048  0.9913253  0.9838554  0.9922892  0.9833735  0.9939759
 0.9807229  0.98240966 0.98963857 0.97614455 0.98963857 0.9850602
 0.97927713 0.98024094 0.97590363 0.99060243 0.993494  ]
2022-01-18 22:23:36,943 - INFO - Epoch time: 397.89372730255127
2022-01-18 22:23:36,943 - INFO - 
Epoch: 50
2022-01-18 22:23:36,943 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:25:34,311 - INFO - [Step=42000]	Loss=0.6983	255.9 examples/second
2022-01-18 22:27:29,696 - INFO - [Step=42250]	Loss=0.7029	277.3 examples/second
2022-01-18 22:29:25,046 - INFO - [Step=42500]	Loss=0.7135	277.4 examples/second
2022-01-18 22:30:11,850 - INFO - Test Loss=0.8494, Test top-1 acc=0.7947
2022-01-18 22:30:11,851 - INFO - Group Accuracy:

2022-01-18 22:30:11,851 - INFO - [0.97927713 0.99108434 0.98433733 0.9927711  0.98433733 0.99373496
 0.9814458  0.9850602  0.99036145 0.9768675  0.98722893 0.98361444
 0.973253   0.98024094 0.97638553 0.98722893 0.99493974]
2022-01-18 22:30:11,852 - INFO - Epoch time: 394.9085032939911
2022-01-18 22:30:11,852 - INFO - 
Epoch: 51
2022-01-18 22:30:11,852 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:31:30,693 - INFO - [Step=42750]	Loss=0.6990	254.7 examples/second
2022-01-18 22:33:27,096 - INFO - [Step=43000]	Loss=0.6835	274.9 examples/second
2022-01-18 22:35:23,482 - INFO - [Step=43250]	Loss=0.7196	274.9 examples/second
2022-01-18 22:36:50,439 - INFO - Test Loss=0.8486, Test top-1 acc=0.7966
2022-01-18 22:36:50,439 - INFO - Group Accuracy:

2022-01-18 22:36:50,439 - INFO - [0.97951806 0.9913253  0.9840964  0.993253   0.98240966 0.99421686
 0.9821687  0.9838554  0.99060243 0.97493976 0.9901205  0.98313254
 0.9771084  0.98024094 0.97493976 0.9889157  0.9951807 ]
2022-01-18 22:36:50,440 - INFO - Epoch time: 398.588454246521
2022-01-18 22:36:50,440 - INFO - 
Epoch: 52
2022-01-18 22:36:50,440 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:37:29,862 - INFO - [Step=43500]	Loss=0.7150	253.2 examples/second
2022-01-18 22:39:25,168 - INFO - [Step=43750]	Loss=0.6765	277.5 examples/second
2022-01-18 22:41:20,203 - INFO - [Step=44000]	Loss=0.6878	278.2 examples/second
2022-01-18 22:43:15,472 - INFO - [Step=44250]	Loss=0.6954	277.6 examples/second
2022-01-18 22:43:25,577 - INFO - Test Loss=0.8744, Test top-1 acc=0.7971
2022-01-18 22:43:25,577 - INFO - Group Accuracy:

2022-01-18 22:43:25,577 - INFO - [0.9809638  0.99156624 0.98433733 0.993253   0.9826506  0.993494
 0.9804819  0.98313254 0.9891566  0.9780723  0.98674697 0.98433733
 0.97614455 0.9804819  0.97638553 0.9881928  0.99445784]
2022-01-18 22:43:25,578 - INFO - Epoch time: 395.1376328468323
2022-01-18 22:43:25,578 - INFO - 
Epoch: 53
2022-01-18 22:43:25,578 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:45:21,506 - INFO - [Step=44500]	Loss=0.6769	253.9 examples/second
2022-01-18 22:47:17,886 - INFO - [Step=44750]	Loss=0.6926	275.0 examples/second
2022-01-18 22:49:14,219 - INFO - [Step=45000]	Loss=0.7032	275.1 examples/second
2022-01-18 22:50:04,189 - INFO - Test Loss=0.8365, Test top-1 acc=0.7988
2022-01-18 22:50:04,189 - INFO - Group Accuracy:

2022-01-18 22:50:04,189 - INFO - [0.98       0.9898795  0.98433733 0.9922892  0.98433733 0.9939759
 0.9778313  0.9812048  0.9898795  0.9746988  0.98963857 0.9850602
 0.97951806 0.98240966 0.9778313  0.9891566  0.9959036 ]
2022-01-18 22:50:04,190 - INFO - Epoch time: 398.6117944717407
2022-01-18 22:50:04,190 - INFO - 
Epoch: 54
2022-01-18 22:50:04,190 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:51:20,462 - INFO - [Step=45250]	Loss=0.6853	253.5 examples/second
2022-01-18 22:53:16,310 - INFO - [Step=45500]	Loss=0.6690	276.2 examples/second
2022-01-18 22:55:11,933 - INFO - [Step=45750]	Loss=0.6875	276.8 examples/second
2022-01-18 22:56:40,631 - INFO - Test Loss=0.8319, Test top-1 acc=0.7998
2022-01-18 22:56:40,631 - INFO - Group Accuracy:

2022-01-18 22:56:40,631 - INFO - [0.9809638  0.9893976  0.9845783  0.9925301  0.98       0.9946988
 0.9816868  0.9812048  0.99060243 0.97638553 0.98963857 0.98650604
 0.9766265  0.9812048  0.97590363 0.9881928  0.99493974]
2022-01-18 22:56:40,632 - INFO - Epoch time: 396.44266414642334
2022-01-18 22:56:40,633 - INFO - 
Epoch: 55
2022-01-18 22:56:40,633 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:57:17,399 - INFO - [Step=46000]	Loss=0.6944	255.1 examples/second
2022-01-18 22:59:13,617 - INFO - [Step=46250]	Loss=0.6637	275.3 examples/second
2022-01-18 23:01:09,851 - INFO - [Step=46500]	Loss=0.6714	275.3 examples/second
2022-01-18 23:03:06,052 - INFO - [Step=46750]	Loss=0.6861	275.4 examples/second
2022-01-18 23:03:18,240 - INFO - Test Loss=0.8512, Test top-1 acc=0.7937
2022-01-18 23:03:18,240 - INFO - Group Accuracy:

2022-01-18 23:03:18,240 - INFO - [0.97903615 0.9901205  0.9840964  0.99373496 0.9819277  0.9939759
 0.9804819  0.9814458  0.9881928  0.9775904  0.9891566  0.98433733
 0.9737349  0.97927713 0.97638553 0.98698795 0.9961446 ]
2022-01-18 23:03:18,241 - INFO - Epoch time: 397.6083106994629
2022-01-18 23:03:18,241 - INFO - 
Epoch: 56
2022-01-18 23:03:18,241 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:05:11,917 - INFO - [Step=47000]	Loss=0.6608	254.2 examples/second
2022-01-18 23:07:07,847 - INFO - [Step=47250]	Loss=0.6734	276.0 examples/second
2022-01-18 23:09:03,906 - INFO - [Step=47500]	Loss=0.6744	275.7 examples/second
2022-01-18 23:09:55,764 - INFO - Test Loss=0.8725, Test top-1 acc=0.7933
2022-01-18 23:09:55,764 - INFO - Group Accuracy:

2022-01-18 23:09:55,764 - INFO - [0.9785542  0.9901205  0.9840964  0.9913253  0.98361444 0.993253
 0.97927713 0.98       0.9891566  0.97518075 0.99108434 0.98433733
 0.97831327 0.98024094 0.9742169  0.9879518  0.9954217 ]
2022-01-18 23:09:55,765 - INFO - Epoch time: 397.5242576599121
2022-01-18 23:09:55,765 - INFO - 
Epoch: 57
2022-01-18 23:09:55,765 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:11:09,735 - INFO - [Step=47750]	Loss=0.6640	254.3 examples/second
2022-01-18 23:13:04,985 - INFO - [Step=48000]	Loss=0.6665	277.7 examples/second
2022-01-18 23:15:00,349 - INFO - [Step=48250]	Loss=0.6657	277.4 examples/second
2022-01-18 23:16:31,477 - INFO - Test Loss=0.8429, Test top-1 acc=0.7983
2022-01-18 23:16:31,478 - INFO - Group Accuracy:

2022-01-18 23:16:31,478 - INFO - [0.97927713 0.99060243 0.9853012  0.9922892  0.98313254 0.9939759
 0.9816868  0.98313254 0.9898795  0.9768675  0.99108434 0.9860241
 0.9780723  0.98       0.9768675  0.9881928  0.9959036 ]
2022-01-18 23:16:31,479 - INFO - Epoch time: 395.71328997612
2022-01-18 23:16:31,479 - INFO - 
Epoch: 58
2022-01-18 23:16:31,479 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:17:06,200 - INFO - [Step=48500]	Loss=0.6718	254.3 examples/second
2022-01-18 23:19:01,907 - INFO - [Step=48750]	Loss=0.6542	276.6 examples/second
2022-01-18 23:20:57,251 - INFO - [Step=49000]	Loss=0.6515	277.4 examples/second
2022-01-18 23:22:52,781 - INFO - [Step=49250]	Loss=0.6717	277.0 examples/second
2022-01-18 23:23:07,488 - INFO - Test Loss=0.8630, Test top-1 acc=0.7964
2022-01-18 23:23:07,488 - INFO - Group Accuracy:

2022-01-18 23:23:07,488 - INFO - [0.97951806 0.9886747  0.9850602  0.9922892  0.98289156 0.99373496
 0.9804819  0.98313254 0.99036145 0.9771084  0.9889157  0.9848193
 0.9771084  0.9816868  0.9766265  0.9898795  0.9954217 ]
2022-01-18 23:23:07,489 - INFO - Epoch time: 396.0102255344391
2022-01-18 23:23:07,489 - INFO - 
Epoch: 59
2022-01-18 23:23:07,489 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:24:58,153 - INFO - [Step=49500]	Loss=0.6208	255.2 examples/second
2022-01-18 23:26:53,502 - INFO - [Step=49750]	Loss=0.5842	277.4 examples/second
2022-01-18 23:28:48,895 - INFO - [Step=50000]	Loss=0.5701	277.3 examples/second
2022-01-18 23:29:42,604 - INFO - Test Loss=0.7972, Test top-1 acc=0.8087
2022-01-18 23:29:42,605 - INFO - Group Accuracy:

2022-01-18 23:29:42,605 - INFO - [0.9816868  0.9913253  0.9850602  0.99373496 0.9845783  0.99373496
 0.98289156 0.98361444 0.99060243 0.9778313  0.99084336 0.98433733
 0.9780723  0.98289156 0.9775904  0.98963857 0.9956626 ]
2022-01-18 23:29:42,606 - INFO - Saving...
2022-01-18 23:29:42,834 - INFO - Epoch time: 395.3451006412506
2022-01-18 23:29:42,834 - INFO - 
Epoch: 60
2022-01-18 23:29:42,834 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:30:54,507 - INFO - [Step=50250]	Loss=0.5739	254.8 examples/second
2022-01-18 23:32:49,740 - INFO - [Step=50500]	Loss=0.5821	277.7 examples/second
2022-01-18 23:34:44,870 - INFO - [Step=50750]	Loss=0.5709	277.9 examples/second
2022-01-18 23:36:17,893 - INFO - Test Loss=0.7925, Test top-1 acc=0.8108
2022-01-18 23:36:17,894 - INFO - Group Accuracy:

2022-01-18 23:36:17,894 - INFO - [0.9812048  0.9913253  0.9850602  0.9930121  0.98361444 0.99421686
 0.9826506  0.98361444 0.99108434 0.9780723  0.99156624 0.9840964
 0.97927713 0.98313254 0.9775904  0.9901205  0.9959036 ]
2022-01-18 23:36:17,894 - INFO - Saving...
2022-01-18 23:36:18,081 - INFO - Epoch time: 395.2464134693146
2022-01-18 23:36:18,081 - INFO - 
Epoch: 61
2022-01-18 23:36:18,081 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:36:50,524 - INFO - [Step=51000]	Loss=0.5636	254.7 examples/second
2022-01-18 23:38:47,669 - INFO - [Step=51250]	Loss=0.5524	273.2 examples/second
2022-01-18 23:40:44,210 - INFO - [Step=51500]	Loss=0.5518	274.6 examples/second
2022-01-18 23:42:40,936 - INFO - [Step=51750]	Loss=0.5590	274.1 examples/second
2022-01-18 23:42:58,140 - INFO - Test Loss=0.7859, Test top-1 acc=0.8133
2022-01-18 23:42:58,140 - INFO - Group Accuracy:

2022-01-18 23:42:58,150 - INFO - [0.98240966 0.99108434 0.9845783  0.99421686 0.9845783  0.99445784
 0.9821687  0.98313254 0.99060243 0.9780723  0.9918072  0.9850602
 0.9787952  0.98240966 0.97831327 0.99108434 0.9956626 ]
2022-01-18 23:42:58,151 - INFO - Saving...
2022-01-18 23:42:58,346 - INFO - Epoch time: 400.2651710510254
2022-01-18 23:42:58,346 - INFO - 
Epoch: 62
2022-01-18 23:42:58,346 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:44:47,945 - INFO - [Step=52000]	Loss=0.5606	252.0 examples/second
2022-01-18 23:46:44,735 - INFO - [Step=52250]	Loss=0.5540	274.0 examples/second
2022-01-18 23:48:41,420 - INFO - [Step=52500]	Loss=0.5468	274.2 examples/second
2022-01-18 23:49:38,358 - INFO - Test Loss=0.7856, Test top-1 acc=0.8099
2022-01-18 23:49:38,358 - INFO - Group Accuracy:

2022-01-18 23:49:38,358 - INFO - [0.98240966 0.9913253  0.9850602  0.99421686 0.9838554  0.9939759
 0.98361444 0.98289156 0.9901205  0.9771084  0.9913253  0.9850602
 0.9785542  0.98313254 0.9778313  0.99036145 0.9961446 ]
2022-01-18 23:49:38,368 - INFO - Epoch time: 400.0214765071869
2022-01-18 23:49:38,368 - INFO - 
Epoch: 63
2022-01-18 23:49:38,368 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:50:47,730 - INFO - [Step=52750]	Loss=0.5511	253.3 examples/second
2022-01-18 23:52:42,989 - INFO - [Step=53000]	Loss=0.5473	277.6 examples/second
2022-01-18 23:54:38,249 - INFO - [Step=53250]	Loss=0.5429	277.6 examples/second
2022-01-18 23:56:13,429 - INFO - Test Loss=0.7908, Test top-1 acc=0.8111
2022-01-18 23:56:13,429 - INFO - Group Accuracy:

2022-01-18 23:56:13,429 - INFO - [0.9814458  0.99108434 0.9855422  0.993494   0.98433733 0.9939759
 0.9833735  0.98361444 0.9901205  0.9773494  0.9918072  0.9850602
 0.9787952  0.9819277  0.97927713 0.98963857 0.9963855 ]
2022-01-18 23:56:13,430 - INFO - Epoch time: 395.06161308288574
2022-01-18 23:56:13,430 - INFO - 
Epoch: 64
2022-01-18 23:56:13,430 - INFO - 
Learning Rate: 0.0010
2022-01-18 23:56:43,357 - INFO - [Step=53500]	Loss=0.5371	255.8 examples/second
2022-01-18 23:58:39,320 - INFO - [Step=53750]	Loss=0.5413	276.0 examples/second
2022-01-19 00:00:35,067 - INFO - [Step=54000]	Loss=0.5355	276.5 examples/second
2022-01-19 00:02:30,878 - INFO - [Step=54250]	Loss=0.5443	276.3 examples/second
2022-01-19 00:02:50,023 - INFO - Test Loss=0.7900, Test top-1 acc=0.8123
2022-01-19 00:02:50,023 - INFO - Group Accuracy:

2022-01-19 00:02:50,023 - INFO - [0.9826506  0.9918072  0.9848193  0.99421686 0.9838554  0.9946988
 0.98240966 0.98289156 0.98963857 0.97638553 0.9925301  0.9850602
 0.97831327 0.98289156 0.9787952  0.98963857 0.9963855 ]
2022-01-19 00:02:50,024 - INFO - Epoch time: 396.59417629241943
2022-01-19 00:02:50,024 - INFO - 
Epoch: 65
2022-01-19 00:02:50,024 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:04:36,809 - INFO - [Step=54500]	Loss=0.5329	254.1 examples/second
2022-01-19 00:06:32,980 - INFO - [Step=54750]	Loss=0.5303	275.5 examples/second
2022-01-19 00:08:28,915 - INFO - [Step=55000]	Loss=0.5419	276.0 examples/second
2022-01-19 00:09:27,851 - INFO - Test Loss=0.7895, Test top-1 acc=0.8111
2022-01-19 00:09:27,852 - INFO - Group Accuracy:

2022-01-19 00:09:27,852 - INFO - [0.9816868  0.9918072  0.98433733 0.993494   0.98313254 0.99445784
 0.98240966 0.9821687  0.9901205  0.9771084  0.9925301  0.98433733
 0.9780723  0.98289156 0.9787952  0.9893976  0.9968675 ]
2022-01-19 00:09:27,853 - INFO - Epoch time: 397.8288960456848
2022-01-19 00:09:27,853 - INFO - 
Epoch: 66
2022-01-19 00:09:27,853 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:10:35,049 - INFO - [Step=55250]	Loss=0.5290	253.7 examples/second
2022-01-19 00:12:31,736 - INFO - [Step=55500]	Loss=0.5380	274.2 examples/second
2022-01-19 00:14:28,453 - INFO - [Step=55750]	Loss=0.5349	274.2 examples/second
2022-01-19 00:16:07,140 - INFO - Test Loss=0.7900, Test top-1 acc=0.8120
2022-01-19 00:16:07,141 - INFO - Group Accuracy:

2022-01-19 00:16:07,141 - INFO - [0.9812048  0.9925301  0.9848193  0.993253   0.98361444 0.9939759
 0.9826506  0.98361444 0.99060243 0.9771084  0.99156624 0.9845783
 0.9785542  0.98289156 0.97903615 0.9898795  0.9966265 ]
2022-01-19 00:16:07,142 - INFO - Epoch time: 399.2888581752777
2022-01-19 00:16:07,142 - INFO - 
Epoch: 67
2022-01-19 00:16:07,142 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:16:35,101 - INFO - [Step=56000]	Loss=0.5307	252.7 examples/second
2022-01-19 00:18:31,739 - INFO - [Step=56250]	Loss=0.5160	274.4 examples/second
2022-01-19 00:20:28,428 - INFO - [Step=56500]	Loss=0.5375	274.2 examples/second
2022-01-19 00:22:25,241 - INFO - [Step=56750]	Loss=0.5263	273.9 examples/second
2022-01-19 00:22:46,831 - INFO - Test Loss=0.7876, Test top-1 acc=0.8118
2022-01-19 00:22:46,832 - INFO - Group Accuracy:

2022-01-19 00:22:46,832 - INFO - [0.9821687  0.9920482  0.9855422  0.9939759  0.98361444 0.99421686
 0.9838554  0.98240966 0.9898795  0.9773494  0.9925301  0.9845783
 0.97831327 0.9826506  0.97927713 0.9901205  0.9968675 ]
2022-01-19 00:22:46,833 - INFO - Epoch time: 399.6909353733063
2022-01-19 00:22:46,833 - INFO - 
Epoch: 68
2022-01-19 00:22:46,833 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:24:30,879 - INFO - [Step=57000]	Loss=0.5322	254.7 examples/second
2022-01-19 00:26:26,390 - INFO - [Step=57250]	Loss=0.5321	277.0 examples/second
2022-01-19 00:28:21,750 - INFO - [Step=57500]	Loss=0.5288	277.4 examples/second
2022-01-19 00:29:22,811 - INFO - Test Loss=0.7929, Test top-1 acc=0.8113
2022-01-19 00:29:22,811 - INFO - Group Accuracy:

2022-01-19 00:29:22,811 - INFO - [0.9814458  0.9913253  0.98578316 0.9939759  0.9840964  0.99421686
 0.98289156 0.9821687  0.9901205  0.9766265  0.9925301  0.9853012
 0.9785542  0.98313254 0.97927713 0.9901205  0.9968675 ]
2022-01-19 00:29:22,812 - INFO - Epoch time: 395.9787051677704
2022-01-19 00:29:22,812 - INFO - 
Epoch: 69
2022-01-19 00:29:22,812 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:30:27,411 - INFO - [Step=57750]	Loss=0.5373	254.7 examples/second
2022-01-19 00:32:22,834 - INFO - [Step=58000]	Loss=0.5302	277.2 examples/second
2022-01-19 00:34:18,187 - INFO - [Step=58250]	Loss=0.5262	277.4 examples/second
2022-01-19 00:35:58,661 - INFO - Test Loss=0.7866, Test top-1 acc=0.8113
2022-01-19 00:35:58,661 - INFO - Group Accuracy:

2022-01-19 00:35:58,661 - INFO - [0.9812048  0.99108434 0.98626506 0.9939759  0.9821687  0.99445784
 0.98289156 0.9826506  0.9893976  0.9768675  0.9920482  0.9850602
 0.97831327 0.9833735  0.97903615 0.9898795  0.9966265 ]
2022-01-19 00:35:58,662 - INFO - Epoch time: 395.85076117515564
2022-01-19 00:35:58,662 - INFO - 
Epoch: 70
2022-01-19 00:35:58,663 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:36:24,500 - INFO - [Step=58500]	Loss=0.5171	253.3 examples/second
2022-01-19 00:38:20,431 - INFO - [Step=58750]	Loss=0.5119	276.0 examples/second
2022-01-19 00:40:16,397 - INFO - [Step=59000]	Loss=0.5208	275.9 examples/second
2022-01-19 00:42:12,366 - INFO - [Step=59250]	Loss=0.5279	275.9 examples/second
2022-01-19 00:42:36,514 - INFO - Test Loss=0.7955, Test top-1 acc=0.8089
2022-01-19 00:42:36,515 - INFO - Group Accuracy:

2022-01-19 00:42:36,515 - INFO - [0.98024094 0.99084336 0.9853012  0.9927711  0.9840964  0.99421686
 0.98240966 0.9819277  0.9901205  0.97614455 0.9922892  0.9845783
 0.97903615 0.98361444 0.97927713 0.9901205  0.9968675 ]
2022-01-19 00:42:36,515 - INFO - Epoch time: 397.85299587249756
2022-01-19 00:42:36,516 - INFO - 
Epoch: 71
2022-01-19 00:42:36,516 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:44:17,940 - INFO - [Step=59500]	Loss=0.5196	254.8 examples/second
2022-01-19 00:46:13,146 - INFO - [Step=59750]	Loss=0.5171	277.8 examples/second
2022-01-19 00:48:08,419 - INFO - [Step=60000]	Loss=0.5156	277.6 examples/second
2022-01-19 00:49:12,126 - INFO - Test Loss=0.7881, Test top-1 acc=0.8145
2022-01-19 00:49:12,126 - INFO - Group Accuracy:

2022-01-19 00:49:12,126 - INFO - [0.9814458  0.99084336 0.98626506 0.993253   0.9833735  0.9939759
 0.98361444 0.98240966 0.9901205  0.9773494  0.9913253  0.9855422
 0.97831327 0.9838554  0.97903615 0.99036145 0.9961446 ]
2022-01-19 00:49:12,127 - INFO - Saving...
2022-01-19 00:49:12,407 - INFO - Epoch time: 395.89137530326843
2022-01-19 00:49:12,407 - INFO - 
Epoch: 72
2022-01-19 00:49:12,407 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:50:14,516 - INFO - [Step=60250]	Loss=0.5203	253.8 examples/second
2022-01-19 00:52:09,677 - INFO - [Step=60500]	Loss=0.5221	277.9 examples/second
2022-01-19 00:54:05,002 - INFO - [Step=60750]	Loss=0.5181	277.5 examples/second
2022-01-19 00:55:47,319 - INFO - Test Loss=0.7882, Test top-1 acc=0.8123
2022-01-19 00:55:47,320 - INFO - Group Accuracy:

2022-01-19 00:55:47,320 - INFO - [0.9809638  0.99108434 0.98578316 0.993494   0.9838554  0.99421686
 0.9833735  0.9819277  0.99060243 0.9766265  0.9925301  0.9853012
 0.9787952  0.9838554  0.9785542  0.98963857 0.9966265 ]
2022-01-19 00:55:47,321 - INFO - Epoch time: 394.9136803150177
2022-01-19 00:55:47,321 - INFO - 
Epoch: 73
2022-01-19 00:55:47,321 - INFO - 
Learning Rate: 0.0010
2022-01-19 00:56:10,461 - INFO - [Step=61000]	Loss=0.5230	255.1 examples/second
2022-01-19 00:58:06,232 - INFO - [Step=61250]	Loss=0.5111	276.4 examples/second
2022-01-19 01:00:02,104 - INFO - [Step=61500]	Loss=0.5247	276.2 examples/second
2022-01-19 01:01:58,086 - INFO - [Step=61750]	Loss=0.5133	275.9 examples/second
2022-01-19 01:02:24,640 - INFO - Test Loss=0.7948, Test top-1 acc=0.8092
2022-01-19 01:02:24,640 - INFO - Group Accuracy:

2022-01-19 01:02:24,640 - INFO - [0.98024094 0.9920482  0.98626506 0.99373496 0.98289156 0.99421686
 0.98361444 0.9816868  0.9901205  0.97614455 0.9913253  0.98578316
 0.9773494  0.98289156 0.97951806 0.99060243 0.9963855 ]
2022-01-19 01:02:24,641 - INFO - Epoch time: 397.32051277160645
2022-01-19 01:02:24,642 - INFO - 
Epoch: 74
2022-01-19 01:02:24,642 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:04:04,238 - INFO - [Step=62000]	Loss=0.5229	253.7 examples/second
2022-01-19 01:05:59,798 - INFO - [Step=62250]	Loss=0.5051	276.9 examples/second
2022-01-19 01:07:55,556 - INFO - [Step=62500]	Loss=0.5085	276.4 examples/second
2022-01-19 01:09:01,037 - INFO - Test Loss=0.7985, Test top-1 acc=0.8116
2022-01-19 01:09:01,037 - INFO - Group Accuracy:

2022-01-19 01:09:01,037 - INFO - [0.9814458  0.9913253  0.9850602  0.993494   0.98361444 0.9939759
 0.98313254 0.98240966 0.9901205  0.9766265  0.99156624 0.9850602
 0.97831327 0.9826506  0.97975904 0.9898795  0.9961446 ]
2022-01-19 01:09:01,038 - INFO - Epoch time: 396.39657950401306
2022-01-19 01:09:01,038 - INFO - 
Epoch: 75
2022-01-19 01:09:01,038 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:10:01,572 - INFO - [Step=62750]	Loss=0.5117	253.9 examples/second
2022-01-19 01:11:58,383 - INFO - [Step=63000]	Loss=0.5041	274.0 examples/second
2022-01-19 01:13:55,131 - INFO - [Step=63250]	Loss=0.5271	274.1 examples/second
2022-01-19 01:15:40,718 - INFO - Test Loss=0.7947, Test top-1 acc=0.8108
2022-01-19 01:15:40,718 - INFO - Group Accuracy:

2022-01-19 01:15:40,719 - INFO - [0.9819277  0.9920482  0.98578316 0.9939759  0.9840964  0.99421686
 0.9819277  0.98289156 0.99036145 0.9773494  0.9922892  0.9848193
 0.9780723  0.98313254 0.9785542  0.99060243 0.9963855 ]
2022-01-19 01:15:40,719 - INFO - Epoch time: 399.68114948272705
2022-01-19 01:15:40,719 - INFO - 
Epoch: 76
2022-01-19 01:15:40,720 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:16:01,363 - INFO - [Step=63500]	Loss=0.5162	253.5 examples/second
2022-01-19 01:17:56,505 - INFO - [Step=63750]	Loss=0.5055	277.9 examples/second
2022-01-19 01:19:51,899 - INFO - [Step=64000]	Loss=0.5165	277.3 examples/second
2022-01-19 01:21:47,279 - INFO - [Step=64250]	Loss=0.4985	277.3 examples/second
2022-01-19 01:22:16,037 - INFO - Test Loss=0.7914, Test top-1 acc=0.8130
2022-01-19 01:22:16,037 - INFO - Group Accuracy:

2022-01-19 01:22:16,037 - INFO - [0.9819277  0.9918072  0.98650604 0.9939759  0.9838554  0.99493974
 0.98289156 0.9816868  0.99084336 0.9766265  0.9918072  0.9840964
 0.9780723  0.9840964  0.98024094 0.99108434 0.9963855 ]
2022-01-19 01:22:16,038 - INFO - Epoch time: 395.31860160827637
2022-01-19 01:22:16,038 - INFO - 
Epoch: 77
2022-01-19 01:22:16,038 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:23:53,262 - INFO - [Step=64500]	Loss=0.5008	254.0 examples/second
2022-01-19 01:25:49,546 - INFO - [Step=64750]	Loss=0.5169	275.2 examples/second
2022-01-19 01:27:45,913 - INFO - [Step=65000]	Loss=0.4920	275.0 examples/second
2022-01-19 01:28:54,101 - INFO - Test Loss=0.7911, Test top-1 acc=0.8130
2022-01-19 01:28:54,101 - INFO - Group Accuracy:

2022-01-19 01:28:54,102 - INFO - [0.9821687  0.99084336 0.9855422  0.99421686 0.98289156 0.9951807
 0.9821687  0.9821687  0.99060243 0.9766265  0.9920482  0.9850602
 0.9785542  0.9840964  0.97927713 0.9893976  0.9961446 ]
2022-01-19 01:28:54,102 - INFO - Epoch time: 398.0641474723816
2022-01-19 01:28:54,102 - INFO - 
Epoch: 78
2022-01-19 01:28:54,102 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:29:51,743 - INFO - [Step=65250]	Loss=0.5016	254.3 examples/second
2022-01-19 01:31:47,770 - INFO - [Step=65500]	Loss=0.5169	275.8 examples/second
2022-01-19 01:33:43,694 - INFO - [Step=65750]	Loss=0.5010	276.0 examples/second
2022-01-19 01:35:31,093 - INFO - Test Loss=0.8008, Test top-1 acc=0.8070
2022-01-19 01:35:31,094 - INFO - Group Accuracy:

2022-01-19 01:35:31,094 - INFO - [0.9807229  0.99060243 0.9855422  0.99421686 0.98289156 0.99445784
 0.9821687  0.98240966 0.9901205  0.97542167 0.9913253  0.9850602
 0.9780723  0.98313254 0.97975904 0.99036145 0.9961446 ]
2022-01-19 01:35:31,095 - INFO - Epoch time: 396.9921383857727
2022-01-19 01:35:31,095 - INFO - 
Epoch: 79
2022-01-19 01:35:31,095 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:35:49,317 - INFO - [Step=66000]	Loss=0.5055	254.7 examples/second
2022-01-19 01:37:44,762 - INFO - [Step=66250]	Loss=0.4949	277.2 examples/second
2022-01-19 01:39:40,452 - INFO - [Step=66500]	Loss=0.5018	276.6 examples/second
2022-01-19 01:41:36,140 - INFO - [Step=66750]	Loss=0.5129	276.6 examples/second
2022-01-19 01:42:07,065 - INFO - Test Loss=0.8058, Test top-1 acc=0.8106
2022-01-19 01:42:07,066 - INFO - Group Accuracy:

2022-01-19 01:42:07,075 - INFO - [0.98       0.99108434 0.9855422  0.99445784 0.98289156 0.99445784
 0.9833735  0.98240966 0.9901205  0.9766265  0.9920482  0.98433733
 0.9775904  0.98361444 0.9787952  0.99060243 0.9963855 ]
2022-01-19 01:42:07,076 - INFO - Epoch time: 395.9811999797821
2022-01-19 01:42:07,076 - INFO - 
Epoch: 80
2022-01-19 01:42:07,076 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:43:41,785 - INFO - [Step=67000]	Loss=0.5031	254.7 examples/second
2022-01-19 01:45:37,130 - INFO - [Step=67250]	Loss=0.4936	277.4 examples/second
2022-01-19 01:47:32,739 - INFO - [Step=67500]	Loss=0.4986	276.8 examples/second
2022-01-19 01:48:42,613 - INFO - Test Loss=0.8022, Test top-1 acc=0.8106
2022-01-19 01:48:42,613 - INFO - Group Accuracy:

2022-01-19 01:48:42,613 - INFO - [0.9807229  0.99084336 0.9850602  0.99445784 0.9840964  0.99445784
 0.9833735  0.9826506  0.99060243 0.9771084  0.9918072  0.9853012
 0.9773494  0.98313254 0.97927713 0.99156624 0.9963855 ]
2022-01-19 01:48:42,614 - INFO - Epoch time: 395.53831911087036
2022-01-19 01:48:42,614 - INFO - 
Epoch: 81
2022-01-19 01:48:42,614 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:49:38,577 - INFO - [Step=67750]	Loss=0.5021	254.3 examples/second
2022-01-19 01:51:35,314 - INFO - [Step=68000]	Loss=0.4956	274.1 examples/second
2022-01-19 01:53:31,978 - INFO - [Step=68250]	Loss=0.4872	274.3 examples/second
2022-01-19 01:55:21,808 - INFO - Test Loss=0.8020, Test top-1 acc=0.8116
2022-01-19 01:55:21,809 - INFO - Group Accuracy:

2022-01-19 01:55:21,809 - INFO - [0.9814458  0.9901205  0.9853012  0.9939759  0.9838554  0.99445784
 0.9826506  0.98240966 0.9901205  0.9785542  0.9918072  0.9855422
 0.9785542  0.98240966 0.97951806 0.9893976  0.9966265 ]
2022-01-19 01:55:21,810 - INFO - Epoch time: 399.19554018974304
2022-01-19 01:55:21,810 - INFO - 
Epoch: 82
2022-01-19 01:55:21,810 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:55:38,003 - INFO - [Step=68500]	Loss=0.4959	253.9 examples/second
2022-01-19 01:57:34,557 - INFO - [Step=68750]	Loss=0.4961	274.6 examples/second
2022-01-19 01:59:31,155 - INFO - [Step=69000]	Loss=0.4913	274.4 examples/second
2022-01-19 02:01:27,803 - INFO - [Step=69250]	Loss=0.4955	274.3 examples/second
2022-01-19 02:02:01,448 - INFO - Test Loss=0.7994, Test top-1 acc=0.8113
2022-01-19 02:02:01,449 - INFO - Group Accuracy:

2022-01-19 02:02:01,449 - INFO - [0.9809638  0.99108434 0.98578316 0.99421686 0.9838554  0.9946988
 0.9821687  0.9816868  0.99060243 0.9768675  0.99108434 0.9850602
 0.9780723  0.9833735  0.9785542  0.99084336 0.9968675 ]
2022-01-19 02:02:01,449 - INFO - Epoch time: 399.63958263397217
2022-01-19 02:02:01,450 - INFO - 
Epoch: 83
2022-01-19 02:02:01,450 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:03:33,401 - INFO - [Step=69500]	Loss=0.4828	254.8 examples/second
2022-01-19 02:05:28,495 - INFO - [Step=69750]	Loss=0.4941	278.0 examples/second
2022-01-19 02:07:23,862 - INFO - [Step=70000]	Loss=0.4909	277.4 examples/second
2022-01-19 02:08:35,991 - INFO - Test Loss=0.7991, Test top-1 acc=0.8077
2022-01-19 02:08:35,991 - INFO - Group Accuracy:

2022-01-19 02:08:35,991 - INFO - [0.9812048  0.99108434 0.98578316 0.9939759  0.9816868  0.99373496
 0.9826506  0.9816868  0.9898795  0.9771084  0.99108434 0.9845783
 0.9787952  0.9826506  0.97903615 0.99060243 0.9963855 ]
2022-01-19 02:08:35,992 - INFO - Epoch time: 394.54220509529114
2022-01-19 02:08:35,992 - INFO - 
Epoch: 84
2022-01-19 02:08:35,992 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:09:29,261 - INFO - [Step=70250]	Loss=0.4957	255.2 examples/second
2022-01-19 02:11:25,797 - INFO - [Step=70500]	Loss=0.4907	274.6 examples/second
2022-01-19 02:13:22,625 - INFO - [Step=70750]	Loss=0.4975	273.9 examples/second
2022-01-19 02:15:15,276 - INFO - Test Loss=0.7990, Test top-1 acc=0.8094
2022-01-19 02:15:15,277 - INFO - Group Accuracy:

2022-01-19 02:15:15,277 - INFO - [0.9812048  0.9913253  0.9855422  0.99373496 0.98289156 0.99421686
 0.9826506  0.9821687  0.9898795  0.97638553 0.9913253  0.9850602
 0.9787952  0.9826506  0.97831327 0.99084336 0.9966265 ]
2022-01-19 02:15:15,278 - INFO - Epoch time: 399.2858076095581
2022-01-19 02:15:15,278 - INFO - 
Epoch: 85
2022-01-19 02:15:15,278 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:15:29,243 - INFO - [Step=71000]	Loss=0.4945	252.7 examples/second
2022-01-19 02:17:24,487 - INFO - [Step=71250]	Loss=0.4863	277.7 examples/second
2022-01-19 02:19:19,953 - INFO - [Step=71500]	Loss=0.4919	277.1 examples/second
2022-01-19 02:21:15,292 - INFO - [Step=71750]	Loss=0.4873	277.4 examples/second
2022-01-19 02:21:50,662 - INFO - Test Loss=0.8068, Test top-1 acc=0.8104
2022-01-19 02:21:50,662 - INFO - Group Accuracy:

2022-01-19 02:21:50,663 - INFO - [0.9814458  0.9918072  0.9850602  0.99373496 0.9838554  0.99445784
 0.98313254 0.9826506  0.9898795  0.9766265  0.99108434 0.9848193
 0.97927713 0.98240966 0.97903615 0.99084336 0.9961446 ]
2022-01-19 02:21:50,663 - INFO - Epoch time: 395.38546776771545
2022-01-19 02:21:50,663 - INFO - 
Epoch: 86
2022-01-19 02:21:50,663 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:23:20,232 - INFO - [Step=72000]	Loss=0.5020	256.1 examples/second
2022-01-19 02:25:15,251 - INFO - [Step=72250]	Loss=0.4911	278.2 examples/second
2022-01-19 02:27:10,668 - INFO - [Step=72500]	Loss=0.4914	277.3 examples/second
2022-01-19 02:28:25,193 - INFO - Test Loss=0.8064, Test top-1 acc=0.8080
2022-01-19 02:28:25,193 - INFO - Group Accuracy:

2022-01-19 02:28:25,193 - INFO - [0.9812048  0.9918072  0.9850602  0.993494   0.9833735  0.99421686
 0.98313254 0.9816868  0.9898795  0.97638553 0.9920482  0.9840964
 0.97903615 0.98240966 0.9785542  0.9891566  0.9961446 ]
2022-01-19 02:28:25,194 - INFO - Epoch time: 394.5308129787445
2022-01-19 02:28:25,194 - INFO - 
Epoch: 87
2022-01-19 02:28:25,194 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:29:16,363 - INFO - [Step=72750]	Loss=0.4888	254.6 examples/second
2022-01-19 02:31:12,817 - INFO - [Step=73000]	Loss=0.4914	274.8 examples/second
2022-01-19 02:33:09,600 - INFO - [Step=73250]	Loss=0.4820	274.0 examples/second
2022-01-19 02:35:05,150 - INFO - Test Loss=0.8011, Test top-1 acc=0.8118
2022-01-19 02:35:05,150 - INFO - Group Accuracy:

2022-01-19 02:35:05,150 - INFO - [0.9821687  0.9925301  0.9860241  0.9939759  0.98240966 0.99445784
 0.9826506  0.9816868  0.9898795  0.9768675  0.9920482  0.9838554
 0.97951806 0.98313254 0.9785542  0.9901205  0.9963855 ]
2022-01-19 02:35:05,151 - INFO - Epoch time: 399.95692348480225
2022-01-19 02:35:05,151 - INFO - 
Epoch: 88
2022-01-19 02:35:05,151 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:35:17,004 - INFO - [Step=73500]	Loss=0.4967	251.2 examples/second
2022-01-19 02:37:12,325 - INFO - [Step=73750]	Loss=0.4902	277.5 examples/second
2022-01-19 02:39:08,003 - INFO - [Step=74000]	Loss=0.4872	276.6 examples/second
2022-01-19 02:41:03,271 - INFO - [Step=74250]	Loss=0.4838	277.6 examples/second
2022-01-19 02:41:40,896 - INFO - Test Loss=0.8084, Test top-1 acc=0.8087
2022-01-19 02:41:40,896 - INFO - Group Accuracy:

2022-01-19 02:41:40,896 - INFO - [0.9821687  0.9918072  0.9848193  0.99373496 0.9833735  0.99445784
 0.98240966 0.9821687  0.9901205  0.97614455 0.99156624 0.9840964
 0.98       0.98313254 0.97831327 0.98963857 0.9961446 ]
2022-01-19 02:41:40,897 - INFO - Epoch time: 395.7456650733948
2022-01-19 02:41:40,897 - INFO - 
Epoch: 89
2022-01-19 02:41:40,897 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:43:08,962 - INFO - [Step=74500]	Loss=0.4904	254.6 examples/second
2022-01-19 02:45:05,587 - INFO - [Step=74750]	Loss=0.4872	274.4 examples/second
2022-01-19 02:47:02,179 - INFO - [Step=75000]	Loss=0.4791	274.5 examples/second
2022-01-19 02:48:20,036 - INFO - Test Loss=0.8123, Test top-1 acc=0.8092
2022-01-19 02:48:20,036 - INFO - Group Accuracy:

2022-01-19 02:48:20,036 - INFO - [0.9814458  0.9918072  0.9850602  0.99373496 0.9833735  0.9946988
 0.9821687  0.98240966 0.99060243 0.9768675  0.99084336 0.98433733
 0.97831327 0.9833735  0.9785542  0.9901205  0.9963855 ]
2022-01-19 02:48:20,037 - INFO - Epoch time: 399.14035844802856
2022-01-19 02:48:31,434 - INFO - Computing OOD Statistics...
2022-01-19 02:48:31,446 - INFO - 	Baseline.          AUROC: 0.4447. TNR@95TPR: 0.0235. AUPR OUT: 0.1473
2022-01-19 02:48:31,455 - INFO - 	ODIN (T=1000).     AUROC: 0.9040. TNR@95TPR: 0.5529. AUPR OUT: 0.6652
2022-01-19 02:48:31,456 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 02:48:31,456 - INFO - Top 1 Accuracy:  Min: 0.8145; Max: 0.8145; Avg: 0.8145; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - Top 5 Accuracy:  Min: 0.9863; Max: 0.9863; Avg: 0.9863; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - **********************************************************************
2022-01-19 02:48:31,456 - INFO - 	MSP (auroc): [0.4447192062367116] Min: 0.4447; Max: 0.4447; Avg: 0.4447; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - 	MSP (tnr): [0.02352941176470591] Min: 0.0235; Max: 0.0235; Avg: 0.0235; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - 	MSP (aupr): [0.14733448908115593] Min: 0.1473; Max: 0.1473; Avg: 0.1473; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - 	ODIN (auroc): [0.9039793054571226] Min: 0.9040; Max: 0.9040; Avg: 0.9040; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - 	ODIN (tnr): [0.5529411764705883] Min: 0.5529; Max: 0.5529; Avg: 0.5529; Std: 0.0000; Len: 1
2022-01-19 02:48:31,456 - INFO - 	ODIN (aupr): [0.6652029917559553] Min: 0.6652; Max: 0.6652; Avg: 0.6652; Std: 0.0000; Len: 1

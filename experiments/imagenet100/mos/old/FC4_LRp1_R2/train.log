2022-01-19 15:17:06,683 - INFO - ==> Preparing data..
2022-01-19 15:17:07,055 - INFO - checkpoint filename: experiments/coarse/mos/FC4_LRp1_R2/checkpoint.pt
2022-01-19 15:17:07,055 - INFO - log filename: experiments/coarse/mos/FC4_LRp1_R2/train.log
2022-01-19 15:17:07,055 - INFO - ********************************************************
2022-01-19 15:17:07,055 - INFO - Starting Iter: 0 / 1
2022-01-19 15:17:07,055 - INFO - ********************************************************
2022-01-19 15:17:10,167 - INFO - cuda
2022-01-19 15:17:10,217 - INFO - 
Epoch: 0
2022-01-19 15:17:10,217 - INFO - 
Learning Rate: 0.0100
2022-01-19 15:19:08,069 - INFO - [Step=250]	Loss=7.1678	271.5 examples/second
2022-01-19 15:21:04,507 - INFO - [Step=500]	Loss=5.5616	274.8 examples/second
2022-01-19 15:23:01,196 - INFO - [Step=750]	Loss=5.3873	274.2 examples/second
2022-01-19 15:23:47,867 - INFO - Test Loss=5.3195, Test top-1 acc=0.0349
2022-01-19 15:23:47,867 - INFO - Group Accuracy:

2022-01-19 15:23:47,867 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-19 15:23:47,868 - INFO - Saving...
2022-01-19 15:23:48,001 - INFO - Epoch time: 397.7835156917572
2022-01-19 15:23:48,001 - INFO - 
Epoch: 1
2022-01-19 15:23:48,001 - INFO - 
Learning Rate: 0.0280
2022-01-19 15:25:06,269 - INFO - [Step=1000]	Loss=5.2778	255.9 examples/second
2022-01-19 15:27:02,470 - INFO - [Step=1250]	Loss=5.0481	275.4 examples/second
2022-01-19 15:28:58,708 - INFO - [Step=1500]	Loss=4.8265	275.3 examples/second
2022-01-19 15:30:24,655 - INFO - Test Loss=4.7048, Test top-1 acc=0.1241
2022-01-19 15:30:24,655 - INFO - Group Accuracy:

2022-01-19 15:30:24,655 - INFO - [0.939759   0.9395181  0.939759   0.9438554  0.939759   0.940241
 0.939759   0.939759   0.939759   0.9395181  0.9518072  0.939759
 0.939759   0.939759   0.9392771  0.939759   0.95301205]
2022-01-19 15:30:24,656 - INFO - Saving...
2022-01-19 15:30:24,904 - INFO - Epoch time: 396.9027681350708
2022-01-19 15:30:24,904 - INFO - 
Epoch: 2
2022-01-19 15:30:24,904 - INFO - 
Learning Rate: 0.0460
2022-01-19 15:31:03,881 - INFO - [Step=1750]	Loss=4.6996	255.6 examples/second
2022-01-19 15:33:01,235 - INFO - [Step=2000]	Loss=4.5487	272.7 examples/second
2022-01-19 15:34:58,567 - INFO - [Step=2250]	Loss=4.3510	272.7 examples/second
2022-01-19 15:36:56,186 - INFO - [Step=2500]	Loss=4.1586	272.1 examples/second
2022-01-19 15:37:05,537 - INFO - Test Loss=3.8984, Test top-1 acc=0.2347
2022-01-19 15:37:05,538 - INFO - Group Accuracy:

2022-01-19 15:37:05,538 - INFO - [0.94192773 0.94216865 0.9404819  0.9515663  0.94168675 0.94626504
 0.94289154 0.9433735  0.9486747  0.93903613 0.9513253  0.9404819
 0.94       0.93903613 0.940241   0.9404819  0.95373493]
2022-01-19 15:37:05,539 - INFO - Saving...
2022-01-19 15:37:05,796 - INFO - Epoch time: 400.89169096946716
2022-01-19 15:37:05,796 - INFO - 
Epoch: 3
2022-01-19 15:37:05,796 - INFO - 
Learning Rate: 0.0640
2022-01-19 15:39:00,484 - INFO - [Step=2750]	Loss=4.0792	257.4 examples/second
2022-01-19 15:40:56,420 - INFO - [Step=3000]	Loss=3.9432	276.0 examples/second
2022-01-19 15:42:52,523 - INFO - [Step=3250]	Loss=3.7951	275.6 examples/second
2022-01-19 15:43:41,408 - INFO - Test Loss=3.5773, Test top-1 acc=0.2990
2022-01-19 15:43:41,409 - INFO - Group Accuracy:

2022-01-19 15:43:41,416 - INFO - [0.9440964  0.94939756 0.94096386 0.9551807  0.9436145  0.9559036
 0.94289154 0.9436145  0.9481928  0.94168675 0.9554217  0.94168675
 0.94120485 0.9407229  0.9407229  0.94240963 0.9590362 ]
2022-01-19 15:43:41,417 - INFO - Saving...
2022-01-19 15:43:41,661 - INFO - Epoch time: 395.8648293018341
2022-01-19 15:43:41,661 - INFO - 
Epoch: 4
2022-01-19 15:43:41,661 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:44:58,388 - INFO - [Step=3500]	Loss=3.7252	254.2 examples/second
2022-01-19 15:46:55,659 - INFO - [Step=3750]	Loss=3.6085	272.9 examples/second
2022-01-19 15:48:53,073 - INFO - [Step=4000]	Loss=3.4848	272.5 examples/second
2022-01-19 15:50:22,218 - INFO - Test Loss=3.2411, Test top-1 acc=0.3378
2022-01-19 15:50:22,219 - INFO - Group Accuracy:

2022-01-19 15:50:22,219 - INFO - [0.9431325  0.9498795  0.94120485 0.96       0.94120485 0.96024096
 0.9359036  0.9515663  0.9583132  0.9426506  0.95349395 0.9426506
 0.9407229  0.9433735  0.9426506  0.94891566 0.9657831 ]
2022-01-19 15:50:22,220 - INFO - Saving...
2022-01-19 15:50:22,457 - INFO - Epoch time: 400.7959794998169
2022-01-19 15:50:22,457 - INFO - 
Epoch: 5
2022-01-19 15:50:22,457 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:50:59,047 - INFO - [Step=4250]	Loss=3.3618	254.0 examples/second
2022-01-19 15:52:56,283 - INFO - [Step=4500]	Loss=3.2344	273.0 examples/second
2022-01-19 15:54:53,674 - INFO - [Step=4750]	Loss=3.1042	272.6 examples/second
2022-01-19 15:56:51,244 - INFO - [Step=5000]	Loss=3.0315	272.2 examples/second
2022-01-19 15:57:02,957 - INFO - Test Loss=2.8998, Test top-1 acc=0.4070
2022-01-19 15:57:02,958 - INFO - Group Accuracy:

2022-01-19 15:57:02,958 - INFO - [0.94843376 0.9580723  0.9479518  0.96361446 0.9474699  0.9701205
 0.9472289  0.9474699  0.96361446 0.946747   0.9590362  0.9448193
 0.939759   0.9431325  0.94506025 0.9498795  0.96891564]
2022-01-19 15:57:02,959 - INFO - Saving...
2022-01-19 15:57:03,200 - INFO - Epoch time: 400.7424280643463
2022-01-19 15:57:03,200 - INFO - 
Epoch: 6
2022-01-19 15:57:03,200 - INFO - 
Learning Rate: 0.1000
2022-01-19 15:58:56,596 - INFO - [Step=5250]	Loss=2.9238	255.3 examples/second
2022-01-19 16:00:53,833 - INFO - [Step=5500]	Loss=2.8634	273.0 examples/second
2022-01-19 16:02:51,297 - INFO - [Step=5750]	Loss=2.7891	272.4 examples/second
2022-01-19 16:03:43,030 - INFO - Test Loss=2.6551, Test top-1 acc=0.4463
2022-01-19 16:03:43,030 - INFO - Group Accuracy:

2022-01-19 16:03:43,030 - INFO - [0.9508434  0.96168673 0.9501205  0.9696385  0.946506   0.9725301
 0.94963855 0.9561446  0.966506   0.9498795  0.95975906 0.9515663
 0.94192773 0.94891566 0.9479518  0.9515663  0.9766265 ]
2022-01-19 16:03:43,031 - INFO - Saving...
2022-01-19 16:03:43,268 - INFO - Epoch time: 400.0680568218231
2022-01-19 16:03:43,268 - INFO - 
Epoch: 7
2022-01-19 16:03:43,268 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:04:56,738 - INFO - [Step=6000]	Loss=2.7197	255.1 examples/second
2022-01-19 16:06:52,359 - INFO - [Step=6250]	Loss=2.6484	276.8 examples/second
2022-01-19 16:08:48,423 - INFO - [Step=6500]	Loss=2.6220	275.7 examples/second
2022-01-19 16:10:19,361 - INFO - Test Loss=2.7599, Test top-1 acc=0.4422
2022-01-19 16:10:19,361 - INFO - Group Accuracy:

2022-01-19 16:10:19,361 - INFO - [0.94939756 0.9621687  0.9219277  0.97156626 0.95277107 0.97180724
 0.94963855 0.95325303 0.9662651  0.9498795  0.9612048  0.9515663
 0.9354217  0.94       0.9477109  0.95759034 0.97228914]
2022-01-19 16:10:19,362 - INFO - Epoch time: 396.09370040893555
2022-01-19 16:10:19,362 - INFO - 
Epoch: 8
2022-01-19 16:10:19,362 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:10:53,683 - INFO - [Step=6750]	Loss=2.5480	255.5 examples/second
2022-01-19 16:12:51,059 - INFO - [Step=7000]	Loss=2.5033	272.6 examples/second
2022-01-19 16:14:48,460 - INFO - [Step=7250]	Loss=2.4230	272.6 examples/second
2022-01-19 16:16:46,074 - INFO - [Step=7500]	Loss=2.3897	272.1 examples/second
2022-01-19 16:17:00,202 - INFO - Test Loss=2.3256, Test top-1 acc=0.5202
2022-01-19 16:17:00,203 - INFO - Group Accuracy:

2022-01-19 16:17:00,203 - INFO - [0.96024096 0.96048194 0.9513253  0.9766265  0.9559036  0.97927713
 0.9460241  0.96096385 0.96795183 0.9551807  0.9686747  0.9583132
 0.9479518  0.9513253  0.9477109  0.96096385 0.9816868 ]
2022-01-19 16:17:00,203 - INFO - Saving...
2022-01-19 16:17:00,436 - INFO - Epoch time: 401.07419633865356
2022-01-19 16:17:00,437 - INFO - 
Epoch: 9
2022-01-19 16:17:00,437 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:18:51,737 - INFO - [Step=7750]	Loss=2.3141	254.7 examples/second
2022-01-19 16:20:48,709 - INFO - [Step=8000]	Loss=2.2836	273.6 examples/second
2022-01-19 16:22:45,807 - INFO - [Step=8250]	Loss=2.2524	273.3 examples/second
2022-01-19 16:23:39,569 - INFO - Test Loss=2.2575, Test top-1 acc=0.5265
2022-01-19 16:23:39,569 - INFO - Group Accuracy:

2022-01-19 16:23:39,569 - INFO - [0.9583132  0.9631325  0.95638555 0.9746988  0.9561446  0.9816868
 0.95421684 0.95686746 0.9672289  0.9573494  0.9701205  0.9653012
 0.9474699  0.9460241  0.9559036  0.9624096  0.97927713]
2022-01-19 16:23:39,570 - INFO - Saving...
2022-01-19 16:23:39,810 - INFO - Epoch time: 399.373167514801
2022-01-19 16:23:39,810 - INFO - 
Epoch: 10
2022-01-19 16:23:39,810 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:24:51,479 - INFO - [Step=8500]	Loss=2.1992	254.6 examples/second
2022-01-19 16:26:48,431 - INFO - [Step=8750]	Loss=2.1932	273.6 examples/second
2022-01-19 16:28:45,460 - INFO - [Step=9000]	Loss=2.1441	273.4 examples/second
2022-01-19 16:30:19,058 - INFO - Test Loss=2.0338, Test top-1 acc=0.5745
2022-01-19 16:30:19,059 - INFO - Group Accuracy:

2022-01-19 16:30:19,059 - INFO - [0.95975906 0.9696385  0.9590362  0.97518075 0.96457833 0.9814458
 0.95421684 0.9653012  0.97493976 0.9614458  0.9691566  0.96048194
 0.9469879  0.9518072  0.95566267 0.9703615  0.9848193 ]
2022-01-19 16:30:19,060 - INFO - Saving...
2022-01-19 16:30:19,241 - INFO - Epoch time: 399.43091773986816
2022-01-19 16:30:19,241 - INFO - 
Epoch: 11
2022-01-19 16:30:19,241 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:30:51,274 - INFO - [Step=9250]	Loss=2.1150	254.3 examples/second
2022-01-19 16:32:48,641 - INFO - [Step=9500]	Loss=2.0538	272.7 examples/second
2022-01-19 16:34:46,102 - INFO - [Step=9750]	Loss=2.0488	272.4 examples/second
2022-01-19 16:36:43,685 - INFO - [Step=10000]	Loss=2.0183	272.1 examples/second
2022-01-19 16:37:00,018 - INFO - Test Loss=1.9492, Test top-1 acc=0.5783
2022-01-19 16:37:00,018 - INFO - Group Accuracy:

2022-01-19 16:37:00,018 - INFO - [0.9612048  0.96891564 0.9626506  0.9833735  0.96481925 0.9807229
 0.96096385 0.9554217  0.9807229  0.96361446 0.97445786 0.9631325
 0.9472289  0.95301205 0.9561446  0.96409637 0.9848193 ]
2022-01-19 16:37:00,019 - INFO - Saving...
2022-01-19 16:37:00,210 - INFO - Epoch time: 400.96889781951904
2022-01-19 16:37:00,210 - INFO - 
Epoch: 12
2022-01-19 16:37:00,210 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:38:49,759 - INFO - [Step=10250]	Loss=1.9785	253.8 examples/second
2022-01-19 16:40:47,418 - INFO - [Step=10500]	Loss=1.9392	272.0 examples/second
2022-01-19 16:42:45,199 - INFO - [Step=10750]	Loss=1.9322	271.7 examples/second
2022-01-19 16:43:41,501 - INFO - Test Loss=1.8283, Test top-1 acc=0.6000
2022-01-19 16:43:41,501 - INFO - Group Accuracy:

2022-01-19 16:43:41,501 - INFO - [0.96385545 0.9771084  0.9686747  0.9840964  0.96457833 0.9850602
 0.96072286 0.96409637 0.9812048  0.9655422  0.97493976 0.96506023
 0.9508434  0.940241   0.9554217  0.9698795  0.98024094]
2022-01-19 16:43:41,502 - INFO - Saving...
2022-01-19 16:43:41,754 - INFO - Epoch time: 401.5434453487396
2022-01-19 16:43:41,754 - INFO - 
Epoch: 13
2022-01-19 16:43:41,754 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:44:50,830 - INFO - [Step=11000]	Loss=1.8947	254.7 examples/second
2022-01-19 16:46:47,973 - INFO - [Step=11250]	Loss=1.8700	273.2 examples/second
2022-01-19 16:48:45,202 - INFO - [Step=11500]	Loss=1.8777	273.0 examples/second
2022-01-19 16:50:21,217 - INFO - Test Loss=1.9745, Test top-1 acc=0.5872
2022-01-19 16:50:21,217 - INFO - Group Accuracy:

2022-01-19 16:50:21,217 - INFO - [0.9626506  0.973253   0.966506   0.9701205  0.9621687  0.9860241
 0.96096385 0.95301205 0.97590363 0.9662651  0.96891564 0.96457833
 0.9474699  0.9580723  0.95662653 0.9693976  0.98361444]
2022-01-19 16:50:21,218 - INFO - Epoch time: 399.4643280506134
2022-01-19 16:50:21,218 - INFO - 
Epoch: 14
2022-01-19 16:50:21,218 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:50:50,747 - INFO - [Step=11750]	Loss=1.8619	254.9 examples/second
2022-01-19 16:52:47,983 - INFO - [Step=12000]	Loss=1.8089	273.0 examples/second
2022-01-19 16:54:45,455 - INFO - [Step=12250]	Loss=1.7976	272.4 examples/second
2022-01-19 16:56:43,143 - INFO - [Step=12500]	Loss=1.7951	271.9 examples/second
2022-01-19 16:57:01,828 - INFO - Test Loss=1.9574, Test top-1 acc=0.5988
2022-01-19 16:57:01,829 - INFO - Group Accuracy:

2022-01-19 16:57:01,829 - INFO - [0.9614458  0.9693976  0.9590362  0.9807229  0.9662651  0.98578316
 0.9624096  0.96771085 0.9739759  0.9653012  0.9693976  0.96891564
 0.9387952  0.95662653 0.96409637 0.973253   0.9855422 ]
2022-01-19 16:57:01,830 - INFO - Epoch time: 400.61130237579346
2022-01-19 16:57:01,830 - INFO - 
Epoch: 15
2022-01-19 16:57:01,830 - INFO - 
Learning Rate: 0.1000
2022-01-19 16:58:48,586 - INFO - [Step=12750]	Loss=1.7575	255.1 examples/second
2022-01-19 17:00:45,498 - INFO - [Step=13000]	Loss=1.7511	273.7 examples/second
2022-01-19 17:02:42,652 - INFO - [Step=13250]	Loss=1.7516	273.1 examples/second
2022-01-19 17:03:40,962 - INFO - Test Loss=1.8951, Test top-1 acc=0.6048
2022-01-19 17:03:40,962 - INFO - Group Accuracy:

2022-01-19 17:03:40,962 - INFO - [0.96481925 0.95710844 0.96       0.9826506  0.9696385  0.9848193
 0.95325303 0.9696385  0.9742169  0.9653012  0.9727711  0.9660241
 0.95301205 0.95301205 0.9619277  0.96481925 0.9884337 ]
2022-01-19 17:03:40,963 - INFO - Saving...
2022-01-19 17:03:41,200 - INFO - Epoch time: 399.36987948417664
2022-01-19 17:03:41,200 - INFO - 
Epoch: 16
2022-01-19 17:03:41,200 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:04:47,639 - INFO - [Step=13500]	Loss=1.7205	256.0 examples/second
2022-01-19 17:06:43,480 - INFO - [Step=13750]	Loss=1.6911	276.2 examples/second
2022-01-19 17:08:39,629 - INFO - [Step=14000]	Loss=1.6950	275.5 examples/second
2022-01-19 17:10:17,577 - INFO - Test Loss=1.8208, Test top-1 acc=0.6217
2022-01-19 17:10:17,577 - INFO - Group Accuracy:

2022-01-19 17:10:17,577 - INFO - [0.9628916  0.973253   0.96698797 0.98313254 0.9662651  0.98240966
 0.9674699  0.94963855 0.9780723  0.9672289  0.9691566  0.966747
 0.95638555 0.95975906 0.96072286 0.9662651  0.9879518 ]
2022-01-19 17:10:17,578 - INFO - Saving...
2022-01-19 17:10:17,758 - INFO - Epoch time: 396.55795669555664
2022-01-19 17:10:17,758 - INFO - 
Epoch: 17
2022-01-19 17:10:17,758 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:10:44,840 - INFO - [Step=14250]	Loss=1.6805	255.6 examples/second
2022-01-19 17:12:41,500 - INFO - [Step=14500]	Loss=1.6406	274.3 examples/second
2022-01-19 17:14:38,821 - INFO - [Step=14750]	Loss=1.6633	272.8 examples/second
2022-01-19 17:16:36,442 - INFO - [Step=15000]	Loss=1.6500	272.1 examples/second
2022-01-19 17:16:57,393 - INFO - Test Loss=1.8685, Test top-1 acc=0.6142
2022-01-19 17:16:57,394 - INFO - Group Accuracy:

2022-01-19 17:16:57,394 - INFO - [0.9621687  0.9708434  0.96457833 0.9766265  0.9662651  0.9819277
 0.96096385 0.9693976  0.97301203 0.9660241  0.97445786 0.96457833
 0.9580723  0.96024096 0.9626506  0.9708434  0.98698795]
2022-01-19 17:16:57,395 - INFO - Epoch time: 399.6368794441223
2022-01-19 17:16:57,395 - INFO - 
Epoch: 18
2022-01-19 17:16:57,395 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:18:41,432 - INFO - [Step=15250]	Loss=1.5763	256.0 examples/second
2022-01-19 17:20:38,045 - INFO - [Step=15500]	Loss=1.6302	274.4 examples/second
2022-01-19 17:22:34,473 - INFO - [Step=15750]	Loss=1.6124	274.9 examples/second
2022-01-19 17:23:35,034 - INFO - Test Loss=1.8692, Test top-1 acc=0.6402
2022-01-19 17:23:35,035 - INFO - Group Accuracy:

2022-01-19 17:23:35,035 - INFO - [0.96843374 0.9660241  0.97156626 0.97927713 0.9631325  0.98771083
 0.9662651  0.96506023 0.9809638  0.9657831  0.9768675  0.9737349
 0.9595181  0.9621687  0.966506   0.9691566  0.9889157 ]
2022-01-19 17:23:35,036 - INFO - Saving...
2022-01-19 17:23:35,302 - INFO - Epoch time: 397.9073734283447
2022-01-19 17:23:35,303 - INFO - 
Epoch: 19
2022-01-19 17:23:35,303 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:24:40,129 - INFO - [Step=16000]	Loss=1.6003	254.7 examples/second
2022-01-19 17:26:37,516 - INFO - [Step=16250]	Loss=1.5705	272.6 examples/second
2022-01-19 17:28:34,904 - INFO - [Step=16500]	Loss=1.5649	272.6 examples/second
2022-01-19 17:30:15,704 - INFO - Test Loss=2.0440, Test top-1 acc=0.6077
2022-01-19 17:30:15,705 - INFO - Group Accuracy:

2022-01-19 17:30:15,705 - INFO - [0.9621687  0.9727711  0.9674699  0.97542167 0.9691566  0.98433733
 0.9580723  0.9662651  0.9787952  0.96481925 0.9693976  0.96168673
 0.94963855 0.96024096 0.96024096 0.97108436 0.98674697]
2022-01-19 17:30:15,706 - INFO - Epoch time: 400.403094291687
2022-01-19 17:30:15,706 - INFO - 
Epoch: 20
2022-01-19 17:30:15,706 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:30:40,787 - INFO - [Step=16750]	Loss=1.5694	254.2 examples/second
2022-01-19 17:32:38,471 - INFO - [Step=17000]	Loss=1.5430	271.9 examples/second
2022-01-19 17:34:36,141 - INFO - [Step=17250]	Loss=1.5446	271.9 examples/second
2022-01-19 17:36:33,743 - INFO - [Step=17500]	Loss=1.5461	272.1 examples/second
2022-01-19 17:36:56,999 - INFO - Test Loss=1.5741, Test top-1 acc=0.6549
2022-01-19 17:36:56,999 - INFO - Group Accuracy:

2022-01-19 17:36:57,000 - INFO - [0.96385545 0.97590363 0.97180724 0.9826506  0.96433735 0.9879518
 0.9653012  0.9725301  0.9807229  0.9672289  0.9768675  0.9742169
 0.96361446 0.9621687  0.96096385 0.96819276 0.9886747 ]
2022-01-19 17:36:57,000 - INFO - Saving...
2022-01-19 17:36:57,178 - INFO - Epoch time: 401.47224402427673
2022-01-19 17:36:57,178 - INFO - 
Epoch: 21
2022-01-19 17:36:57,178 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:38:38,370 - INFO - [Step=17750]	Loss=1.5167	256.8 examples/second
2022-01-19 17:40:34,218 - INFO - [Step=18000]	Loss=1.5234	276.2 examples/second
2022-01-19 17:42:30,869 - INFO - [Step=18250]	Loss=1.5324	274.3 examples/second
2022-01-19 17:43:33,642 - INFO - Test Loss=1.5254, Test top-1 acc=0.6733
2022-01-19 17:43:33,642 - INFO - Group Accuracy:

2022-01-19 17:43:33,642 - INFO - [0.9701205  0.9768675  0.96843374 0.9850602  0.97301203 0.9886747
 0.9614458  0.9737349  0.9812048  0.96891564 0.9775904  0.97518075
 0.96433735 0.9653012  0.9653012  0.97445786 0.9884337 ]
2022-01-19 17:43:33,643 - INFO - Saving...
2022-01-19 17:43:33,880 - INFO - Epoch time: 396.7020616531372
2022-01-19 17:43:33,880 - INFO - 
Epoch: 22
2022-01-19 17:43:33,880 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:44:36,526 - INFO - [Step=18500]	Loss=1.4950	254.7 examples/second
2022-01-19 17:46:33,923 - INFO - [Step=18750]	Loss=1.4974	272.6 examples/second
2022-01-19 17:48:31,522 - INFO - [Step=19000]	Loss=1.5175	272.1 examples/second
2022-01-19 17:50:14,517 - INFO - Test Loss=1.8498, Test top-1 acc=0.6246
2022-01-19 17:50:14,517 - INFO - Group Accuracy:

2022-01-19 17:50:14,517 - INFO - [0.9580723  0.97518075 0.966747   0.973494   0.96771085 0.9886747
 0.9696385  0.95662653 0.98240966 0.96506023 0.9725301  0.96891564
 0.9614458  0.96385545 0.946747   0.97180724 0.9893976 ]
2022-01-19 17:50:14,518 - INFO - Epoch time: 400.63768434524536
2022-01-19 17:50:14,518 - INFO - 
Epoch: 23
2022-01-19 17:50:14,518 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:50:37,093 - INFO - [Step=19250]	Loss=1.4763	254.8 examples/second
2022-01-19 17:52:34,610 - INFO - [Step=19500]	Loss=1.4619	272.3 examples/second
2022-01-19 17:54:32,268 - INFO - [Step=19750]	Loss=1.4849	272.0 examples/second
2022-01-19 17:56:30,187 - INFO - [Step=20000]	Loss=1.4617	271.4 examples/second
2022-01-19 17:56:55,913 - INFO - Test Loss=1.4329, Test top-1 acc=0.6872
2022-01-19 17:56:55,913 - INFO - Group Accuracy:

2022-01-19 17:56:55,913 - INFO - [0.96795183 0.97831327 0.9703615  0.98433733 0.9708434  0.9901205
 0.9708434  0.97445786 0.97975904 0.9653012  0.9812048  0.9775904
 0.9624096  0.96457833 0.9628916  0.9771084  0.9918072 ]
2022-01-19 17:56:55,914 - INFO - Saving...
2022-01-19 17:56:56,160 - INFO - Epoch time: 401.64193320274353
2022-01-19 17:56:56,160 - INFO - 
Epoch: 24
2022-01-19 17:56:56,160 - INFO - 
Learning Rate: 0.1000
2022-01-19 17:58:35,085 - INFO - [Step=20250]	Loss=1.4431	256.2 examples/second
2022-01-19 18:00:30,838 - INFO - [Step=20500]	Loss=1.4570	276.5 examples/second
2022-01-19 18:02:27,934 - INFO - [Step=20750]	Loss=1.4661	273.3 examples/second
2022-01-19 18:03:33,362 - INFO - Test Loss=1.6249, Test top-1 acc=0.6516
2022-01-19 18:03:33,363 - INFO - Group Accuracy:

2022-01-19 18:03:33,363 - INFO - [0.96698797 0.97566265 0.9696385  0.9845783  0.9696385  0.98650604
 0.96698797 0.9708434  0.9838554  0.9686747  0.9746988  0.97228914
 0.96096385 0.95301205 0.9612048  0.9672289  0.98674697]
2022-01-19 18:03:33,364 - INFO - Epoch time: 397.2034478187561
2022-01-19 18:03:33,364 - INFO - 
Epoch: 25
2022-01-19 18:03:33,364 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:04:33,186 - INFO - [Step=21000]	Loss=1.4234	255.5 examples/second
2022-01-19 18:06:30,471 - INFO - [Step=21250]	Loss=1.4435	272.8 examples/second
2022-01-19 18:08:27,712 - INFO - [Step=21500]	Loss=1.4507	272.9 examples/second
2022-01-19 18:10:13,033 - INFO - Test Loss=1.4566, Test top-1 acc=0.6810
2022-01-19 18:10:13,033 - INFO - Group Accuracy:

2022-01-19 18:10:13,034 - INFO - [0.9686747  0.9773494  0.9746988  0.9860241  0.97493976 0.9884337
 0.96819276 0.973494   0.98024094 0.9693976  0.9812048  0.9742169
 0.9587952  0.96481925 0.9621687  0.9746988  0.99036145]
2022-01-19 18:10:13,034 - INFO - Epoch time: 399.6703586578369
2022-01-19 18:10:13,034 - INFO - 
Epoch: 26
2022-01-19 18:10:13,034 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:10:33,090 - INFO - [Step=21750]	Loss=1.4413	255.2 examples/second
2022-01-19 18:12:30,422 - INFO - [Step=22000]	Loss=1.3863	272.7 examples/second
2022-01-19 18:14:27,820 - INFO - [Step=22250]	Loss=1.4165	272.6 examples/second
2022-01-19 18:16:25,169 - INFO - [Step=22500]	Loss=1.4150	272.7 examples/second
2022-01-19 18:16:53,074 - INFO - Test Loss=1.4172, Test top-1 acc=0.6793
2022-01-19 18:16:53,075 - INFO - Group Accuracy:

2022-01-19 18:16:53,075 - INFO - [0.9706024  0.97590363 0.9708434  0.98578316 0.9672289  0.9893976
 0.96481925 0.9737349  0.98240966 0.9725301  0.97831327 0.973494
 0.966506   0.9660241  0.96819276 0.9778313  0.9898795 ]
2022-01-19 18:16:53,076 - INFO - Epoch time: 400.04116702079773
2022-01-19 18:16:53,076 - INFO - 
Epoch: 27
2022-01-19 18:16:53,076 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:18:30,054 - INFO - [Step=22750]	Loss=1.3638	256.2 examples/second
2022-01-19 18:20:26,509 - INFO - [Step=23000]	Loss=1.3881	274.8 examples/second
2022-01-19 18:22:23,298 - INFO - [Step=23250]	Loss=1.4161	274.0 examples/second
2022-01-19 18:23:30,871 - INFO - Test Loss=1.7165, Test top-1 acc=0.6463
2022-01-19 18:23:30,872 - INFO - Group Accuracy:

2022-01-19 18:23:30,872 - INFO - [0.9619277  0.9787952  0.9696385  0.9855422  0.9706024  0.98698795
 0.9657831  0.9739759  0.97614455 0.966506   0.973494   0.96843374
 0.95759034 0.96433735 0.96698797 0.9739759  0.9901205 ]
2022-01-19 18:23:30,872 - INFO - Epoch time: 397.79686641693115
2022-01-19 18:23:30,872 - INFO - 
Epoch: 28
2022-01-19 18:23:30,873 - INFO - 
Learning Rate: 0.1000
2022-01-19 18:24:28,458 - INFO - [Step=23500]	Loss=1.3888	255.7 examples/second
2022-01-19 18:26:25,278 - INFO - [Step=23750]	Loss=1.3823	273.9 examples/second
2022-01-19 18:28:21,960 - INFO - [Step=24000]	Loss=1.3944	274.3 examples/second
2022-01-19 18:30:09,107 - INFO - Test Loss=1.3569, Test top-1 acc=0.6942
2022-01-19 18:30:09,107 - INFO - Group Accuracy:

2022-01-19 18:30:09,107 - INFO - [0.97108436 0.97614455 0.97590363 0.9848193  0.97518075 0.98698795
 0.97108436 0.97493976 0.9848193  0.96795183 0.97518075 0.97566265
 0.9631325  0.9701205  0.96771085 0.97927713 0.99108434]
2022-01-19 18:30:09,108 - INFO - Saving...
2022-01-19 18:30:09,384 - INFO - Epoch time: 398.5115828514099
2022-01-19 18:30:09,384 - INFO - 
Epoch: 29
2022-01-19 18:30:09,384 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:30:27,210 - INFO - [Step=24250]	Loss=1.3616	255.5 examples/second
2022-01-19 18:32:23,930 - INFO - [Step=24500]	Loss=1.0815	274.2 examples/second
2022-01-19 18:34:20,889 - INFO - [Step=24750]	Loss=1.0075	273.6 examples/second
2022-01-19 18:36:17,739 - INFO - [Step=25000]	Loss=0.9916	273.9 examples/second
2022-01-19 18:36:47,928 - INFO - Test Loss=0.8943, Test top-1 acc=0.7788
2022-01-19 18:36:47,928 - INFO - Group Accuracy:

2022-01-19 18:36:47,928 - INFO - [0.97831327 0.9891566  0.9848193  0.9920482  0.98313254 0.9927711
 0.97903615 0.9819277  0.9886747  0.97493976 0.9891566  0.9833735
 0.9742169  0.97638553 0.9766265  0.98674697 0.99373496]
2022-01-19 18:36:47,929 - INFO - Saving...
2022-01-19 18:36:48,207 - INFO - Epoch time: 398.82227659225464
2022-01-19 18:36:48,207 - INFO - 
Epoch: 30
2022-01-19 18:36:48,207 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:38:23,364 - INFO - [Step=25250]	Loss=0.9375	254.7 examples/second
2022-01-19 18:40:20,811 - INFO - [Step=25500]	Loss=0.9323	272.5 examples/second
2022-01-19 18:42:18,345 - INFO - [Step=25750]	Loss=0.9227	272.3 examples/second
2022-01-19 18:43:28,606 - INFO - Test Loss=0.8568, Test top-1 acc=0.7872
2022-01-19 18:43:28,606 - INFO - Group Accuracy:

2022-01-19 18:43:28,606 - INFO - [0.97975904 0.9893976  0.9850602  0.993494   0.98289156 0.9927711
 0.98       0.9826506  0.98963857 0.97542167 0.9891566  0.98313254
 0.97542167 0.9775904  0.9771084  0.98722893 0.993494  ]
2022-01-19 18:43:28,607 - INFO - Saving...
2022-01-19 18:43:28,780 - INFO - Epoch time: 400.57290959358215
2022-01-19 18:43:28,780 - INFO - 
Epoch: 31
2022-01-19 18:43:28,780 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:44:23,713 - INFO - [Step=26000]	Loss=0.9325	255.2 examples/second
2022-01-19 18:46:19,547 - INFO - [Step=26250]	Loss=0.8982	276.3 examples/second
2022-01-19 18:48:15,830 - INFO - [Step=26500]	Loss=0.8895	275.2 examples/second
2022-01-19 18:50:04,897 - INFO - Test Loss=0.8471, Test top-1 acc=0.7877
2022-01-19 18:50:04,898 - INFO - Group Accuracy:

2022-01-19 18:50:04,898 - INFO - [0.97975904 0.98963857 0.98650604 0.9920482  0.98289156 0.993253
 0.9809638  0.98240966 0.99060243 0.97542167 0.9886747  0.98313254
 0.9771084  0.9780723  0.97614455 0.9881928  0.9946988 ]
2022-01-19 18:50:04,899 - INFO - Saving...
2022-01-19 18:50:05,091 - INFO - Epoch time: 396.3105528354645
2022-01-19 18:50:05,091 - INFO - 
Epoch: 32
2022-01-19 18:50:05,091 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:50:20,675 - INFO - [Step=26750]	Loss=0.8942	256.3 examples/second
2022-01-19 18:52:17,559 - INFO - [Step=27000]	Loss=0.8720	273.8 examples/second
2022-01-19 18:54:15,022 - INFO - [Step=27250]	Loss=0.8754	272.4 examples/second
2022-01-19 18:56:12,389 - INFO - [Step=27500]	Loss=0.8739	272.6 examples/second
2022-01-19 18:56:45,047 - INFO - Test Loss=0.8404, Test top-1 acc=0.7843
2022-01-19 18:56:45,048 - INFO - Group Accuracy:

2022-01-19 18:56:45,058 - INFO - [0.97831327 0.9893976  0.9850602  0.9930121  0.98313254 0.99373496
 0.98024094 0.9826506  0.99036145 0.97518075 0.9881928  0.9845783
 0.9771084  0.9787952  0.9746988  0.98722893 0.99373496]
2022-01-19 18:56:45,059 - INFO - Epoch time: 399.9681339263916
2022-01-19 18:56:45,059 - INFO - 
Epoch: 33
2022-01-19 18:56:45,059 - INFO - 
Learning Rate: 0.0100
2022-01-19 18:58:17,129 - INFO - [Step=27750]	Loss=0.8543	256.5 examples/second
2022-01-19 19:00:12,923 - INFO - [Step=28000]	Loss=0.8582	276.4 examples/second
2022-01-19 19:02:09,359 - INFO - [Step=28250]	Loss=0.8385	274.8 examples/second
2022-01-19 19:03:21,291 - INFO - Test Loss=0.8227, Test top-1 acc=0.7928
2022-01-19 19:03:21,291 - INFO - Group Accuracy:

2022-01-19 19:03:21,291 - INFO - [0.97975904 0.99036145 0.9848193  0.9930121  0.9833735  0.993494
 0.9809638  0.9826506  0.9893976  0.97445786 0.9889157  0.98433733
 0.97590363 0.9816868  0.9773494  0.98626506 0.99493974]
2022-01-19 19:03:21,293 - INFO - Saving...
2022-01-19 19:03:21,542 - INFO - Epoch time: 396.48351860046387
2022-01-19 19:03:21,543 - INFO - 
Epoch: 34
2022-01-19 19:03:21,543 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:04:13,967 - INFO - [Step=28500]	Loss=0.8512	256.8 examples/second
2022-01-19 19:06:10,364 - INFO - [Step=28750]	Loss=0.8580	274.9 examples/second
2022-01-19 19:08:07,572 - INFO - [Step=29000]	Loss=0.8255	273.0 examples/second
2022-01-19 19:09:59,872 - INFO - Test Loss=0.8373, Test top-1 acc=0.7906
2022-01-19 19:09:59,873 - INFO - Group Accuracy:

2022-01-19 19:09:59,873 - INFO - [0.98       0.9898795  0.9840964  0.9939759  0.98361444 0.99445784
 0.9814458  0.98289156 0.99108434 0.97518075 0.9898795  0.9840964
 0.97445786 0.98       0.9766265  0.98771083 0.993494  ]
2022-01-19 19:09:59,874 - INFO - Epoch time: 398.33103466033936
2022-01-19 19:09:59,874 - INFO - 
Epoch: 35
2022-01-19 19:09:59,874 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:10:13,276 - INFO - [Step=29250]	Loss=0.8381	254.6 examples/second
2022-01-19 19:12:10,563 - INFO - [Step=29500]	Loss=0.8337	272.8 examples/second
2022-01-19 19:14:07,847 - INFO - [Step=29750]	Loss=0.8374	272.8 examples/second
2022-01-19 19:16:04,856 - INFO - [Step=30000]	Loss=0.8283	273.5 examples/second
2022-01-19 19:16:39,747 - INFO - Test Loss=0.8253, Test top-1 acc=0.7933
2022-01-19 19:16:39,747 - INFO - Group Accuracy:

2022-01-19 19:16:39,747 - INFO - [0.97975904 0.9898795  0.9848193  0.9920482  0.98240966 0.9939759
 0.9804819  0.9804819  0.99108434 0.97445786 0.9893976  0.9848193
 0.97493976 0.97975904 0.9775904  0.9884337  0.9954217 ]
2022-01-19 19:16:39,749 - INFO - Saving...
2022-01-19 19:16:39,938 - INFO - Epoch time: 400.0644211769104
2022-01-19 19:16:39,938 - INFO - 
Epoch: 36
2022-01-19 19:16:39,938 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:18:09,679 - INFO - [Step=30250]	Loss=0.8000	256.4 examples/second
2022-01-19 19:20:05,526 - INFO - [Step=30500]	Loss=0.8159	276.2 examples/second
2022-01-19 19:22:02,318 - INFO - [Step=30750]	Loss=0.8140	274.0 examples/second
2022-01-19 19:23:17,111 - INFO - Test Loss=0.8136, Test top-1 acc=0.7935
2022-01-19 19:23:17,111 - INFO - Group Accuracy:

2022-01-19 19:23:17,111 - INFO - [0.97975904 0.9898795  0.9845783  0.9927711  0.98289156 0.993253
 0.98024094 0.9807229  0.98963857 0.9746988  0.9898795  0.98578316
 0.9775904  0.9819277  0.9775904  0.9901205  0.9954217 ]
2022-01-19 19:23:17,113 - INFO - Saving...
2022-01-19 19:23:17,374 - INFO - Epoch time: 397.43594622612
2022-01-19 19:23:17,375 - INFO - 
Epoch: 37
2022-01-19 19:23:17,375 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:24:07,842 - INFO - [Step=31000]	Loss=0.8021	254.9 examples/second
2022-01-19 19:26:03,990 - INFO - [Step=31250]	Loss=0.8040	275.5 examples/second
2022-01-19 19:28:00,363 - INFO - [Step=31500]	Loss=0.8082	275.0 examples/second
2022-01-19 19:29:53,888 - INFO - Test Loss=0.8401, Test top-1 acc=0.7935
2022-01-19 19:29:53,889 - INFO - Group Accuracy:

2022-01-19 19:29:53,889 - INFO - [0.98024094 0.9901205  0.9840964  0.9927711  0.9848193  0.993494
 0.98240966 0.9833735  0.99084336 0.9742169  0.98963857 0.9845783
 0.9766265  0.98024094 0.97638553 0.9884337  0.99445784]
2022-01-19 19:29:53,890 - INFO - Epoch time: 396.5152704715729
2022-01-19 19:29:53,890 - INFO - 
Epoch: 38
2022-01-19 19:29:53,890 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:30:04,959 - INFO - [Step=31750]	Loss=0.7808	256.8 examples/second
2022-01-19 19:32:02,290 - INFO - [Step=32000]	Loss=0.7782	272.7 examples/second
2022-01-19 19:33:59,828 - INFO - [Step=32250]	Loss=0.7849	272.3 examples/second
2022-01-19 19:35:56,998 - INFO - [Step=32500]	Loss=0.7902	273.1 examples/second
2022-01-19 19:36:34,489 - INFO - Test Loss=0.8154, Test top-1 acc=0.8007
2022-01-19 19:36:34,490 - INFO - Group Accuracy:

2022-01-19 19:36:34,490 - INFO - [0.9814458  0.99084336 0.9845783  0.9920482  0.98240966 0.993253
 0.98361444 0.9826506  0.99036145 0.97542167 0.99084336 0.9848193
 0.9773494  0.9812048  0.9778313  0.9884337  0.9946988 ]
2022-01-19 19:36:34,491 - INFO - Saving...
2022-01-19 19:36:34,730 - INFO - Epoch time: 400.8398087024689
2022-01-19 19:36:34,730 - INFO - 
Epoch: 39
2022-01-19 19:36:34,730 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:38:02,964 - INFO - [Step=32750]	Loss=0.7827	254.0 examples/second
2022-01-19 19:40:00,514 - INFO - [Step=33000]	Loss=0.7700	272.2 examples/second
2022-01-19 19:41:58,294 - INFO - [Step=33250]	Loss=0.7691	271.7 examples/second
2022-01-19 19:43:15,605 - INFO - Test Loss=0.8073, Test top-1 acc=0.7988
2022-01-19 19:43:15,606 - INFO - Group Accuracy:

2022-01-19 19:43:15,606 - INFO - [0.9804819  0.99060243 0.98650604 0.9922892  0.98240966 0.9925301
 0.9812048  0.98289156 0.99036145 0.97518075 0.9891566  0.9850602
 0.9787952  0.9804819  0.9768675  0.9884337  0.9951807 ]
2022-01-19 19:43:15,607 - INFO - Epoch time: 400.87681794166565
2022-01-19 19:43:15,607 - INFO - 
Epoch: 40
2022-01-19 19:43:15,607 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:44:04,080 - INFO - [Step=33500]	Loss=0.7799	254.4 examples/second
2022-01-19 19:46:01,695 - INFO - [Step=33750]	Loss=0.7511	272.1 examples/second
2022-01-19 19:47:59,264 - INFO - [Step=34000]	Loss=0.7759	272.2 examples/second
2022-01-19 19:49:56,533 - INFO - Test Loss=0.8088, Test top-1 acc=0.7973
2022-01-19 19:49:56,534 - INFO - Group Accuracy:

2022-01-19 19:49:56,534 - INFO - [0.97951806 0.9893976  0.9860241  0.9918072  0.98361444 0.993494
 0.98289156 0.9821687  0.99084336 0.97445786 0.9898795  0.98578316
 0.9775904  0.9807229  0.9773494  0.9881928  0.99445784]
2022-01-19 19:49:56,535 - INFO - Epoch time: 400.9278881549835
2022-01-19 19:49:56,535 - INFO - 
Epoch: 41
2022-01-19 19:49:56,535 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:50:05,056 - INFO - [Step=34250]	Loss=0.7759	254.4 examples/second
2022-01-19 19:52:01,968 - INFO - [Step=34500]	Loss=0.7667	273.7 examples/second
2022-01-19 19:53:58,785 - INFO - [Step=34750]	Loss=0.7525	273.9 examples/second
2022-01-19 19:55:55,300 - INFO - [Step=35000]	Loss=0.7531	274.6 examples/second
2022-01-19 19:56:34,736 - INFO - Test Loss=0.7954, Test top-1 acc=0.7952
2022-01-19 19:56:34,737 - INFO - Group Accuracy:

2022-01-19 19:56:34,737 - INFO - [0.97903615 0.98963857 0.9853012  0.9927711  0.9840964  0.99373496
 0.98       0.9845783  0.99060243 0.97614455 0.9898795  0.98433733
 0.97614455 0.9826506  0.9785542  0.9884337  0.9946988 ]
2022-01-19 19:56:34,738 - INFO - Epoch time: 398.2029619216919
2022-01-19 19:56:34,738 - INFO - 
Epoch: 42
2022-01-19 19:56:34,738 - INFO - 
Learning Rate: 0.0100
2022-01-19 19:58:00,096 - INFO - [Step=35250]	Loss=0.7500	256.4 examples/second
2022-01-19 19:59:57,515 - INFO - [Step=35500]	Loss=0.7492	272.5 examples/second
2022-01-19 20:01:55,243 - INFO - [Step=35750]	Loss=0.7521	271.8 examples/second
2022-01-19 20:03:15,021 - INFO - Test Loss=0.8186, Test top-1 acc=0.7935
2022-01-19 20:03:15,022 - INFO - Group Accuracy:

2022-01-19 20:03:15,022 - INFO - [0.9821687  0.99060243 0.9848193  0.99421686 0.98313254 0.993253
 0.97903615 0.9812048  0.9901205  0.97590363 0.9881928  0.98433733
 0.9771084  0.97903615 0.97566265 0.98746985 0.9951807 ]
2022-01-19 20:03:15,022 - INFO - Epoch time: 400.2842917442322
2022-01-19 20:03:15,022 - INFO - 
Epoch: 43
2022-01-19 20:03:15,022 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:04:01,027 - INFO - [Step=36000]	Loss=0.7452	254.4 examples/second
2022-01-19 20:05:58,674 - INFO - [Step=36250]	Loss=0.7364	272.0 examples/second
2022-01-19 20:07:55,282 - INFO - [Step=36500]	Loss=0.7403	274.4 examples/second
2022-01-19 20:09:53,105 - INFO - Test Loss=0.8160, Test top-1 acc=0.8002
2022-01-19 20:09:53,106 - INFO - Group Accuracy:

2022-01-19 20:09:53,106 - INFO - [0.9807229  0.9901205  0.9855422  0.993253   0.9848193  0.99373496
 0.97975904 0.9819277  0.9898795  0.9768675  0.9898795  0.9855422
 0.97493976 0.9804819  0.9773494  0.9881928  0.99445784]
2022-01-19 20:09:53,106 - INFO - Epoch time: 398.0841238498688
2022-01-19 20:09:53,107 - INFO - 
Epoch: 44
2022-01-19 20:09:53,107 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:09:59,347 - INFO - [Step=36750]	Loss=0.7386	257.9 examples/second
2022-01-19 20:11:54,659 - INFO - [Step=37000]	Loss=0.7069	277.5 examples/second
2022-01-19 20:13:51,409 - INFO - [Step=37250]	Loss=0.7394	274.1 examples/second
2022-01-19 20:15:48,638 - INFO - [Step=37500]	Loss=0.7406	273.0 examples/second
2022-01-19 20:16:30,807 - INFO - Test Loss=0.8729, Test top-1 acc=0.7964
2022-01-19 20:16:30,807 - INFO - Group Accuracy:

2022-01-19 20:16:30,807 - INFO - [0.9819277  0.9893976  0.9838554  0.9930121  0.9838554  0.993253
 0.9804819  0.98240966 0.9889157  0.9766265  0.99108434 0.98674697
 0.97445786 0.9814458  0.97638553 0.9884337  0.9951807 ]
2022-01-19 20:16:30,808 - INFO - Epoch time: 397.70126509666443
2022-01-19 20:16:30,808 - INFO - 
Epoch: 45
2022-01-19 20:16:30,808 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:17:54,165 - INFO - [Step=37750]	Loss=0.7179	254.9 examples/second
2022-01-19 20:19:51,215 - INFO - [Step=38000]	Loss=0.7274	273.4 examples/second
2022-01-19 20:21:48,193 - INFO - [Step=38250]	Loss=0.7281	273.6 examples/second
2022-01-19 20:23:09,782 - INFO - Test Loss=0.8491, Test top-1 acc=0.7966
2022-01-19 20:23:09,782 - INFO - Group Accuracy:

2022-01-19 20:23:09,783 - INFO - [0.9804819  0.98963857 0.98650604 0.9927711  0.9833735  0.9930121
 0.9812048  0.98240966 0.9891566  0.97566265 0.9893976  0.9838554
 0.97542167 0.9807229  0.9787952  0.9881928  0.99445784]
2022-01-19 20:23:09,783 - INFO - Epoch time: 398.9753770828247
2022-01-19 20:23:09,783 - INFO - 
Epoch: 46
2022-01-19 20:23:09,783 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:23:53,664 - INFO - [Step=38500]	Loss=0.7406	255.0 examples/second
2022-01-19 20:25:51,125 - INFO - [Step=38750]	Loss=0.7220	272.4 examples/second
2022-01-19 20:27:48,331 - INFO - [Step=39000]	Loss=0.7328	273.0 examples/second
2022-01-19 20:29:50,331 - INFO - Test Loss=0.8625, Test top-1 acc=0.7988
2022-01-19 20:29:50,332 - INFO - Group Accuracy:

2022-01-19 20:29:50,332 - INFO - [0.9814458  0.9901205  0.9845783  0.9930121  0.98289156 0.9930121
 0.98289156 0.98       0.9898795  0.97518075 0.9891566  0.9848193
 0.9766265  0.9804819  0.9780723  0.9891566  0.9973494 ]
2022-01-19 20:29:50,333 - INFO - Epoch time: 400.54978489875793
2022-01-19 20:29:50,333 - INFO - 
Epoch: 47
2022-01-19 20:29:50,333 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:29:54,400 - INFO - [Step=39250]	Loss=0.7184	253.8 examples/second
2022-01-19 20:31:51,656 - INFO - [Step=39500]	Loss=0.7076	272.9 examples/second
2022-01-19 20:33:49,230 - INFO - [Step=39750]	Loss=0.7092	272.2 examples/second
2022-01-19 20:35:46,458 - INFO - [Step=40000]	Loss=0.7108	273.0 examples/second
2022-01-19 20:36:30,918 - INFO - Test Loss=1.2885, Test top-1 acc=0.7877
2022-01-19 20:36:30,918 - INFO - Group Accuracy:

2022-01-19 20:36:30,918 - INFO - [0.9780723  0.9891566  0.9833735  0.9922892  0.9845783  0.9930121
 0.97951806 0.9816868  0.9891566  0.97301203 0.9881928  0.9814458
 0.97493976 0.97975904 0.97831327 0.9886747  0.99493974]
2022-01-19 20:36:30,919 - INFO - Epoch time: 400.5861597061157
2022-01-19 20:36:30,919 - INFO - 
Epoch: 48
2022-01-19 20:36:30,919 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:37:51,885 - INFO - [Step=40250]	Loss=0.7014	255.1 examples/second
2022-01-19 20:39:49,027 - INFO - [Step=40500]	Loss=0.7005	273.2 examples/second
2022-01-19 20:41:46,018 - INFO - [Step=40750]	Loss=0.7149	273.5 examples/second
2022-01-19 20:43:09,994 - INFO - Test Loss=0.8038, Test top-1 acc=0.8058
2022-01-19 20:43:09,995 - INFO - Group Accuracy:

2022-01-19 20:43:09,995 - INFO - [0.9807229  0.9898795  0.98698795 0.9930121  0.9848193  0.9939759
 0.9814458  0.9826506  0.99084336 0.97590363 0.9913253  0.9848193
 0.97638553 0.9814458  0.9785542  0.9889157  0.9966265 ]
2022-01-19 20:43:09,995 - INFO - Saving...
2022-01-19 20:43:10,237 - INFO - Epoch time: 399.31746220588684
2022-01-19 20:43:10,237 - INFO - 
Epoch: 49
2022-01-19 20:43:10,237 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:43:51,409 - INFO - [Step=41000]	Loss=0.7079	255.2 examples/second
2022-01-19 20:45:48,126 - INFO - [Step=41250]	Loss=0.6875	274.2 examples/second
2022-01-19 20:47:44,938 - INFO - [Step=41500]	Loss=0.6859	273.9 examples/second
2022-01-19 20:49:41,752 - INFO - [Step=41750]	Loss=0.7129	273.9 examples/second
2022-01-19 20:49:48,568 - INFO - Test Loss=0.8211, Test top-1 acc=0.7981
2022-01-19 20:49:48,568 - INFO - Group Accuracy:

2022-01-19 20:49:48,568 - INFO - [0.98       0.9898795  0.9860241  0.9930121  0.9850602  0.9925301
 0.9778313  0.9840964  0.9898795  0.97638553 0.9891566  0.98433733
 0.9768675  0.9787952  0.9766265  0.9901205  0.9956626 ]
2022-01-19 20:49:48,569 - INFO - Epoch time: 398.3319482803345
2022-01-19 20:49:48,569 - INFO - 
Epoch: 50
2022-01-19 20:49:48,569 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:51:47,219 - INFO - [Step=42000]	Loss=0.6926	255.0 examples/second
2022-01-19 20:53:44,610 - INFO - [Step=42250]	Loss=0.6882	272.6 examples/second
2022-01-19 20:55:41,798 - INFO - [Step=42500]	Loss=0.7023	273.1 examples/second
2022-01-19 20:56:28,477 - INFO - Test Loss=0.8356, Test top-1 acc=0.7993
2022-01-19 20:56:28,478 - INFO - Group Accuracy:

2022-01-19 20:56:28,478 - INFO - [0.97903615 0.99036145 0.98433733 0.99373496 0.9833735  0.993253
 0.9804819  0.9819277  0.99036145 0.97638553 0.9901205  0.9855422
 0.9768675  0.9804819  0.97542167 0.98963857 0.9951807 ]
2022-01-19 20:56:28,478 - INFO - Epoch time: 399.9093647003174
2022-01-19 20:56:28,479 - INFO - 
Epoch: 51
2022-01-19 20:56:28,479 - INFO - 
Learning Rate: 0.0100
2022-01-19 20:57:47,286 - INFO - [Step=42750]	Loss=0.7072	255.0 examples/second
2022-01-19 20:59:44,605 - INFO - [Step=43000]	Loss=0.6779	272.8 examples/second
2022-01-19 21:01:41,653 - INFO - [Step=43250]	Loss=0.7002	273.4 examples/second
2022-01-19 21:03:08,127 - INFO - Test Loss=0.8379, Test top-1 acc=0.8002
2022-01-19 21:03:08,127 - INFO - Group Accuracy:

2022-01-19 21:03:08,127 - INFO - [0.98024094 0.9901205  0.9853012  0.99373496 0.98240966 0.9925301
 0.9821687  0.9833735  0.98963857 0.9771084  0.9891566  0.98433733
 0.9785542  0.9807229  0.97831327 0.9879518  0.9959036 ]
2022-01-19 21:03:08,128 - INFO - Epoch time: 399.6498456001282
2022-01-19 21:03:08,128 - INFO - 
Epoch: 52
2022-01-19 21:03:08,129 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:03:47,052 - INFO - [Step=43500]	Loss=0.6835	255.2 examples/second
2022-01-19 21:05:43,902 - INFO - [Step=43750]	Loss=0.6838	273.9 examples/second
2022-01-19 21:07:40,790 - INFO - [Step=44000]	Loss=0.6790	273.8 examples/second
2022-01-19 21:09:37,509 - INFO - [Step=44250]	Loss=0.6973	274.2 examples/second
2022-01-19 21:09:46,624 - INFO - Test Loss=0.9398, Test top-1 acc=0.7959
2022-01-19 21:09:46,624 - INFO - Group Accuracy:

2022-01-19 21:09:46,624 - INFO - [0.98024094 0.98963857 0.9850602  0.9930121  0.9845783  0.9927711
 0.9812048  0.98024094 0.9889157  0.97590363 0.9889157  0.98433733
 0.97566265 0.9804819  0.97927713 0.9889157  0.9966265 ]
2022-01-19 21:09:46,625 - INFO - Epoch time: 398.4964714050293
2022-01-19 21:09:46,625 - INFO - 
Epoch: 53
2022-01-19 21:09:46,625 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:11:42,703 - INFO - [Step=44500]	Loss=0.6664	255.6 examples/second
2022-01-19 21:13:39,711 - INFO - [Step=44750]	Loss=0.6783	273.5 examples/second
2022-01-19 21:15:36,600 - INFO - [Step=45000]	Loss=0.6954	273.8 examples/second
2022-01-19 21:16:25,605 - INFO - Test Loss=0.9022, Test top-1 acc=0.7916
2022-01-19 21:16:25,606 - INFO - Group Accuracy:

2022-01-19 21:16:25,606 - INFO - [0.97831327 0.99036145 0.9838554  0.9927711  0.98433733 0.993494
 0.98       0.9812048  0.9893976  0.97518075 0.9893976  0.9845783
 0.9768675  0.9816868  0.9771084  0.98963857 0.9954217 ]
2022-01-19 21:16:25,606 - INFO - Epoch time: 398.9812898635864
2022-01-19 21:16:25,606 - INFO - 
Epoch: 54
2022-01-19 21:16:25,606 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:17:42,168 - INFO - [Step=45250]	Loss=0.6650	254.8 examples/second
2022-01-19 21:19:39,902 - INFO - [Step=45500]	Loss=0.6807	271.8 examples/second
2022-01-19 21:21:37,547 - INFO - [Step=45750]	Loss=0.6678	272.0 examples/second
2022-01-19 21:23:06,836 - INFO - Test Loss=0.8114, Test top-1 acc=0.8043
2022-01-19 21:23:06,842 - INFO - Group Accuracy:

2022-01-19 21:23:06,842 - INFO - [0.9807229  0.9901205  0.98722893 0.9939759  0.98433733 0.99421686
 0.98024094 0.98361444 0.9901205  0.9739759  0.9922892  0.9850602
 0.9773494  0.9816868  0.97590363 0.9901205  0.9956626 ]
2022-01-19 21:23:06,843 - INFO - Epoch time: 401.23673582077026
2022-01-19 21:23:06,843 - INFO - 
Epoch: 55
2022-01-19 21:23:06,843 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:23:43,505 - INFO - [Step=46000]	Loss=0.6618	254.1 examples/second
2022-01-19 21:25:41,296 - INFO - [Step=46250]	Loss=0.6646	271.7 examples/second
2022-01-19 21:27:39,077 - INFO - [Step=46500]	Loss=0.6729	271.7 examples/second
2022-01-19 21:29:36,821 - INFO - [Step=46750]	Loss=0.6680	271.8 examples/second
2022-01-19 21:29:48,760 - INFO - Test Loss=0.8111, Test top-1 acc=0.7993
2022-01-19 21:29:48,761 - INFO - Group Accuracy:

2022-01-19 21:29:48,761 - INFO - [0.9812048  0.99156624 0.98626506 0.99373496 0.98361444 0.993494
 0.98024094 0.9814458  0.9901205  0.97638553 0.98674697 0.9853012
 0.97614455 0.9812048  0.97590363 0.98963857 0.99710846]
2022-01-19 21:29:48,762 - INFO - Epoch time: 401.9185583591461
2022-01-19 21:29:48,762 - INFO - 
Epoch: 56
2022-01-19 21:29:48,762 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:31:42,488 - INFO - [Step=47000]	Loss=0.6513	254.6 examples/second
2022-01-19 21:33:39,118 - INFO - [Step=47250]	Loss=0.6726	274.4 examples/second
2022-01-19 21:35:35,533 - INFO - [Step=47500]	Loss=0.6792	274.9 examples/second
2022-01-19 21:36:27,180 - INFO - Test Loss=0.8822, Test top-1 acc=0.8048
2022-01-19 21:36:27,180 - INFO - Group Accuracy:

2022-01-19 21:36:27,180 - INFO - [0.9809638  0.9893976  0.9853012  0.99421686 0.9850602  0.9930121
 0.9838554  0.98289156 0.99060243 0.9780723  0.98746985 0.9848193
 0.97566265 0.9807229  0.9778313  0.9893976  0.9973494 ]
2022-01-19 21:36:27,181 - INFO - Epoch time: 398.4193606376648
2022-01-19 21:36:27,181 - INFO - 
Epoch: 57
2022-01-19 21:36:27,181 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:37:41,580 - INFO - [Step=47750]	Loss=0.6553	253.9 examples/second
2022-01-19 21:39:39,117 - INFO - [Step=48000]	Loss=0.6413	272.3 examples/second
2022-01-19 21:41:36,697 - INFO - [Step=48250]	Loss=0.6621	272.2 examples/second
2022-01-19 21:43:08,625 - INFO - Test Loss=0.8604, Test top-1 acc=0.7993
2022-01-19 21:43:08,626 - INFO - Group Accuracy:

2022-01-19 21:43:08,626 - INFO - [0.9804819  0.99036145 0.9850602  0.9930121  0.98313254 0.99445784
 0.97975904 0.9821687  0.98963857 0.9771084  0.9898795  0.9860241
 0.9727711  0.9804819  0.97493976 0.9886747  0.9956626 ]
2022-01-19 21:43:08,626 - INFO - Epoch time: 401.4450144767761
2022-01-19 21:43:08,626 - INFO - 
Epoch: 58
2022-01-19 21:43:08,626 - INFO - 
Learning Rate: 0.0100
2022-01-19 21:43:42,798 - INFO - [Step=48500]	Loss=0.6667	253.8 examples/second
2022-01-19 21:45:39,545 - INFO - [Step=48750]	Loss=0.6447	274.1 examples/second
2022-01-19 21:47:36,385 - INFO - [Step=49000]	Loss=0.6480	273.9 examples/second
2022-01-19 21:49:33,370 - INFO - [Step=49250]	Loss=0.6541	273.5 examples/second
2022-01-19 21:49:47,359 - INFO - Test Loss=0.8308, Test top-1 acc=0.7976
2022-01-19 21:49:47,360 - INFO - Group Accuracy:

2022-01-19 21:49:47,360 - INFO - [0.9787952  0.9901205  0.9838554  0.9939759  0.98240966 0.993494
 0.9819277  0.9826506  0.99036145 0.9775904  0.99060243 0.9860241
 0.9775904  0.9804819  0.9746988  0.99036145 0.9956626 ]
2022-01-19 21:49:47,360 - INFO - Epoch time: 398.73402547836304
2022-01-19 21:49:47,360 - INFO - 
Epoch: 59
2022-01-19 21:49:47,360 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:51:38,747 - INFO - [Step=49500]	Loss=0.6187	255.2 examples/second
2022-01-19 21:53:35,521 - INFO - [Step=49750]	Loss=0.5838	274.0 examples/second
2022-01-19 21:55:32,127 - INFO - [Step=50000]	Loss=0.5690	274.4 examples/second
2022-01-19 21:56:25,827 - INFO - Test Loss=0.7705, Test top-1 acc=0.8094
2022-01-19 21:56:25,828 - INFO - Group Accuracy:

2022-01-19 21:56:25,828 - INFO - [0.9819277  0.9922892  0.98722893 0.9939759  0.9853012  0.99421686
 0.9816868  0.9821687  0.99156624 0.9778313  0.99108434 0.9860241
 0.9771084  0.98240966 0.97566265 0.9891566  0.9961446 ]
2022-01-19 21:56:25,828 - INFO - Saving...
2022-01-19 21:56:26,000 - INFO - Epoch time: 398.6397066116333
2022-01-19 21:56:26,000 - INFO - 
Epoch: 60
2022-01-19 21:56:26,000 - INFO - 
Learning Rate: 0.0010
2022-01-19 21:57:37,726 - INFO - [Step=50250]	Loss=0.5586	254.8 examples/second
2022-01-19 21:59:34,840 - INFO - [Step=50500]	Loss=0.5773	273.2 examples/second
2022-01-19 22:01:31,573 - INFO - [Step=50750]	Loss=0.5600	274.1 examples/second
2022-01-19 22:03:04,964 - INFO - Test Loss=0.7672, Test top-1 acc=0.8125
2022-01-19 22:03:04,965 - INFO - Group Accuracy:

2022-01-19 22:03:04,965 - INFO - [0.9812048  0.9927711  0.98771083 0.99373496 0.9855422  0.99445784
 0.98313254 0.98289156 0.99156624 0.9773494  0.99108434 0.98698795
 0.9775904  0.9819277  0.97566265 0.99036145 0.9963855 ]
2022-01-19 22:03:04,966 - INFO - Saving...
2022-01-19 22:03:05,230 - INFO - Epoch time: 399.22967314720154
2022-01-19 22:03:05,230 - INFO - 
Epoch: 61
2022-01-19 22:03:05,230 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:03:37,667 - INFO - [Step=51000]	Loss=0.5650	253.8 examples/second
2022-01-19 22:05:35,245 - INFO - [Step=51250]	Loss=0.5469	272.2 examples/second
2022-01-19 22:07:32,586 - INFO - [Step=51500]	Loss=0.5502	272.7 examples/second
2022-01-19 22:09:30,186 - INFO - [Step=51750]	Loss=0.5461	272.1 examples/second
2022-01-19 22:09:46,483 - INFO - Test Loss=0.7734, Test top-1 acc=0.8082
2022-01-19 22:09:46,483 - INFO - Group Accuracy:

2022-01-19 22:09:46,483 - INFO - [0.97975904 0.9918072  0.98722893 0.99421686 0.98578316 0.99421686
 0.9821687  0.98289156 0.9913253  0.9771084  0.99036145 0.9853012
 0.97831327 0.9816868  0.97614455 0.9901205  0.9961446 ]
2022-01-19 22:09:46,484 - INFO - Epoch time: 401.2536029815674
2022-01-19 22:09:46,484 - INFO - 
Epoch: 62
2022-01-19 22:09:46,484 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:11:36,396 - INFO - [Step=52000]	Loss=0.5412	253.5 examples/second
2022-01-19 22:13:34,149 - INFO - [Step=52250]	Loss=0.5409	271.8 examples/second
2022-01-19 22:15:31,903 - INFO - [Step=52500]	Loss=0.5536	271.8 examples/second
2022-01-19 22:16:28,432 - INFO - Test Loss=0.7722, Test top-1 acc=0.8104
2022-01-19 22:16:28,433 - INFO - Group Accuracy:

2022-01-19 22:16:28,433 - INFO - [0.9812048  0.9925301  0.98674697 0.993494   0.9853012  0.99445784
 0.9826506  0.9826506  0.9918072  0.9768675  0.99060243 0.98650604
 0.9780723  0.9816868  0.97566265 0.9898795  0.9963855 ]
2022-01-19 22:16:28,434 - INFO - Epoch time: 401.94979977607727
2022-01-19 22:16:28,434 - INFO - 
Epoch: 63
2022-01-19 22:16:28,434 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:17:37,812 - INFO - [Step=52750]	Loss=0.5409	254.2 examples/second
2022-01-19 22:19:34,787 - INFO - [Step=53000]	Loss=0.5436	273.6 examples/second
2022-01-19 22:21:31,787 - INFO - [Step=53250]	Loss=0.5403	273.5 examples/second
2022-01-19 22:23:07,688 - INFO - Test Loss=0.7743, Test top-1 acc=0.8096
2022-01-19 22:23:07,689 - INFO - Group Accuracy:

2022-01-19 22:23:07,696 - INFO - [0.9807229  0.9922892  0.9879518  0.9939759  0.9845783  0.99445784
 0.9833735  0.98240966 0.9920482  0.9775904  0.99036145 0.9855422
 0.9780723  0.9814458  0.97590363 0.9898795  0.9961446 ]
2022-01-19 22:23:07,697 - INFO - Epoch time: 399.26313638687134
2022-01-19 22:23:07,697 - INFO - 
Epoch: 64
2022-01-19 22:23:07,697 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:23:37,390 - INFO - [Step=53500]	Loss=0.5364	254.8 examples/second
2022-01-19 22:25:34,928 - INFO - [Step=53750]	Loss=0.5330	272.3 examples/second
2022-01-19 22:27:32,443 - INFO - [Step=54000]	Loss=0.5406	272.3 examples/second
2022-01-19 22:29:29,978 - INFO - [Step=54250]	Loss=0.5246	272.3 examples/second
2022-01-19 22:29:48,844 - INFO - Test Loss=0.7771, Test top-1 acc=0.8101
2022-01-19 22:29:48,844 - INFO - Group Accuracy:

2022-01-19 22:29:48,844 - INFO - [0.9812048  0.9925301  0.98771083 0.99421686 0.9850602  0.9946988
 0.9821687  0.98313254 0.9913253  0.9768675  0.99108434 0.9853012
 0.9778313  0.9819277  0.97614455 0.9901205  0.9961446 ]
2022-01-19 22:29:48,845 - INFO - Epoch time: 401.147997379303
2022-01-19 22:29:48,845 - INFO - 
Epoch: 65
2022-01-19 22:29:48,845 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:31:36,195 - INFO - [Step=54500]	Loss=0.5148	253.5 examples/second
2022-01-19 22:33:33,770 - INFO - [Step=54750]	Loss=0.5289	272.2 examples/second
2022-01-19 22:35:31,220 - INFO - [Step=55000]	Loss=0.5466	272.5 examples/second
2022-01-19 22:36:29,932 - INFO - Test Loss=0.7789, Test top-1 acc=0.8077
2022-01-19 22:36:29,932 - INFO - Group Accuracy:

2022-01-19 22:36:29,932 - INFO - [0.98024094 0.9922892  0.98674697 0.99373496 0.9850602  0.99445784
 0.9826506  0.98240966 0.9913253  0.9773494  0.99084336 0.9853012
 0.9775904  0.9819277  0.97638553 0.9886747  0.9959036 ]
2022-01-19 22:36:29,934 - INFO - Epoch time: 401.08844113349915
2022-01-19 22:36:29,934 - INFO - 
Epoch: 66
2022-01-19 22:36:29,934 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:37:36,981 - INFO - [Step=55250]	Loss=0.5249	254.5 examples/second
2022-01-19 22:39:33,791 - INFO - [Step=55500]	Loss=0.5253	274.0 examples/second
2022-01-19 22:41:30,689 - INFO - [Step=55750]	Loss=0.5097	273.7 examples/second
2022-01-19 22:43:08,846 - INFO - Test Loss=0.7814, Test top-1 acc=0.8094
2022-01-19 22:43:08,846 - INFO - Group Accuracy:

2022-01-19 22:43:08,846 - INFO - [0.9809638  0.9920482  0.98674697 0.99421686 0.9850602  0.99421686
 0.98289156 0.98240966 0.99108434 0.97638553 0.9920482  0.9855422
 0.9778313  0.9814458  0.97638553 0.9891566  0.9966265 ]
2022-01-19 22:43:08,847 - INFO - Epoch time: 398.9137318134308
2022-01-19 22:43:08,847 - INFO - 
Epoch: 67
2022-01-19 22:43:08,847 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:43:36,237 - INFO - [Step=56000]	Loss=0.5331	254.9 examples/second
2022-01-19 22:45:33,327 - INFO - [Step=56250]	Loss=0.5190	273.3 examples/second
2022-01-19 22:47:30,256 - INFO - [Step=56500]	Loss=0.5296	273.7 examples/second
2022-01-19 22:49:27,246 - INFO - [Step=56750]	Loss=0.5267	273.5 examples/second
2022-01-19 22:49:48,260 - INFO - Test Loss=0.7839, Test top-1 acc=0.8125
2022-01-19 22:49:48,260 - INFO - Group Accuracy:

2022-01-19 22:49:48,260 - INFO - [0.9814458  0.9920482  0.98746985 0.99373496 0.9853012  0.99493974
 0.9821687  0.98289156 0.99108434 0.9766265  0.99036145 0.9860241
 0.9785542  0.9814458  0.97638553 0.98963857 0.9963855 ]
2022-01-19 22:49:48,261 - INFO - Epoch time: 399.4131247997284
2022-01-19 22:49:48,261 - INFO - 
Epoch: 68
2022-01-19 22:49:48,261 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:51:32,700 - INFO - [Step=57000]	Loss=0.5200	255.1 examples/second
2022-01-19 22:53:29,518 - INFO - [Step=57250]	Loss=0.5190	273.9 examples/second
2022-01-19 22:55:26,384 - INFO - [Step=57500]	Loss=0.5217	273.8 examples/second
2022-01-19 22:56:27,232 - INFO - Test Loss=0.7822, Test top-1 acc=0.8108
2022-01-19 22:56:27,232 - INFO - Group Accuracy:

2022-01-19 22:56:27,232 - INFO - [0.9804819  0.99156624 0.98698795 0.99421686 0.9853012  0.9946988
 0.98240966 0.9826506  0.99036145 0.9773494  0.9918072  0.98578316
 0.9775904  0.9821687  0.97590363 0.9891566  0.9966265 ]
2022-01-19 22:56:27,233 - INFO - Epoch time: 398.97270822525024
2022-01-19 22:56:27,233 - INFO - 
Epoch: 69
2022-01-19 22:56:27,233 - INFO - 
Learning Rate: 0.0010
2022-01-19 22:57:32,406 - INFO - [Step=57750]	Loss=0.5378	253.9 examples/second
2022-01-19 22:59:29,287 - INFO - [Step=58000]	Loss=0.5101	273.8 examples/second
2022-01-19 23:01:26,199 - INFO - [Step=58250]	Loss=0.5157	273.7 examples/second
2022-01-19 23:03:06,564 - INFO - Test Loss=0.7869, Test top-1 acc=0.8087
2022-01-19 23:03:06,564 - INFO - Group Accuracy:

2022-01-19 23:03:06,564 - INFO - [0.9804819  0.9920482  0.98674697 0.99445784 0.9855422  0.99421686
 0.9816868  0.9812048  0.99084336 0.9775904  0.99108434 0.98650604
 0.9773494  0.98240966 0.97566265 0.9893976  0.9961446 ]
2022-01-19 23:03:06,565 - INFO - Epoch time: 399.33146023750305
2022-01-19 23:03:06,565 - INFO - 
Epoch: 70
2022-01-19 23:03:06,565 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:03:32,018 - INFO - [Step=58500]	Loss=0.5144	254.3 examples/second
2022-01-19 23:05:30,143 - INFO - [Step=58750]	Loss=0.5174	270.9 examples/second
2022-01-19 23:07:28,009 - INFO - [Step=59000]	Loss=0.5095	271.5 examples/second
2022-01-19 23:09:25,664 - INFO - [Step=59250]	Loss=0.5212	272.0 examples/second
2022-01-19 23:09:49,026 - INFO - Test Loss=0.7846, Test top-1 acc=0.8084
2022-01-19 23:09:49,027 - INFO - Group Accuracy:

2022-01-19 23:09:49,027 - INFO - [0.9807229  0.99156624 0.98698795 0.99421686 0.9850602  0.99421686
 0.98240966 0.98289156 0.99156624 0.9771084  0.9913253  0.9853012
 0.9775904  0.9826506  0.97614455 0.9898795  0.9966265 ]
2022-01-19 23:09:49,028 - INFO - Epoch time: 402.4628505706787
2022-01-19 23:09:49,028 - INFO - 
Epoch: 71
2022-01-19 23:09:49,028 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:11:32,167 - INFO - [Step=59500]	Loss=0.5040	253.0 examples/second
2022-01-19 23:13:29,866 - INFO - [Step=59750]	Loss=0.5105	271.9 examples/second
2022-01-19 23:15:27,607 - INFO - [Step=60000]	Loss=0.5219	271.8 examples/second
2022-01-19 23:16:31,080 - INFO - Test Loss=0.7783, Test top-1 acc=0.8108
2022-01-19 23:16:31,080 - INFO - Group Accuracy:

2022-01-19 23:16:31,080 - INFO - [0.9804819  0.9922892  0.9884337  0.99493974 0.9853012  0.99421686
 0.9833735  0.9819277  0.99108434 0.97614455 0.9913253  0.9860241
 0.9773494  0.9826506  0.97638553 0.9889157  0.9966265 ]
2022-01-19 23:16:31,081 - INFO - Epoch time: 402.05325961112976
2022-01-19 23:16:31,081 - INFO - 
Epoch: 72
2022-01-19 23:16:31,081 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:17:33,696 - INFO - [Step=60250]	Loss=0.5145	253.8 examples/second
2022-01-19 23:19:31,401 - INFO - [Step=60500]	Loss=0.5083	271.9 examples/second
2022-01-19 23:21:29,042 - INFO - [Step=60750]	Loss=0.5016	272.0 examples/second
2022-01-19 23:23:12,468 - INFO - Test Loss=0.7837, Test top-1 acc=0.8113
2022-01-19 23:23:12,468 - INFO - Group Accuracy:

2022-01-19 23:23:12,468 - INFO - [0.9807229  0.9918072  0.98746985 0.99373496 0.9853012  0.9946988
 0.9833735  0.98313254 0.99156624 0.9778313  0.99108434 0.9855422
 0.9775904  0.9821687  0.9766265  0.9891566  0.9963855 ]
2022-01-19 23:23:12,469 - INFO - Epoch time: 401.3877544403076
2022-01-19 23:23:12,469 - INFO - 
Epoch: 73
2022-01-19 23:23:12,469 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:23:35,252 - INFO - [Step=61000]	Loss=0.5214	253.5 examples/second
2022-01-19 23:25:32,120 - INFO - [Step=61250]	Loss=0.5114	273.8 examples/second
2022-01-19 23:27:28,994 - INFO - [Step=61500]	Loss=0.5100	273.8 examples/second
2022-01-19 23:29:25,873 - INFO - [Step=61750]	Loss=0.5091	273.8 examples/second
2022-01-19 23:29:51,719 - INFO - Test Loss=0.7841, Test top-1 acc=0.8101
2022-01-19 23:29:51,720 - INFO - Group Accuracy:

2022-01-19 23:29:51,720 - INFO - [0.98240966 0.9920482  0.98771083 0.9946988  0.9848193  0.9946988
 0.9826506  0.9816868  0.9913253  0.9768675  0.99060243 0.98650604
 0.9787952  0.9819277  0.97590363 0.9893976  0.9959036 ]
2022-01-19 23:29:51,721 - INFO - Epoch time: 399.25192975997925
2022-01-19 23:29:51,721 - INFO - 
Epoch: 74
2022-01-19 23:29:51,721 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:31:31,717 - INFO - [Step=62000]	Loss=0.5176	254.3 examples/second
2022-01-19 23:33:28,293 - INFO - [Step=62250]	Loss=0.4963	274.5 examples/second
2022-01-19 23:35:24,989 - INFO - [Step=62500]	Loss=0.4934	274.2 examples/second
2022-01-19 23:36:30,458 - INFO - Test Loss=0.7835, Test top-1 acc=0.8075
2022-01-19 23:36:30,458 - INFO - Group Accuracy:

2022-01-19 23:36:30,459 - INFO - [0.9809638  0.9913253  0.98650604 0.99445784 0.98626506 0.9951807
 0.98289156 0.9826506  0.9913253  0.97614455 0.9918072  0.9850602
 0.9775904  0.9816868  0.9768675  0.9898795  0.9961446 ]
2022-01-19 23:36:30,459 - INFO - Epoch time: 398.73832154273987
2022-01-19 23:36:30,459 - INFO - 
Epoch: 75
2022-01-19 23:36:30,460 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:37:31,041 - INFO - [Step=62750]	Loss=0.4941	253.9 examples/second
2022-01-19 23:39:27,167 - INFO - [Step=63000]	Loss=0.4962	275.6 examples/second
2022-01-19 23:41:23,488 - INFO - [Step=63250]	Loss=0.5071	275.1 examples/second
2022-01-19 23:43:08,308 - INFO - Test Loss=0.7924, Test top-1 acc=0.8101
2022-01-19 23:43:08,309 - INFO - Group Accuracy:

2022-01-19 23:43:08,309 - INFO - [0.9816868  0.9920482  0.9884337  0.99373496 0.9850602  0.9946988
 0.9826506  0.9819277  0.9918072  0.9768675  0.9913253  0.9860241
 0.97903615 0.9819277  0.97638553 0.9891566  0.9961446 ]
2022-01-19 23:43:08,310 - INFO - Epoch time: 397.85015630722046
2022-01-19 23:43:08,310 - INFO - 
Epoch: 76
2022-01-19 23:43:08,310 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:43:28,649 - INFO - [Step=63500]	Loss=0.5054	255.7 examples/second
2022-01-19 23:45:24,289 - INFO - [Step=63750]	Loss=0.5000	276.7 examples/second
2022-01-19 23:47:19,890 - INFO - [Step=64000]	Loss=0.4912	276.8 examples/second
2022-01-19 23:49:15,876 - INFO - [Step=64250]	Loss=0.4789	275.9 examples/second
2022-01-19 23:49:44,068 - INFO - Test Loss=0.7908, Test top-1 acc=0.8101
2022-01-19 23:49:44,069 - INFO - Group Accuracy:

2022-01-19 23:49:44,069 - INFO - [0.9819277  0.99108434 0.98771083 0.9939759  0.9848193  0.9939759
 0.9833735  0.98240966 0.99084336 0.9778313  0.99084336 0.9855422
 0.9768675  0.9821687  0.9768675  0.9891566  0.9966265 ]
2022-01-19 23:49:44,070 - INFO - Epoch time: 395.7598147392273
2022-01-19 23:49:44,070 - INFO - 
Epoch: 77
2022-01-19 23:49:44,070 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:51:22,170 - INFO - [Step=64500]	Loss=0.5043	253.4 examples/second
2022-01-19 23:53:19,995 - INFO - [Step=64750]	Loss=0.4928	271.6 examples/second
2022-01-19 23:55:17,902 - INFO - [Step=65000]	Loss=0.4990	271.4 examples/second
2022-01-19 23:56:26,437 - INFO - Test Loss=0.8009, Test top-1 acc=0.8067
2022-01-19 23:56:26,437 - INFO - Group Accuracy:

2022-01-19 23:56:26,438 - INFO - [0.9814458  0.9913253  0.98698795 0.99421686 0.9850602  0.9939759
 0.98313254 0.9812048  0.99084336 0.9775904  0.99084336 0.9853012
 0.97831327 0.9819277  0.97614455 0.9889157  0.9951807 ]
2022-01-19 23:56:26,438 - INFO - Epoch time: 402.3687090873718
2022-01-19 23:56:26,438 - INFO - 
Epoch: 78
2022-01-19 23:56:26,438 - INFO - 
Learning Rate: 0.0010
2022-01-19 23:57:24,511 - INFO - [Step=65250]	Loss=0.4964	252.7 examples/second
2022-01-19 23:59:22,184 - INFO - [Step=65500]	Loss=0.4917	271.9 examples/second
2022-01-20 00:01:19,806 - INFO - [Step=65750]	Loss=0.4928	272.1 examples/second
2022-01-20 00:03:07,926 - INFO - Test Loss=0.7914, Test top-1 acc=0.8094
2022-01-20 00:03:07,926 - INFO - Group Accuracy:

2022-01-20 00:03:07,936 - INFO - [0.9814458  0.9920482  0.98650604 0.99421686 0.9860241  0.99421686
 0.98289156 0.9821687  0.9901205  0.9785542  0.99084336 0.9860241
 0.9785542  0.9816868  0.97566265 0.9889157  0.9959036 ]
2022-01-20 00:03:07,937 - INFO - Epoch time: 401.49843072891235
2022-01-20 00:03:07,937 - INFO - 
Epoch: 79
2022-01-20 00:03:07,937 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:03:26,021 - INFO - [Step=66000]	Loss=0.5069	253.5 examples/second
2022-01-20 00:05:23,566 - INFO - [Step=66250]	Loss=0.5049	272.2 examples/second
2022-01-20 00:07:21,221 - INFO - [Step=66500]	Loss=0.4905	272.0 examples/second
2022-01-20 00:09:18,940 - INFO - [Step=66750]	Loss=0.4975	271.8 examples/second
2022-01-20 00:09:49,524 - INFO - Test Loss=0.7867, Test top-1 acc=0.8099
2022-01-20 00:09:49,525 - INFO - Group Accuracy:

2022-01-20 00:09:49,525 - INFO - [0.9819277  0.9913253  0.98626506 0.9939759  0.9855422  0.99445784
 0.98361444 0.9819277  0.99084336 0.97638553 0.9920482  0.98650604
 0.9780723  0.9819277  0.9766265  0.9889157  0.9966265 ]
2022-01-20 00:09:49,527 - INFO - Epoch time: 401.58983397483826
2022-01-20 00:09:49,527 - INFO - 
Epoch: 80
2022-01-20 00:09:49,527 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:11:25,397 - INFO - [Step=67000]	Loss=0.4846	253.1 examples/second
2022-01-20 00:13:23,329 - INFO - [Step=67250]	Loss=0.4899	271.3 examples/second
2022-01-20 00:15:21,294 - INFO - [Step=67500]	Loss=0.4930	271.3 examples/second
2022-01-20 00:16:30,812 - INFO - Test Loss=0.7985, Test top-1 acc=0.8063
2022-01-20 00:16:30,812 - INFO - Group Accuracy:

2022-01-20 00:16:30,813 - INFO - [0.9812048  0.99108434 0.98771083 0.99373496 0.9845783  0.99445784
 0.98240966 0.9819277  0.99108434 0.9778313  0.9920482  0.9853012
 0.9780723  0.9819277  0.9766265  0.9889157  0.9959036 ]
2022-01-20 00:16:30,813 - INFO - Epoch time: 401.2864463329315
2022-01-20 00:16:30,813 - INFO - 
Epoch: 81
2022-01-20 00:16:30,813 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:17:25,700 - INFO - [Step=67750]	Loss=0.4924	257.2 examples/second
2022-01-20 00:19:21,369 - INFO - [Step=68000]	Loss=0.4909	276.7 examples/second
2022-01-20 00:21:17,111 - INFO - [Step=68250]	Loss=0.4950	276.5 examples/second
2022-01-20 00:23:06,217 - INFO - Test Loss=0.7979, Test top-1 acc=0.8096
2022-01-20 00:23:06,217 - INFO - Group Accuracy:

2022-01-20 00:23:06,217 - INFO - [0.9812048  0.9920482  0.98698795 0.99421686 0.9850602  0.99421686
 0.98289156 0.98240966 0.9913253  0.9773494  0.9920482  0.98578316
 0.9773494  0.9816868  0.9768675  0.98963857 0.9963855 ]
2022-01-20 00:23:06,218 - INFO - Epoch time: 395.40431809425354
2022-01-20 00:23:06,218 - INFO - 
Epoch: 82
2022-01-20 00:23:06,218 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:23:21,790 - INFO - [Step=68500]	Loss=0.4841	256.7 examples/second
2022-01-20 00:25:17,593 - INFO - [Step=68750]	Loss=0.4915	276.3 examples/second
2022-01-20 00:27:15,432 - INFO - [Step=69000]	Loss=0.4937	271.6 examples/second
2022-01-20 00:29:13,532 - INFO - [Step=69250]	Loss=0.4895	271.0 examples/second
2022-01-20 00:29:46,416 - INFO - Test Loss=0.7990, Test top-1 acc=0.8118
2022-01-20 00:29:46,416 - INFO - Group Accuracy:

2022-01-20 00:29:46,416 - INFO - [0.9812048  0.99156624 0.98722893 0.99373496 0.9860241  0.9946988
 0.98289156 0.9814458  0.99036145 0.9773494  0.9922892  0.98698795
 0.9775904  0.9821687  0.9768675  0.9884337  0.9963855 ]
2022-01-20 00:29:46,418 - INFO - Epoch time: 400.1997616291046
2022-01-20 00:29:46,418 - INFO - 
Epoch: 83
2022-01-20 00:29:46,418 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:31:19,857 - INFO - [Step=69500]	Loss=0.4770	253.3 examples/second
2022-01-20 00:33:17,538 - INFO - [Step=69750]	Loss=0.4903	271.9 examples/second
2022-01-20 00:35:14,925 - INFO - [Step=70000]	Loss=0.5121	272.6 examples/second
2022-01-20 00:36:28,142 - INFO - Test Loss=0.7975, Test top-1 acc=0.8099
2022-01-20 00:36:28,143 - INFO - Group Accuracy:

2022-01-20 00:36:28,143 - INFO - [0.9812048  0.99156624 0.98746985 0.9930121  0.9855422  0.99421686
 0.98289156 0.9826506  0.99060243 0.9775904  0.99084336 0.98578316
 0.9780723  0.9816868  0.9771084  0.98963857 0.9959036 ]
2022-01-20 00:36:28,144 - INFO - Epoch time: 401.7261438369751
2022-01-20 00:36:28,144 - INFO - 
Epoch: 84
2022-01-20 00:36:28,144 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:37:21,691 - INFO - [Step=70250]	Loss=0.4786	252.4 examples/second
2022-01-20 00:39:19,520 - INFO - [Step=70500]	Loss=0.4781	271.6 examples/second
2022-01-20 00:41:17,269 - INFO - [Step=70750]	Loss=0.4825	271.8 examples/second
2022-01-20 00:43:10,527 - INFO - Test Loss=0.8080, Test top-1 acc=0.8128
2022-01-20 00:43:10,527 - INFO - Group Accuracy:

2022-01-20 00:43:10,527 - INFO - [0.9812048  0.9918072  0.98771083 0.99373496 0.9855422  0.99445784
 0.98361444 0.9814458  0.99060243 0.9768675  0.99084336 0.9860241
 0.9780723  0.9826506  0.9775904  0.9898795  0.9961446 ]
2022-01-20 00:43:10,528 - INFO - Saving...
2022-01-20 00:43:10,758 - INFO - Epoch time: 402.6135778427124
2022-01-20 00:43:10,758 - INFO - 
Epoch: 85
2022-01-20 00:43:10,758 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:43:23,908 - INFO - [Step=71000]	Loss=0.4798	252.7 examples/second
2022-01-20 00:45:21,767 - INFO - [Step=71250]	Loss=0.4968	271.5 examples/second
2022-01-20 00:47:19,690 - INFO - [Step=71500]	Loss=0.4934	271.4 examples/second
2022-01-20 00:49:17,655 - INFO - [Step=71750]	Loss=0.4856	271.3 examples/second
2022-01-20 00:49:53,024 - INFO - Test Loss=0.8094, Test top-1 acc=0.8080
2022-01-20 00:49:53,025 - INFO - Group Accuracy:

2022-01-20 00:49:53,025 - INFO - [0.9807229  0.9918072  0.9884337  0.99421686 0.9853012  0.99421686
 0.9819277  0.9821687  0.99060243 0.9771084  0.9918072  0.9855422
 0.97638553 0.9821687  0.9766265  0.98963857 0.9963855 ]
2022-01-20 00:49:53,026 - INFO - Epoch time: 402.2679440975189
2022-01-20 00:49:53,026 - INFO - 
Epoch: 86
2022-01-20 00:49:53,026 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:51:24,036 - INFO - [Step=72000]	Loss=0.4785	253.2 examples/second
2022-01-20 00:53:20,531 - INFO - [Step=72250]	Loss=0.4923	274.7 examples/second
2022-01-20 00:55:16,442 - INFO - [Step=72500]	Loss=0.4767	276.1 examples/second
2022-01-20 00:56:31,405 - INFO - Test Loss=0.8013, Test top-1 acc=0.8096
2022-01-20 00:56:31,405 - INFO - Group Accuracy:

2022-01-20 00:56:31,405 - INFO - [0.9809638  0.9918072  0.98771083 0.9946988  0.9853012  0.99445784
 0.9816868  0.9816868  0.99060243 0.9775904  0.9920482  0.98674697
 0.9771084  0.9819277  0.9768675  0.9889157  0.9961446 ]
2022-01-20 00:56:31,406 - INFO - Epoch time: 398.3801259994507
2022-01-20 00:56:31,406 - INFO - 
Epoch: 87
2022-01-20 00:56:31,406 - INFO - 
Learning Rate: 0.0010
2022-01-20 00:57:22,319 - INFO - [Step=72750]	Loss=0.4780	254.2 examples/second
2022-01-20 00:59:20,030 - INFO - [Step=73000]	Loss=0.4778	271.9 examples/second
2022-01-20 01:01:17,844 - INFO - [Step=73250]	Loss=0.4788	271.6 examples/second
2022-01-20 01:03:13,549 - INFO - Test Loss=0.8067, Test top-1 acc=0.8089
2022-01-20 01:03:13,550 - INFO - Group Accuracy:

2022-01-20 01:03:13,550 - INFO - [0.9809638  0.9920482  0.98674697 0.99421686 0.98626506 0.99445784
 0.9819277  0.98240966 0.99084336 0.9771084  0.9927711  0.98626506
 0.9768675  0.9821687  0.9775904  0.98963857 0.9963855 ]
2022-01-20 01:03:13,551 - INFO - Epoch time: 402.1447432041168
2022-01-20 01:03:13,551 - INFO - 
Epoch: 88
2022-01-20 01:03:13,551 - INFO - 
Learning Rate: 0.0010
2022-01-20 01:03:24,592 - INFO - [Step=73500]	Loss=0.4820	252.5 examples/second
2022-01-20 01:05:22,417 - INFO - [Step=73750]	Loss=0.4752	271.6 examples/second
2022-01-20 01:07:20,025 - INFO - [Step=74000]	Loss=0.4726	272.1 examples/second
2022-01-20 01:09:18,076 - INFO - [Step=74250]	Loss=0.4796	271.1 examples/second
2022-01-20 01:09:55,876 - INFO - Test Loss=0.8146, Test top-1 acc=0.8092
2022-01-20 01:09:55,876 - INFO - Group Accuracy:

2022-01-20 01:09:55,876 - INFO - [0.9807229  0.9913253  0.98722893 0.9946988  0.9838554  0.99421686
 0.98289156 0.98313254 0.9901205  0.9780723  0.99084336 0.98650604
 0.9771084  0.9816868  0.97566265 0.9891566  0.9961446 ]
2022-01-20 01:09:55,877 - INFO - Epoch time: 402.32614612579346
2022-01-20 01:09:55,877 - INFO - 
Epoch: 89
2022-01-20 01:09:55,877 - INFO - 
Learning Rate: 0.0010
2022-01-20 01:11:25,065 - INFO - [Step=74500]	Loss=0.4819	252.0 examples/second
2022-01-20 01:13:22,959 - INFO - [Step=74750]	Loss=0.4665	271.4 examples/second
2022-01-20 01:15:20,612 - INFO - [Step=75000]	Loss=0.4917	272.0 examples/second
2022-01-20 01:16:38,210 - INFO - Test Loss=0.8044, Test top-1 acc=0.8120
2022-01-20 01:16:38,211 - INFO - Group Accuracy:

2022-01-20 01:16:38,211 - INFO - [0.9819277  0.99156624 0.98771083 0.99373496 0.9853012  0.9939759
 0.98289156 0.9826506  0.9913253  0.9778313  0.99084336 0.9855422
 0.97831327 0.9821687  0.9768675  0.9891566  0.9961446 ]
2022-01-20 01:16:38,212 - INFO - Epoch time: 402.33462834358215
2022-01-20 01:16:47,710 - INFO - Computing OOD Statistics...
2022-01-20 01:16:47,722 - INFO - 	Baseline.          AUROC: 0.3816. TNR@95TPR: 0.0282. AUPR OUT: 0.1334
2022-01-20 01:16:47,727 - INFO - 	ODIN (T=1000).     AUROC: 0.8966. TNR@95TPR: 0.5235. AUPR OUT: 0.6500
2022-01-20 01:16:47,727 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-20 01:16:47,727 - INFO - Top 1 Accuracy:  Min: 0.8128; Max: 0.8128; Avg: 0.8128; Std: 0.0000; Len: 1
2022-01-20 01:16:47,727 - INFO - Top 5 Accuracy:  Min: 0.9864; Max: 0.9864; Avg: 0.9864; Std: 0.0000; Len: 1
2022-01-20 01:16:47,727 - INFO - **********************************************************************
2022-01-20 01:16:47,727 - INFO - 	MSP (auroc): [0.38156853295535076] Min: 0.3816; Max: 0.3816; Avg: 0.3816; Std: 0.0000; Len: 1
2022-01-20 01:16:47,727 - INFO - 	MSP (tnr): [0.028235294117647025] Min: 0.0282; Max: 0.0282; Avg: 0.0282; Std: 0.0000; Len: 1
2022-01-20 01:16:47,727 - INFO - 	MSP (aupr): [0.1333870614723211] Min: 0.1334; Max: 0.1334; Avg: 0.1334; Std: 0.0000; Len: 1
2022-01-20 01:16:47,727 - INFO - 	ODIN (auroc): [0.8966109142452161] Min: 0.8966; Max: 0.8966; Avg: 0.8966; Std: 0.0000; Len: 1
2022-01-20 01:16:47,728 - INFO - 	ODIN (tnr): [0.5235294117647059] Min: 0.5235; Max: 0.5235; Avg: 0.5235; Std: 0.0000; Len: 1
2022-01-20 01:16:47,728 - INFO - 	ODIN (aupr): [0.6500062715780097] Min: 0.6500; Max: 0.6500; Avg: 0.6500; Std: 0.0000; Len: 1

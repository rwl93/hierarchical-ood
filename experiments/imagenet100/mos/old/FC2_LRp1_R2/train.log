2022-01-18 17:10:27,532 - INFO - ==> Preparing data..
2022-01-18 17:10:28,108 - INFO - checkpoint filename: experiments/coarse/mos/FC2_LRp1_R2/checkpoint.pt
2022-01-18 17:10:28,108 - INFO - log filename: experiments/coarse/mos/FC2_LRp1_R2/train.log
2022-01-18 17:10:28,108 - INFO - ********************************************************
2022-01-18 17:10:28,108 - INFO - Starting Iter: 0 / 1
2022-01-18 17:10:28,108 - INFO - ********************************************************
2022-01-18 17:10:33,980 - INFO - cuda
2022-01-18 17:10:34,012 - INFO - 
Epoch: 0
2022-01-18 17:10:34,013 - INFO - 
Learning Rate: 0.0100
2022-01-18 17:12:50,140 - INFO - [Step=250]	Loss=7.1527	235.1 examples/second
2022-01-18 17:15:14,258 - INFO - [Step=500]	Loss=5.4917	222.0 examples/second
2022-01-18 17:17:37,703 - INFO - [Step=750]	Loss=5.3617	223.1 examples/second
2022-01-18 17:18:37,851 - INFO - Test Loss=5.4160, Test top-1 acc=0.0316
2022-01-18 17:18:37,852 - INFO - Group Accuracy:

2022-01-18 17:18:37,852 - INFO - [0.9392771 0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.9339759 0.9518072]
2022-01-18 17:18:37,853 - INFO - Saving...
2022-01-18 17:18:38,126 - INFO - Epoch time: 484.1136643886566
2022-01-18 17:18:38,126 - INFO - 
Epoch: 1
2022-01-18 17:18:38,126 - INFO - 
Learning Rate: 0.0280
2022-01-18 17:20:17,619 - INFO - [Step=1000]	Loss=5.3134	200.1 examples/second
2022-01-18 17:22:39,305 - INFO - [Step=1250]	Loss=5.1120	225.9 examples/second
2022-01-18 17:25:04,566 - INFO - [Step=1500]	Loss=4.9082	220.3 examples/second
2022-01-18 17:26:47,587 - INFO - Test Loss=4.6557, Test top-1 acc=0.1034
2022-01-18 17:26:47,587 - INFO - Group Accuracy:

2022-01-18 17:26:47,587 - INFO - [0.939759   0.940241   0.939759   0.94289154 0.939759   0.94120485
 0.9395181  0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.9395181  0.9395181  0.9515663 ]
2022-01-18 17:26:47,588 - INFO - Saving...
2022-01-18 17:26:48,069 - INFO - Epoch time: 489.94250202178955
2022-01-18 17:26:48,069 - INFO - 
Epoch: 2
2022-01-18 17:26:48,069 - INFO - 
Learning Rate: 0.0460
2022-01-18 17:27:32,829 - INFO - [Step=1750]	Loss=4.7425	215.8 examples/second
2022-01-18 17:29:52,061 - INFO - [Step=2000]	Loss=4.6215	229.8 examples/second
2022-01-18 17:32:21,949 - INFO - [Step=2250]	Loss=4.4091	213.5 examples/second
2022-01-18 17:34:44,394 - INFO - [Step=2500]	Loss=4.2317	224.6 examples/second
2022-01-18 17:35:00,178 - INFO - Test Loss=4.1385, Test top-1 acc=0.2101
2022-01-18 17:35:00,178 - INFO - Group Accuracy:

2022-01-18 17:35:00,178 - INFO - [0.94120485 0.94216865 0.94096386 0.9481928  0.94144577 0.94843376
 0.9407229  0.940241   0.9354217  0.939759   0.95228916 0.9387952
 0.939759   0.939759   0.939759   0.9395181  0.95228916]
2022-01-18 17:35:00,179 - INFO - Saving...
2022-01-18 17:35:00,912 - INFO - Epoch time: 492.84239172935486
2022-01-18 17:35:00,913 - INFO - 
Epoch: 3
2022-01-18 17:35:00,913 - INFO - 
Learning Rate: 0.0640
2022-01-18 17:37:25,957 - INFO - [Step=2750]	Loss=4.1128	198.1 examples/second
2022-01-18 17:39:56,744 - INFO - [Step=3000]	Loss=3.9654	212.2 examples/second
2022-01-18 17:42:20,231 - INFO - [Step=3250]	Loss=3.8343	223.0 examples/second
2022-01-18 17:43:25,085 - INFO - Test Loss=3.5195, Test top-1 acc=0.2904
2022-01-18 17:43:25,085 - INFO - Group Accuracy:

2022-01-18 17:43:25,085 - INFO - [0.9426506  0.94915664 0.9404819  0.9585542  0.94192773 0.9561446
 0.94216865 0.94554216 0.94506025 0.94120485 0.9546988  0.94168675
 0.94096386 0.940241   0.94120485 0.9438554  0.9621687 ]
2022-01-18 17:43:25,086 - INFO - Saving...
2022-01-18 17:43:25,497 - INFO - Epoch time: 504.5840253829956
2022-01-18 17:43:25,497 - INFO - 
Epoch: 4
2022-01-18 17:43:25,497 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:44:53,053 - INFO - [Step=3500]	Loss=3.7719	209.4 examples/second
2022-01-18 17:47:10,563 - INFO - [Step=3750]	Loss=3.6432	232.7 examples/second
2022-01-18 17:49:29,252 - INFO - [Step=4000]	Loss=3.5209	230.7 examples/second
2022-01-18 17:51:17,812 - INFO - Test Loss=3.2124, Test top-1 acc=0.3434
2022-01-18 17:51:17,812 - INFO - Group Accuracy:

2022-01-18 17:51:17,812 - INFO - [0.9433735  0.94939756 0.94192773 0.96168673 0.9426506  0.9631325
 0.93493974 0.95325303 0.96048194 0.94626504 0.9539759  0.9433735
 0.94120485 0.94240963 0.94144577 0.94554216 0.9674699 ]
2022-01-18 17:51:17,813 - INFO - Saving...
2022-01-18 17:51:18,424 - INFO - Epoch time: 472.92719864845276
2022-01-18 17:51:18,425 - INFO - 
Epoch: 5
2022-01-18 17:51:18,425 - INFO - 
Learning Rate: 0.1000
2022-01-18 17:52:02,852 - INFO - [Step=4250]	Loss=3.3855	208.3 examples/second
2022-01-18 17:54:20,827 - INFO - [Step=4500]	Loss=3.2582	231.9 examples/second
2022-01-18 17:56:40,722 - INFO - [Step=4750]	Loss=3.1327	228.7 examples/second
2022-01-18 17:59:00,264 - INFO - [Step=5000]	Loss=3.0473	229.3 examples/second
2022-01-18 17:59:14,620 - INFO - Test Loss=3.0031, Test top-1 acc=0.3913
2022-01-18 17:59:14,620 - INFO - Group Accuracy:

2022-01-18 17:59:14,620 - INFO - [0.9486747  0.95349395 0.946506   0.9624096  0.94192773 0.96771085
 0.946506   0.946747   0.9612048  0.9448193  0.96       0.9498795
 0.940241   0.9433735  0.9436145  0.9510843  0.96506023]
2022-01-18 17:59:14,621 - INFO - Saving...
2022-01-18 17:59:15,106 - INFO - Epoch time: 476.6810030937195
2022-01-18 17:59:15,106 - INFO - 
Epoch: 6
2022-01-18 17:59:15,106 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:01:30,876 - INFO - [Step=5250]	Loss=2.9578	212.5 examples/second
2022-01-18 18:03:50,011 - INFO - [Step=5500]	Loss=2.9074	230.0 examples/second
2022-01-18 18:06:06,850 - INFO - [Step=5750]	Loss=2.8137	233.9 examples/second
2022-01-18 18:07:09,746 - INFO - Test Loss=2.8007, Test top-1 acc=0.4157
2022-01-18 18:07:09,747 - INFO - Group Accuracy:

2022-01-18 18:07:09,747 - INFO - [0.9448193  0.96048194 0.9481928  0.9631325  0.94578314 0.97180724
 0.9498795  0.95253015 0.9633735  0.9472289  0.9612048  0.946747
 0.9407229  0.946506   0.9469879  0.9546988  0.9691566 ]
2022-01-18 18:07:09,748 - INFO - Saving...
2022-01-18 18:07:10,279 - INFO - Epoch time: 475.1731402873993
2022-01-18 18:07:10,280 - INFO - 
Epoch: 7
2022-01-18 18:07:10,281 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:08:39,871 - INFO - [Step=6000]	Loss=2.7431	209.1 examples/second
2022-01-18 18:10:55,828 - INFO - [Step=6250]	Loss=2.6507	235.4 examples/second
2022-01-18 18:13:14,051 - INFO - [Step=6500]	Loss=2.6234	231.5 examples/second
2022-01-18 18:15:01,942 - INFO - Test Loss=2.3496, Test top-1 acc=0.4993
2022-01-18 18:15:01,944 - INFO - Group Accuracy:

2022-01-18 18:15:01,945 - INFO - [0.9539759  0.9619277  0.9508434  0.97301203 0.95325303 0.9775904
 0.95421684 0.95975906 0.96819276 0.95710844 0.96506023 0.95638555
 0.9438554  0.9472289  0.9546988  0.9583132  0.9821687 ]
2022-01-18 18:15:01,948 - INFO - Saving...
2022-01-18 18:15:02,369 - INFO - Epoch time: 472.0886368751526
2022-01-18 18:15:02,371 - INFO - 
Epoch: 8
2022-01-18 18:15:02,371 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:15:42,797 - INFO - [Step=6750]	Loss=2.5360	215.1 examples/second
2022-01-18 18:18:00,521 - INFO - [Step=7000]	Loss=2.4944	232.4 examples/second
2022-01-18 18:20:19,243 - INFO - [Step=7250]	Loss=2.4294	230.7 examples/second
2022-01-18 18:22:35,362 - INFO - [Step=7500]	Loss=2.3868	235.1 examples/second
2022-01-18 18:22:53,184 - INFO - Test Loss=2.3851, Test top-1 acc=0.5051
2022-01-18 18:22:53,184 - INFO - Group Accuracy:

2022-01-18 18:22:53,184 - INFO - [0.9559036  0.9614458  0.95228916 0.973494   0.95759034 0.9821687
 0.9498795  0.96       0.9559036  0.94843376 0.9662651  0.96048194
 0.94626504 0.94963855 0.95253015 0.9546988  0.9787952 ]
2022-01-18 18:22:53,185 - INFO - Saving...
2022-01-18 18:22:53,632 - INFO - Epoch time: 471.2613444328308
2022-01-18 18:22:53,632 - INFO - 
Epoch: 9
2022-01-18 18:22:53,632 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:25:04,684 - INFO - [Step=7750]	Loss=2.3030	214.3 examples/second
2022-01-18 18:27:21,694 - INFO - [Step=8000]	Loss=2.2732	233.6 examples/second
2022-01-18 18:29:38,600 - INFO - [Step=8250]	Loss=2.2509	233.7 examples/second
2022-01-18 18:30:42,610 - INFO - Test Loss=2.0612, Test top-1 acc=0.5595
2022-01-18 18:30:42,611 - INFO - Group Accuracy:

2022-01-18 18:30:42,611 - INFO - [0.96024096 0.96048194 0.96072286 0.9785542  0.95710844 0.98024094
 0.95566267 0.9674699  0.9706024  0.9587952  0.96891564 0.96457833
 0.9513253  0.9513253  0.9551807  0.96385545 0.9848193 ]
2022-01-18 18:30:42,611 - INFO - Saving...
2022-01-18 18:30:43,142 - INFO - Epoch time: 469.509813785553
2022-01-18 18:30:43,142 - INFO - 
Epoch: 10
2022-01-18 18:30:43,142 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:32:06,665 - INFO - [Step=8500]	Loss=2.2000	216.1 examples/second
2022-01-18 18:34:23,550 - INFO - [Step=8750]	Loss=2.1794	233.8 examples/second
2022-01-18 18:36:41,067 - INFO - [Step=9000]	Loss=2.1439	232.7 examples/second
2022-01-18 18:38:32,684 - INFO - Test Loss=2.3037, Test top-1 acc=0.5154
2022-01-18 18:38:32,684 - INFO - Group Accuracy:

2022-01-18 18:38:32,684 - INFO - [0.95662653 0.96481925 0.94939756 0.97590363 0.96072286 0.9804819
 0.9481928  0.96385545 0.9703615  0.9612048  0.966747   0.9580723
 0.9431325  0.946506   0.9520482  0.96361446 0.9804819 ]
2022-01-18 18:38:32,685 - INFO - Epoch time: 469.5426948070526
2022-01-18 18:38:32,685 - INFO - 
Epoch: 11
2022-01-18 18:38:32,685 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:39:10,656 - INFO - [Step=9250]	Loss=2.1103	213.9 examples/second
2022-01-18 18:41:27,375 - INFO - [Step=9500]	Loss=2.0676	234.1 examples/second
2022-01-18 18:43:43,671 - INFO - [Step=9750]	Loss=2.0494	234.8 examples/second
2022-01-18 18:46:04,034 - INFO - [Step=10000]	Loss=2.0223	228.0 examples/second
2022-01-18 18:46:25,557 - INFO - Test Loss=1.8949, Test top-1 acc=0.5911
2022-01-18 18:46:25,558 - INFO - Group Accuracy:

2022-01-18 18:46:25,558 - INFO - [0.96409637 0.9708434  0.96024096 0.97590363 0.9653012  0.98313254
 0.9612048  0.9674699  0.97566265 0.9624096  0.9742169  0.9621687
 0.9501205  0.9508434  0.9578313  0.9657831  0.9838554 ]
2022-01-18 18:46:25,562 - INFO - Saving...
2022-01-18 18:46:25,987 - INFO - Epoch time: 473.30206847190857
2022-01-18 18:46:25,987 - INFO - 
Epoch: 12
2022-01-18 18:46:25,987 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:48:40,285 - INFO - [Step=10250]	Loss=1.9869	204.8 examples/second
2022-01-18 18:51:00,625 - INFO - [Step=10500]	Loss=1.9616	228.0 examples/second
2022-01-18 18:53:21,403 - INFO - [Step=10750]	Loss=1.9307	227.3 examples/second
2022-01-18 18:54:31,793 - INFO - Test Loss=1.8899, Test top-1 acc=0.5990
2022-01-18 18:54:31,794 - INFO - Group Accuracy:

2022-01-18 18:54:31,794 - INFO - [0.9653012  0.97614455 0.9633735  0.9809638  0.966506   0.98433733
 0.96096385 0.96409637 0.9780723  0.9660241  0.97108436 0.96506023
 0.9546988  0.9510843  0.9583132  0.966747   0.9809638 ]
2022-01-18 18:54:31,795 - INFO - Saving...
2022-01-18 18:54:32,388 - INFO - Epoch time: 486.40045857429504
2022-01-18 18:54:32,388 - INFO - 
Epoch: 13
2022-01-18 18:54:32,388 - INFO - 
Learning Rate: 0.1000
2022-01-18 18:55:57,134 - INFO - [Step=11000]	Loss=1.9130	205.5 examples/second
2022-01-18 18:58:16,884 - INFO - [Step=11250]	Loss=1.8867	229.0 examples/second
2022-01-18 19:00:38,213 - INFO - [Step=11500]	Loss=1.8828	226.4 examples/second
2022-01-18 19:02:34,223 - INFO - Test Loss=2.1449, Test top-1 acc=0.5701
2022-01-18 19:02:34,223 - INFO - Group Accuracy:

2022-01-18 19:02:34,223 - INFO - [0.9583132  0.97180724 0.9554217  0.9780723  0.9619277  0.9812048
 0.9590362  0.95710844 0.9727711  0.96433735 0.96891564 0.9561446
 0.9486747  0.95638555 0.95710844 0.966506   0.9826506 ]
2022-01-18 19:02:34,224 - INFO - Epoch time: 481.83581471443176
2022-01-18 19:02:34,224 - INFO - 
Epoch: 14
2022-01-18 19:02:34,224 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:03:10,751 - INFO - [Step=11750]	Loss=1.8817	209.8 examples/second
2022-01-18 19:05:32,389 - INFO - [Step=12000]	Loss=1.8252	225.9 examples/second
2022-01-18 19:07:47,544 - INFO - [Step=12250]	Loss=1.8115	236.8 examples/second
2022-01-18 19:10:10,678 - INFO - [Step=12500]	Loss=1.8030	223.6 examples/second
2022-01-18 19:10:38,247 - INFO - Test Loss=1.7854, Test top-1 acc=0.6113
2022-01-18 19:10:38,248 - INFO - Group Accuracy:

2022-01-18 19:10:38,248 - INFO - [0.96457833 0.9693976  0.9653012  0.97903615 0.96481925 0.98361444
 0.9595181  0.96819276 0.9804819  0.9657831  0.97301203 0.9657831
 0.9472289  0.9583132  0.96361446 0.97301203 0.98771083]
2022-01-18 19:10:38,249 - INFO - Saving...
2022-01-18 19:10:38,960 - INFO - Epoch time: 484.73593187332153
2022-01-18 19:10:38,963 - INFO - 
Epoch: 15
2022-01-18 19:10:38,964 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:12:55,712 - INFO - [Step=12750]	Loss=1.7906	193.9 examples/second
2022-01-18 19:15:20,691 - INFO - [Step=13000]	Loss=1.7661	220.7 examples/second
2022-01-18 19:17:43,597 - INFO - [Step=13250]	Loss=1.7607	223.9 examples/second
2022-01-18 19:19:01,295 - INFO - Test Loss=2.0204, Test top-1 acc=0.6010
2022-01-18 19:19:01,297 - INFO - Group Accuracy:

2022-01-18 19:19:01,297 - INFO - [0.96481925 0.9674699  0.966747   0.97951806 0.9621687  0.9850602
 0.9583132  0.97180724 0.96771085 0.96457833 0.97542167 0.9672289
 0.9578313  0.9585542  0.95301205 0.9633735  0.9850602 ]
2022-01-18 19:19:01,300 - INFO - Epoch time: 502.3370990753174
2022-01-18 19:19:01,300 - INFO - 
Epoch: 16
2022-01-18 19:19:01,300 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:20:27,848 - INFO - [Step=13500]	Loss=1.7305	194.8 examples/second
2022-01-18 19:22:51,054 - INFO - [Step=13750]	Loss=1.7179	223.5 examples/second
2022-01-18 19:25:11,252 - INFO - [Step=14000]	Loss=1.7074	228.3 examples/second
2022-01-18 19:27:08,348 - INFO - Test Loss=1.8387, Test top-1 acc=0.6352
2022-01-18 19:27:08,348 - INFO - Group Accuracy:

2022-01-18 19:27:08,348 - INFO - [0.9624096  0.9773494  0.9662651  0.973253   0.96771085 0.98240966
 0.96048194 0.9703615  0.9826506  0.9691566  0.9771084  0.9737349
 0.9573494  0.9595181  0.9595181  0.9703615  0.9884337 ]
2022-01-18 19:27:08,349 - INFO - Saving...
2022-01-18 19:27:08,745 - INFO - Epoch time: 487.44516134262085
2022-01-18 19:27:08,746 - INFO - 
Epoch: 17
2022-01-18 19:27:08,746 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:27:42,811 - INFO - [Step=14250]	Loss=1.6950	211.1 examples/second
2022-01-18 19:29:58,890 - INFO - [Step=14500]	Loss=1.6711	235.2 examples/second
2022-01-18 19:32:15,730 - INFO - [Step=14750]	Loss=1.6781	233.9 examples/second
2022-01-18 19:34:32,724 - INFO - [Step=15000]	Loss=1.6519	233.6 examples/second
2022-01-18 19:34:59,541 - INFO - Test Loss=1.7142, Test top-1 acc=0.6267
2022-01-18 19:34:59,542 - INFO - Group Accuracy:

2022-01-18 19:34:59,542 - INFO - [0.9619277  0.97156626 0.96891564 0.9833735  0.9653012  0.98578316
 0.96457833 0.96795183 0.97566265 0.966747   0.97228914 0.9706024
 0.9590362  0.9633735  0.9614458  0.97204816 0.9845783 ]
2022-01-18 19:34:59,543 - INFO - Epoch time: 470.7978332042694
2022-01-18 19:34:59,544 - INFO - 
Epoch: 18
2022-01-18 19:34:59,544 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:37:01,348 - INFO - [Step=15250]	Loss=1.5919	215.3 examples/second
2022-01-18 19:39:19,118 - INFO - [Step=15500]	Loss=1.6374	232.3 examples/second
2022-01-18 19:41:37,459 - INFO - [Step=15750]	Loss=1.6287	231.3 examples/second
2022-01-18 19:42:50,086 - INFO - Test Loss=1.6902, Test top-1 acc=0.6494
2022-01-18 19:42:50,086 - INFO - Group Accuracy:

2022-01-18 19:42:50,086 - INFO - [0.96891564 0.96843374 0.97180724 0.98313254 0.973253   0.98626506
 0.9655422  0.96795183 0.98361444 0.96698797 0.97831327 0.97156626
 0.9614458  0.96024096 0.9614458  0.9739759  0.98674697]
2022-01-18 19:42:50,087 - INFO - Saving...
2022-01-18 19:42:50,472 - INFO - Epoch time: 470.9283814430237
2022-01-18 19:42:50,472 - INFO - 
Epoch: 19
2022-01-18 19:42:50,472 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:44:06,134 - INFO - [Step=16000]	Loss=1.6099	215.2 examples/second
2022-01-18 19:46:24,482 - INFO - [Step=16250]	Loss=1.5966	231.3 examples/second
2022-01-18 19:48:42,733 - INFO - [Step=16500]	Loss=1.5893	231.5 examples/second
2022-01-18 19:50:41,566 - INFO - Test Loss=1.6198, Test top-1 acc=0.6472
2022-01-18 19:50:41,567 - INFO - Group Accuracy:

2022-01-18 19:50:41,567 - INFO - [0.9691566  0.9778313  0.96843374 0.98024094 0.9703615  0.98746985
 0.9628916  0.96843374 0.9809638  0.9662651  0.9746988  0.9674699
 0.9590362  0.96096385 0.96457833 0.9708434  0.98746985]
2022-01-18 19:50:41,568 - INFO - Epoch time: 471.095335483551
2022-01-18 19:50:41,568 - INFO - 
Epoch: 20
2022-01-18 19:50:41,568 - INFO - 
Learning Rate: 0.1000
2022-01-18 19:51:11,741 - INFO - [Step=16750]	Loss=1.5899	214.8 examples/second
2022-01-18 19:53:29,693 - INFO - [Step=17000]	Loss=1.5655	232.0 examples/second
2022-01-18 19:55:48,329 - INFO - [Step=17250]	Loss=1.5496	230.8 examples/second
2022-01-18 19:58:04,772 - INFO - [Step=17500]	Loss=1.5593	234.5 examples/second
2022-01-18 19:58:38,027 - INFO - Test Loss=1.5171, Test top-1 acc=0.6631
2022-01-18 19:58:38,028 - INFO - Group Accuracy:

2022-01-18 19:58:38,028 - INFO - [0.96771085 0.9778313  0.9737349  0.98674697 0.9672289  0.98722893
 0.96795183 0.97180724 0.9812048  0.9674699  0.98       0.97493976
 0.96385545 0.96409637 0.9621687  0.9655422  0.9879518 ]
2022-01-18 19:58:38,029 - INFO - Saving...
2022-01-18 19:58:38,750 - INFO - Epoch time: 477.1817510128021
2022-01-18 19:58:38,752 - INFO - 
Epoch: 21
2022-01-18 19:58:38,752 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:00:46,863 - INFO - [Step=17750]	Loss=1.5288	197.4 examples/second
2022-01-18 20:03:17,103 - INFO - [Step=18000]	Loss=1.5359	213.0 examples/second
2022-01-18 20:05:45,524 - INFO - [Step=18250]	Loss=1.5368	215.6 examples/second
2022-01-18 20:07:07,195 - INFO - Test Loss=1.4986, Test top-1 acc=0.6660
2022-01-18 20:07:07,195 - INFO - Group Accuracy:

2022-01-18 20:07:07,196 - INFO - [0.96891564 0.9812048  0.9691566  0.9860241  0.9742169  0.9879518
 0.9626506  0.9698795  0.98       0.966506   0.97638553 0.96891564
 0.9631325  0.96433735 0.96168673 0.97518075 0.9886747 ]
2022-01-18 20:07:07,196 - INFO - Saving...
2022-01-18 20:07:07,660 - INFO - Epoch time: 508.90817880630493
2022-01-18 20:07:07,660 - INFO - 
Epoch: 22
2022-01-18 20:07:07,660 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:08:23,179 - INFO - [Step=18500]	Loss=1.4967	203.0 examples/second
2022-01-18 20:10:55,384 - INFO - [Step=18750]	Loss=1.5037	210.2 examples/second
2022-01-18 20:13:19,045 - INFO - [Step=19000]	Loss=1.5095	222.7 examples/second
2022-01-18 20:15:26,209 - INFO - Test Loss=1.9970, Test top-1 acc=0.6111
2022-01-18 20:15:26,209 - INFO - Group Accuracy:

2022-01-18 20:15:26,209 - INFO - [0.95710844 0.97566265 0.9583132  0.96843374 0.9633735  0.98578316
 0.9655422  0.96433735 0.97975904 0.9628916  0.9708434  0.9708434
 0.9587952  0.9626506  0.9508434  0.96771085 0.98650604]
2022-01-18 20:15:26,210 - INFO - Epoch time: 498.55023407936096
2022-01-18 20:15:26,210 - INFO - 
Epoch: 23
2022-01-18 20:15:26,210 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:15:53,625 - INFO - [Step=19250]	Loss=1.4954	207.0 examples/second
2022-01-18 20:18:13,402 - INFO - [Step=19500]	Loss=1.4779	228.9 examples/second
2022-01-18 20:20:42,658 - INFO - [Step=19750]	Loss=1.5082	214.4 examples/second
2022-01-18 20:23:08,253 - INFO - [Step=20000]	Loss=1.4885	219.8 examples/second
2022-01-18 20:23:45,097 - INFO - Test Loss=1.6216, Test top-1 acc=0.6492
2022-01-18 20:23:45,098 - INFO - Group Accuracy:

2022-01-18 20:23:45,098 - INFO - [0.9585542  0.97228914 0.9693976  0.98289156 0.9713253  0.98963857
 0.96698797 0.97445786 0.9708434  0.9633735  0.98024094 0.97108436
 0.9614458  0.96048194 0.9653012  0.97542167 0.98722893]
2022-01-18 20:23:45,100 - INFO - Epoch time: 498.88987922668457
2022-01-18 20:23:45,101 - INFO - 
Epoch: 24
2022-01-18 20:23:45,101 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:25:51,184 - INFO - [Step=20250]	Loss=1.4423	196.4 examples/second
2022-01-18 20:28:17,424 - INFO - [Step=20500]	Loss=1.4657	218.8 examples/second
2022-01-18 20:30:41,228 - INFO - [Step=20750]	Loss=1.4727	222.5 examples/second
2022-01-18 20:32:08,051 - INFO - Test Loss=1.4830, Test top-1 acc=0.6653
2022-01-18 20:32:08,051 - INFO - Group Accuracy:

2022-01-18 20:32:08,051 - INFO - [0.96843374 0.9775904  0.9727711  0.9879518  0.96698797 0.98771083
 0.96771085 0.97493976 0.9812048  0.96361446 0.9771084  0.9708434
 0.9621687  0.96024096 0.9653012  0.973253   0.9913253 ]
2022-01-18 20:32:08,052 - INFO - Epoch time: 502.95141768455505
2022-01-18 20:32:08,052 - INFO - 
Epoch: 25
2022-01-18 20:32:08,052 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:33:25,956 - INFO - [Step=21000]	Loss=1.4425	194.3 examples/second
2022-01-18 20:35:43,218 - INFO - [Step=21250]	Loss=1.4550	233.1 examples/second
2022-01-18 20:38:03,402 - INFO - [Step=21500]	Loss=1.4516	228.3 examples/second
2022-01-18 20:40:13,380 - INFO - Test Loss=1.5156, Test top-1 acc=0.6627
2022-01-18 20:40:13,380 - INFO - Group Accuracy:

2022-01-18 20:40:13,380 - INFO - [0.9698795  0.97590363 0.9703615  0.98361444 0.97156626 0.98698795
 0.96457833 0.9739759  0.97951806 0.9691566  0.9787952  0.9727711
 0.9559036  0.9672289  0.9657831  0.9780723  0.98771083]
2022-01-18 20:40:13,381 - INFO - Epoch time: 485.3289213180542
2022-01-18 20:40:13,381 - INFO - 
Epoch: 26
2022-01-18 20:40:13,381 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:40:39,379 - INFO - [Step=21750]	Loss=1.4564	205.2 examples/second
2022-01-18 20:42:57,648 - INFO - [Step=22000]	Loss=1.4033	231.4 examples/second
2022-01-18 20:45:18,235 - INFO - [Step=22250]	Loss=1.4414	227.6 examples/second
2022-01-18 20:47:36,039 - INFO - [Step=22500]	Loss=1.4298	232.2 examples/second
2022-01-18 20:48:13,798 - INFO - Test Loss=1.5524, Test top-1 acc=0.6607
2022-01-18 20:48:13,799 - INFO - Group Accuracy:

2022-01-18 20:48:13,799 - INFO - [0.9674699  0.97614455 0.966747   0.9838554  0.9626506  0.9901205
 0.96361446 0.9696385  0.9804819  0.9703615  0.98       0.97180724
 0.9660241  0.96409637 0.96481925 0.9727711  0.9886747 ]
2022-01-18 20:48:13,800 - INFO - Epoch time: 480.4187250137329
2022-01-18 20:48:13,800 - INFO - 
Epoch: 27
2022-01-18 20:48:13,800 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:50:12,185 - INFO - [Step=22750]	Loss=1.3848	204.9 examples/second
2022-01-18 20:52:30,826 - INFO - [Step=23000]	Loss=1.4019	230.8 examples/second
2022-01-18 20:54:50,298 - INFO - [Step=23250]	Loss=1.4214	229.4 examples/second
2022-01-18 20:56:09,428 - INFO - Test Loss=1.6105, Test top-1 acc=0.6537
2022-01-18 20:56:09,428 - INFO - Group Accuracy:

2022-01-18 20:56:09,428 - INFO - [0.9662651  0.97542167 0.9739759  0.98433733 0.9674699  0.9860241
 0.9662651  0.9737349  0.9766265  0.96481925 0.97518075 0.9725301
 0.9513253  0.9653012  0.9660241  0.9739759  0.9918072 ]
2022-01-18 20:56:09,429 - INFO - Epoch time: 475.62924003601074
2022-01-18 20:56:09,429 - INFO - 
Epoch: 28
2022-01-18 20:56:09,429 - INFO - 
Learning Rate: 0.1000
2022-01-18 20:57:17,885 - INFO - [Step=23500]	Loss=1.4076	216.8 examples/second
2022-01-18 20:59:36,464 - INFO - [Step=23750]	Loss=1.3952	230.9 examples/second
2022-01-18 21:01:57,355 - INFO - [Step=24000]	Loss=1.4075	227.1 examples/second
2022-01-18 21:04:10,274 - INFO - Test Loss=1.6296, Test top-1 acc=0.6496
2022-01-18 21:04:10,274 - INFO - Group Accuracy:

2022-01-18 21:04:10,274 - INFO - [0.96795183 0.9807229  0.97180724 0.9778313  0.9737349  0.9848193
 0.96698797 0.9703615  0.98240966 0.9554217  0.9713253  0.97108436
 0.96024096 0.96409637 0.9626506  0.97566265 0.9884337 ]
2022-01-18 21:04:10,275 - INFO - Epoch time: 480.845933675766
2022-01-18 21:04:10,275 - INFO - 
Epoch: 29
2022-01-18 21:04:10,275 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:04:33,474 - INFO - [Step=24250]	Loss=1.3773	205.0 examples/second
2022-01-18 21:06:51,899 - INFO - [Step=24500]	Loss=1.0915	231.2 examples/second
2022-01-18 21:09:12,033 - INFO - [Step=24750]	Loss=1.0207	228.4 examples/second
2022-01-18 21:11:33,670 - INFO - [Step=25000]	Loss=1.0016	225.9 examples/second
2022-01-18 21:12:09,257 - INFO - Test Loss=0.9401, Test top-1 acc=0.7733
2022-01-18 21:12:09,257 - INFO - Group Accuracy:

2022-01-18 21:12:09,257 - INFO - [0.9768675  0.9879518  0.9826506  0.9920482  0.97951806 0.9930121
 0.97831327 0.9816868  0.98963857 0.97542167 0.9879518  0.98240966
 0.9742169  0.9787952  0.973494   0.9850602  0.9946988 ]
2022-01-18 21:12:09,258 - INFO - Saving...
2022-01-18 21:12:09,569 - INFO - Epoch time: 479.29413056373596
2022-01-18 21:12:09,570 - INFO - 
Epoch: 30
2022-01-18 21:12:09,570 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:14:05,359 - INFO - [Step=25250]	Loss=0.9544	211.0 examples/second
2022-01-18 21:16:28,212 - INFO - [Step=25500]	Loss=0.9432	224.0 examples/second
2022-01-18 21:18:47,855 - INFO - [Step=25750]	Loss=0.9362	229.2 examples/second
2022-01-18 21:20:13,601 - INFO - Test Loss=0.8901, Test top-1 acc=0.7781
2022-01-18 21:20:13,601 - INFO - Group Accuracy:

2022-01-18 21:20:13,601 - INFO - [0.9785542  0.9879518  0.9840964  0.9930121  0.9816868  0.9927711
 0.97831327 0.98240966 0.9889157  0.97590363 0.98746985 0.98361444
 0.97614455 0.97903615 0.97566265 0.98674697 0.99493974]
2022-01-18 21:20:13,602 - INFO - Saving...
2022-01-18 21:20:14,236 - INFO - Epoch time: 484.66584300994873
2022-01-18 21:20:14,238 - INFO - 
Epoch: 31
2022-01-18 21:20:14,239 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:21:21,056 - INFO - [Step=26000]	Loss=0.9372	208.9 examples/second
2022-01-18 21:23:41,600 - INFO - [Step=26250]	Loss=0.9069	227.7 examples/second
2022-01-18 21:25:57,077 - INFO - [Step=26500]	Loss=0.8987	236.2 examples/second
2022-01-18 21:28:10,284 - INFO - Test Loss=0.8759, Test top-1 acc=0.7841
2022-01-18 21:28:10,284 - INFO - Group Accuracy:

2022-01-18 21:28:10,284 - INFO - [0.9780723  0.9889157  0.98361444 0.993253   0.98289156 0.993253
 0.98024094 0.9819277  0.9898795  0.9768675  0.9879518  0.9838554
 0.97493976 0.9804819  0.9742169  0.9860241  0.99493974]
2022-01-18 21:28:10,285 - INFO - Saving...
2022-01-18 21:28:10,875 - INFO - Epoch time: 476.636798620224
2022-01-18 21:28:10,875 - INFO - 
Epoch: 32
2022-01-18 21:28:10,875 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:28:28,894 - INFO - [Step=26750]	Loss=0.9015	210.8 examples/second
2022-01-18 21:30:53,171 - INFO - [Step=27000]	Loss=0.8818	221.8 examples/second
2022-01-18 21:33:13,340 - INFO - [Step=27250]	Loss=0.8875	228.3 examples/second
2022-01-18 21:35:38,362 - INFO - [Step=27500]	Loss=0.8811	220.7 examples/second
2022-01-18 21:36:23,577 - INFO - Test Loss=0.8865, Test top-1 acc=0.7819
2022-01-18 21:36:23,578 - INFO - Group Accuracy:

2022-01-18 21:36:23,578 - INFO - [0.9787952  0.9891566  0.98313254 0.993253   0.9816868  0.993494
 0.98024094 0.9821687  0.9886747  0.97566265 0.98650604 0.9845783
 0.9746988  0.9778313  0.9739759  0.9850602  0.9954217 ]
2022-01-18 21:36:23,579 - INFO - Epoch time: 492.7042489051819
2022-01-18 21:36:23,579 - INFO - 
Epoch: 33
2022-01-18 21:36:23,579 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:38:17,668 - INFO - [Step=27750]	Loss=0.8641	200.9 examples/second
2022-01-18 21:40:47,029 - INFO - [Step=28000]	Loss=0.8686	214.2 examples/second
2022-01-18 21:43:07,151 - INFO - [Step=28250]	Loss=0.8474	228.4 examples/second
2022-01-18 21:44:41,205 - INFO - Test Loss=0.8573, Test top-1 acc=0.7860
2022-01-18 21:44:41,205 - INFO - Group Accuracy:

2022-01-18 21:44:41,205 - INFO - [0.9787952  0.9898795  0.98240966 0.9930121  0.9814458  0.993253
 0.98024094 0.9814458  0.9889157  0.97445786 0.98771083 0.9845783
 0.97614455 0.97975904 0.973253   0.9855422  0.9956626 ]
2022-01-18 21:44:41,206 - INFO - Saving...
2022-01-18 21:44:41,709 - INFO - Epoch time: 498.12978506088257
2022-01-18 21:44:41,709 - INFO - 
Epoch: 34
2022-01-18 21:44:41,709 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:45:44,484 - INFO - [Step=28500]	Loss=0.8635	203.4 examples/second
2022-01-18 21:48:06,167 - INFO - [Step=28750]	Loss=0.8676	225.9 examples/second
2022-01-18 21:50:26,990 - INFO - [Step=29000]	Loss=0.8406	227.2 examples/second
2022-01-18 21:52:42,952 - INFO - Test Loss=0.8541, Test top-1 acc=0.7875
2022-01-18 21:52:42,952 - INFO - Group Accuracy:

2022-01-18 21:52:42,952 - INFO - [0.98024094 0.98963857 0.98361444 0.9930121  0.97975904 0.9946988
 0.97903615 0.98289156 0.9898795  0.97590363 0.9891566  0.98361444
 0.97590363 0.97975904 0.97542167 0.9860241  0.9951807 ]
2022-01-18 21:52:42,953 - INFO - Saving...
2022-01-18 21:52:43,415 - INFO - Epoch time: 481.7062921524048
2022-01-18 21:52:43,416 - INFO - 
Epoch: 35
2022-01-18 21:52:43,416 - INFO - 
Learning Rate: 0.0100
2022-01-18 21:52:58,586 - INFO - [Step=29250]	Loss=0.8460	211.1 examples/second
2022-01-18 21:55:20,540 - INFO - [Step=29500]	Loss=0.8491	225.4 examples/second
2022-01-18 21:57:40,799 - INFO - [Step=29750]	Loss=0.8434	228.2 examples/second
2022-01-18 22:00:02,955 - INFO - [Step=30000]	Loss=0.8360	225.1 examples/second
2022-01-18 22:00:49,767 - INFO - Test Loss=0.8585, Test top-1 acc=0.7875
2022-01-18 22:00:49,769 - INFO - Group Accuracy:

2022-01-18 22:00:49,769 - INFO - [0.97903615 0.9898795  0.9855422  0.9925301  0.98313254 0.99445784
 0.9804819  0.98240966 0.9898795  0.9768675  0.9881928  0.98361444
 0.97614455 0.9807229  0.97493976 0.9845783  0.9951807 ]
2022-01-18 22:00:49,772 - INFO - Epoch time: 486.3558611869812
2022-01-18 22:00:49,772 - INFO - 
Epoch: 36
2022-01-18 22:00:49,772 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:02:39,803 - INFO - [Step=30250]	Loss=0.8115	204.0 examples/second
2022-01-18 22:05:01,851 - INFO - [Step=30500]	Loss=0.8267	225.3 examples/second
2022-01-18 22:07:20,920 - INFO - [Step=30750]	Loss=0.8163	230.1 examples/second
2022-01-18 22:08:58,804 - INFO - Test Loss=0.8637, Test top-1 acc=0.7918
2022-01-18 22:08:58,805 - INFO - Group Accuracy:

2022-01-18 22:08:58,805 - INFO - [0.9804819  0.9893976  0.9833735  0.9927711  0.9816868  0.9939759
 0.9804819  0.97975904 0.99108434 0.97614455 0.98698795 0.98578316
 0.9775904  0.97975904 0.9746988  0.98698795 0.9959036 ]
2022-01-18 22:08:58,807 - INFO - Saving...
2022-01-18 22:08:59,562 - INFO - Epoch time: 489.7896988391876
2022-01-18 22:08:59,562 - INFO - 
Epoch: 37
2022-01-18 22:08:59,562 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:10:11,360 - INFO - [Step=31000]	Loss=0.8114	187.8 examples/second
2022-01-18 22:12:38,667 - INFO - [Step=31250]	Loss=0.8098	217.2 examples/second
2022-01-18 22:15:06,515 - INFO - [Step=31500]	Loss=0.8243	216.4 examples/second
2022-01-18 22:17:43,889 - INFO - Test Loss=0.8603, Test top-1 acc=0.7911
2022-01-18 22:17:43,891 - INFO - Group Accuracy:

2022-01-18 22:17:43,891 - INFO - [0.98       0.99060243 0.98361444 0.9930121  0.98289156 0.993253
 0.9819277  0.98240966 0.9891566  0.9773494  0.98722893 0.9850602
 0.9778313  0.97975904 0.9746988  0.9848193  0.9951807 ]
2022-01-18 22:17:43,892 - INFO - Epoch time: 524.3301877975464
2022-01-18 22:17:43,892 - INFO - 
Epoch: 38
2022-01-18 22:17:43,892 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:17:58,477 - INFO - [Step=31750]	Loss=0.7869	186.1 examples/second
2022-01-18 22:20:34,697 - INFO - [Step=32000]	Loss=0.7885	204.8 examples/second
2022-01-18 22:22:52,549 - INFO - [Step=32250]	Loss=0.7970	232.1 examples/second
2022-01-18 22:25:13,280 - INFO - [Step=32500]	Loss=0.7972	227.4 examples/second
2022-01-18 22:26:00,869 - INFO - Test Loss=0.8469, Test top-1 acc=0.7913
2022-01-18 22:26:00,870 - INFO - Group Accuracy:

2022-01-18 22:26:00,870 - INFO - [0.9778313  0.9901205  0.9838554  0.99156624 0.98361444 0.99373496
 0.9804819  0.9816868  0.9891566  0.97493976 0.98746985 0.9855422
 0.9766265  0.9809638  0.97445786 0.9879518  0.9959036 ]
2022-01-18 22:26:00,871 - INFO - Epoch time: 496.9787063598633
2022-01-18 22:26:00,871 - INFO - 
Epoch: 39
2022-01-18 22:26:00,871 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:27:47,450 - INFO - [Step=32750]	Loss=0.7909	207.6 examples/second
2022-01-18 22:30:07,724 - INFO - [Step=33000]	Loss=0.7800	228.1 examples/second
2022-01-18 22:32:27,540 - INFO - [Step=33250]	Loss=0.7819	228.9 examples/second
2022-01-18 22:34:02,457 - INFO - Test Loss=0.8531, Test top-1 acc=0.7949
2022-01-18 22:34:02,457 - INFO - Group Accuracy:

2022-01-18 22:34:02,457 - INFO - [0.9787952  0.99108434 0.9826506  0.9922892  0.9816868  0.99445784
 0.97927713 0.9821687  0.9891566  0.9775904  0.9893976  0.98433733
 0.9785542  0.97927713 0.97493976 0.98626506 0.99493974]
2022-01-18 22:34:02,458 - INFO - Saving...
2022-01-18 22:34:02,975 - INFO - Epoch time: 482.10447669029236
2022-01-18 22:34:02,976 - INFO - 
Epoch: 40
2022-01-18 22:34:02,976 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:35:02,392 - INFO - [Step=33500]	Loss=0.7886	206.7 examples/second
2022-01-18 22:37:23,249 - INFO - [Step=33750]	Loss=0.7570	227.2 examples/second
2022-01-18 22:39:41,705 - INFO - [Step=34000]	Loss=0.7849	231.1 examples/second
2022-01-18 22:42:04,985 - INFO - Test Loss=0.8669, Test top-1 acc=0.7901
2022-01-18 22:42:04,985 - INFO - Group Accuracy:

2022-01-18 22:42:04,985 - INFO - [0.9807229  0.9893976  0.9833735  0.9925301  0.9807229  0.993494
 0.98       0.9814458  0.99108434 0.9766265  0.9884337  0.9850602
 0.9768675  0.97903615 0.9742169  0.98626506 0.9951807 ]
2022-01-18 22:42:04,986 - INFO - Epoch time: 482.01049542427063
2022-01-18 22:42:04,986 - INFO - 
Epoch: 41
2022-01-18 22:42:04,986 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:42:16,334 - INFO - [Step=34250]	Loss=0.7836	206.9 examples/second
2022-01-18 22:44:35,899 - INFO - [Step=34500]	Loss=0.7709	229.3 examples/second
2022-01-18 22:46:53,366 - INFO - [Step=34750]	Loss=0.7688	232.8 examples/second
2022-01-18 22:49:13,210 - INFO - [Step=35000]	Loss=0.7648	228.8 examples/second
2022-01-18 22:50:04,295 - INFO - Test Loss=0.8609, Test top-1 acc=0.7949
2022-01-18 22:50:04,296 - INFO - Group Accuracy:

2022-01-18 22:50:04,296 - INFO - [0.9787952  0.98963857 0.98361444 0.9922892  0.9814458  0.993253
 0.98024094 0.98313254 0.9901205  0.9780723  0.9901205  0.9853012
 0.9768675  0.9812048  0.97518075 0.98674697 0.9959036 ]
2022-01-18 22:50:04,298 - INFO - Epoch time: 479.3115417957306
2022-01-18 22:50:04,298 - INFO - 
Epoch: 42
2022-01-18 22:50:04,298 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:51:44,773 - INFO - [Step=35250]	Loss=0.7567	211.1 examples/second
2022-01-18 22:54:03,962 - INFO - [Step=35500]	Loss=0.7646	229.9 examples/second
2022-01-18 22:56:28,488 - INFO - [Step=35750]	Loss=0.7623	221.4 examples/second
2022-01-18 22:58:04,526 - INFO - Test Loss=0.8635, Test top-1 acc=0.7949
2022-01-18 22:58:04,527 - INFO - Group Accuracy:

2022-01-18 22:58:04,527 - INFO - [0.98       0.99060243 0.98289156 0.993494   0.98289156 0.99421686
 0.9804819  0.9826506  0.98963857 0.97831327 0.9893976  0.9855422
 0.9768675  0.97951806 0.9739759  0.98626506 0.9954217 ]
2022-01-18 22:58:04,528 - INFO - Epoch time: 480.2297329902649
2022-01-18 22:58:04,528 - INFO - 
Epoch: 43
2022-01-18 22:58:04,528 - INFO - 
Learning Rate: 0.0100
2022-01-18 22:59:00,597 - INFO - [Step=36000]	Loss=0.7533	210.4 examples/second
2022-01-18 23:01:23,301 - INFO - [Step=36250]	Loss=0.7453	224.2 examples/second
2022-01-18 23:03:45,127 - INFO - [Step=36500]	Loss=0.7485	225.6 examples/second
2022-01-18 23:06:16,940 - INFO - Test Loss=0.8866, Test top-1 acc=0.7916
2022-01-18 23:06:16,940 - INFO - Group Accuracy:

2022-01-18 23:06:16,941 - INFO - [0.97903615 0.99108434 0.9840964  0.993494   0.97975904 0.99421686
 0.9814458  0.9809638  0.9893976  0.9771084  0.9884337  0.98361444
 0.9771084  0.97975904 0.97638553 0.98698795 0.99493974]
2022-01-18 23:06:16,945 - INFO - Epoch time: 492.41698598861694
2022-01-18 23:06:16,945 - INFO - 
Epoch: 44
2022-01-18 23:06:16,946 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:06:26,213 - INFO - [Step=36750]	Loss=0.7494	198.7 examples/second
2022-01-18 23:08:49,987 - INFO - [Step=37000]	Loss=0.7196	222.6 examples/second
2022-01-18 23:11:11,587 - INFO - [Step=37250]	Loss=0.7451	226.0 examples/second
2022-01-18 23:13:30,569 - INFO - [Step=37500]	Loss=0.7431	230.2 examples/second
2022-01-18 23:14:24,119 - INFO - Test Loss=0.8729, Test top-1 acc=0.7930
2022-01-18 23:14:24,119 - INFO - Group Accuracy:

2022-01-18 23:14:24,119 - INFO - [0.98024094 0.99084336 0.9840964  0.993253   0.9816868  0.9946988
 0.9816868  0.9804819  0.9893976  0.9768675  0.9901205  0.9850602
 0.97638553 0.9785542  0.9771084  0.98698795 0.9954217 ]
2022-01-18 23:14:24,120 - INFO - Epoch time: 487.17482829093933
2022-01-18 23:14:24,120 - INFO - 
Epoch: 45
2022-01-18 23:14:24,120 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:16:06,663 - INFO - [Step=37750]	Loss=0.7299	205.0 examples/second
2022-01-18 23:18:26,608 - INFO - [Step=38000]	Loss=0.7368	228.7 examples/second
2022-01-18 23:20:47,377 - INFO - [Step=38250]	Loss=0.7381	227.3 examples/second
2022-01-18 23:22:29,539 - INFO - Test Loss=0.8756, Test top-1 acc=0.7928
2022-01-18 23:22:29,540 - INFO - Group Accuracy:

2022-01-18 23:22:29,540 - INFO - [0.98024094 0.99060243 0.9853012  0.9925301  0.9816868  0.99373496
 0.9809638  0.9809638  0.99036145 0.97542167 0.9884337  0.9848193
 0.9768675  0.97975904 0.9771084  0.98722893 0.9959036 ]
2022-01-18 23:22:29,541 - INFO - Epoch time: 485.42124128341675
2022-01-18 23:22:29,541 - INFO - 
Epoch: 46
2022-01-18 23:22:29,542 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:23:20,698 - INFO - [Step=38500]	Loss=0.7466	208.7 examples/second
2022-01-18 23:25:41,887 - INFO - [Step=38750]	Loss=0.7278	226.6 examples/second
2022-01-18 23:28:01,742 - INFO - [Step=39000]	Loss=0.7364	228.8 examples/second
2022-01-18 23:30:31,867 - INFO - Test Loss=0.8584, Test top-1 acc=0.7990
2022-01-18 23:30:31,867 - INFO - Group Accuracy:

2022-01-18 23:30:31,867 - INFO - [0.98240966 0.9886747  0.9853012  0.9930121  0.9826506  0.9930121
 0.9807229  0.9819277  0.9893976  0.9766265  0.9893976  0.98626506
 0.9771084  0.9804819  0.9778313  0.98722893 0.9954217 ]
2022-01-18 23:30:31,868 - INFO - Saving...
2022-01-18 23:30:32,526 - INFO - Epoch time: 482.98393082618713
2022-01-18 23:30:32,530 - INFO - 
Epoch: 47
2022-01-18 23:30:32,530 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:30:39,382 - INFO - [Step=39250]	Loss=0.7223	203.0 examples/second
2022-01-18 23:32:57,397 - INFO - [Step=39500]	Loss=0.7193	231.9 examples/second
2022-01-18 23:35:17,165 - INFO - [Step=39750]	Loss=0.7194	229.0 examples/second
2022-01-18 23:37:36,516 - INFO - [Step=40000]	Loss=0.7303	229.6 examples/second
2022-01-18 23:38:32,836 - INFO - Test Loss=0.8947, Test top-1 acc=0.7942
2022-01-18 23:38:32,837 - INFO - Group Accuracy:

2022-01-18 23:38:32,837 - INFO - [0.9787952  0.9901205  0.98361444 0.9925301  0.98289156 0.99445784
 0.98240966 0.9819277  0.9884337  0.9737349  0.9879518  0.98361444
 0.9771084  0.9804819  0.97614455 0.9879518  0.9961446 ]
2022-01-18 23:38:32,838 - INFO - Epoch time: 480.30813932418823
2022-01-18 23:38:32,838 - INFO - 
Epoch: 48
2022-01-18 23:38:32,838 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:40:11,406 - INFO - [Step=40250]	Loss=0.7161	206.6 examples/second
2022-01-18 23:42:32,162 - INFO - [Step=40500]	Loss=0.7073	227.3 examples/second
2022-01-18 23:44:50,070 - INFO - [Step=40750]	Loss=0.7189	232.0 examples/second
2022-01-18 23:46:33,989 - INFO - Test Loss=0.9024, Test top-1 acc=0.7995
2022-01-18 23:46:33,989 - INFO - Group Accuracy:

2022-01-18 23:46:33,989 - INFO - [0.98       0.9901205  0.98433733 0.9930121  0.9833735  0.9939759
 0.9816868  0.9812048  0.9913253  0.97542167 0.9881928  0.98361444
 0.9773494  0.9819277  0.97493976 0.9884337  0.9956626 ]
2022-01-18 23:46:33,990 - INFO - Saving...
2022-01-18 23:46:34,474 - INFO - Epoch time: 481.6360602378845
2022-01-18 23:46:34,474 - INFO - 
Epoch: 49
2022-01-18 23:46:34,474 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:47:24,944 - INFO - [Step=41000]	Loss=0.7170	206.6 examples/second
2022-01-18 23:49:45,909 - INFO - [Step=41250]	Loss=0.7019	227.0 examples/second
2022-01-18 23:52:05,851 - INFO - [Step=41500]	Loss=0.6977	228.7 examples/second
2022-01-18 23:54:27,476 - INFO - [Step=41750]	Loss=0.7280	225.9 examples/second
2022-01-18 23:54:38,343 - INFO - Test Loss=0.8582, Test top-1 acc=0.8000
2022-01-18 23:54:38,343 - INFO - Group Accuracy:

2022-01-18 23:54:38,343 - INFO - [0.9812048  0.9898795  0.9838554  0.9930121  0.98240966 0.99445784
 0.9819277  0.98313254 0.9893976  0.97903615 0.9891566  0.9826506
 0.9778313  0.97831327 0.9768675  0.9889157  0.99421686]
2022-01-18 23:54:38,344 - INFO - Saving...
2022-01-18 23:54:38,801 - INFO - Epoch time: 484.32649993896484
2022-01-18 23:54:38,801 - INFO - 
Epoch: 50
2022-01-18 23:54:38,801 - INFO - 
Learning Rate: 0.0100
2022-01-18 23:57:00,010 - INFO - [Step=42000]	Loss=0.6987	209.8 examples/second
2022-01-18 23:59:21,370 - INFO - [Step=42250]	Loss=0.6996	226.4 examples/second
2022-01-19 00:01:43,630 - INFO - [Step=42500]	Loss=0.7168	224.9 examples/second
2022-01-19 00:02:38,640 - INFO - Test Loss=0.9163, Test top-1 acc=0.7916
2022-01-19 00:02:38,640 - INFO - Group Accuracy:

2022-01-19 00:02:38,640 - INFO - [0.98024094 0.99156624 0.98433733 0.99156624 0.9809638  0.9939759
 0.9804819  0.9816868  0.9901205  0.97542167 0.9879518  0.9838554
 0.97614455 0.98       0.97566265 0.98771083 0.99445784]
2022-01-19 00:02:38,641 - INFO - Epoch time: 479.8399965763092
2022-01-19 00:02:38,641 - INFO - 
Epoch: 51
2022-01-19 00:02:38,641 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:04:10,066 - INFO - [Step=42750]	Loss=0.7140	218.5 examples/second
2022-01-19 00:06:33,062 - INFO - [Step=43000]	Loss=0.6884	223.8 examples/second
2022-01-19 00:09:01,059 - INFO - [Step=43250]	Loss=0.7164	216.2 examples/second
2022-01-19 00:10:48,102 - INFO - Test Loss=0.8793, Test top-1 acc=0.7949
2022-01-19 00:10:48,102 - INFO - Group Accuracy:

2022-01-19 00:10:48,102 - INFO - [0.9819277  0.99036145 0.98289156 0.9925301  0.9809638  0.99373496
 0.9787952  0.9821687  0.9891566  0.9775904  0.9886747  0.9845783
 0.97831327 0.98       0.97566265 0.98746985 0.9951807 ]
2022-01-19 00:10:48,103 - INFO - Epoch time: 489.46181988716125
2022-01-19 00:10:48,103 - INFO - 
Epoch: 52
2022-01-19 00:10:48,103 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:11:34,353 - INFO - [Step=43500]	Loss=0.6932	208.8 examples/second
2022-01-19 00:14:01,834 - INFO - [Step=43750]	Loss=0.6943	217.0 examples/second
2022-01-19 00:16:25,645 - INFO - [Step=44000]	Loss=0.6826	222.5 examples/second
2022-01-19 00:18:52,037 - INFO - [Step=44250]	Loss=0.6983	218.6 examples/second
2022-01-19 00:19:06,276 - INFO - Test Loss=0.8633, Test top-1 acc=0.7993
2022-01-19 00:19:06,276 - INFO - Group Accuracy:

2022-01-19 00:19:06,276 - INFO - [0.98024094 0.98963857 0.9853012  0.993494   0.9845783  0.99445784
 0.98024094 0.9816868  0.99036145 0.9771084  0.99060243 0.9833735
 0.9778313  0.98024094 0.9768675  0.9879518  0.9963855 ]
2022-01-19 00:19:06,277 - INFO - Epoch time: 498.17374539375305
2022-01-19 00:19:06,277 - INFO - 
Epoch: 53
2022-01-19 00:19:06,277 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:21:27,778 - INFO - [Step=44500]	Loss=0.6741	205.5 examples/second
2022-01-19 00:23:52,171 - INFO - [Step=44750]	Loss=0.6812	221.6 examples/second
2022-01-19 00:26:15,010 - INFO - [Step=45000]	Loss=0.7070	224.0 examples/second
2022-01-19 00:27:12,752 - INFO - Test Loss=0.8723, Test top-1 acc=0.7882
2022-01-19 00:27:12,752 - INFO - Group Accuracy:

2022-01-19 00:27:12,752 - INFO - [0.98024094 0.9898795  0.9855422  0.9925301  0.98313254 0.9951807
 0.97927713 0.9819277  0.99036145 0.97638553 0.99036145 0.98289156
 0.97542167 0.9778313  0.973494   0.9879518  0.99493974]
2022-01-19 00:27:12,753 - INFO - Epoch time: 486.4760272502899
2022-01-19 00:27:12,753 - INFO - 
Epoch: 54
2022-01-19 00:27:12,753 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:28:40,989 - INFO - [Step=45250]	Loss=0.6729	219.2 examples/second
2022-01-19 00:31:00,120 - INFO - [Step=45500]	Loss=0.6855	230.0 examples/second
2022-01-19 00:33:22,424 - INFO - [Step=45750]	Loss=0.6786	224.9 examples/second
2022-01-19 00:35:09,529 - INFO - Test Loss=0.8556, Test top-1 acc=0.7966
2022-01-19 00:35:09,529 - INFO - Group Accuracy:

2022-01-19 00:35:09,529 - INFO - [0.9804819  0.9901205  0.9840964  0.9939759  0.9833735  0.9946988
 0.9816868  0.9833735  0.9901205  0.97614455 0.9884337  0.9838554
 0.9771084  0.97975904 0.97590363 0.98698795 0.9961446 ]
2022-01-19 00:35:09,530 - INFO - Epoch time: 476.77692556381226
2022-01-19 00:35:09,530 - INFO - 
Epoch: 55
2022-01-19 00:35:09,530 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:35:54,979 - INFO - [Step=46000]	Loss=0.6678	209.8 examples/second
2022-01-19 00:38:19,427 - INFO - [Step=46250]	Loss=0.6777	221.5 examples/second
2022-01-19 00:40:40,641 - INFO - [Step=46500]	Loss=0.6864	226.6 examples/second
2022-01-19 00:43:06,865 - INFO - [Step=46750]	Loss=0.6875	218.8 examples/second
2022-01-19 00:43:24,517 - INFO - Test Loss=0.8641, Test top-1 acc=0.7937
2022-01-19 00:43:24,517 - INFO - Group Accuracy:

2022-01-19 00:43:24,517 - INFO - [0.9814458  0.99060243 0.98433733 0.9939759  0.9826506  0.9939759
 0.9814458  0.9816868  0.9898795  0.9768675  0.98698795 0.98361444
 0.97638553 0.97831327 0.97518075 0.9881928  0.9963855 ]
2022-01-19 00:43:24,520 - INFO - Epoch time: 494.98948907852173
2022-01-19 00:43:24,520 - INFO - 
Epoch: 56
2022-01-19 00:43:24,520 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:45:43,135 - INFO - [Step=47000]	Loss=0.6648	204.8 examples/second
2022-01-19 00:48:07,499 - INFO - [Step=47250]	Loss=0.6866	221.7 examples/second
2022-01-19 00:50:23,636 - INFO - [Step=47500]	Loss=0.6813	235.1 examples/second
2022-01-19 00:51:26,124 - INFO - Test Loss=0.8692, Test top-1 acc=0.7952
2022-01-19 00:51:26,124 - INFO - Group Accuracy:

2022-01-19 00:51:26,124 - INFO - [0.9804819  0.98963857 0.9845783  0.9925301  0.9826506  0.993494
 0.97927713 0.9838554  0.99036145 0.9766265  0.9881928  0.9855422
 0.9780723  0.97831327 0.9775904  0.9886747  0.99445784]
2022-01-19 00:51:26,125 - INFO - Epoch time: 481.6052429676056
2022-01-19 00:51:26,125 - INFO - 
Epoch: 57
2022-01-19 00:51:26,125 - INFO - 
Learning Rate: 0.0100
2022-01-19 00:52:54,062 - INFO - [Step=47750]	Loss=0.6717	212.7 examples/second
2022-01-19 00:55:13,585 - INFO - [Step=48000]	Loss=0.6589	229.4 examples/second
2022-01-19 00:57:31,855 - INFO - [Step=48250]	Loss=0.6730	231.4 examples/second
2022-01-19 00:59:23,440 - INFO - Test Loss=0.9318, Test top-1 acc=0.7913
2022-01-19 00:59:23,440 - INFO - Group Accuracy:

2022-01-19 00:59:23,440 - INFO - [0.97831327 0.99060243 0.9838554  0.9920482  0.9838554  0.9930121
 0.97975904 0.9812048  0.99060243 0.9773494  0.9886747  0.98433733
 0.9739759  0.9804819  0.97445786 0.98626506 0.99421686]
2022-01-19 00:59:23,441 - INFO - Epoch time: 477.31627440452576
2022-01-19 00:59:23,441 - INFO - 
Epoch: 58
2022-01-19 00:59:23,441 - INFO - 
Learning Rate: 0.0100
2022-01-19 01:00:05,630 - INFO - [Step=48500]	Loss=0.6727	208.1 examples/second
2022-01-19 01:02:24,657 - INFO - [Step=48750]	Loss=0.6527	230.2 examples/second
2022-01-19 01:04:42,727 - INFO - [Step=49000]	Loss=0.6535	231.8 examples/second
2022-01-19 01:07:03,323 - INFO - [Step=49250]	Loss=0.6652	227.6 examples/second
2022-01-19 01:07:22,136 - INFO - Test Loss=0.8891, Test top-1 acc=0.7928
2022-01-19 01:07:22,136 - INFO - Group Accuracy:

2022-01-19 01:07:22,136 - INFO - [0.98       0.9893976  0.9845783  0.99373496 0.9826506  0.99421686
 0.9807229  0.9807229  0.99036145 0.9766265  0.9891566  0.98289156
 0.97638553 0.97927713 0.9775904  0.98746985 0.9954217 ]
2022-01-19 01:07:22,137 - INFO - Epoch time: 478.6957702636719
2022-01-19 01:07:22,137 - INFO - 
Epoch: 59
2022-01-19 01:07:22,137 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:09:35,164 - INFO - [Step=49500]	Loss=0.6303	210.7 examples/second
2022-01-19 01:11:55,846 - INFO - [Step=49750]	Loss=0.5956	227.5 examples/second
2022-01-19 01:14:13,135 - INFO - [Step=50000]	Loss=0.5745	233.1 examples/second
2022-01-19 01:15:23,978 - INFO - Test Loss=0.8226, Test top-1 acc=0.8065
2022-01-19 01:15:23,979 - INFO - Group Accuracy:

2022-01-19 01:15:23,979 - INFO - [0.9819277  0.9920482  0.98578316 0.9939759  0.9853012  0.99445784
 0.9819277  0.9821687  0.99036145 0.9766265  0.99060243 0.9853012
 0.97638553 0.9807229  0.9771084  0.9884337  0.9959036 ]
2022-01-19 01:15:23,979 - INFO - Saving...
2022-01-19 01:15:24,629 - INFO - Epoch time: 482.49206376075745
2022-01-19 01:15:24,630 - INFO - 
Epoch: 60
2022-01-19 01:15:24,630 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:16:54,061 - INFO - [Step=50250]	Loss=0.5718	198.8 examples/second
2022-01-19 01:19:21,227 - INFO - [Step=50500]	Loss=0.5882	217.4 examples/second
2022-01-19 01:21:42,539 - INFO - [Step=50750]	Loss=0.5712	226.5 examples/second
2022-01-19 01:23:40,149 - INFO - Test Loss=0.8270, Test top-1 acc=0.8080
2022-01-19 01:23:40,149 - INFO - Group Accuracy:

2022-01-19 01:23:40,150 - INFO - [0.9814458  0.99108434 0.9860241  0.993253   0.98578316 0.9946988
 0.9819277  0.9821687  0.99060243 0.9768675  0.9901205  0.98578316
 0.9768675  0.9812048  0.97831327 0.98771083 0.9963855 ]
2022-01-19 01:23:40,150 - INFO - Saving...
2022-01-19 01:23:40,610 - INFO - Epoch time: 495.9799702167511
2022-01-19 01:23:40,610 - INFO - 
Epoch: 61
2022-01-19 01:23:40,610 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:24:17,158 - INFO - [Step=51000]	Loss=0.5696	207.0 examples/second
2022-01-19 01:26:42,435 - INFO - [Step=51250]	Loss=0.5582	220.3 examples/second
2022-01-19 01:29:03,575 - INFO - [Step=51500]	Loss=0.5604	226.7 examples/second
2022-01-19 01:31:27,363 - INFO - [Step=51750]	Loss=0.5509	222.6 examples/second
2022-01-19 01:31:46,908 - INFO - Test Loss=0.8195, Test top-1 acc=0.8099
2022-01-19 01:31:46,908 - INFO - Group Accuracy:

2022-01-19 01:31:46,908 - INFO - [0.98289156 0.99108434 0.98626506 0.99373496 0.9860241  0.99493974
 0.9819277  0.98313254 0.9898795  0.9771084  0.9901205  0.98578316
 0.9771084  0.9807229  0.97927713 0.9881928  0.9966265 ]
2022-01-19 01:31:46,909 - INFO - Saving...
2022-01-19 01:31:47,350 - INFO - Epoch time: 486.7400221824646
2022-01-19 01:31:47,350 - INFO - 
Epoch: 62
2022-01-19 01:31:47,350 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:33:59,195 - INFO - [Step=52000]	Loss=0.5518	210.8 examples/second
2022-01-19 01:36:25,917 - INFO - [Step=52250]	Loss=0.5527	218.1 examples/second
2022-01-19 01:38:49,123 - INFO - [Step=52500]	Loss=0.5573	223.5 examples/second
2022-01-19 01:40:06,114 - INFO - Test Loss=0.8120, Test top-1 acc=0.8106
2022-01-19 01:40:06,114 - INFO - Group Accuracy:

2022-01-19 01:40:06,114 - INFO - [0.9812048  0.9918072  0.98650604 0.9930121  0.98433733 0.99493974
 0.98240966 0.9833735  0.99036145 0.9775904  0.9901205  0.98578316
 0.9773494  0.9807229  0.97927713 0.98746985 0.9966265 ]
2022-01-19 01:40:06,116 - INFO - Saving...
2022-01-19 01:40:06,924 - INFO - Epoch time: 499.57377910614014
2022-01-19 01:40:06,924 - INFO - 
Epoch: 63
2022-01-19 01:40:06,925 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:41:33,735 - INFO - [Step=52750]	Loss=0.5560	194.4 examples/second
2022-01-19 01:44:03,850 - INFO - [Step=53000]	Loss=0.5541	213.2 examples/second
2022-01-19 01:46:27,259 - INFO - [Step=53250]	Loss=0.5545	223.1 examples/second
2022-01-19 01:48:20,371 - INFO - Test Loss=0.8159, Test top-1 acc=0.8140
2022-01-19 01:48:20,371 - INFO - Group Accuracy:

2022-01-19 01:48:20,371 - INFO - [0.98240966 0.9920482  0.9860241  0.993253   0.98433733 0.9946988
 0.98313254 0.9826506  0.99036145 0.9773494  0.99156624 0.9855422
 0.9775904  0.98024094 0.9785542  0.9881928  0.9963855 ]
2022-01-19 01:48:20,372 - INFO - Saving...
2022-01-19 01:48:20,815 - INFO - Epoch time: 493.89022612571716
2022-01-19 01:48:20,815 - INFO - 
Epoch: 64
2022-01-19 01:48:20,815 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:48:55,139 - INFO - [Step=53500]	Loss=0.5429	216.4 examples/second
2022-01-19 01:51:14,491 - INFO - [Step=53750]	Loss=0.5382	229.6 examples/second
2022-01-19 01:53:35,587 - INFO - [Step=54000]	Loss=0.5488	226.8 examples/second
2022-01-19 01:55:54,582 - INFO - [Step=54250]	Loss=0.5366	230.2 examples/second
2022-01-19 01:56:20,801 - INFO - Test Loss=0.8190, Test top-1 acc=0.8111
2022-01-19 01:56:20,801 - INFO - Group Accuracy:

2022-01-19 01:56:20,801 - INFO - [0.9819277  0.99084336 0.9860241  0.993494   0.9848193  0.9946988
 0.9826506  0.9833735  0.99036145 0.9766265  0.99084336 0.9855422
 0.9771084  0.98024094 0.9787952  0.98771083 0.9968675 ]
2022-01-19 01:56:20,802 - INFO - Epoch time: 479.9870789051056
2022-01-19 01:56:20,802 - INFO - 
Epoch: 65
2022-01-19 01:56:20,802 - INFO - 
Learning Rate: 0.0010
2022-01-19 01:58:31,786 - INFO - [Step=54500]	Loss=0.5232	203.6 examples/second
2022-01-19 02:00:49,383 - INFO - [Step=54750]	Loss=0.5396	232.6 examples/second
2022-01-19 02:03:10,949 - INFO - [Step=55000]	Loss=0.5633	226.0 examples/second
2022-01-19 02:04:21,845 - INFO - Test Loss=0.8308, Test top-1 acc=0.8094
2022-01-19 02:04:21,845 - INFO - Group Accuracy:

2022-01-19 02:04:21,845 - INFO - [0.9819277  0.99156624 0.98578316 0.993253   0.9848193  0.99493974
 0.9816868  0.98313254 0.98963857 0.97638553 0.98963857 0.9853012
 0.9775904  0.9812048  0.9787952  0.98698795 0.9966265 ]
2022-01-19 02:04:21,846 - INFO - Epoch time: 481.04377007484436
2022-01-19 02:04:21,846 - INFO - 
Epoch: 66
2022-01-19 02:04:21,846 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:05:44,494 - INFO - [Step=55250]	Loss=0.5310	208.4 examples/second
2022-01-19 02:08:03,118 - INFO - [Step=55500]	Loss=0.5307	230.8 examples/second
2022-01-19 02:10:18,621 - INFO - [Step=55750]	Loss=0.5181	236.2 examples/second
2022-01-19 02:12:15,024 - INFO - Test Loss=0.8345, Test top-1 acc=0.8067
2022-01-19 02:12:15,025 - INFO - Group Accuracy:

2022-01-19 02:12:15,025 - INFO - [0.9819277  0.9913253  0.98578316 0.9939759  0.9845783  0.9946988
 0.9821687  0.9826506  0.99060243 0.97590363 0.99060243 0.9853012
 0.9780723  0.9809638  0.97903615 0.98722893 0.9966265 ]
2022-01-19 02:12:15,028 - INFO - Epoch time: 473.18164682388306
2022-01-19 02:12:15,028 - INFO - 
Epoch: 67
2022-01-19 02:12:15,028 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:12:47,693 - INFO - [Step=56000]	Loss=0.5440	214.7 examples/second
2022-01-19 02:15:05,406 - INFO - [Step=56250]	Loss=0.5345	232.4 examples/second
2022-01-19 02:17:23,380 - INFO - [Step=56500]	Loss=0.5397	231.9 examples/second
2022-01-19 02:19:39,356 - INFO - [Step=56750]	Loss=0.5348	235.3 examples/second
2022-01-19 02:20:05,301 - INFO - Test Loss=0.8386, Test top-1 acc=0.8072
2022-01-19 02:20:05,301 - INFO - Group Accuracy:

2022-01-19 02:20:05,302 - INFO - [0.9819277  0.99156624 0.98578316 0.99373496 0.98433733 0.9946988
 0.9814458  0.98313254 0.9898795  0.9766265  0.9898795  0.9860241
 0.97831327 0.9804819  0.9780723  0.98746985 0.99710846]
2022-01-19 02:20:05,303 - INFO - Epoch time: 470.27548813819885
2022-01-19 02:20:05,303 - INFO - 
Epoch: 68
2022-01-19 02:20:05,303 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:22:08,489 - INFO - [Step=57000]	Loss=0.5274	214.6 examples/second
2022-01-19 02:24:26,403 - INFO - [Step=57250]	Loss=0.5267	232.0 examples/second
2022-01-19 02:26:44,566 - INFO - [Step=57500]	Loss=0.5287	231.6 examples/second
2022-01-19 02:27:55,308 - INFO - Test Loss=0.8313, Test top-1 acc=0.8089
2022-01-19 02:27:55,308 - INFO - Group Accuracy:

2022-01-19 02:27:55,308 - INFO - [0.9819277  0.9922892  0.9860241  0.99373496 0.9855422  0.9946988
 0.9814458  0.98433733 0.99036145 0.9768675  0.98963857 0.9855422
 0.9785542  0.9804819  0.9780723  0.98746985 0.9968675 ]
2022-01-19 02:27:55,309 - INFO - Epoch time: 470.00574946403503
2022-01-19 02:27:55,309 - INFO - 
Epoch: 69
2022-01-19 02:27:55,309 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:29:10,834 - INFO - [Step=57750]	Loss=0.5463	218.8 examples/second
2022-01-19 02:31:26,307 - INFO - [Step=58000]	Loss=0.5177	236.2 examples/second
2022-01-19 02:33:41,864 - INFO - [Step=58250]	Loss=0.5243	236.1 examples/second
2022-01-19 02:35:39,350 - INFO - Test Loss=0.8385, Test top-1 acc=0.8082
2022-01-19 02:35:39,351 - INFO - Group Accuracy:

2022-01-19 02:35:39,351 - INFO - [0.98289156 0.9913253  0.98674697 0.9920482  0.9848193  0.99445784
 0.9819277  0.9826506  0.99036145 0.9771084  0.9898795  0.9855422
 0.97831327 0.98       0.97831327 0.9884337  0.9966265 ]
2022-01-19 02:35:39,351 - INFO - Epoch time: 464.0421214103699
2022-01-19 02:35:39,351 - INFO - 
Epoch: 70
2022-01-19 02:35:39,352 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:36:09,229 - INFO - [Step=58500]	Loss=0.5220	217.2 examples/second
2022-01-19 02:38:25,116 - INFO - [Step=58750]	Loss=0.5257	235.5 examples/second
2022-01-19 02:40:41,165 - INFO - [Step=59000]	Loss=0.5244	235.2 examples/second
2022-01-19 02:42:57,798 - INFO - [Step=59250]	Loss=0.5303	234.2 examples/second
2022-01-19 02:43:24,763 - INFO - Test Loss=0.8354, Test top-1 acc=0.8087
2022-01-19 02:43:24,763 - INFO - Group Accuracy:

2022-01-19 02:43:24,763 - INFO - [0.9821687  0.9920482  0.98578316 0.993253   0.98433733 0.99445784
 0.9814458  0.98313254 0.9898795  0.9773494  0.98963857 0.9860241
 0.97903615 0.98       0.97831327 0.98771083 0.9968675 ]
2022-01-19 02:43:24,764 - INFO - Epoch time: 465.4127240180969
2022-01-19 02:43:24,764 - INFO - 
Epoch: 71
2022-01-19 02:43:24,764 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:45:27,267 - INFO - [Step=59500]	Loss=0.5130	214.1 examples/second
2022-01-19 02:47:54,749 - INFO - [Step=59750]	Loss=0.5204	217.0 examples/second
2022-01-19 02:50:17,516 - INFO - [Step=60000]	Loss=0.5306	224.1 examples/second
2022-01-19 02:51:42,146 - INFO - Test Loss=0.8346, Test top-1 acc=0.8113
2022-01-19 02:51:42,149 - INFO - Group Accuracy:

2022-01-19 02:51:42,149 - INFO - [0.98240966 0.9918072  0.9855422  0.99421686 0.98433733 0.9946988
 0.98289156 0.9838554  0.99108434 0.9773494  0.9901205  0.9860241
 0.97927713 0.98024094 0.9778313  0.9879518  0.99710846]
2022-01-19 02:51:42,152 - INFO - Epoch time: 497.3871901035309
2022-01-19 02:51:42,152 - INFO - 
Epoch: 72
2022-01-19 02:51:42,153 - INFO - 
Learning Rate: 0.0010
2022-01-19 02:52:58,491 - INFO - [Step=60250]	Loss=0.5229	198.8 examples/second
2022-01-19 02:55:28,474 - INFO - [Step=60500]	Loss=0.5168	213.4 examples/second
2022-01-19 02:57:52,746 - INFO - [Step=60750]	Loss=0.5123	221.8 examples/second
2022-01-19 02:59:56,700 - INFO - Test Loss=0.8232, Test top-1 acc=0.8135
2022-01-19 02:59:56,700 - INFO - Group Accuracy:

2022-01-19 02:59:56,700 - INFO - [0.98289156 0.9918072  0.98650604 0.993253   0.9853012  0.9946988
 0.9814458  0.9833735  0.99060243 0.9775904  0.99084336 0.9855422
 0.97903615 0.9807229  0.98024094 0.9886747  0.9963855 ]
2022-01-19 02:59:56,701 - INFO - Epoch time: 494.5484802722931
2022-01-19 02:59:56,701 - INFO - 
Epoch: 73
2022-01-19 02:59:56,701 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:00:23,140 - INFO - [Step=61000]	Loss=0.5287	212.8 examples/second
2022-01-19 03:02:41,195 - INFO - [Step=61250]	Loss=0.5202	231.8 examples/second
2022-01-19 03:05:02,008 - INFO - [Step=61500]	Loss=0.5136	227.3 examples/second
2022-01-19 03:07:21,000 - INFO - [Step=61750]	Loss=0.5146	230.2 examples/second
2022-01-19 03:07:55,635 - INFO - Test Loss=0.8406, Test top-1 acc=0.8111
2022-01-19 03:07:58,360 - INFO - Group Accuracy:

2022-01-19 03:07:58,360 - INFO - [0.98289156 0.9913253  0.98650604 0.99373496 0.9848193  0.99493974
 0.98240966 0.98361444 0.9913253  0.9768675  0.9898795  0.9860241
 0.97831327 0.9804819  0.97903615 0.9881928  0.9966265 ]
2022-01-19 03:07:58,364 - INFO - Epoch time: 481.6628634929657
2022-01-19 03:07:58,364 - INFO - 
Epoch: 74
2022-01-19 03:07:58,364 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:10:03,265 - INFO - [Step=62000]	Loss=0.5257	197.2 examples/second
2022-01-19 03:12:23,473 - INFO - [Step=62250]	Loss=0.5025	228.2 examples/second
2022-01-19 03:14:47,171 - INFO - [Step=62500]	Loss=0.5037	222.7 examples/second
2022-01-19 03:16:06,491 - INFO - Test Loss=0.8238, Test top-1 acc=0.8116
2022-01-19 03:16:06,491 - INFO - Group Accuracy:

2022-01-19 03:16:06,491 - INFO - [0.9819277  0.99156624 0.9855422  0.993494   0.98433733 0.9946988
 0.9819277  0.98433733 0.9898795  0.9773494  0.99084336 0.98578316
 0.9780723  0.98024094 0.98       0.9889157  0.9968675 ]
2022-01-19 03:16:06,492 - INFO - Epoch time: 488.1278350353241
2022-01-19 03:16:06,492 - INFO - 
Epoch: 75
2022-01-19 03:16:06,492 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:17:16,421 - INFO - [Step=62750]	Loss=0.5052	214.4 examples/second
2022-01-19 03:19:38,249 - INFO - [Step=63000]	Loss=0.5044	225.6 examples/second
2022-01-19 03:21:53,525 - INFO - [Step=63250]	Loss=0.5113	236.6 examples/second
2022-01-19 03:24:05,350 - INFO - Test Loss=0.8358, Test top-1 acc=0.8104
2022-01-19 03:24:05,350 - INFO - Group Accuracy:

2022-01-19 03:24:05,350 - INFO - [0.98240966 0.9918072  0.9860241  0.9939759  0.98433733 0.99493974
 0.98289156 0.98289156 0.99036145 0.97614455 0.9901205  0.98578316
 0.9780723  0.98024094 0.97831327 0.9893976  0.9963855 ]
2022-01-19 03:24:05,351 - INFO - Epoch time: 478.8588447570801
2022-01-19 03:24:05,351 - INFO - 
Epoch: 76
2022-01-19 03:24:05,351 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:24:33,317 - INFO - [Step=63500]	Loss=0.5157	200.3 examples/second
2022-01-19 03:27:00,529 - INFO - [Step=63750]	Loss=0.5099	217.4 examples/second
2022-01-19 03:29:22,515 - INFO - [Step=64000]	Loss=0.4959	225.4 examples/second
2022-01-19 03:31:44,871 - INFO - [Step=64250]	Loss=0.4878	224.8 examples/second
2022-01-19 03:32:23,784 - INFO - Test Loss=0.8758, Test top-1 acc=0.8118
2022-01-19 03:32:23,785 - INFO - Group Accuracy:

2022-01-19 03:32:23,785 - INFO - [0.9826506  0.9918072  0.9853012  0.9939759  0.9848193  0.9939759
 0.9819277  0.98313254 0.99060243 0.9766265  0.9913253  0.98674697
 0.97903615 0.9804819  0.9785542  0.9889157  0.9961446 ]
2022-01-19 03:32:23,786 - INFO - Epoch time: 498.4345784187317
2022-01-19 03:32:23,786 - INFO - 
Epoch: 77
2022-01-19 03:32:23,786 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:34:28,949 - INFO - [Step=64500]	Loss=0.5135	195.0 examples/second
2022-01-19 03:36:49,665 - INFO - [Step=64750]	Loss=0.5038	227.4 examples/second
2022-01-19 03:39:13,225 - INFO - [Step=65000]	Loss=0.5087	222.9 examples/second
2022-01-19 03:40:32,074 - INFO - Test Loss=0.8572, Test top-1 acc=0.8092
2022-01-19 03:40:32,074 - INFO - Group Accuracy:

2022-01-19 03:40:32,074 - INFO - [0.9814458  0.9918072  0.9850602  0.99421686 0.9860241  0.99445784
 0.98240966 0.9838554  0.9901205  0.9766265  0.9884337  0.9848193
 0.97831327 0.9809638  0.9785542  0.9886747  0.9968675 ]
2022-01-19 03:40:32,075 - INFO - Epoch time: 488.28949213027954
2022-01-19 03:40:32,075 - INFO - 
Epoch: 78
2022-01-19 03:40:32,075 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:41:44,213 - INFO - [Step=65250]	Loss=0.5041	211.9 examples/second
2022-01-19 03:44:08,331 - INFO - [Step=65500]	Loss=0.5020	222.0 examples/second
2022-01-19 03:46:31,454 - INFO - [Step=65750]	Loss=0.4996	223.6 examples/second
2022-01-19 03:48:51,288 - INFO - Test Loss=0.8525, Test top-1 acc=0.8099
2022-01-19 03:48:51,288 - INFO - Group Accuracy:

2022-01-19 03:48:51,288 - INFO - [0.98289156 0.99108434 0.9848193  0.99373496 0.9848193  0.99445784
 0.9814458  0.98433733 0.9898795  0.9778313  0.9891566  0.9853012
 0.97903615 0.98024094 0.9775904  0.9889157  0.9963855 ]
2022-01-19 03:48:51,289 - INFO - Epoch time: 499.21373772621155
2022-01-19 03:48:51,289 - INFO - 
Epoch: 79
2022-01-19 03:48:51,289 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:49:15,745 - INFO - [Step=66000]	Loss=0.5143	194.8 examples/second
2022-01-19 03:51:39,157 - INFO - [Step=66250]	Loss=0.5108	223.1 examples/second
2022-01-19 03:54:02,615 - INFO - [Step=66500]	Loss=0.5001	223.1 examples/second
2022-01-19 03:56:33,432 - INFO - [Step=66750]	Loss=0.5117	212.2 examples/second
2022-01-19 03:57:09,092 - INFO - Test Loss=0.8493, Test top-1 acc=0.8120
2022-01-19 03:57:09,092 - INFO - Group Accuracy:

2022-01-19 03:57:09,092 - INFO - [0.9821687  0.9918072  0.9850602  0.9939759  0.9860241  0.9946988
 0.9826506  0.98240966 0.9898795  0.97566265 0.9901205  0.9855422
 0.9785542  0.9809638  0.9787952  0.9884337  0.9966265 ]
2022-01-19 03:57:09,093 - INFO - Epoch time: 497.8038272857666
2022-01-19 03:57:09,093 - INFO - 
Epoch: 80
2022-01-19 03:57:09,093 - INFO - 
Learning Rate: 0.0010
2022-01-19 03:59:02,167 - INFO - [Step=67000]	Loss=0.4915	215.1 examples/second
2022-01-19 04:01:26,175 - INFO - [Step=67250]	Loss=0.5035	222.2 examples/second
2022-01-19 04:03:54,188 - INFO - [Step=67500]	Loss=0.5026	216.2 examples/second
2022-01-19 04:05:18,230 - INFO - Test Loss=0.8339, Test top-1 acc=0.8111
2022-01-19 04:05:18,230 - INFO - Group Accuracy:

2022-01-19 04:05:18,230 - INFO - [0.9821687  0.9918072  0.9853012  0.99445784 0.9845783  0.9946988
 0.9821687  0.9833735  0.99108434 0.9780723  0.99060243 0.9848193
 0.9780723  0.98024094 0.97927713 0.98963857 0.9959036 ]
2022-01-19 04:05:18,231 - INFO - Epoch time: 489.13820719718933
2022-01-19 04:05:18,231 - INFO - 
Epoch: 81
2022-01-19 04:05:18,231 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:06:28,067 - INFO - [Step=67750]	Loss=0.4977	208.0 examples/second
2022-01-19 04:08:55,002 - INFO - [Step=68000]	Loss=0.4975	217.8 examples/second
2022-01-19 04:11:18,095 - INFO - [Step=68250]	Loss=0.4992	223.6 examples/second
2022-01-19 04:13:38,715 - INFO - Test Loss=0.8466, Test top-1 acc=0.8111
2022-01-19 04:13:38,715 - INFO - Group Accuracy:

2022-01-19 04:13:38,715 - INFO - [0.9826506  0.99156624 0.9848193  0.9930121  0.9848193  0.9946988
 0.98240966 0.98313254 0.99108434 0.9766265  0.9898795  0.9860241
 0.9775904  0.9804819  0.97927713 0.9886747  0.9961446 ]
2022-01-19 04:13:38,716 - INFO - Epoch time: 500.48471665382385
2022-01-19 04:13:38,716 - INFO - 
Epoch: 82
2022-01-19 04:13:38,716 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:13:58,757 - INFO - [Step=68500]	Loss=0.4870	199.2 examples/second
2022-01-19 04:16:20,574 - INFO - [Step=68750]	Loss=0.4984	225.6 examples/second
2022-01-19 04:18:43,875 - INFO - [Step=69000]	Loss=0.5016	223.3 examples/second
2022-01-19 04:21:03,263 - INFO - [Step=69250]	Loss=0.4912	229.6 examples/second
2022-01-19 04:21:44,977 - INFO - Test Loss=0.8445, Test top-1 acc=0.8101
2022-01-19 04:21:44,977 - INFO - Group Accuracy:

2022-01-19 04:21:44,977 - INFO - [0.98240966 0.99156624 0.9850602  0.9927711  0.9838554  0.99445784
 0.98313254 0.98361444 0.99156624 0.9771084  0.99036145 0.98626506
 0.9771084  0.98       0.9787952  0.9886747  0.9963855 ]
2022-01-19 04:21:44,979 - INFO - Epoch time: 486.26245307922363
2022-01-19 04:21:44,979 - INFO - 
Epoch: 83
2022-01-19 04:21:44,979 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:23:45,098 - INFO - [Step=69500]	Loss=0.4825	197.7 examples/second
2022-01-19 04:26:09,676 - INFO - [Step=69750]	Loss=0.4996	221.3 examples/second
2022-01-19 04:28:35,131 - INFO - [Step=70000]	Loss=0.5200	220.0 examples/second
2022-01-19 04:30:13,457 - INFO - Test Loss=0.8510, Test top-1 acc=0.8060
2022-01-19 04:30:13,457 - INFO - Group Accuracy:

2022-01-19 04:30:13,458 - INFO - [0.9816868  0.9918072  0.98578316 0.99445784 0.9840964  0.9946988
 0.9819277  0.9819277  0.9898795  0.97566265 0.9901205  0.98433733
 0.9780723  0.97975904 0.97927713 0.9891566  0.9966265 ]
2022-01-19 04:30:13,458 - INFO - Epoch time: 508.4797029495239
2022-01-19 04:30:13,458 - INFO - 
Epoch: 84
2022-01-19 04:30:13,458 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:31:23,568 - INFO - [Step=70250]	Loss=0.4915	190.0 examples/second
2022-01-19 04:33:51,656 - INFO - [Step=70500]	Loss=0.4863	216.1 examples/second
2022-01-19 04:36:11,287 - INFO - [Step=70750]	Loss=0.4923	229.2 examples/second
2022-01-19 04:38:31,784 - INFO - Test Loss=0.8276, Test top-1 acc=0.8094
2022-01-19 04:38:31,785 - INFO - Group Accuracy:

2022-01-19 04:38:31,785 - INFO - [0.9816868  0.9918072  0.9848193  0.99373496 0.9845783  0.9946988
 0.9807229  0.98313254 0.99108434 0.97493976 0.99036145 0.98578316
 0.9775904  0.98024094 0.9778313  0.9884337  0.9966265 ]
2022-01-19 04:38:31,787 - INFO - Epoch time: 498.32879304885864
2022-01-19 04:38:31,787 - INFO - 
Epoch: 85
2022-01-19 04:38:31,787 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:38:49,432 - INFO - [Step=71000]	Loss=0.4866	202.3 examples/second
2022-01-19 04:41:18,067 - INFO - [Step=71250]	Loss=0.5080	215.3 examples/second
2022-01-19 04:43:42,645 - INFO - [Step=71500]	Loss=0.4991	221.3 examples/second
2022-01-19 04:46:14,463 - INFO - [Step=71750]	Loss=0.4971	210.8 examples/second
2022-01-19 04:46:58,835 - INFO - Test Loss=0.8519, Test top-1 acc=0.8087
2022-01-19 04:46:58,836 - INFO - Group Accuracy:

2022-01-19 04:46:58,836 - INFO - [0.9814458  0.9918072  0.9860241  0.9939759  0.9840964  0.99493974
 0.9814458  0.9833735  0.99084336 0.97638553 0.99036145 0.9850602
 0.9787952  0.9804819  0.97975904 0.9891566  0.99710846]
2022-01-19 04:46:58,837 - INFO - Epoch time: 507.0492298603058
2022-01-19 04:46:58,837 - INFO - 
Epoch: 86
2022-01-19 04:46:58,837 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:48:52,732 - INFO - [Step=72000]	Loss=0.4856	202.2 examples/second
2022-01-19 04:51:21,630 - INFO - [Step=72250]	Loss=0.5013	214.9 examples/second
2022-01-19 04:53:44,752 - INFO - [Step=72500]	Loss=0.4840	223.6 examples/second
2022-01-19 04:55:22,651 - INFO - Test Loss=0.8207, Test top-1 acc=0.8111
2022-01-19 04:55:22,651 - INFO - Group Accuracy:

2022-01-19 04:55:22,651 - INFO - [0.9821687  0.9918072  0.98626506 0.99421686 0.9850602  0.99445784
 0.9819277  0.9838554  0.99060243 0.9771084  0.9913253  0.9853012
 0.9780723  0.98024094 0.9780723  0.9886747  0.9973494 ]
2022-01-19 04:55:22,652 - INFO - Epoch time: 503.8155002593994
2022-01-19 04:55:22,652 - INFO - 
Epoch: 87
2022-01-19 04:55:22,652 - INFO - 
Learning Rate: 0.0010
2022-01-19 04:56:24,900 - INFO - [Step=72750]	Loss=0.4932	199.8 examples/second
2022-01-19 04:58:46,929 - INFO - [Step=73000]	Loss=0.4881	225.3 examples/second
2022-01-19 05:01:13,178 - INFO - [Step=73250]	Loss=0.4840	218.8 examples/second
2022-01-19 05:03:36,868 - INFO - Test Loss=0.8460, Test top-1 acc=0.8082
2022-01-19 05:03:36,869 - INFO - Group Accuracy:

2022-01-19 05:03:36,869 - INFO - [0.9814458  0.9922892  0.9850602  0.9930121  0.98433733 0.99493974
 0.9809638  0.98313254 0.9901205  0.97614455 0.99108434 0.9853012
 0.9766265  0.9807229  0.97951806 0.9884337  0.99710846]
2022-01-19 05:03:36,870 - INFO - Epoch time: 494.21751737594604
2022-01-19 05:03:36,870 - INFO - 
Epoch: 88
2022-01-19 05:03:36,870 - INFO - 
Learning Rate: 0.0010
2022-01-19 05:03:49,660 - INFO - [Step=73500]	Loss=0.4881	204.5 examples/second
2022-01-19 05:06:17,926 - INFO - [Step=73750]	Loss=0.4856	215.8 examples/second
2022-01-19 05:08:46,750 - INFO - [Step=74000]	Loss=0.4736	215.0 examples/second
2022-01-19 05:11:13,021 - INFO - [Step=74250]	Loss=0.4864	218.8 examples/second
2022-01-19 05:12:03,183 - INFO - Test Loss=0.8606, Test top-1 acc=0.8072
2022-01-19 05:12:03,184 - INFO - Group Accuracy:

2022-01-19 05:12:03,184 - INFO - [0.9807229  0.9913253  0.98578316 0.99421686 0.9840964  0.9946988
 0.9821687  0.98361444 0.9913253  0.97638553 0.99084336 0.98578316
 0.9768675  0.98024094 0.9780723  0.9891566  0.9966265 ]
2022-01-19 05:12:03,185 - INFO - Epoch time: 506.3147888183594
2022-01-19 05:12:03,185 - INFO - 
Epoch: 89
2022-01-19 05:12:03,185 - INFO - 
Learning Rate: 0.0010
2022-01-19 05:13:51,314 - INFO - [Step=74500]	Loss=0.4833	202.2 examples/second
2022-01-19 05:16:16,631 - INFO - [Step=74750]	Loss=0.4765	220.2 examples/second
2022-01-19 05:18:35,083 - INFO - [Step=75000]	Loss=0.4949	231.1 examples/second
2022-01-19 05:20:07,493 - INFO - Test Loss=0.8332, Test top-1 acc=0.8130
2022-01-19 05:20:07,493 - INFO - Group Accuracy:

2022-01-19 05:20:07,493 - INFO - [0.9816868  0.9913253  0.9848193  0.9930121  0.9848193  0.9946988
 0.9821687  0.98433733 0.99036145 0.9773494  0.99084336 0.9848193
 0.9787952  0.97975904 0.97951806 0.9891566  0.9963855 ]
2022-01-19 05:20:07,494 - INFO - Epoch time: 484.30930352211
2022-01-19 05:20:19,107 - INFO - Computing OOD Statistics...
2022-01-19 05:20:19,114 - INFO - 	Baseline.          AUROC: 0.2923. TNR@95TPR: 0.0235. AUPR OUT: 0.1170
2022-01-19 05:20:19,119 - INFO - 	ODIN (T=1000).     AUROC: 0.8746. TNR@95TPR: 0.4565. AUPR OUT: 0.6046
2022-01-19 05:20:19,120 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-19 05:20:19,120 - INFO - Top 1 Accuracy:  Min: 0.8140; Max: 0.8140; Avg: 0.8140; Std: 0.0000; Len: 1
2022-01-19 05:20:19,120 - INFO - Top 5 Accuracy:  Min: 0.9861; Max: 0.9861; Avg: 0.9861; Std: 0.0000; Len: 1
2022-01-19 05:20:19,120 - INFO - **********************************************************************
2022-01-19 05:20:19,120 - INFO - 	MSP (auroc): [0.29225655563430186] Min: 0.2923; Max: 0.2923; Avg: 0.2923; Std: 0.0000; Len: 1
2022-01-19 05:20:19,120 - INFO - 	MSP (tnr): [0.02352941176470591] Min: 0.0235; Max: 0.0235; Avg: 0.0235; Std: 0.0000; Len: 1
2022-01-19 05:20:19,120 - INFO - 	MSP (aupr): [0.11703755304719139] Min: 0.1170; Max: 0.1170; Avg: 0.1170; Std: 0.0000; Len: 1
2022-01-19 05:20:19,120 - INFO - 	ODIN (auroc): [0.8746248051027641] Min: 0.8746; Max: 0.8746; Avg: 0.8746; Std: 0.0000; Len: 1
2022-01-19 05:20:19,121 - INFO - 	ODIN (tnr): [0.4564705882352941] Min: 0.4565; Max: 0.4565; Avg: 0.4565; Std: 0.0000; Len: 1
2022-01-19 05:20:19,121 - INFO - 	ODIN (aupr): [0.6046114213920123] Min: 0.6046; Max: 0.6046; Avg: 0.6046; Std: 0.0000; Len: 1

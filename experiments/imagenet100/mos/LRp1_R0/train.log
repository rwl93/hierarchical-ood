2022-01-10 08:36:42,070 - INFO - ==> Preparing data..
2022-01-10 08:36:42,508 - INFO - checkpoint filename: experiments/coarse/mos/LRp1_R0/checkpoint.pt
2022-01-10 08:36:42,508 - INFO - log filename: experiments/coarse/mos/LRp1_R0/train.log
2022-01-10 08:36:42,508 - INFO - ********************************************************
2022-01-10 08:36:42,508 - INFO - Starting Iter: 0 / 1
2022-01-10 08:36:42,508 - INFO - ********************************************************
2022-01-10 08:36:46,116 - INFO - 
Epoch: 0
2022-01-10 08:36:46,116 - INFO - 
Learning Rate: 0.0100
2022-01-10 08:38:58,988 - INFO - [Step=250]	Loss=7.2799	240.8 examples/second
2022-01-10 08:41:10,456 - INFO - [Step=500]	Loss=5.4375	243.4 examples/second
2022-01-10 08:43:22,516 - INFO - [Step=750]	Loss=5.2915	242.3 examples/second
2022-01-10 08:44:15,069 - INFO - Test Loss=5.1399, Test top-1 acc=0.0412
2022-01-10 08:44:15,069 - INFO - Group Accuracy:

2022-01-10 08:44:15,069 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.9395181
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.939759  0.939759  0.9518072]
2022-01-10 08:44:15,070 - INFO - Saving...
2022-01-10 08:44:15,259 - INFO - Epoch time: 449.1433103084564
2022-01-10 08:44:15,259 - INFO - 
Epoch: 1
2022-01-10 08:44:15,259 - INFO - 
Learning Rate: 0.0280
2022-01-10 08:45:43,588 - INFO - [Step=1000]	Loss=5.1587	226.8 examples/second
2022-01-10 08:47:53,406 - INFO - [Step=1250]	Loss=4.9257	246.5 examples/second
2022-01-10 08:50:03,029 - INFO - [Step=1500]	Loss=4.7176	246.9 examples/second
2022-01-10 08:51:39,013 - INFO - Test Loss=4.5809, Test top-1 acc=0.0602
2022-01-10 08:51:39,013 - INFO - Group Accuracy:

2022-01-10 08:51:39,013 - INFO - [0.9395181  0.93831325 0.939759   0.94289154 0.939759   0.9368675
 0.9392771  0.939759   0.9395181  0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.9387952  0.9515663 ]
2022-01-10 08:51:39,014 - INFO - Saving...
2022-01-10 08:51:39,311 - INFO - Epoch time: 444.051739692688
2022-01-10 08:51:39,311 - INFO - 
Epoch: 2
2022-01-10 08:51:39,311 - INFO - 
Learning Rate: 0.0460
2022-01-10 08:52:23,085 - INFO - [Step=1750]	Loss=4.5898	228.5 examples/second
2022-01-10 08:54:34,208 - INFO - [Step=2000]	Loss=4.4642	244.0 examples/second
2022-01-10 08:56:45,324 - INFO - [Step=2250]	Loss=4.3238	244.1 examples/second
2022-01-10 08:58:56,263 - INFO - [Step=2500]	Loss=4.1623	244.4 examples/second
2022-01-10 08:59:07,049 - INFO - Test Loss=3.9828, Test top-1 acc=0.1366
2022-01-10 08:59:07,049 - INFO - Group Accuracy:

2022-01-10 08:59:07,049 - INFO - [0.94096386 0.94506025 0.94       0.9501205  0.94096386 0.9474699
 0.94216865 0.94433737 0.9453012  0.939759   0.95349395 0.940241
 0.939759   0.939759   0.93807226 0.94096386 0.95301205]
2022-01-10 08:59:07,050 - INFO - Saving...
2022-01-10 08:59:07,356 - INFO - Epoch time: 448.04484033584595
2022-01-10 08:59:07,356 - INFO - 
Epoch: 3
2022-01-10 08:59:07,356 - INFO - 
Learning Rate: 0.0640
2022-01-10 09:01:16,745 - INFO - [Step=2750]	Loss=4.0384	227.8 examples/second
2022-01-10 09:03:26,932 - INFO - [Step=3000]	Loss=3.8814	245.8 examples/second
2022-01-10 09:05:36,912 - INFO - [Step=3250]	Loss=3.7201	246.2 examples/second
2022-01-10 09:06:31,325 - INFO - Test Loss=3.4576, Test top-1 acc=0.1901
2022-01-10 09:06:31,326 - INFO - Group Accuracy:

2022-01-10 09:06:31,326 - INFO - [0.9445783  0.9469879  0.94168675 0.95373493 0.9426506  0.95759034
 0.94240963 0.94626504 0.94963855 0.94120485 0.9518072  0.94216865
 0.94144577 0.94240963 0.94192773 0.946747   0.9583132 ]
2022-01-10 09:06:31,326 - INFO - Saving...
2022-01-10 09:06:31,617 - INFO - Epoch time: 444.26085090637207
2022-01-10 09:06:31,617 - INFO - 
Epoch: 4
2022-01-10 09:06:31,617 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:07:56,728 - INFO - [Step=3500]	Loss=3.6676	228.9 examples/second
2022-01-10 09:10:08,658 - INFO - [Step=3750]	Loss=3.5675	242.6 examples/second
2022-01-10 09:12:20,170 - INFO - [Step=4000]	Loss=3.5278	243.3 examples/second
2022-01-10 09:13:59,746 - INFO - Test Loss=3.3603, Test top-1 acc=0.2465
2022-01-10 09:13:59,746 - INFO - Group Accuracy:

2022-01-10 09:13:59,746 - INFO - [0.94506025 0.94939756 0.94216865 0.9573494  0.9440964  0.9619277
 0.9448193  0.94843376 0.95277107 0.9392771  0.95349395 0.9426506
 0.94192773 0.94240963 0.94       0.94891566 0.9614458 ]
2022-01-10 09:13:59,748 - INFO - Saving...
2022-01-10 09:14:00,010 - INFO - Epoch time: 448.3924117088318
2022-01-10 09:14:00,010 - INFO - 
Epoch: 5
2022-01-10 09:14:00,010 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:14:41,497 - INFO - [Step=4250]	Loss=3.3966	226.4 examples/second
2022-01-10 09:16:53,956 - INFO - [Step=4500]	Loss=3.1870	241.6 examples/second
2022-01-10 09:19:04,611 - INFO - [Step=4750]	Loss=3.1063	244.9 examples/second
2022-01-10 09:21:15,415 - INFO - [Step=5000]	Loss=2.9924	244.6 examples/second
2022-01-10 09:21:28,809 - INFO - Test Loss=3.1302, Test top-1 acc=0.2827
2022-01-10 09:21:28,810 - INFO - Group Accuracy:

2022-01-10 09:21:28,810 - INFO - [0.946506   0.9445783  0.94506025 0.9633735  0.94626504 0.96771085
 0.9291566  0.9479518  0.9551807  0.94915664 0.9573494  0.9477109
 0.94120485 0.94506025 0.9460241  0.9539759  0.97156626]
2022-01-10 09:21:28,811 - INFO - Saving...
2022-01-10 09:21:29,109 - INFO - Epoch time: 449.09861993789673
2022-01-10 09:21:29,109 - INFO - 
Epoch: 6
2022-01-10 09:21:29,109 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:23:36,937 - INFO - [Step=5250]	Loss=2.9205	226.1 examples/second
2022-01-10 09:25:46,923 - INFO - [Step=5500]	Loss=2.8566	246.2 examples/second
2022-01-10 09:27:57,249 - INFO - [Step=5750]	Loss=2.8228	245.5 examples/second
2022-01-10 09:28:55,073 - INFO - Test Loss=2.7635, Test top-1 acc=0.3359
2022-01-10 09:28:55,074 - INFO - Group Accuracy:

2022-01-10 09:28:55,074 - INFO - [0.94891566 0.9585542  0.9498795  0.9653012  0.9518072  0.9737349
 0.93710846 0.95759034 0.9578313  0.9515663  0.96433735 0.94939756
 0.94289154 0.933253   0.9479518  0.9573494  0.97518075]
2022-01-10 09:28:55,075 - INFO - Saving...
2022-01-10 09:28:55,382 - INFO - Epoch time: 446.27271461486816
2022-01-10 09:28:55,382 - INFO - 
Epoch: 7
2022-01-10 09:28:55,382 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:30:18,702 - INFO - [Step=6000]	Loss=2.7136	226.2 examples/second
2022-01-10 09:32:28,824 - INFO - [Step=6250]	Loss=2.6321	245.9 examples/second
2022-01-10 09:34:39,092 - INFO - [Step=6500]	Loss=2.6019	245.6 examples/second
2022-01-10 09:36:21,866 - INFO - Test Loss=2.2606, Test top-1 acc=0.4207
2022-01-10 09:36:21,866 - INFO - Group Accuracy:

2022-01-10 09:36:21,866 - INFO - [0.95710844 0.96024096 0.94963855 0.97493976 0.9544578  0.97927713
 0.9506024  0.9595181  0.96771085 0.96361446 0.9672289  0.9583132
 0.94506025 0.94626504 0.9539759  0.96072286 0.9826506 ]
2022-01-10 09:36:21,867 - INFO - Saving...
2022-01-10 09:36:22,131 - INFO - Epoch time: 446.74918508529663
2022-01-10 09:36:22,131 - INFO - 
Epoch: 8
2022-01-10 09:36:22,131 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:37:00,535 - INFO - [Step=6750]	Loss=2.5073	226.2 examples/second
2022-01-10 09:39:10,730 - INFO - [Step=7000]	Loss=2.4612	245.8 examples/second
2022-01-10 09:41:20,668 - INFO - [Step=7250]	Loss=2.4244	246.3 examples/second
2022-01-10 09:43:31,451 - INFO - [Step=7500]	Loss=2.3888	244.7 examples/second
2022-01-10 09:43:47,001 - INFO - Test Loss=2.2570, Test top-1 acc=0.4373
2022-01-10 09:43:47,001 - INFO - Group Accuracy:

2022-01-10 09:43:47,001 - INFO - [0.96048194 0.9631325  0.9578313  0.9693976  0.9592771  0.9814458
 0.95253015 0.96048194 0.9739759  0.9549398  0.96698797 0.9578313
 0.946747   0.9510843  0.9506024  0.9626506  0.98      ]
2022-01-10 09:43:47,002 - INFO - Saving...
2022-01-10 09:43:47,288 - INFO - Epoch time: 445.1560893058777
2022-01-10 09:43:47,288 - INFO - 
Epoch: 9
2022-01-10 09:43:47,288 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:45:51,902 - INFO - [Step=7750]	Loss=2.2983	227.8 examples/second
2022-01-10 09:48:02,486 - INFO - [Step=8000]	Loss=2.2924	245.1 examples/second
2022-01-10 09:50:14,018 - INFO - [Step=8250]	Loss=2.2487	243.3 examples/second
2022-01-10 09:51:13,802 - INFO - Test Loss=2.2402, Test top-1 acc=0.4316
2022-01-10 09:51:13,802 - INFO - Group Accuracy:

2022-01-10 09:51:13,817 - INFO - [0.9578313  0.9624096  0.95421684 0.97951806 0.96048194 0.97951806
 0.95349395 0.9585542  0.9672289  0.9592771  0.9633735  0.9614458
 0.9515663  0.9481928  0.9486747  0.96385545 0.9812048 ]
2022-01-10 09:51:13,818 - INFO - Epoch time: 446.5298147201538
2022-01-10 09:51:13,818 - INFO - 
Epoch: 10
2022-01-10 09:51:13,818 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:52:33,809 - INFO - [Step=8500]	Loss=2.1867	228.9 examples/second
2022-01-10 09:54:43,511 - INFO - [Step=8750]	Loss=2.1741	246.7 examples/second
2022-01-10 09:56:54,222 - INFO - [Step=9000]	Loss=2.1382	244.8 examples/second
2022-01-10 09:58:37,888 - INFO - Test Loss=4.1497, Test top-1 acc=0.4207
2022-01-10 09:58:37,888 - INFO - Group Accuracy:

2022-01-10 09:58:37,888 - INFO - [0.9501205  0.9633735  0.9515663  0.97542167 0.9573494  0.97951806
 0.9510843  0.9592771  0.9657831  0.95686746 0.96361446 0.96096385
 0.946747   0.94963855 0.9513253  0.9549398  0.98024094]
2022-01-10 09:58:37,889 - INFO - Epoch time: 444.07104778289795
2022-01-10 09:58:37,889 - INFO - 
Epoch: 11
2022-01-10 09:58:37,889 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:59:13,443 - INFO - [Step=9250]	Loss=2.1052	229.9 examples/second
2022-01-10 10:01:23,417 - INFO - [Step=9500]	Loss=2.0744	246.2 examples/second
2022-01-10 10:03:33,784 - INFO - [Step=9750]	Loss=2.0410	245.5 examples/second
2022-01-10 10:05:43,564 - INFO - [Step=10000]	Loss=2.0197	246.6 examples/second
2022-01-10 10:06:02,070 - INFO - Test Loss=2.3851, Test top-1 acc=0.4699
2022-01-10 10:06:02,071 - INFO - Group Accuracy:

2022-01-10 10:06:02,071 - INFO - [0.9621687  0.9698795  0.946747   0.9785542  0.9631325  0.97951806
 0.95975906 0.96       0.9771084  0.966506   0.97228914 0.9701205
 0.95253015 0.95421684 0.9559036  0.966747   0.98361444]
2022-01-10 10:06:02,071 - INFO - Saving...
2022-01-10 10:06:02,338 - INFO - Epoch time: 444.44878935813904
2022-01-10 10:06:02,338 - INFO - 
Epoch: 12
2022-01-10 10:06:02,338 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:08:04,106 - INFO - [Step=10250]	Loss=1.9718	227.7 examples/second
2022-01-10 10:10:14,579 - INFO - [Step=10500]	Loss=1.9981	245.3 examples/second
2022-01-10 10:12:24,718 - INFO - [Step=10750]	Loss=1.9492	245.9 examples/second
2022-01-10 10:13:27,133 - INFO - Test Loss=1.9558, Test top-1 acc=0.5002
2022-01-10 10:13:27,134 - INFO - Group Accuracy:

2022-01-10 10:13:27,134 - INFO - [0.96168673 0.9698795  0.96024096 0.9804819  0.96096385 0.98361444
 0.96048194 0.9614458  0.98       0.9633735  0.97301203 0.9657831
 0.9469879  0.9561446  0.95662653 0.9621687  0.9812048 ]
2022-01-10 10:13:27,135 - INFO - Saving...
2022-01-10 10:13:27,415 - INFO - Epoch time: 445.0773060321808
2022-01-10 10:13:27,416 - INFO - 
Epoch: 13
2022-01-10 10:13:27,416 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:14:44,438 - INFO - [Step=11000]	Loss=1.9037	229.0 examples/second
2022-01-10 10:16:53,682 - INFO - [Step=11250]	Loss=1.9051	247.6 examples/second
2022-01-10 10:19:02,570 - INFO - [Step=11500]	Loss=1.8811	248.3 examples/second
2022-01-10 10:20:48,018 - INFO - Test Loss=2.0005, Test top-1 acc=0.5414
2022-01-10 10:20:48,019 - INFO - Group Accuracy:

2022-01-10 10:20:48,019 - INFO - [0.966506   0.9725301  0.9592771  0.9848193  0.9619277  0.9816868
 0.9595181  0.9672289  0.97831327 0.96795183 0.97614455 0.9706024
 0.95277107 0.9580723  0.9614458  0.973253   0.98698795]
2022-01-10 10:20:48,020 - INFO - Saving...
2022-01-10 10:20:48,294 - INFO - Epoch time: 440.87848830223083
2022-01-10 10:20:48,294 - INFO - 
Epoch: 14
2022-01-10 10:20:48,295 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:21:21,238 - INFO - [Step=11750]	Loss=1.8705	230.8 examples/second
2022-01-10 10:23:31,690 - INFO - [Step=12000]	Loss=1.8187	245.3 examples/second
2022-01-10 10:28:13,086 - INFO - [Step=12250]	Loss=1.8124	113.7 examples/second
2022-01-10 10:33:58,852 - INFO - [Step=12500]	Loss=1.8208	92.5 examples/second
2022-01-10 10:34:49,003 - INFO - Test Loss=1.9046, Test top-1 acc=0.5219
2022-01-10 10:34:49,003 - INFO - Group Accuracy:

2022-01-10 10:34:49,003 - INFO - [0.9631325  0.97590363 0.96457833 0.9812048  0.9619277  0.9821687
 0.95349395 0.9657831  0.97566265 0.9631325  0.9686747  0.96457833
 0.9544578  0.94843376 0.96024096 0.96891564 0.98674697]
2022-01-10 10:34:49,004 - INFO - Epoch time: 840.709549665451
2022-01-10 10:34:49,004 - INFO - 
Epoch: 15
2022-01-10 10:34:49,004 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:40:01,840 - INFO - [Step=12750]	Loss=1.7699	88.2 examples/second
2022-01-10 10:45:49,639 - INFO - [Step=13000]	Loss=1.7668	92.0 examples/second
2022-01-10 10:51:38,675 - INFO - [Step=13250]	Loss=1.7580	91.7 examples/second
2022-01-10 10:54:26,830 - INFO - Test Loss=1.7094, Test top-1 acc=0.5814
2022-01-10 10:54:26,831 - INFO - Group Accuracy:

2022-01-10 10:54:26,831 - INFO - [0.96506023 0.9780723  0.96385545 0.98240966 0.96771085 0.9840964
 0.9539759  0.9727711  0.9771084  0.96771085 0.9785542  0.9655422
 0.9578313  0.96168673 0.96024096 0.9725301  0.98650604]
2022-01-10 10:54:26,832 - INFO - Saving...
2022-01-10 10:54:27,475 - INFO - Epoch time: 1178.4708869457245
2022-01-10 10:54:27,475 - INFO - 
Epoch: 16
2022-01-10 10:54:27,476 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:56:17,480 - INFO - [Step=13500]	Loss=1.7502	114.8 examples/second
2022-01-10 10:58:29,052 - INFO - [Step=13750]	Loss=1.6996	243.2 examples/second
2022-01-10 11:00:41,161 - INFO - [Step=14000]	Loss=1.7254	242.2 examples/second
2022-01-10 11:02:31,850 - INFO - Test Loss=1.7153, Test top-1 acc=0.5795
2022-01-10 11:02:31,850 - INFO - Group Accuracy:

2022-01-10 11:02:31,850 - INFO - [0.9655422  0.9727711  0.9580723  0.9826506  0.9660241  0.98771083
 0.95710844 0.966747   0.9785542  0.9674699  0.9746988  0.9672289
 0.9612048  0.9628916  0.96385545 0.9691566  0.98746985]
2022-01-10 11:02:31,851 - INFO - Epoch time: 484.37566328048706
2022-01-10 11:02:31,851 - INFO - 
Epoch: 17
2022-01-10 11:02:31,851 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:03:02,840 - INFO - [Step=14250]	Loss=1.6929	225.9 examples/second
2022-01-10 11:05:14,939 - INFO - [Step=14500]	Loss=1.6569	242.2 examples/second
2022-01-10 11:07:26,408 - INFO - [Step=14750]	Loss=1.6672	243.4 examples/second
2022-01-10 11:09:37,289 - INFO - [Step=15000]	Loss=1.6730	244.5 examples/second
2022-01-10 11:10:00,753 - INFO - Test Loss=2.8262, Test top-1 acc=0.5557
2022-01-10 11:10:00,753 - INFO - Group Accuracy:

2022-01-10 11:10:00,753 - INFO - [0.9655422  0.97445786 0.9621687  0.9819277  0.9706024  0.9809638
 0.9619277  0.966747   0.98024094 0.9653012  0.97493976 0.9708434
 0.95325303 0.95759034 0.95349395 0.96843374 0.9886747 ]
2022-01-10 11:10:00,754 - INFO - Epoch time: 448.90281319618225
2022-01-10 11:10:00,754 - INFO - 
Epoch: 18
2022-01-10 11:10:00,754 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:11:58,037 - INFO - [Step=15250]	Loss=1.6179	227.4 examples/second
2022-01-10 11:14:09,939 - INFO - [Step=15500]	Loss=1.6259	242.6 examples/second
2022-01-10 11:16:20,992 - INFO - [Step=15750]	Loss=1.6205	244.2 examples/second
2022-01-10 11:17:28,926 - INFO - Test Loss=1.7217, Test top-1 acc=0.5631
2022-01-10 11:17:28,927 - INFO - Group Accuracy:

2022-01-10 11:17:28,927 - INFO - [0.96168673 0.9787952  0.9655422  0.9819277  0.9693976  0.9860241
 0.9633735  0.9631325  0.98240966 0.9706024  0.96506023 0.9660241
 0.95662653 0.9631325  0.9619277  0.9628916  0.9879518 ]
2022-01-10 11:17:28,928 - INFO - Epoch time: 448.1738295555115
2022-01-10 11:17:28,928 - INFO - 
Epoch: 19
2022-01-10 11:17:28,928 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:18:41,364 - INFO - [Step=16000]	Loss=1.5864	228.0 examples/second
2022-01-10 11:20:52,414 - INFO - [Step=16250]	Loss=1.6058	244.2 examples/second
2022-01-10 11:23:03,581 - INFO - [Step=16500]	Loss=1.5928	244.0 examples/second
2022-01-10 11:24:56,078 - INFO - Test Loss=1.6027, Test top-1 acc=0.5940
2022-01-10 11:24:56,078 - INFO - Group Accuracy:

2022-01-10 11:24:56,078 - INFO - [0.96771085 0.97614455 0.9660241  0.9821687  0.9691566  0.9886747
 0.96024096 0.96771085 0.9814458  0.96506023 0.97638553 0.9708434
 0.9587952  0.96361446 0.9592771  0.9742169  0.98578316]
2022-01-10 11:24:56,079 - INFO - Saving...
2022-01-10 11:24:56,395 - INFO - Epoch time: 447.4672911167145
2022-01-10 11:24:56,395 - INFO - 
Epoch: 20
2022-01-10 11:24:56,396 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:25:24,283 - INFO - [Step=16750]	Loss=1.5852	227.4 examples/second
2022-01-10 11:27:33,655 - INFO - [Step=17000]	Loss=1.5473	247.4 examples/second
2022-01-10 11:29:44,821 - INFO - [Step=17250]	Loss=1.5494	244.0 examples/second
2022-01-10 11:31:55,324 - INFO - [Step=17500]	Loss=1.5720	245.2 examples/second
2022-01-10 11:32:21,249 - INFO - Test Loss=1.5993, Test top-1 acc=0.5899
2022-01-10 11:32:21,249 - INFO - Group Accuracy:

2022-01-10 11:32:21,249 - INFO - [0.9672289  0.9812048  0.96819276 0.98361444 0.9686747  0.9886747
 0.96506023 0.96819276 0.97614455 0.9696385  0.97493976 0.9701205
 0.96048194 0.96168673 0.96072286 0.97566265 0.9879518 ]
2022-01-10 11:32:21,250 - INFO - Epoch time: 444.8548982143402
2022-01-10 11:32:21,250 - INFO - 
Epoch: 21
2022-01-10 11:32:21,251 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:34:14,581 - INFO - [Step=17750]	Loss=1.5149	229.8 examples/second
2022-01-10 11:36:24,540 - INFO - [Step=18000]	Loss=1.5302	246.2 examples/second
2022-01-10 11:38:34,975 - INFO - [Step=18250]	Loss=1.5438	245.3 examples/second
2022-01-10 11:39:46,070 - INFO - Test Loss=1.6335, Test top-1 acc=0.5870
2022-01-10 11:39:46,070 - INFO - Group Accuracy:

2022-01-10 11:39:46,070 - INFO - [0.9674699  0.9775904  0.9701205  0.97927713 0.96891564 0.98771083
 0.96481925 0.9655422  0.98240966 0.9628916  0.9768675  0.9686747
 0.9580723  0.96385545 0.9544578  0.97180724 0.9886747 ]
2022-01-10 11:39:46,071 - INFO - Epoch time: 444.8203046321869
2022-01-10 11:39:46,071 - INFO - 
Epoch: 22
2022-01-10 11:39:46,071 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:40:55,469 - INFO - [Step=18500]	Loss=1.5109	227.8 examples/second
2022-01-10 11:43:05,462 - INFO - [Step=18750]	Loss=1.4918	246.2 examples/second
2022-01-10 11:45:16,259 - INFO - [Step=19000]	Loss=1.5010	244.7 examples/second
2022-01-10 11:47:11,453 - INFO - Test Loss=1.8394, Test top-1 acc=0.5817
2022-01-10 11:47:11,454 - INFO - Group Accuracy:

2022-01-10 11:47:11,454 - INFO - [0.95759034 0.966747   0.9614458  0.9826506  0.9686747  0.9860241
 0.96024096 0.96506023 0.9838554  0.9626506  0.97180724 0.9706024
 0.9614458  0.96481925 0.96433735 0.973494   0.9891566 ]
2022-01-10 11:47:11,455 - INFO - Epoch time: 445.3843665122986
2022-01-10 11:47:11,455 - INFO - 
Epoch: 23
2022-01-10 11:47:11,455 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:47:36,837 - INFO - [Step=19250]	Loss=1.5030	227.6 examples/second
2022-01-10 11:49:47,832 - INFO - [Step=19500]	Loss=1.4790	244.3 examples/second
2022-01-10 11:51:59,271 - INFO - [Step=19750]	Loss=1.4826	243.5 examples/second
2022-01-10 11:54:10,322 - INFO - [Step=20000]	Loss=1.4874	244.2 examples/second
2022-01-10 11:54:39,020 - INFO - Test Loss=1.5533, Test top-1 acc=0.6113
2022-01-10 11:54:39,020 - INFO - Group Accuracy:

2022-01-10 11:54:39,020 - INFO - [0.9633735  0.9787952  0.9662651  0.98       0.97228914 0.9891566
 0.96409637 0.97180724 0.98578316 0.9674699  0.97493976 0.9727711
 0.9614458  0.966506   0.9619277  0.97638553 0.9884337 ]
2022-01-10 11:54:39,021 - INFO - Saving...
2022-01-10 11:54:39,306 - INFO - Epoch time: 447.85052013397217
2022-01-10 11:54:39,306 - INFO - 
Epoch: 24
2022-01-10 11:54:39,306 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:56:31,332 - INFO - [Step=20250]	Loss=1.4549	226.9 examples/second
2022-01-10 11:58:42,178 - INFO - [Step=20500]	Loss=1.4681	244.6 examples/second
2022-01-10 12:00:53,134 - INFO - [Step=20750]	Loss=1.4690	244.4 examples/second
2022-01-10 12:02:06,102 - INFO - Test Loss=1.4043, Test top-1 acc=0.6349
2022-01-10 12:02:06,102 - INFO - Group Accuracy:

2022-01-10 12:02:06,102 - INFO - [0.97204816 0.9819277  0.97445786 0.9848193  0.9742169  0.9879518
 0.9621687  0.9725301  0.98433733 0.9703615  0.9826506  0.9773494
 0.96481925 0.966506   0.9612048  0.97204816 0.98771083]
2022-01-10 12:02:06,103 - INFO - Saving...
2022-01-10 12:02:06,402 - INFO - Epoch time: 447.0960485935211
2022-01-10 12:02:06,403 - INFO - 
Epoch: 25
2022-01-10 12:02:06,403 - INFO - 
Learning Rate: 0.1000
2022-01-10 12:03:14,330 - INFO - [Step=21000]	Loss=1.4525	226.6 examples/second
2022-01-10 12:05:26,580 - INFO - [Step=21250]	Loss=1.4439	242.0 examples/second
2022-01-10 12:07:38,816 - INFO - [Step=21500]	Loss=1.4544	242.0 examples/second
2022-01-10 12:09:38,330 - INFO - Test Loss=1.5313, Test top-1 acc=0.6133
2022-01-10 12:09:38,331 - INFO - Group Accuracy:

2022-01-10 12:09:38,331 - INFO - [0.9672289  0.97638553 0.9713253  0.9860241  0.97108436 0.9860241
 0.9653012  0.97566265 0.9826506  0.9698795  0.9814458  0.97228914
 0.9621687  0.9573494  0.96409637 0.973253   0.9889157 ]
2022-01-10 12:09:38,332 - INFO - Epoch time: 451.92986273765564
2022-01-10 12:09:38,332 - INFO - 
Epoch: 26
2022-01-10 12:09:38,333 - INFO - 
Learning Rate: 0.1000
2022-01-10 12:10:01,133 - INFO - [Step=21750]	Loss=1.4493	224.9 examples/second
2022-01-10 12:12:13,385 - INFO - [Step=22000]	Loss=1.4107	242.0 examples/second
2022-01-10 12:14:25,713 - INFO - [Step=22250]	Loss=1.4475	241.8 examples/second
2022-01-10 12:16:38,129 - INFO - [Step=22500]	Loss=1.4368	241.7 examples/second
2022-01-10 12:17:09,691 - INFO - Test Loss=1.4393, Test top-1 acc=0.6359
2022-01-10 12:17:09,691 - INFO - Group Accuracy:

2022-01-10 12:17:09,691 - INFO - [0.9706024  0.97831327 0.9746988  0.98578316 0.96771085 0.98674697
 0.9653012  0.97566265 0.98361444 0.966747   0.97831327 0.97445786
 0.9587952  0.9655422  0.966506   0.97590363 0.9898795 ]
2022-01-10 12:17:09,692 - INFO - Saving...
2022-01-10 12:17:10,060 - INFO - Epoch time: 451.72719836235046
2022-01-10 12:17:10,060 - INFO - 
Epoch: 27
2022-01-10 12:17:10,060 - INFO - 
Learning Rate: 0.1000
2022-01-10 12:19:00,117 - INFO - [Step=22750]	Loss=1.3917	225.4 examples/second
2022-01-10 12:21:13,016 - INFO - [Step=23000]	Loss=1.4217	240.8 examples/second
2022-01-10 12:23:25,310 - INFO - [Step=23250]	Loss=1.4131	241.9 examples/second
2022-01-10 12:24:41,555 - INFO - Test Loss=1.4002, Test top-1 acc=0.6366
2022-01-10 12:24:41,555 - INFO - Group Accuracy:

2022-01-10 12:24:41,556 - INFO - [0.9703615  0.98240966 0.97518075 0.9840964  0.9698795  0.9891566
 0.9660241  0.9746988  0.98313254 0.9657831  0.97951806 0.97228914
 0.9631325  0.96795183 0.96891564 0.9768675  0.99108434]
2022-01-10 12:24:41,556 - INFO - Saving...
2022-01-10 12:24:41,829 - INFO - Epoch time: 451.7685294151306
2022-01-10 12:24:41,829 - INFO - 
Epoch: 28
2022-01-10 12:24:41,829 - INFO - 
Learning Rate: 0.1000
2022-01-10 12:25:46,659 - INFO - [Step=23500]	Loss=1.4041	226.4 examples/second
2022-01-10 12:27:57,410 - INFO - [Step=23750]	Loss=1.3892	244.7 examples/second
2022-01-10 12:30:09,064 - INFO - [Step=24000]	Loss=1.3809	243.1 examples/second
2022-01-10 12:32:09,508 - INFO - Test Loss=1.5676, Test top-1 acc=0.6065
2022-01-10 12:32:09,509 - INFO - Group Accuracy:

2022-01-10 12:32:09,509 - INFO - [0.96457833 0.9812048  0.9713253  0.9816868  0.96433735 0.98650604
 0.9708434  0.973253   0.9819277  0.9696385  0.97590363 0.97156626
 0.96771085 0.96506023 0.9614458  0.973253   0.98963857]
2022-01-10 12:32:09,510 - INFO - Epoch time: 447.6808383464813
2022-01-10 12:32:09,510 - INFO - 
Epoch: 29
2022-01-10 12:32:09,510 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:32:29,453 - INFO - [Step=24250]	Loss=1.3898	227.9 examples/second
2022-01-10 12:34:41,477 - INFO - [Step=24500]	Loss=1.0734	242.4 examples/second
2022-01-10 12:36:53,266 - INFO - [Step=24750]	Loss=1.0200	242.8 examples/second
2022-01-10 12:39:04,919 - INFO - [Step=25000]	Loss=1.0015	243.1 examples/second
2022-01-10 12:39:38,674 - INFO - Test Loss=0.9250, Test top-1 acc=0.7448
2022-01-10 12:39:38,675 - INFO - Group Accuracy:

2022-01-10 12:39:38,675 - INFO - [0.9775904  0.99084336 0.98240966 0.99108434 0.9804819  0.9930121
 0.9780723  0.9807229  0.9884337  0.97638553 0.9886747  0.9809638
 0.9739759  0.9775904  0.9746988  0.9855422  0.99421686]
2022-01-10 12:39:38,675 - INFO - Saving...
2022-01-10 12:39:39,033 - INFO - Epoch time: 449.5237555503845
2022-01-10 12:39:39,034 - INFO - 
Epoch: 30
2022-01-10 12:39:39,034 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:41:24,619 - INFO - [Step=25250]	Loss=0.9621	229.1 examples/second
2022-01-10 12:43:33,965 - INFO - [Step=25500]	Loss=0.9583	247.4 examples/second
2022-01-10 12:45:43,797 - INFO - [Step=25750]	Loss=0.9359	246.5 examples/second
2022-01-10 12:47:01,910 - INFO - Test Loss=0.8999, Test top-1 acc=0.7472
2022-01-10 12:47:01,910 - INFO - Group Accuracy:

2022-01-10 12:47:01,910 - INFO - [0.9771084  0.99036145 0.9807229  0.9918072  0.98       0.99373496
 0.97927713 0.98240966 0.9891566  0.97566265 0.9884337  0.9833735
 0.973253   0.9780723  0.97590363 0.98626506 0.9946988 ]
2022-01-10 12:47:01,911 - INFO - Saving...
2022-01-10 12:47:02,193 - INFO - Epoch time: 443.15945315361023
2022-01-10 12:47:02,194 - INFO - 
Epoch: 31
2022-01-10 12:47:02,194 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:48:03,475 - INFO - [Step=26000]	Loss=0.9229	229.1 examples/second
2022-01-10 12:50:12,504 - INFO - [Step=26250]	Loss=0.9043	248.0 examples/second
2022-01-10 12:52:21,068 - INFO - [Step=26500]	Loss=0.9166	248.9 examples/second
2022-01-10 12:54:21,571 - INFO - Test Loss=0.8737, Test top-1 acc=0.7530
2022-01-10 12:54:21,571 - INFO - Group Accuracy:

2022-01-10 12:54:21,582 - INFO - [0.97951806 0.9898795  0.9809638  0.9918072  0.98024094 0.9946988
 0.97975904 0.9819277  0.9893976  0.9768675  0.9879518  0.9826506
 0.97590363 0.97903615 0.9766265  0.98578316 0.99373496]
2022-01-10 12:54:21,583 - INFO - Saving...
2022-01-10 12:54:22,402 - INFO - Epoch time: 440.2086145877838
2022-01-10 12:54:22,402 - INFO - 
Epoch: 32
2022-01-10 12:54:22,402 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:54:39,726 - INFO - [Step=26750]	Loss=0.9126	230.8 examples/second
2022-01-10 12:56:50,909 - INFO - [Step=27000]	Loss=0.8953	243.9 examples/second
2022-01-10 12:59:01,128 - INFO - [Step=27250]	Loss=0.8815	245.7 examples/second
2022-01-10 13:01:11,164 - INFO - [Step=27500]	Loss=0.8650	246.1 examples/second
2022-01-10 13:01:47,170 - INFO - Test Loss=0.8709, Test top-1 acc=0.7557
2022-01-10 13:01:47,170 - INFO - Group Accuracy:

2022-01-10 13:01:47,170 - INFO - [0.97927713 0.9901205  0.98289156 0.9918072  0.9804819  0.9946988
 0.98       0.98240966 0.9893976  0.97518075 0.9889157  0.9845783
 0.97566265 0.9807229  0.97566265 0.9848193  0.99445784]
2022-01-10 13:01:47,171 - INFO - Saving...
2022-01-10 13:01:47,454 - INFO - Epoch time: 445.051513671875
2022-01-10 13:01:47,454 - INFO - 
Epoch: 33
2022-01-10 13:01:47,454 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:03:30,003 - INFO - [Step=27750]	Loss=0.8563	230.5 examples/second
2022-01-10 13:05:39,187 - INFO - [Step=28000]	Loss=0.8563	247.7 examples/second
2022-01-10 13:07:47,632 - INFO - [Step=28250]	Loss=0.8850	249.1 examples/second
2022-01-10 13:09:07,206 - INFO - Test Loss=0.8697, Test top-1 acc=0.7622
2022-01-10 13:09:07,207 - INFO - Group Accuracy:

2022-01-10 13:09:07,207 - INFO - [0.9785542  0.9901205  0.98289156 0.9922892  0.9819277  0.99445784
 0.9807229  0.9821687  0.9889157  0.9775904  0.9891566  0.9840964
 0.97614455 0.9809638  0.9766265  0.98626506 0.9954217 ]
2022-01-10 13:09:07,208 - INFO - Saving...
2022-01-10 13:09:07,661 - INFO - Epoch time: 440.2062337398529
2022-01-10 13:09:07,661 - INFO - 
Epoch: 34
2022-01-10 13:09:07,661 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:10:05,655 - INFO - [Step=28500]	Loss=0.8642	231.8 examples/second
2022-01-10 13:12:13,414 - INFO - [Step=28750]	Loss=0.8575	250.5 examples/second
2022-01-10 13:14:21,666 - INFO - [Step=29000]	Loss=0.8486	249.5 examples/second
2022-01-10 13:16:24,645 - INFO - Test Loss=0.8515, Test top-1 acc=0.7614
2022-01-10 13:16:24,646 - INFO - Group Accuracy:

2022-01-10 13:16:24,646 - INFO - [0.98024094 0.9918072  0.98361444 0.9913253  0.9807229  0.9939759
 0.9804819  0.9840964  0.99036145 0.97614455 0.9898795  0.98433733
 0.97518075 0.9821687  0.97493976 0.98722893 0.9951807 ]
2022-01-10 13:16:24,646 - INFO - Epoch time: 436.98550629615784
2022-01-10 13:16:24,646 - INFO - 
Epoch: 35
2022-01-10 13:16:24,646 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:16:39,273 - INFO - [Step=29250]	Loss=0.8458	232.5 examples/second
2022-01-10 13:18:47,156 - INFO - [Step=29500]	Loss=0.8229	250.2 examples/second
2022-01-10 13:20:55,040 - INFO - [Step=29750]	Loss=0.8183	250.2 examples/second
2022-01-10 13:23:03,106 - INFO - [Step=30000]	Loss=0.8335	249.9 examples/second
2022-01-10 13:23:41,255 - INFO - Test Loss=0.8506, Test top-1 acc=0.7639
2022-01-10 13:23:41,256 - INFO - Group Accuracy:

2022-01-10 13:23:41,256 - INFO - [0.97927713 0.9913253  0.9819277  0.9922892  0.9804819  0.99493974
 0.97975904 0.9838554  0.9898795  0.9773494  0.9891566  0.98240966
 0.97518075 0.98       0.9773494  0.98722893 0.99421686]
2022-01-10 13:23:41,257 - INFO - Saving...
2022-01-10 13:23:42,126 - INFO - Epoch time: 437.47913575172424
2022-01-10 13:23:42,126 - INFO - 
Epoch: 36
2022-01-10 13:23:42,126 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:25:21,414 - INFO - [Step=30250]	Loss=0.8289	231.4 examples/second
2022-01-10 13:27:29,427 - INFO - [Step=30500]	Loss=0.8246	250.0 examples/second
2022-01-10 13:29:37,762 - INFO - [Step=30750]	Loss=0.8265	249.3 examples/second
2022-01-10 13:30:59,277 - INFO - Test Loss=0.8428, Test top-1 acc=0.7636
2022-01-10 13:30:59,278 - INFO - Group Accuracy:

2022-01-10 13:30:59,278 - INFO - [0.98       0.99108434 0.98289156 0.9925301  0.9821687  0.9946988
 0.97975904 0.9840964  0.9893976  0.9771084  0.99108434 0.9840964
 0.97831327 0.9809638  0.9768675  0.98650604 0.99445784]
2022-01-10 13:30:59,279 - INFO - Epoch time: 437.1527154445648
2022-01-10 13:30:59,279 - INFO - 
Epoch: 37
2022-01-10 13:30:59,279 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:31:54,277 - INFO - [Step=31000]	Loss=0.8070	234.4 examples/second
2022-01-10 13:34:02,735 - INFO - [Step=31250]	Loss=0.7934	249.1 examples/second
2022-01-10 13:36:11,566 - INFO - [Step=31500]	Loss=0.8205	248.4 examples/second
2022-01-10 13:38:16,536 - INFO - Test Loss=0.8517, Test top-1 acc=0.7586
2022-01-10 13:38:16,536 - INFO - Group Accuracy:

2022-01-10 13:38:16,536 - INFO - [0.9785542  0.9901205  0.9814458  0.9927711  0.9821687  0.9954217
 0.9807229  0.98313254 0.9889157  0.97638553 0.9884337  0.9833735
 0.97542167 0.98024094 0.9766265  0.9881928  0.99493974]
2022-01-10 13:38:16,537 - INFO - Epoch time: 437.25867533683777
2022-01-10 13:38:16,537 - INFO - 
Epoch: 38
2022-01-10 13:38:16,537 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:38:28,587 - INFO - [Step=31750]	Loss=0.7957	233.5 examples/second
2022-01-10 13:40:36,407 - INFO - [Step=32000]	Loss=0.7974	250.4 examples/second
2022-01-10 13:42:44,796 - INFO - [Step=32250]	Loss=0.8013	249.2 examples/second
2022-01-10 13:44:52,352 - INFO - [Step=32500]	Loss=0.7891	250.9 examples/second
2022-01-10 13:45:32,961 - INFO - Test Loss=0.8597, Test top-1 acc=0.7617
2022-01-10 13:45:32,962 - INFO - Group Accuracy:

2022-01-10 13:45:32,962 - INFO - [0.9775904  0.9913253  0.9826506  0.9920482  0.9826506  0.9946988
 0.9804819  0.98240966 0.9898795  0.97493976 0.98698795 0.9833735
 0.97590363 0.9812048  0.97638553 0.98698795 0.993494  ]
2022-01-10 13:45:32,962 - INFO - Epoch time: 436.42485070228577
2022-01-10 13:45:32,962 - INFO - 
Epoch: 39
2022-01-10 13:45:32,962 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:47:09,279 - INFO - [Step=32750]	Loss=0.7930	233.7 examples/second
2022-01-10 13:49:17,631 - INFO - [Step=33000]	Loss=0.7861	249.3 examples/second
2022-01-10 13:51:25,227 - INFO - [Step=33250]	Loss=0.8002	250.8 examples/second
2022-01-10 13:52:49,703 - INFO - Test Loss=0.8377, Test top-1 acc=0.7653
2022-01-10 13:52:49,704 - INFO - Group Accuracy:

2022-01-10 13:52:49,704 - INFO - [0.98       0.9891566  0.98361444 0.9930121  0.98240966 0.9946988
 0.9809638  0.9826506  0.98963857 0.9775904  0.9901205  0.9850602
 0.97590363 0.9804819  0.97638553 0.98746985 0.9946988 ]
2022-01-10 13:52:49,705 - INFO - Saving...
2022-01-10 13:52:50,261 - INFO - Epoch time: 437.2987484931946
2022-01-10 13:52:50,261 - INFO - 
Epoch: 40
2022-01-10 13:52:50,262 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:53:42,963 - INFO - [Step=33500]	Loss=0.7755	232.3 examples/second
2022-01-10 13:55:51,278 - INFO - [Step=33750]	Loss=0.7801	249.4 examples/second
2022-01-10 13:57:59,323 - INFO - [Step=34000]	Loss=0.7752	249.9 examples/second
2022-01-10 14:00:07,084 - INFO - Test Loss=0.8726, Test top-1 acc=0.7684
2022-01-10 14:00:07,085 - INFO - Group Accuracy:

2022-01-10 14:00:07,085 - INFO - [0.98024094 0.99036145 0.9850602  0.9922892  0.9819277  0.9939759
 0.98       0.9838554  0.9881928  0.9778313  0.98963857 0.9845783
 0.97566265 0.9812048  0.97493976 0.9860241  0.99445784]
2022-01-10 14:00:07,085 - INFO - Saving...
2022-01-10 14:00:07,325 - INFO - Epoch time: 437.0635476112366
2022-01-10 14:00:07,325 - INFO - 
Epoch: 41
2022-01-10 14:00:07,325 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:00:16,648 - INFO - [Step=34250]	Loss=0.7774	233.0 examples/second
2022-01-10 14:02:24,550 - INFO - [Step=34500]	Loss=0.7699	250.2 examples/second
2022-01-10 14:04:32,123 - INFO - [Step=34750]	Loss=0.7685	250.8 examples/second
2022-01-10 14:06:40,313 - INFO - [Step=35000]	Loss=0.7652	249.6 examples/second
2022-01-10 14:07:24,097 - INFO - Test Loss=0.8428, Test top-1 acc=0.7706
2022-01-10 14:07:24,098 - INFO - Group Accuracy:

2022-01-10 14:07:24,098 - INFO - [0.97951806 0.99084336 0.9833735  0.9922892  0.9833735  0.9946988
 0.9807229  0.98361444 0.99036145 0.9771084  0.9893976  0.9838554
 0.9771084  0.98       0.9771084  0.9879518  0.9946988 ]
2022-01-10 14:07:24,098 - INFO - Saving...
2022-01-10 14:07:24,592 - INFO - Epoch time: 437.26692748069763
2022-01-10 14:07:24,593 - INFO - 
Epoch: 42
2022-01-10 14:07:24,593 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:08:58,057 - INFO - [Step=35250]	Loss=0.7578	232.3 examples/second
2022-01-10 14:11:05,189 - INFO - [Step=35500]	Loss=0.7606	251.7 examples/second
2022-01-10 14:13:13,348 - INFO - [Step=35750]	Loss=0.7610	249.7 examples/second
2022-01-10 14:14:40,559 - INFO - Test Loss=0.8426, Test top-1 acc=0.7745
2022-01-10 14:14:40,559 - INFO - Group Accuracy:

2022-01-10 14:14:40,559 - INFO - [0.98024094 0.99108434 0.98361444 0.9930121  0.98313254 0.99373496
 0.9807229  0.9840964  0.9889157  0.97903615 0.9891566  0.9855422
 0.9768675  0.9812048  0.97638553 0.9884337  0.9954217 ]
2022-01-10 14:14:40,561 - INFO - Saving...
2022-01-10 14:14:40,861 - INFO - Epoch time: 436.2688820362091
2022-01-10 14:14:40,862 - INFO - 
Epoch: 43
2022-01-10 14:14:40,862 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:15:31,061 - INFO - [Step=36000]	Loss=0.7548	232.4 examples/second
2022-01-10 14:17:38,461 - INFO - [Step=36250]	Loss=0.7439	251.2 examples/second
2022-01-10 14:19:46,452 - INFO - [Step=36500]	Loss=0.7424	250.0 examples/second
2022-01-10 14:21:56,244 - INFO - Test Loss=0.8643, Test top-1 acc=0.7675
2022-01-10 14:21:56,245 - INFO - Group Accuracy:

2022-01-10 14:21:56,245 - INFO - [0.97951806 0.99060243 0.9833735  0.9920482  0.9819277  0.99373496
 0.97975904 0.9812048  0.9898795  0.9775904  0.9913253  0.98313254
 0.9773494  0.98024094 0.97518075 0.98771083 0.99421686]
2022-01-10 14:21:56,246 - INFO - Epoch time: 435.38401055336
2022-01-10 14:21:56,246 - INFO - 
Epoch: 44
2022-01-10 14:21:56,246 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:22:03,371 - INFO - [Step=36750]	Loss=0.7511	233.7 examples/second
2022-01-10 14:24:10,831 - INFO - [Step=37000]	Loss=0.7403	251.1 examples/second
2022-01-10 14:26:18,476 - INFO - [Step=37250]	Loss=0.7305	250.7 examples/second
2022-01-10 14:28:26,382 - INFO - [Step=37500]	Loss=0.7571	250.2 examples/second
2022-01-10 14:29:12,093 - INFO - Test Loss=0.8257, Test top-1 acc=0.7757
2022-01-10 14:29:12,093 - INFO - Group Accuracy:

2022-01-10 14:29:12,093 - INFO - [0.9804819  0.99156624 0.98433733 0.993253   0.98240966 0.99373496
 0.97951806 0.98361444 0.99084336 0.9773494  0.9881928  0.9840964
 0.9771084  0.9807229  0.97638553 0.9886747  0.9954217 ]
2022-01-10 14:29:12,094 - INFO - Saving...
2022-01-10 14:29:12,360 - INFO - Epoch time: 436.1145112514496
2022-01-10 14:29:12,361 - INFO - 
Epoch: 45
2022-01-10 14:29:12,361 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:30:43,366 - INFO - [Step=37750]	Loss=0.7374	233.6 examples/second
2022-01-10 14:32:51,566 - INFO - [Step=38000]	Loss=0.7331	249.6 examples/second
2022-01-10 14:34:59,762 - INFO - [Step=38250]	Loss=0.7369	249.6 examples/second
2022-01-10 14:36:28,986 - INFO - Test Loss=0.8319, Test top-1 acc=0.7733
2022-01-10 14:36:28,987 - INFO - Group Accuracy:

2022-01-10 14:36:28,987 - INFO - [0.97927713 0.99156624 0.9845783  0.9925301  0.9821687  0.99421686
 0.9809638  0.9826506  0.9898795  0.9768675  0.9901205  0.9850602
 0.9775904  0.9809638  0.9778313  0.98771083 0.9951807 ]
2022-01-10 14:36:28,988 - INFO - Epoch time: 436.6271514892578
2022-01-10 14:36:28,988 - INFO - 
Epoch: 46
2022-01-10 14:36:28,988 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:37:16,555 - INFO - [Step=38500]	Loss=0.7305	233.9 examples/second
2022-01-10 14:39:24,662 - INFO - [Step=38750]	Loss=0.7139	249.8 examples/second
2022-01-10 14:41:32,496 - INFO - [Step=39000]	Loss=0.7438	250.3 examples/second
2022-01-10 14:43:45,273 - INFO - Test Loss=0.8324, Test top-1 acc=0.7745
2022-01-10 14:43:45,273 - INFO - Group Accuracy:

2022-01-10 14:43:45,273 - INFO - [0.9778313  0.99108434 0.9850602  0.9927711  0.9821687  0.99421686
 0.9819277  0.9826506  0.9891566  0.9775904  0.9879518  0.9855422
 0.9766265  0.9814458  0.9768675  0.9886747  0.9951807 ]
2022-01-10 14:43:45,274 - INFO - Epoch time: 436.28647017478943
2022-01-10 14:43:45,274 - INFO - 
Epoch: 47
2022-01-10 14:43:45,274 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:43:49,545 - INFO - [Step=39250]	Loss=0.7506	233.5 examples/second
2022-01-10 14:45:57,534 - INFO - [Step=39500]	Loss=0.6950	250.0 examples/second
2022-01-10 14:48:05,394 - INFO - [Step=39750]	Loss=0.7270	250.3 examples/second
2022-01-10 14:50:13,479 - INFO - [Step=40000]	Loss=0.7293	249.8 examples/second
2022-01-10 14:51:01,741 - INFO - Test Loss=0.8740, Test top-1 acc=0.7651
2022-01-10 14:51:01,742 - INFO - Group Accuracy:

2022-01-10 14:51:01,742 - INFO - [0.9787952  0.99036145 0.9826506  0.9913253  0.9826506  0.993494
 0.9812048  0.9816868  0.9913253  0.9775904  0.9881928  0.9833735
 0.97638553 0.9780723  0.97638553 0.98746985 0.99421686]
2022-01-10 14:51:01,742 - INFO - Epoch time: 436.46811866760254
2022-01-10 14:51:01,743 - INFO - 
Epoch: 48
2022-01-10 14:51:01,743 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:52:30,528 - INFO - [Step=40250]	Loss=0.7143	233.5 examples/second
2022-01-10 14:54:38,476 - INFO - [Step=40500]	Loss=0.7208	250.1 examples/second
2022-01-10 14:56:46,161 - INFO - [Step=40750]	Loss=0.7178	250.6 examples/second
2022-01-10 14:58:18,423 - INFO - Test Loss=0.8268, Test top-1 acc=0.7701
2022-01-10 14:58:18,424 - INFO - Group Accuracy:

2022-01-10 14:58:18,424 - INFO - [0.97975904 0.9901205  0.98313254 0.9925301  0.98289156 0.9939759
 0.9816868  0.9833735  0.9886747  0.9785542  0.9925301  0.98578316
 0.97493976 0.9809638  0.97566265 0.9886747  0.9959036 ]
2022-01-10 14:58:18,425 - INFO - Epoch time: 436.682505607605
2022-01-10 14:58:18,425 - INFO - 
Epoch: 49
2022-01-10 14:58:18,425 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:59:03,699 - INFO - [Step=41000]	Loss=0.7242	232.7 examples/second
2022-01-10 15:01:12,744 - INFO - [Step=41250]	Loss=0.6948	248.0 examples/second
2022-01-10 15:03:21,224 - INFO - [Step=41500]	Loss=0.7042	249.1 examples/second
2022-01-10 15:05:29,706 - INFO - [Step=41750]	Loss=0.7292	249.1 examples/second
2022-01-10 15:05:37,392 - INFO - Test Loss=0.8646, Test top-1 acc=0.7761
2022-01-10 15:05:37,393 - INFO - Group Accuracy:

2022-01-10 15:05:37,393 - INFO - [0.97927713 0.99108434 0.9833735  0.9925301  0.9814458  0.99373496
 0.9804819  0.9814458  0.9889157  0.9768675  0.9922892  0.9850602
 0.9773494  0.9826506  0.97638553 0.9891566  0.9956626 ]
2022-01-10 15:05:37,394 - INFO - Saving...
2022-01-10 15:05:37,711 - INFO - Epoch time: 439.2854721546173
2022-01-10 15:05:37,711 - INFO - 
Epoch: 50
2022-01-10 15:05:37,711 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:07:47,079 - INFO - [Step=42000]	Loss=0.6952	232.9 examples/second
2022-01-10 15:09:54,725 - INFO - [Step=42250]	Loss=0.6986	250.7 examples/second
2022-01-10 15:12:02,527 - INFO - [Step=42500]	Loss=0.7095	250.4 examples/second
2022-01-10 15:12:53,494 - INFO - Test Loss=0.8537, Test top-1 acc=0.7733
2022-01-10 15:12:53,494 - INFO - Group Accuracy:

2022-01-10 15:12:53,494 - INFO - [0.97831327 0.9913253  0.9848193  0.99156624 0.9821687  0.9946988
 0.9816868  0.9833735  0.9884337  0.9773494  0.9893976  0.98361444
 0.97518075 0.9807229  0.97638553 0.9886747  0.9946988 ]
2022-01-10 15:12:53,495 - INFO - Epoch time: 435.7843544483185
2022-01-10 15:12:53,495 - INFO - 
Epoch: 51
2022-01-10 15:12:53,495 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:14:19,614 - INFO - [Step=42750]	Loss=0.6931	233.4 examples/second
2022-01-10 15:16:26,995 - INFO - [Step=43000]	Loss=0.6907	251.2 examples/second
2022-01-10 15:18:34,978 - INFO - [Step=43250]	Loss=0.7178	250.0 examples/second
2022-01-10 15:20:10,146 - INFO - Test Loss=0.8528, Test top-1 acc=0.7687
2022-01-10 15:20:10,147 - INFO - Group Accuracy:

2022-01-10 15:20:10,147 - INFO - [0.9775904  0.99156624 0.9814458  0.9927711  0.9804819  0.9939759
 0.9804819  0.98024094 0.9889157  0.9773494  0.9918072  0.9848193
 0.9766265  0.9807229  0.9773494  0.9893976  0.99493974]
2022-01-10 15:20:10,148 - INFO - Epoch time: 436.6527347564697
2022-01-10 15:20:10,148 - INFO - 
Epoch: 52
2022-01-10 15:20:10,148 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:20:52,738 - INFO - [Step=43500]	Loss=0.7127	232.3 examples/second
2022-01-10 15:23:00,191 - INFO - [Step=43750]	Loss=0.6825	251.1 examples/second
2022-01-10 15:25:08,135 - INFO - [Step=44000]	Loss=0.6944	250.1 examples/second
2022-01-10 15:27:16,829 - INFO - [Step=44250]	Loss=0.6976	248.7 examples/second
2022-01-10 15:27:27,125 - INFO - Test Loss=0.8639, Test top-1 acc=0.7682
2022-01-10 15:27:27,126 - INFO - Group Accuracy:

2022-01-10 15:27:27,126 - INFO - [0.97951806 0.99084336 0.9826506  0.993494   0.98361444 0.9939759
 0.97975904 0.9826506  0.9893976  0.9773494  0.99036145 0.9840964
 0.97445786 0.9809638  0.97927713 0.98771083 0.99493974]
2022-01-10 15:27:27,126 - INFO - Epoch time: 436.97826623916626
2022-01-10 15:27:27,127 - INFO - 
Epoch: 53
2022-01-10 15:27:27,127 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:29:33,500 - INFO - [Step=44500]	Loss=0.6782	234.1 examples/second
2022-01-10 15:31:41,313 - INFO - [Step=44750]	Loss=0.6986	250.4 examples/second
2022-01-10 15:33:49,308 - INFO - [Step=45000]	Loss=0.7028	250.0 examples/second
2022-01-10 15:34:42,914 - INFO - Test Loss=0.8590, Test top-1 acc=0.7759
2022-01-10 15:34:42,914 - INFO - Group Accuracy:

2022-01-10 15:34:42,914 - INFO - [0.97903615 0.98963857 0.9840964  0.9939759  0.98240966 0.99445784
 0.98024094 0.9812048  0.9898795  0.97638553 0.9893976  0.9850602
 0.9771084  0.9816868  0.9771084  0.98722893 0.99445784]
2022-01-10 15:34:42,915 - INFO - Epoch time: 435.78859758377075
2022-01-10 15:34:42,915 - INFO - 
Epoch: 54
2022-01-10 15:34:42,915 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:36:06,828 - INFO - [Step=45250]	Loss=0.6885	232.7 examples/second
2022-01-10 15:38:14,709 - INFO - [Step=45500]	Loss=0.6637	250.2 examples/second
2022-01-10 15:40:22,658 - INFO - [Step=45750]	Loss=0.6830	250.1 examples/second
2022-01-10 15:41:59,959 - INFO - Test Loss=0.8575, Test top-1 acc=0.7737
2022-01-10 15:41:59,960 - INFO - Group Accuracy:

2022-01-10 15:41:59,960 - INFO - [0.9816868  0.98963857 0.9838554  0.9927711  0.98024094 0.99373496
 0.9778313  0.9814458  0.9884337  0.97614455 0.99156624 0.9840964
 0.97518075 0.9826506  0.97590363 0.9881928  0.99493974]
2022-01-10 15:41:59,961 - INFO - Epoch time: 437.0455389022827
2022-01-10 15:41:59,961 - INFO - 
Epoch: 55
2022-01-10 15:41:59,961 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:42:39,879 - INFO - [Step=46000]	Loss=0.7033	233.2 examples/second
2022-01-10 15:44:47,787 - INFO - [Step=46250]	Loss=0.6673	250.2 examples/second
2022-01-10 15:46:55,709 - INFO - [Step=46500]	Loss=0.6731	250.2 examples/second
2022-01-10 15:49:03,352 - INFO - [Step=46750]	Loss=0.6897	250.7 examples/second
2022-01-10 15:49:16,070 - INFO - Test Loss=0.8800, Test top-1 acc=0.7689
2022-01-10 15:49:16,071 - INFO - Group Accuracy:

2022-01-10 15:49:16,071 - INFO - [0.9838554  0.9884337  0.9833735  0.9927711  0.9812048  0.993253
 0.9804819  0.9816868  0.9881928  0.97566265 0.99108434 0.9821687
 0.9768675  0.9812048  0.97566265 0.98722893 0.9951807 ]
2022-01-10 15:49:16,072 - INFO - Epoch time: 436.1106855869293
2022-01-10 15:49:16,072 - INFO - 
Epoch: 56
2022-01-10 15:49:16,072 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:51:22,327 - INFO - [Step=47000]	Loss=0.6587	230.3 examples/second
2022-01-10 15:53:30,180 - INFO - [Step=47250]	Loss=0.6684	250.3 examples/second
2022-01-10 15:55:37,691 - INFO - [Step=47500]	Loss=0.6698	251.0 examples/second
2022-01-10 15:56:33,938 - INFO - Test Loss=0.8805, Test top-1 acc=0.7723
2022-01-10 15:56:33,938 - INFO - Group Accuracy:

2022-01-10 15:56:33,938 - INFO - [0.98       0.9893976  0.9845783  0.9920482  0.9833735  0.9927711
 0.97975904 0.97927713 0.9893976  0.97590363 0.9886747  0.9850602
 0.9780723  0.98024094 0.97590363 0.98674697 0.99493974]
2022-01-10 15:56:33,939 - INFO - Epoch time: 437.86744809150696
2022-01-10 15:56:33,939 - INFO - 
Epoch: 57
2022-01-10 15:56:33,939 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:57:55,675 - INFO - [Step=47750]	Loss=0.6679	231.9 examples/second
2022-01-10 16:00:03,701 - INFO - [Step=48000]	Loss=0.6713	249.9 examples/second
2022-01-10 16:02:11,236 - INFO - [Step=48250]	Loss=0.6638	250.9 examples/second
2022-01-10 16:03:51,154 - INFO - Test Loss=0.8827, Test top-1 acc=0.7761
2022-01-10 16:03:51,155 - INFO - Group Accuracy:

2022-01-10 16:03:51,155 - INFO - [0.9809638  0.9901205  0.9853012  0.9930121  0.9816868  0.9922892
 0.9819277  0.9804819  0.9901205  0.9773494  0.99108434 0.9833735
 0.97566265 0.9807229  0.9785542  0.98746985 0.99493974]
2022-01-10 16:03:51,156 - INFO - Epoch time: 437.21663522720337
2022-01-10 16:03:51,156 - INFO - 
Epoch: 58
2022-01-10 16:03:51,156 - INFO - 
Learning Rate: 0.0100
2022-01-10 16:04:28,988 - INFO - [Step=48500]	Loss=0.6740	232.3 examples/second
2022-01-10 16:06:37,063 - INFO - [Step=48750]	Loss=0.6541	249.9 examples/second
2022-01-10 16:08:44,550 - INFO - [Step=49000]	Loss=0.6650	251.0 examples/second
2022-01-10 16:10:52,403 - INFO - [Step=49250]	Loss=0.6742	250.3 examples/second
2022-01-10 16:11:07,898 - INFO - Test Loss=0.8849, Test top-1 acc=0.7759
2022-01-10 16:11:07,899 - INFO - Group Accuracy:

2022-01-10 16:11:07,899 - INFO - [0.9785542  0.98963857 0.9840964  0.993253   0.98313254 0.9925301
 0.9833735  0.9809638  0.98963857 0.9775904  0.9901205  0.98313254
 0.9775904  0.9814458  0.9778313  0.9879518  0.9959036 ]
2022-01-10 16:11:07,899 - INFO - Epoch time: 436.74351596832275
2022-01-10 16:11:07,899 - INFO - 
Epoch: 59
2022-01-10 16:11:07,899 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:13:10,163 - INFO - [Step=49500]	Loss=0.6234	232.3 examples/second
2022-01-10 16:15:17,786 - INFO - [Step=49750]	Loss=0.5945	250.7 examples/second
2022-01-10 16:17:25,635 - INFO - [Step=50000]	Loss=0.5739	250.3 examples/second
2022-01-10 16:18:24,383 - INFO - Test Loss=0.8085, Test top-1 acc=0.7923
2022-01-10 16:18:24,383 - INFO - Group Accuracy:

2022-01-10 16:18:24,383 - INFO - [0.9819277  0.9913253  0.98674697 0.9939759  0.9850602  0.99445784
 0.98289156 0.9819277  0.9901205  0.9780723  0.99084336 0.9850602
 0.9775904  0.98240966 0.9787952  0.98746985 0.9956626 ]
2022-01-10 16:18:24,384 - INFO - Saving...
2022-01-10 16:18:24,804 - INFO - Epoch time: 436.9044086933136
2022-01-10 16:18:24,804 - INFO - 
Epoch: 60
2022-01-10 16:18:24,804 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:19:43,979 - INFO - [Step=50250]	Loss=0.5754	231.3 examples/second
2022-01-10 16:21:51,898 - INFO - [Step=50500]	Loss=0.5820	250.2 examples/second
2022-01-10 16:23:59,914 - INFO - [Step=50750]	Loss=0.5715	250.0 examples/second
2022-01-10 16:25:42,148 - INFO - Test Loss=0.8065, Test top-1 acc=0.7937
2022-01-10 16:25:42,149 - INFO - Group Accuracy:

2022-01-10 16:25:42,149 - INFO - [0.9821687  0.9918072  0.9860241  0.993253   0.9848193  0.99421686
 0.98289156 0.98289156 0.99036145 0.9785542  0.9920482  0.9850602
 0.9780723  0.98289156 0.97638553 0.98746985 0.9959036 ]
2022-01-10 16:25:42,150 - INFO - Saving...
2022-01-10 16:25:42,432 - INFO - Epoch time: 437.62749695777893
2022-01-10 16:25:42,432 - INFO - 
Epoch: 61
2022-01-10 16:25:42,432 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:26:17,222 - INFO - [Step=51000]	Loss=0.5687	233.1 examples/second
2022-01-10 16:28:25,435 - INFO - [Step=51250]	Loss=0.5543	249.6 examples/second
2022-01-10 16:30:33,000 - INFO - [Step=51500]	Loss=0.5604	250.9 examples/second
2022-01-10 16:32:41,142 - INFO - [Step=51750]	Loss=0.5627	249.7 examples/second
2022-01-10 16:32:58,673 - INFO - Test Loss=0.7979, Test top-1 acc=0.7945
2022-01-10 16:32:58,674 - INFO - Group Accuracy:

2022-01-10 16:32:58,674 - INFO - [0.98240966 0.99108434 0.98698795 0.99373496 0.9840964  0.99421686
 0.9826506  0.9814458  0.99036145 0.9785542  0.9913253  0.9853012
 0.9778313  0.9833735  0.9780723  0.9891566  0.9959036 ]
2022-01-10 16:32:58,675 - INFO - Saving...
2022-01-10 16:32:58,976 - INFO - Epoch time: 436.5444872379303
2022-01-10 16:32:58,977 - INFO - 
Epoch: 62
2022-01-10 16:32:58,977 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:34:58,601 - INFO - [Step=52000]	Loss=0.5681	232.8 examples/second
2022-01-10 16:37:07,871 - INFO - [Step=52250]	Loss=0.5560	247.5 examples/second
2022-01-10 16:39:15,911 - INFO - [Step=52500]	Loss=0.5508	249.9 examples/second
2022-01-10 16:40:16,817 - INFO - Test Loss=0.7913, Test top-1 acc=0.7920
2022-01-10 16:40:16,817 - INFO - Group Accuracy:

2022-01-10 16:40:16,817 - INFO - [0.9826506  0.99156624 0.9860241  0.99373496 0.9845783  0.99373496
 0.9826506  0.9821687  0.9898795  0.9780723  0.9920482  0.9845783
 0.9780723  0.9826506  0.9766265  0.9886747  0.9961446 ]
2022-01-10 16:40:16,818 - INFO - Epoch time: 437.8414578437805
2022-01-10 16:40:16,818 - INFO - 
Epoch: 63
2022-01-10 16:40:16,818 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:41:32,907 - INFO - [Step=52750]	Loss=0.5529	233.6 examples/second
2022-01-10 16:43:41,262 - INFO - [Step=53000]	Loss=0.5507	249.3 examples/second
2022-01-10 16:45:49,178 - INFO - [Step=53250]	Loss=0.5438	250.2 examples/second
2022-01-10 16:47:33,580 - INFO - Test Loss=0.8037, Test top-1 acc=0.7935
2022-01-10 16:47:33,580 - INFO - Group Accuracy:

2022-01-10 16:47:33,581 - INFO - [0.9819277  0.99156624 0.98578316 0.993494   0.9853012  0.99373496
 0.9833735  0.98313254 0.9898795  0.9775904  0.9922892  0.9848193
 0.9787952  0.9819277  0.9775904  0.9884337  0.9961446 ]
2022-01-10 16:47:33,581 - INFO - Epoch time: 436.76330518722534
2022-01-10 16:47:33,582 - INFO - 
Epoch: 64
2022-01-10 16:47:33,582 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:48:06,129 - INFO - [Step=53500]	Loss=0.5445	233.7 examples/second
2022-01-10 16:50:14,428 - INFO - [Step=53750]	Loss=0.5504	249.4 examples/second
2022-01-10 16:52:22,553 - INFO - [Step=54000]	Loss=0.5386	249.8 examples/second
2022-01-10 16:54:30,230 - INFO - [Step=54250]	Loss=0.5444	250.6 examples/second
2022-01-10 16:54:50,632 - INFO - Test Loss=0.8161, Test top-1 acc=0.7899
2022-01-10 16:54:50,632 - INFO - Group Accuracy:

2022-01-10 16:54:50,632 - INFO - [0.9821687  0.99084336 0.98626506 0.993494   0.9845783  0.993253
 0.98240966 0.98289156 0.9898795  0.9778313  0.9913253  0.9855422
 0.9785542  0.9821687  0.97831327 0.9889157  0.9954217 ]
2022-01-10 16:54:50,633 - INFO - Epoch time: 437.0518012046814
2022-01-10 16:54:50,633 - INFO - 
Epoch: 65
2022-01-10 16:54:50,633 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:56:47,887 - INFO - [Step=54500]	Loss=0.5363	232.5 examples/second
2022-01-10 16:58:56,149 - INFO - [Step=54750]	Loss=0.5343	249.5 examples/second
2022-01-10 17:01:03,814 - INFO - [Step=55000]	Loss=0.5470	250.7 examples/second
2022-01-10 17:02:07,409 - INFO - Test Loss=0.8000, Test top-1 acc=0.7913
2022-01-10 17:02:07,409 - INFO - Group Accuracy:

2022-01-10 17:02:07,409 - INFO - [0.9821687  0.9920482  0.98578316 0.9939759  0.9845783  0.99445784
 0.9838554  0.9821687  0.98963857 0.9775904  0.9922892  0.9840964
 0.97831327 0.9833735  0.97831327 0.9886747  0.9959036 ]
2022-01-10 17:02:07,410 - INFO - Epoch time: 436.7765247821808
2022-01-10 17:02:07,410 - INFO - 
Epoch: 66
2022-01-10 17:02:07,410 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:03:20,903 - INFO - [Step=55250]	Loss=0.5337	233.4 examples/second
2022-01-10 17:05:28,927 - INFO - [Step=55500]	Loss=0.5426	250.0 examples/second
2022-01-10 17:07:36,571 - INFO - [Step=55750]	Loss=0.5409	250.7 examples/second
2022-01-10 17:09:24,549 - INFO - Test Loss=0.8192, Test top-1 acc=0.7913
2022-01-10 17:09:24,549 - INFO - Group Accuracy:

2022-01-10 17:09:24,549 - INFO - [0.9821687  0.99060243 0.98722893 0.9930121  0.9850602  0.9930121
 0.9833735  0.9833735  0.9898795  0.9775904  0.9925301  0.9855422
 0.9780723  0.98313254 0.9768675  0.9889157  0.9956626 ]
2022-01-10 17:09:24,550 - INFO - Epoch time: 437.13993883132935
2022-01-10 17:09:24,550 - INFO - 
Epoch: 67
2022-01-10 17:09:24,550 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:09:54,484 - INFO - [Step=56000]	Loss=0.5355	232.0 examples/second
2022-01-10 17:12:02,462 - INFO - [Step=56250]	Loss=0.5252	250.0 examples/second
2022-01-10 17:14:10,354 - INFO - [Step=56500]	Loss=0.5410	250.2 examples/second
2022-01-10 17:16:18,592 - INFO - [Step=56750]	Loss=0.5306	249.5 examples/second
2022-01-10 17:16:41,542 - INFO - Test Loss=0.8003, Test top-1 acc=0.7966
2022-01-10 17:16:41,542 - INFO - Group Accuracy:

2022-01-10 17:16:41,542 - INFO - [0.98240966 0.9922892  0.9879518  0.993253   0.9840964  0.9939759
 0.98240966 0.98289156 0.98963857 0.9775904  0.9920482  0.9838554
 0.9785542  0.98313254 0.97903615 0.9886747  0.9956626 ]
2022-01-10 17:16:41,543 - INFO - Saving...
2022-01-10 17:16:41,832 - INFO - Epoch time: 437.28166699409485
2022-01-10 17:16:41,832 - INFO - 
Epoch: 68
2022-01-10 17:16:41,832 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:18:36,269 - INFO - [Step=57000]	Loss=0.5378	232.4 examples/second
2022-01-10 17:20:44,054 - INFO - [Step=57250]	Loss=0.5338	250.4 examples/second
2022-01-10 17:22:52,279 - INFO - [Step=57500]	Loss=0.5285	249.6 examples/second
2022-01-10 17:23:58,582 - INFO - Test Loss=0.8056, Test top-1 acc=0.7942
2022-01-10 17:23:58,582 - INFO - Group Accuracy:

2022-01-10 17:23:58,582 - INFO - [0.9826506  0.9920482  0.98746985 0.993494   0.9850602  0.9939759
 0.98361444 0.98313254 0.9893976  0.9778313  0.9913253  0.98626506
 0.9785542  0.98313254 0.9785542  0.9889157  0.9959036 ]
2022-01-10 17:23:58,583 - INFO - Epoch time: 436.75056648254395
2022-01-10 17:23:58,583 - INFO - 
Epoch: 69
2022-01-10 17:23:58,583 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:25:09,693 - INFO - [Step=57750]	Loss=0.5394	232.9 examples/second
2022-01-10 17:27:17,412 - INFO - [Step=58000]	Loss=0.5342	250.6 examples/second
2022-01-10 17:29:25,614 - INFO - [Step=58250]	Loss=0.5263	249.6 examples/second
2022-01-10 17:31:15,860 - INFO - Test Loss=0.7899, Test top-1 acc=0.7978
2022-01-10 17:31:15,861 - INFO - Group Accuracy:

2022-01-10 17:31:15,861 - INFO - [0.98289156 0.99156624 0.98650604 0.99421686 0.9855422  0.99421686
 0.98433733 0.98240966 0.9891566  0.97831327 0.9925301  0.9850602
 0.97927713 0.9826506  0.9780723  0.9886747  0.9959036 ]
2022-01-10 17:31:15,862 - INFO - Saving...
2022-01-10 17:31:16,121 - INFO - Epoch time: 437.53788232803345
2022-01-10 17:31:16,121 - INFO - 
Epoch: 70
2022-01-10 17:31:16,121 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:31:43,110 - INFO - [Step=58500]	Loss=0.5189	232.7 examples/second
2022-01-10 17:33:50,616 - INFO - [Step=58750]	Loss=0.5198	251.0 examples/second
2022-01-10 17:35:58,792 - INFO - [Step=59000]	Loss=0.5289	249.7 examples/second
2022-01-10 17:38:06,976 - INFO - [Step=59250]	Loss=0.5276	249.6 examples/second
2022-01-10 17:38:32,832 - INFO - Test Loss=0.8039, Test top-1 acc=0.7940
2022-01-10 17:38:32,833 - INFO - Group Accuracy:

2022-01-10 17:38:32,833 - INFO - [0.98240966 0.9920482  0.98626506 0.9939759  0.9848193  0.99421686
 0.9838554  0.9826506  0.9891566  0.9787952  0.9925301  0.9850602
 0.9780723  0.9838554  0.9785542  0.9889157  0.9956626 ]
2022-01-10 17:38:32,834 - INFO - Epoch time: 436.7129170894623
2022-01-10 17:38:32,834 - INFO - 
Epoch: 71
2022-01-10 17:38:32,834 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:40:24,553 - INFO - [Step=59500]	Loss=0.5256	232.6 examples/second
2022-01-10 17:42:32,606 - INFO - [Step=59750]	Loss=0.5199	249.9 examples/second
2022-01-10 17:44:40,808 - INFO - [Step=60000]	Loss=0.5190	249.6 examples/second
2022-01-10 17:45:49,522 - INFO - Test Loss=0.8006, Test top-1 acc=0.7942
2022-01-10 17:45:49,522 - INFO - Group Accuracy:

2022-01-10 17:45:49,522 - INFO - [0.98313254 0.99156624 0.98650604 0.9946988  0.9848193  0.99421686
 0.9826506  0.98289156 0.9886747  0.9780723  0.9918072  0.9848193
 0.97951806 0.98361444 0.9787952  0.9886747  0.9956626 ]
2022-01-10 17:45:49,523 - INFO - Epoch time: 436.689510345459
2022-01-10 17:45:49,523 - INFO - 
Epoch: 72
2022-01-10 17:45:49,523 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:46:57,852 - INFO - [Step=60250]	Loss=0.5256	233.5 examples/second
2022-01-10 17:49:05,869 - INFO - [Step=60500]	Loss=0.5272	250.0 examples/second
2022-01-10 17:51:14,152 - INFO - [Step=60750]	Loss=0.5208	249.4 examples/second
2022-01-10 17:53:06,015 - INFO - Test Loss=0.8550, Test top-1 acc=0.7942
2022-01-10 17:53:06,016 - INFO - Group Accuracy:

2022-01-10 17:53:06,016 - INFO - [0.9816868  0.9913253  0.98674697 0.99445784 0.98433733 0.993253
 0.98361444 0.98313254 0.9893976  0.97831327 0.9920482  0.9853012
 0.9780723  0.9838554  0.9773494  0.9893976  0.9954217 ]
2022-01-10 17:53:06,017 - INFO - Epoch time: 436.493355512619
2022-01-10 17:53:06,017 - INFO - 
Epoch: 73
2022-01-10 17:53:06,017 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:53:30,958 - INFO - [Step=61000]	Loss=0.5222	233.9 examples/second
2022-01-10 17:55:38,864 - INFO - [Step=61250]	Loss=0.5199	250.2 examples/second
2022-01-10 17:57:46,563 - INFO - [Step=61500]	Loss=0.5318	250.6 examples/second
2022-01-10 17:59:54,316 - INFO - [Step=61750]	Loss=0.5191	250.5 examples/second
2022-01-10 18:00:22,302 - INFO - Test Loss=0.8157, Test top-1 acc=0.7957
2022-01-10 18:00:22,303 - INFO - Group Accuracy:

2022-01-10 18:00:22,303 - INFO - [0.98313254 0.99156624 0.98650604 0.99493974 0.9845783  0.99421686
 0.9821687  0.98313254 0.98963857 0.9780723  0.9920482  0.98433733
 0.9787952  0.9833735  0.9785542  0.9893976  0.9954217 ]
2022-01-10 18:00:22,304 - INFO - Epoch time: 436.28721714019775
2022-01-10 18:00:22,304 - INFO - 
Epoch: 74
2022-01-10 18:00:22,304 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:02:11,757 - INFO - [Step=62000]	Loss=0.5282	232.8 examples/second
2022-01-10 18:04:19,697 - INFO - [Step=62250]	Loss=0.5050	250.1 examples/second
2022-01-10 18:06:27,444 - INFO - [Step=62500]	Loss=0.5166	250.5 examples/second
2022-01-10 18:07:39,076 - INFO - Test Loss=0.8548, Test top-1 acc=0.7930
2022-01-10 18:07:39,076 - INFO - Group Accuracy:

2022-01-10 18:07:39,077 - INFO - [0.98240966 0.9918072  0.98578316 0.9946988  0.98433733 0.99373496
 0.9826506  0.98289156 0.9884337  0.9773494  0.9930121  0.9848193
 0.9780723  0.9838554  0.9780723  0.9891566  0.9954217 ]
2022-01-10 18:07:39,078 - INFO - Epoch time: 436.77392292022705
2022-01-10 18:07:39,078 - INFO - 
Epoch: 75
2022-01-10 18:07:39,078 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:08:45,355 - INFO - [Step=62750]	Loss=0.5160	232.0 examples/second
2022-01-10 18:10:53,758 - INFO - [Step=63000]	Loss=0.5112	249.2 examples/second
2022-01-10 18:13:01,358 - INFO - [Step=63250]	Loss=0.5307	250.8 examples/second
2022-01-10 18:14:55,563 - INFO - Test Loss=0.8079, Test top-1 acc=0.7930
2022-01-10 18:14:55,563 - INFO - Group Accuracy:

2022-01-10 18:14:55,563 - INFO - [0.9819277  0.9913253  0.98722893 0.9939759  0.9848193  0.99493974
 0.98313254 0.9826506  0.9884337  0.9785542  0.9922892  0.9848193
 0.9787952  0.9838554  0.9778313  0.9891566  0.9956626 ]
2022-01-10 18:14:55,565 - INFO - Epoch time: 436.4862685203552
2022-01-10 18:14:55,565 - INFO - 
Epoch: 76
2022-01-10 18:14:55,565 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:15:18,114 - INFO - [Step=63500]	Loss=0.5198	234.0 examples/second
2022-01-10 18:17:26,403 - INFO - [Step=63750]	Loss=0.5095	249.4 examples/second
2022-01-10 18:19:33,965 - INFO - [Step=64000]	Loss=0.5188	250.9 examples/second
2022-01-10 18:21:41,944 - INFO - [Step=64250]	Loss=0.4958	250.0 examples/second
2022-01-10 18:22:12,187 - INFO - Test Loss=0.8132, Test top-1 acc=0.7942
2022-01-10 18:22:12,188 - INFO - Group Accuracy:

2022-01-10 18:22:12,188 - INFO - [0.98289156 0.99108434 0.98578316 0.993494   0.9848193  0.99445784
 0.98289156 0.98313254 0.9891566  0.9785542  0.9922892  0.9838554
 0.97831327 0.98361444 0.9780723  0.9893976  0.9951807 ]
2022-01-10 18:22:12,189 - INFO - Epoch time: 436.623929977417
2022-01-10 18:22:12,189 - INFO - 
Epoch: 77
2022-01-10 18:22:12,189 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:23:58,843 - INFO - [Step=64500]	Loss=0.5093	233.8 examples/second
2022-01-10 18:26:06,799 - INFO - [Step=64750]	Loss=0.5158	250.1 examples/second
2022-01-10 18:28:14,786 - INFO - [Step=65000]	Loss=0.4973	250.0 examples/second
2022-01-10 18:29:28,938 - INFO - Test Loss=0.8147, Test top-1 acc=0.7964
2022-01-10 18:29:28,939 - INFO - Group Accuracy:

2022-01-10 18:29:28,939 - INFO - [0.98313254 0.99060243 0.9860241  0.993494   0.9850602  0.99445784
 0.98289156 0.98240966 0.98963857 0.9778313  0.9918072  0.9855422
 0.97831327 0.98361444 0.97831327 0.9881928  0.9956626 ]
2022-01-10 18:29:28,940 - INFO - Epoch time: 436.7507929801941
2022-01-10 18:29:28,940 - INFO - 
Epoch: 78
2022-01-10 18:29:28,940 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:30:32,277 - INFO - [Step=65250]	Loss=0.5047	232.7 examples/second
2022-01-10 18:32:38,779 - INFO - [Step=65500]	Loss=0.5226	253.0 examples/second
2022-01-10 18:34:45,107 - INFO - [Step=65750]	Loss=0.5043	253.3 examples/second
2022-01-10 18:36:41,184 - INFO - Test Loss=0.8402, Test top-1 acc=0.7930
2022-01-10 18:36:41,184 - INFO - Group Accuracy:

2022-01-10 18:36:41,184 - INFO - [0.9826506  0.99108434 0.98698795 0.99373496 0.9848193  0.99373496
 0.9840964  0.9821687  0.9891566  0.97831327 0.99084336 0.9860241
 0.9775904  0.9826506  0.9785542  0.9884337  0.9956626 ]
2022-01-10 18:36:41,185 - INFO - Epoch time: 432.24579524993896
2022-01-10 18:36:41,185 - INFO - 
Epoch: 79
2022-01-10 18:36:41,185 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:37:00,604 - INFO - [Step=66000]	Loss=0.5114	236.2 examples/second
2022-01-10 18:39:06,942 - INFO - [Step=66250]	Loss=0.4998	253.3 examples/second
2022-01-10 18:41:13,333 - INFO - [Step=66500]	Loss=0.5106	253.2 examples/second
2022-01-10 18:43:19,247 - INFO - [Step=66750]	Loss=0.5176	254.1 examples/second
2022-01-10 18:43:51,418 - INFO - Test Loss=0.8340, Test top-1 acc=0.7945
2022-01-10 18:43:51,418 - INFO - Group Accuracy:

2022-01-10 18:43:51,428 - INFO - [0.9819277  0.99156624 0.98578316 0.99445784 0.9840964  0.9939759
 0.9833735  0.9826506  0.9893976  0.97903615 0.99156624 0.9855422
 0.9780723  0.9821687  0.97903615 0.98963857 0.9956626 ]
2022-01-10 18:43:51,429 - INFO - Epoch time: 430.24342346191406
2022-01-10 18:43:51,429 - INFO - 
Epoch: 80
2022-01-10 18:43:51,429 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:45:33,942 - INFO - [Step=67000]	Loss=0.5081	237.6 examples/second
2022-01-10 18:47:38,880 - INFO - [Step=67250]	Loss=0.5019	256.1 examples/second
2022-01-10 18:49:44,362 - INFO - [Step=67500]	Loss=0.4989	255.0 examples/second
2022-01-10 18:50:59,331 - INFO - Test Loss=0.8275, Test top-1 acc=0.7916
2022-01-10 18:50:59,331 - INFO - Group Accuracy:

2022-01-10 18:50:59,331 - INFO - [0.98289156 0.9918072  0.9860241  0.99421686 0.9855422  0.99421686
 0.98240966 0.9826506  0.9891566  0.9780723  0.99156624 0.98578316
 0.9778313  0.9826506  0.9787952  0.98963857 0.9956626 ]
2022-01-10 18:50:59,331 - INFO - Epoch time: 427.9024922847748
2022-01-10 18:50:59,331 - INFO - 
Epoch: 81
2022-01-10 18:50:59,332 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:51:58,834 - INFO - [Step=67750]	Loss=0.5015	238.0 examples/second
2022-01-10 18:54:04,507 - INFO - [Step=68000]	Loss=0.4967	254.6 examples/second
2022-01-10 18:56:10,195 - INFO - [Step=68250]	Loss=0.4960	254.6 examples/second
2022-01-10 18:58:08,520 - INFO - Test Loss=0.8368, Test top-1 acc=0.7969
2022-01-10 18:58:08,521 - INFO - Group Accuracy:

2022-01-10 18:58:08,521 - INFO - [0.98313254 0.9918072  0.9855422  0.9939759  0.9848193  0.99373496
 0.98240966 0.98289156 0.9889157  0.9778313  0.9920482  0.9853012
 0.9780723  0.98240966 0.97831327 0.9889157  0.9954217 ]
2022-01-10 18:58:08,522 - INFO - Epoch time: 429.1904318332672
2022-01-10 18:58:08,522 - INFO - 
Epoch: 82
2022-01-10 18:58:08,522 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:58:25,303 - INFO - [Step=68500]	Loss=0.5021	236.8 examples/second
2022-01-10 19:00:31,628 - INFO - [Step=68750]	Loss=0.4998	253.3 examples/second
2022-01-10 19:02:38,270 - INFO - [Step=69000]	Loss=0.4963	252.7 examples/second
2022-01-10 19:04:44,763 - INFO - [Step=69250]	Loss=0.4957	253.0 examples/second
2022-01-10 19:05:19,815 - INFO - Test Loss=0.8143, Test top-1 acc=0.7918
2022-01-10 19:05:19,816 - INFO - Group Accuracy:

2022-01-10 19:05:19,816 - INFO - [0.98240966 0.9918072  0.98674697 0.99421686 0.9845783  0.99445784
 0.98313254 0.98289156 0.9886747  0.9771084  0.9920482  0.9855422
 0.9775904  0.98289156 0.9773494  0.9893976  0.9956626 ]
2022-01-10 19:05:19,817 - INFO - Epoch time: 431.29470133781433
2022-01-10 19:05:19,817 - INFO - 
Epoch: 83
2022-01-10 19:05:19,817 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:07:00,113 - INFO - [Step=69500]	Loss=0.4845	236.4 examples/second
2022-01-10 19:09:06,698 - INFO - [Step=69750]	Loss=0.4986	252.8 examples/second
2022-01-10 19:11:13,713 - INFO - [Step=70000]	Loss=0.4968	251.9 examples/second
2022-01-10 19:12:31,909 - INFO - Test Loss=0.8436, Test top-1 acc=0.7952
2022-01-10 19:12:31,909 - INFO - Group Accuracy:

2022-01-10 19:12:31,909 - INFO - [0.98289156 0.9925301  0.98674697 0.9939759  0.9853012  0.993253
 0.98313254 0.98313254 0.9881928  0.9778313  0.993253   0.98578316
 0.97831327 0.98289156 0.9780723  0.9893976  0.9956626 ]
2022-01-10 19:12:31,910 - INFO - Epoch time: 432.09314131736755
2022-01-10 19:12:31,910 - INFO - 
Epoch: 84
2022-01-10 19:12:31,910 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:13:29,263 - INFO - [Step=70250]	Loss=0.5014	236.1 examples/second
2022-01-10 19:15:35,923 - INFO - [Step=70500]	Loss=0.4994	252.6 examples/second
2022-01-10 19:17:42,320 - INFO - [Step=70750]	Loss=0.4985	253.2 examples/second
2022-01-10 19:19:44,105 - INFO - Test Loss=0.8266, Test top-1 acc=0.7933
2022-01-10 19:19:44,105 - INFO - Group Accuracy:

2022-01-10 19:19:44,105 - INFO - [0.98313254 0.99084336 0.9860241  0.9939759  0.9850602  0.99493974
 0.9826506  0.9833735  0.9889157  0.9771084  0.9930121  0.9848193
 0.9775904  0.9833735  0.97903615 0.9893976  0.9954217 ]
2022-01-10 19:19:44,106 - INFO - Epoch time: 432.1961524486542
2022-01-10 19:19:44,106 - INFO - 
Epoch: 85
2022-01-10 19:19:44,106 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:19:58,781 - INFO - [Step=71000]	Loss=0.5005	234.5 examples/second
2022-01-10 19:22:05,232 - INFO - [Step=71250]	Loss=0.4902	253.1 examples/second
2022-01-10 19:24:11,830 - INFO - [Step=71500]	Loss=0.4905	252.8 examples/second
2022-01-10 19:26:18,271 - INFO - [Step=71750]	Loss=0.4938	253.1 examples/second
2022-01-10 19:26:55,906 - INFO - Test Loss=0.8290, Test top-1 acc=0.7952
2022-01-10 19:26:55,906 - INFO - Group Accuracy:

2022-01-10 19:26:55,906 - INFO - [0.98361444 0.9918072  0.98578316 0.99445784 0.9850602  0.9939759
 0.9826506  0.9821687  0.9884337  0.9771084  0.9922892  0.9855422
 0.9787952  0.98313254 0.98       0.9893976  0.9956626 ]
2022-01-10 19:26:55,907 - INFO - Epoch time: 431.80108666419983
2022-01-10 19:26:55,907 - INFO - 
Epoch: 86
2022-01-10 19:26:55,907 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:28:33,333 - INFO - [Step=72000]	Loss=0.5047	236.9 examples/second
2022-01-10 19:30:39,398 - INFO - [Step=72250]	Loss=0.4932	253.8 examples/second
2022-01-10 19:32:45,958 - INFO - [Step=72500]	Loss=0.4938	252.8 examples/second
2022-01-10 19:34:06,662 - INFO - Test Loss=0.8451, Test top-1 acc=0.7916
2022-01-10 19:34:06,662 - INFO - Group Accuracy:

2022-01-10 19:34:06,662 - INFO - [0.98240966 0.99156624 0.98578316 0.99421686 0.9850602  0.99373496
 0.98240966 0.98313254 0.9886747  0.9771084  0.9913253  0.9855422
 0.9780723  0.98289156 0.9787952  0.9891566  0.9956626 ]
2022-01-10 19:34:06,664 - INFO - Epoch time: 430.7561388015747
2022-01-10 19:34:06,664 - INFO - 
Epoch: 87
2022-01-10 19:34:06,664 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:35:01,318 - INFO - [Step=72750]	Loss=0.4976	236.4 examples/second
2022-01-10 19:37:07,790 - INFO - [Step=73000]	Loss=0.4908	253.0 examples/second
2022-01-10 19:39:14,270 - INFO - [Step=73250]	Loss=0.4874	253.0 examples/second
2022-01-10 19:41:18,486 - INFO - Test Loss=0.8273, Test top-1 acc=0.7930
2022-01-10 19:41:18,486 - INFO - Group Accuracy:

2022-01-10 19:41:18,487 - INFO - [0.98313254 0.9922892  0.9860241  0.9946988  0.98578316 0.9939759
 0.9821687  0.9826506  0.9886747  0.9768675  0.9930121  0.9855422
 0.97831327 0.9848193  0.97831327 0.9889157  0.9956626 ]
2022-01-10 19:41:18,487 - INFO - Epoch time: 431.82356309890747
2022-01-10 19:41:18,487 - INFO - 
Epoch: 88
2022-01-10 19:41:18,487 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:41:30,240 - INFO - [Step=73500]	Loss=0.5002	235.3 examples/second
2022-01-10 19:43:36,496 - INFO - [Step=73750]	Loss=0.4969	253.5 examples/second
2022-01-10 19:45:43,025 - INFO - [Step=74000]	Loss=0.4901	252.9 examples/second
2022-01-10 19:47:49,818 - INFO - [Step=74250]	Loss=0.4892	252.4 examples/second
2022-01-10 19:48:29,566 - INFO - Test Loss=0.8655, Test top-1 acc=0.7882
2022-01-10 19:48:29,567 - INFO - Group Accuracy:

2022-01-10 19:48:29,567 - INFO - [0.98240966 0.9913253  0.9860241  0.99373496 0.9850602  0.99373496
 0.98289156 0.98289156 0.9893976  0.9778313  0.9920482  0.98433733
 0.9778313  0.9826506  0.9785542  0.9881928  0.9956626 ]
2022-01-10 19:48:29,568 - INFO - Epoch time: 431.0812017917633
2022-01-10 19:48:29,569 - INFO - 
Epoch: 89
2022-01-10 19:48:29,569 - INFO - 
Learning Rate: 0.0010
2022-01-10 19:50:04,889 - INFO - [Step=74500]	Loss=0.4965	236.9 examples/second
2022-01-10 19:52:11,491 - INFO - [Step=74750]	Loss=0.4912	252.8 examples/second
2022-01-10 19:54:18,047 - INFO - [Step=75000]	Loss=0.4789	252.9 examples/second
2022-01-10 19:55:41,141 - INFO - Test Loss=0.8950, Test top-1 acc=0.7899
2022-01-10 19:55:41,141 - INFO - Group Accuracy:

2022-01-10 19:55:41,141 - INFO - [0.98313254 0.9920482  0.9860241  0.99421686 0.9850602  0.9939759
 0.9826506  0.9821687  0.98963857 0.9778313  0.9920482  0.98578316
 0.97927713 0.98240966 0.97903615 0.9891566  0.99493974]
2022-01-10 19:55:41,142 - INFO - Epoch time: 431.5736095905304
2022-01-10 19:55:50,862 - INFO - Computing OOD Statistics...
2022-01-10 19:55:50,870 - INFO - 	Baseline.          AUROC: 0.3122. TNR@95TPR: 0.0212. AUPR OUT: 0.1184
2022-01-10 19:55:50,877 - INFO - 	ODIN (T=1000).     AUROC: 0.8783. TNR@95TPR: 0.4376. AUPR OUT: 0.5719
2022-01-10 19:55:50,877 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-10 19:55:50,877 - INFO - Top 1 Accuracy:  Min: 0.7978; Max: 0.7978; Avg: 0.7978; Std: 0.0000; Len: 1
2022-01-10 19:55:50,877 - INFO - Top 5 Accuracy:  Min: 0.9865; Max: 0.9865; Avg: 0.9865; Std: 0.0000; Len: 1
2022-01-10 19:55:50,877 - INFO - **********************************************************************
2022-01-10 19:55:50,878 - INFO - 	MSP (auroc): [0.31220212615166554] Min: 0.3122; Max: 0.3122; Avg: 0.3122; Std: 0.0000; Len: 1
2022-01-10 19:55:50,878 - INFO - 	MSP (tnr): [0.02117647058823524] Min: 0.0212; Max: 0.0212; Avg: 0.0212; Std: 0.0000; Len: 1
2022-01-10 19:55:50,878 - INFO - 	MSP (aupr): [0.11844055037642692] Min: 0.1184; Max: 0.1184; Avg: 0.1184; Std: 0.0000; Len: 1
2022-01-10 19:55:50,878 - INFO - 	ODIN (auroc): [0.8782965272856131] Min: 0.8783; Max: 0.8783; Avg: 0.8783; Std: 0.0000; Len: 1
2022-01-10 19:55:50,878 - INFO - 	ODIN (tnr): [0.4376470588235294] Min: 0.4376; Max: 0.4376; Avg: 0.4376; Std: 0.0000; Len: 1
2022-01-10 19:55:50,878 - INFO - 	ODIN (aupr): [0.57193639878171] Min: 0.5719; Max: 0.5719; Avg: 0.5719; Std: 0.0000; Len: 1

2022-01-20 14:26:39,151 - INFO - ==> Preparing data..
2022-01-20 14:26:39,503 - INFO - checkpoint filename: experiments/coarse/mos/imagenet1000-mos_R2/checkpoint.pt
2022-01-20 14:26:39,503 - INFO - log filename: experiments/coarse/mos/imagenet1000-mos_R2/train.log
2022-01-20 14:26:39,503 - INFO - ********************************************************
2022-01-20 14:26:39,503 - INFO - Starting Iter: 0 / 1
2022-01-20 14:26:39,503 - INFO - ********************************************************
2022-01-20 14:26:42,469 - INFO - cuda
2022-01-20 14:26:42,519 - INFO - 
Epoch: 0
2022-01-20 14:26:42,519 - INFO - 
Learning Rate: 0.0100
2022-01-20 14:28:38,638 - INFO - [Step=250]	Loss=5.3524	275.6 examples/second
2022-01-20 14:30:32,963 - INFO - [Step=500]	Loss=4.4879	279.9 examples/second
2022-01-20 14:32:27,528 - INFO - [Step=750]	Loss=4.1900	279.3 examples/second
2022-01-20 14:33:13,581 - INFO - Test Loss=4.5777, Test top-1 acc=0.1429
2022-01-20 14:33:13,581 - INFO - Group Accuracy:

2022-01-20 14:33:13,581 - INFO - [0.2773494  0.82216865 0.9440964 ]
2022-01-20 14:33:13,582 - INFO - Saving...
2022-01-20 14:33:13,736 - INFO - Epoch time: 391.21697449684143
2022-01-20 14:33:13,736 - INFO - 
Epoch: 1
2022-01-20 14:33:13,736 - INFO - 
Learning Rate: 0.0280
2022-01-20 14:34:30,590 - INFO - [Step=1000]	Loss=4.1280	260.0 examples/second
2022-01-20 14:36:24,477 - INFO - [Step=1250]	Loss=4.0523	281.0 examples/second
2022-01-20 14:38:18,343 - INFO - [Step=1500]	Loss=3.7733	281.0 examples/second
2022-01-20 14:39:42,768 - INFO - Test Loss=4.1044, Test top-1 acc=0.2205
2022-01-20 14:39:42,768 - INFO - Group Accuracy:

2022-01-20 14:39:42,769 - INFO - [0.34891567 0.8286747  0.9549398 ]
2022-01-20 14:39:42,769 - INFO - Saving...
2022-01-20 14:39:43,042 - INFO - Epoch time: 389.30574345588684
2022-01-20 14:39:43,042 - INFO - 
Epoch: 2
2022-01-20 14:39:43,042 - INFO - 
Learning Rate: 0.0460
2022-01-20 14:40:21,422 - INFO - [Step=1750]	Loss=3.6108	260.0 examples/second
2022-01-20 14:42:15,889 - INFO - [Step=2000]	Loss=3.4812	279.6 examples/second
2022-01-20 14:44:10,344 - INFO - [Step=2250]	Loss=3.2751	279.6 examples/second
2022-01-20 14:46:04,762 - INFO - [Step=2500]	Loss=3.1000	279.7 examples/second
2022-01-20 14:46:14,182 - INFO - Test Loss=3.0098, Test top-1 acc=0.3039
2022-01-20 14:46:14,183 - INFO - Group Accuracy:

2022-01-20 14:46:14,183 - INFO - [0.40746987 0.8450602  0.9592771 ]
2022-01-20 14:46:14,184 - INFO - Saving...
2022-01-20 14:46:14,415 - INFO - Epoch time: 391.3732678890228
2022-01-20 14:46:14,415 - INFO - 
Epoch: 3
2022-01-20 14:46:14,415 - INFO - 
Learning Rate: 0.0640
2022-01-20 14:48:07,844 - INFO - [Step=2750]	Loss=3.0318	260.0 examples/second
2022-01-20 14:50:01,603 - INFO - [Step=3000]	Loss=2.9072	281.3 examples/second
2022-01-20 14:51:55,415 - INFO - [Step=3250]	Loss=2.7858	281.2 examples/second
2022-01-20 14:52:43,384 - INFO - Test Loss=2.8869, Test top-1 acc=0.3489
2022-01-20 14:52:43,384 - INFO - Group Accuracy:

2022-01-20 14:52:43,384 - INFO - [0.45903614 0.84361446 0.9612048 ]
2022-01-20 14:52:43,385 - INFO - Saving...
2022-01-20 14:52:43,642 - INFO - Epoch time: 389.2269024848938
2022-01-20 14:52:43,642 - INFO - 
Epoch: 4
2022-01-20 14:52:43,643 - INFO - 
Learning Rate: 0.1000
2022-01-20 14:53:58,476 - INFO - [Step=3500]	Loss=2.7704	260.0 examples/second
2022-01-20 14:55:52,295 - INFO - [Step=3750]	Loss=2.6903	281.1 examples/second
2022-01-20 14:57:46,124 - INFO - [Step=4000]	Loss=2.5810	281.1 examples/second
2022-01-20 14:59:12,908 - INFO - Test Loss=2.2534, Test top-1 acc=0.4460
2022-01-20 14:59:12,909 - INFO - Group Accuracy:

2022-01-20 14:59:12,909 - INFO - [0.54746985 0.86240965 0.96891564]
2022-01-20 14:59:12,909 - INFO - Saving...
2022-01-20 14:59:13,133 - INFO - Epoch time: 389.4908947944641
2022-01-20 14:59:13,134 - INFO - 
Epoch: 5
2022-01-20 14:59:13,134 - INFO - 
Learning Rate: 0.1000
2022-01-20 14:59:49,247 - INFO - [Step=4250]	Loss=2.4623	259.9 examples/second
2022-01-20 15:01:43,151 - INFO - [Step=4500]	Loss=2.3470	280.9 examples/second
2022-01-20 15:03:37,043 - INFO - [Step=4750]	Loss=2.2693	281.0 examples/second
2022-01-20 15:05:30,887 - INFO - [Step=5000]	Loss=2.2079	281.1 examples/second
2022-01-20 15:05:42,466 - INFO - Test Loss=2.5051, Test top-1 acc=0.4593
2022-01-20 15:05:42,467 - INFO - Group Accuracy:

2022-01-20 15:05:42,467 - INFO - [0.55156624 0.8720482  0.9713253 ]
2022-01-20 15:05:42,467 - INFO - Saving...
2022-01-20 15:05:42,634 - INFO - Epoch time: 389.50057005882263
2022-01-20 15:05:42,634 - INFO - 
Epoch: 6
2022-01-20 15:05:42,634 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:07:33,859 - INFO - [Step=5250]	Loss=2.1347	260.2 examples/second
2022-01-20 15:09:27,836 - INFO - [Step=5500]	Loss=2.0849	280.8 examples/second
2022-01-20 15:11:21,782 - INFO - [Step=5750]	Loss=2.0100	280.8 examples/second
2022-01-20 15:12:12,060 - INFO - Test Loss=2.6229, Test top-1 acc=0.4294
2022-01-20 15:12:12,060 - INFO - Group Accuracy:

2022-01-20 15:12:12,060 - INFO - [0.5272289  0.84048194 0.9739759 ]
2022-01-20 15:12:12,061 - INFO - Epoch time: 389.4264554977417
2022-01-20 15:12:12,061 - INFO - 
Epoch: 7
2022-01-20 15:12:12,061 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:13:24,631 - INFO - [Step=6000]	Loss=1.9760	260.5 examples/second
2022-01-20 15:15:18,420 - INFO - [Step=6250]	Loss=1.9056	281.2 examples/second
2022-01-20 15:17:12,272 - INFO - [Step=6500]	Loss=1.8775	281.1 examples/second
2022-01-20 15:18:41,268 - INFO - Test Loss=2.0771, Test top-1 acc=0.5125
2022-01-20 15:18:41,269 - INFO - Group Accuracy:

2022-01-20 15:18:41,269 - INFO - [0.60771084 0.873253   0.9742169 ]
2022-01-20 15:18:41,270 - INFO - Saving...
2022-01-20 15:18:41,494 - INFO - Epoch time: 389.43323516845703
2022-01-20 15:18:41,494 - INFO - 
Epoch: 8
2022-01-20 15:18:41,494 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:19:15,322 - INFO - [Step=6750]	Loss=1.8525	260.1 examples/second
2022-01-20 15:21:09,122 - INFO - [Step=7000]	Loss=1.7960	281.2 examples/second
2022-01-20 15:23:02,905 - INFO - [Step=7250]	Loss=1.7653	281.2 examples/second
2022-01-20 15:24:56,708 - INFO - [Step=7500]	Loss=1.7468	281.2 examples/second
2022-01-20 15:25:10,505 - INFO - Test Loss=1.7802, Test top-1 acc=0.5713
2022-01-20 15:25:10,506 - INFO - Group Accuracy:

2022-01-20 15:25:10,506 - INFO - [0.64891565 0.8992771  0.98024094]
2022-01-20 15:25:10,506 - INFO - Saving...
2022-01-20 15:25:10,757 - INFO - Epoch time: 389.2627167701721
2022-01-20 15:25:10,757 - INFO - 
Epoch: 9
2022-01-20 15:25:10,757 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:26:59,653 - INFO - [Step=7750]	Loss=1.7096	260.3 examples/second
2022-01-20 15:28:53,441 - INFO - [Step=8000]	Loss=1.6731	281.2 examples/second
2022-01-20 15:30:47,281 - INFO - [Step=8250]	Loss=1.6745	281.1 examples/second
2022-01-20 15:31:39,903 - INFO - Test Loss=1.6412, Test top-1 acc=0.5860
2022-01-20 15:31:39,903 - INFO - Group Accuracy:

2022-01-20 15:31:39,903 - INFO - [0.6573494  0.89903617 0.9819277 ]
2022-01-20 15:31:39,903 - INFO - Saving...
2022-01-20 15:31:40,077 - INFO - Epoch time: 389.3199315071106
2022-01-20 15:31:40,078 - INFO - 
Epoch: 10
2022-01-20 15:31:40,078 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:32:50,481 - INFO - [Step=8500]	Loss=1.6112	259.7 examples/second
2022-01-20 15:34:44,313 - INFO - [Step=8750]	Loss=1.6025	281.1 examples/second
2022-01-20 15:36:38,296 - INFO - [Step=9000]	Loss=1.5902	280.7 examples/second
2022-01-20 15:38:09,505 - INFO - Test Loss=1.5111, Test top-1 acc=0.6106
2022-01-20 15:38:09,505 - INFO - Group Accuracy:

2022-01-20 15:38:09,505 - INFO - [0.67566264 0.90746987 0.9814458 ]
2022-01-20 15:38:09,506 - INFO - Saving...
2022-01-20 15:38:09,777 - INFO - Epoch time: 389.6996729373932
2022-01-20 15:38:09,778 - INFO - 
Epoch: 11
2022-01-20 15:38:09,778 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:38:41,307 - INFO - [Step=9250]	Loss=1.5947	260.1 examples/second
2022-01-20 15:40:35,326 - INFO - [Step=9500]	Loss=1.5459	280.7 examples/second
2022-01-20 15:42:29,425 - INFO - [Step=9750]	Loss=1.5274	280.5 examples/second
2022-01-20 15:44:23,283 - INFO - [Step=10000]	Loss=1.5225	281.1 examples/second
2022-01-20 15:44:39,911 - INFO - Test Loss=1.5366, Test top-1 acc=0.6205
2022-01-20 15:44:39,912 - INFO - Group Accuracy:

2022-01-20 15:44:39,912 - INFO - [0.68192774 0.91542166 0.97927713]
2022-01-20 15:44:39,912 - INFO - Saving...
2022-01-20 15:44:40,095 - INFO - Epoch time: 390.3170132637024
2022-01-20 15:44:40,095 - INFO - 
Epoch: 12
2022-01-20 15:44:40,095 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:46:27,631 - INFO - [Step=10250]	Loss=1.4880	257.3 examples/second
2022-01-20 15:48:22,509 - INFO - [Step=10500]	Loss=1.4576	278.6 examples/second
2022-01-20 15:50:17,902 - INFO - [Step=10750]	Loss=1.4822	277.3 examples/second
2022-01-20 15:51:13,989 - INFO - Test Loss=1.5226, Test top-1 acc=0.6063
2022-01-20 15:51:13,989 - INFO - Group Accuracy:

2022-01-20 15:51:13,990 - INFO - [0.6713253  0.90891564 0.9821687 ]
2022-01-20 15:51:13,990 - INFO - Epoch time: 393.8952372074127
2022-01-20 15:51:13,990 - INFO - 
Epoch: 13
2022-01-20 15:51:13,990 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:52:22,981 - INFO - [Step=11000]	Loss=1.4235	255.8 examples/second
2022-01-20 15:54:17,901 - INFO - [Step=11250]	Loss=1.4450	278.5 examples/second
2022-01-20 15:56:13,151 - INFO - [Step=11500]	Loss=1.4289	277.7 examples/second
2022-01-20 15:57:48,726 - INFO - Test Loss=1.2098, Test top-1 acc=0.6631
2022-01-20 15:57:48,726 - INFO - Group Accuracy:

2022-01-20 15:57:48,726 - INFO - [0.7253012  0.92313254 0.9855422 ]
2022-01-20 15:57:48,727 - INFO - Saving...
2022-01-20 15:57:48,905 - INFO - Epoch time: 394.9150333404541
2022-01-20 15:57:48,905 - INFO - 
Epoch: 14
2022-01-20 15:57:48,905 - INFO - 
Learning Rate: 0.1000
2022-01-20 15:58:18,589 - INFO - [Step=11750]	Loss=1.4168	255.1 examples/second
2022-01-20 16:00:13,793 - INFO - [Step=12000]	Loss=1.3740	277.8 examples/second
2022-01-20 16:02:09,136 - INFO - [Step=12250]	Loss=1.3909	277.4 examples/second
2022-01-20 16:04:04,620 - INFO - [Step=12500]	Loss=1.3729	277.1 examples/second
2022-01-20 16:04:24,139 - INFO - Test Loss=1.4967, Test top-1 acc=0.6390
2022-01-20 16:04:24,140 - INFO - Group Accuracy:

2022-01-20 16:04:24,151 - INFO - [0.7033735 0.9045783 0.9833735]
2022-01-20 16:04:24,152 - INFO - Epoch time: 395.2466320991516
2022-01-20 16:04:24,152 - INFO - 
Epoch: 15
2022-01-20 16:04:24,152 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:06:10,191 - INFO - [Step=12750]	Loss=1.3473	254.8 examples/second
2022-01-20 16:08:05,276 - INFO - [Step=13000]	Loss=1.3663	278.1 examples/second
2022-01-20 16:10:00,941 - INFO - [Step=13250]	Loss=1.3675	276.7 examples/second
2022-01-20 16:10:59,749 - INFO - Test Loss=1.4294, Test top-1 acc=0.6422
2022-01-20 16:10:59,750 - INFO - Group Accuracy:

2022-01-20 16:10:59,750 - INFO - [0.7038554  0.91879517 0.97903615]
2022-01-20 16:10:59,750 - INFO - Epoch time: 395.5982151031494
2022-01-20 16:10:59,750 - INFO - 
Epoch: 16
2022-01-20 16:10:59,750 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:12:06,169 - INFO - [Step=13500]	Loss=1.3343	255.5 examples/second
2022-01-20 16:14:01,438 - INFO - [Step=13750]	Loss=1.3153	277.6 examples/second
2022-01-20 16:15:57,028 - INFO - [Step=14000]	Loss=1.3086	276.8 examples/second
2022-01-20 16:17:34,904 - INFO - Test Loss=1.3360, Test top-1 acc=0.6431
2022-01-20 16:17:34,904 - INFO - Group Accuracy:

2022-01-20 16:17:34,905 - INFO - [0.70457834 0.9204819  0.9848193 ]
2022-01-20 16:17:34,905 - INFO - Epoch time: 395.1549825668335
2022-01-20 16:17:34,905 - INFO - 
Epoch: 17
2022-01-20 16:17:34,905 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:18:02,592 - INFO - [Step=14250]	Loss=1.2945	254.9 examples/second
2022-01-20 16:19:57,918 - INFO - [Step=14500]	Loss=1.2886	277.5 examples/second
2022-01-20 16:21:53,049 - INFO - [Step=14750]	Loss=1.2819	277.9 examples/second
2022-01-20 16:23:48,568 - INFO - [Step=15000]	Loss=1.2964	277.0 examples/second
2022-01-20 16:24:10,415 - INFO - Test Loss=1.3794, Test top-1 acc=0.6470
2022-01-20 16:24:10,415 - INFO - Group Accuracy:

2022-01-20 16:24:10,415 - INFO - [0.7079518  0.91831326 0.98361444]
2022-01-20 16:24:10,416 - INFO - Epoch time: 395.51027965545654
2022-01-20 16:24:10,416 - INFO - 
Epoch: 18
2022-01-20 16:24:10,416 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:25:53,709 - INFO - [Step=15250]	Loss=1.2631	255.7 examples/second
2022-01-20 16:27:49,146 - INFO - [Step=15500]	Loss=1.2674	277.2 examples/second
2022-01-20 16:29:44,675 - INFO - [Step=15750]	Loss=1.2588	277.0 examples/second
2022-01-20 16:30:45,954 - INFO - Test Loss=1.2402, Test top-1 acc=0.6684
2022-01-20 16:30:45,954 - INFO - Group Accuracy:

2022-01-20 16:30:45,954 - INFO - [0.7255422  0.93301207 0.98674697]
2022-01-20 16:30:45,955 - INFO - Saving...
2022-01-20 16:30:46,334 - INFO - Epoch time: 395.9182574748993
2022-01-20 16:30:46,334 - INFO - 
Epoch: 19
2022-01-20 16:30:46,334 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:31:51,493 - INFO - [Step=16000]	Loss=1.2654	252.3 examples/second
2022-01-20 16:33:47,063 - INFO - [Step=16250]	Loss=1.2444	276.9 examples/second
2022-01-20 16:35:42,651 - INFO - [Step=16500]	Loss=1.2468	276.8 examples/second
2022-01-20 16:37:22,747 - INFO - Test Loss=1.2252, Test top-1 acc=0.6687
2022-01-20 16:37:22,748 - INFO - Group Accuracy:

2022-01-20 16:37:22,748 - INFO - [0.7293976  0.9248193  0.98626506]
2022-01-20 16:37:22,748 - INFO - Saving...
2022-01-20 16:37:23,076 - INFO - Epoch time: 396.7413728237152
2022-01-20 16:37:23,076 - INFO - 
Epoch: 20
2022-01-20 16:37:23,076 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:37:48,935 - INFO - [Step=16750]	Loss=1.2288	253.4 examples/second
2022-01-20 16:39:44,169 - INFO - [Step=17000]	Loss=1.2120	277.7 examples/second
2022-01-20 16:41:39,451 - INFO - [Step=17250]	Loss=1.2224	277.6 examples/second
2022-01-20 16:43:35,334 - INFO - [Step=17500]	Loss=1.2288	276.1 examples/second
2022-01-20 16:43:59,227 - INFO - Test Loss=1.2656, Test top-1 acc=0.6660
2022-01-20 16:43:59,228 - INFO - Group Accuracy:

2022-01-20 16:43:59,228 - INFO - [0.7221687 0.9289157 0.9853012]
2022-01-20 16:43:59,229 - INFO - Epoch time: 396.1527636051178
2022-01-20 16:43:59,229 - INFO - 
Epoch: 21
2022-01-20 16:43:59,229 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:45:41,087 - INFO - [Step=17750]	Loss=1.2170	254.5 examples/second
2022-01-20 16:47:36,628 - INFO - [Step=18000]	Loss=1.2145	277.0 examples/second
2022-01-20 16:49:32,347 - INFO - [Step=18250]	Loss=1.2266	276.5 examples/second
2022-01-20 16:50:35,594 - INFO - Test Loss=1.2287, Test top-1 acc=0.6773
2022-01-20 16:50:35,594 - INFO - Group Accuracy:

2022-01-20 16:50:35,594 - INFO - [0.73108435 0.933494   0.9816868 ]
2022-01-20 16:50:35,595 - INFO - Saving...
2022-01-20 16:50:35,772 - INFO - Epoch time: 396.5436637401581
2022-01-20 16:50:35,773 - INFO - 
Epoch: 22
2022-01-20 16:50:35,773 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:51:37,817 - INFO - [Step=18500]	Loss=1.1866	255.0 examples/second
2022-01-20 16:53:33,375 - INFO - [Step=18750]	Loss=1.1966	276.9 examples/second
2022-01-20 16:55:28,965 - INFO - [Step=19000]	Loss=1.1890	276.8 examples/second
2022-01-20 16:57:11,893 - INFO - Test Loss=1.1634, Test top-1 acc=0.6848
2022-01-20 16:57:11,893 - INFO - Group Accuracy:

2022-01-20 16:57:11,893 - INFO - [0.7375904 0.9325301 0.9881928]
2022-01-20 16:57:11,893 - INFO - Saving...
2022-01-20 16:57:12,079 - INFO - Epoch time: 396.3059585094452
2022-01-20 16:57:12,079 - INFO - 
Epoch: 23
2022-01-20 16:57:12,079 - INFO - 
Learning Rate: 0.1000
2022-01-20 16:57:35,013 - INFO - [Step=19250]	Loss=1.1855	253.9 examples/second
2022-01-20 16:59:30,534 - INFO - [Step=19500]	Loss=1.1786	277.0 examples/second
2022-01-20 17:01:26,275 - INFO - [Step=19750]	Loss=1.1854	276.5 examples/second
2022-01-20 17:03:22,212 - INFO - [Step=20000]	Loss=1.1967	276.0 examples/second
2022-01-20 17:03:48,486 - INFO - Test Loss=1.2717, Test top-1 acc=0.6761
2022-01-20 17:03:48,486 - INFO - Group Accuracy:

2022-01-20 17:03:48,486 - INFO - [0.7293976  0.93060243 0.9807229 ]
2022-01-20 17:03:48,486 - INFO - Epoch time: 396.407662153244
2022-01-20 17:03:48,487 - INFO - 
Epoch: 24
2022-01-20 17:03:48,487 - INFO - 
Learning Rate: 0.1000
2022-01-20 17:05:28,005 - INFO - [Step=20250]	Loss=1.1681	254.4 examples/second
2022-01-20 17:07:23,712 - INFO - [Step=20500]	Loss=1.1671	276.6 examples/second
2022-01-20 17:09:19,404 - INFO - [Step=20750]	Loss=1.1761	276.6 examples/second
2022-01-20 17:10:24,972 - INFO - Test Loss=1.2571, Test top-1 acc=0.6812
2022-01-20 17:10:24,973 - INFO - Group Accuracy:

2022-01-20 17:10:24,973 - INFO - [0.7313253 0.9284337 0.9855422]
2022-01-20 17:10:24,973 - INFO - Epoch time: 396.4867548942566
2022-01-20 17:10:24,973 - INFO - 
Epoch: 25
2022-01-20 17:10:24,973 - INFO - 
Learning Rate: 0.1000
2022-01-20 17:11:25,307 - INFO - [Step=21000]	Loss=1.1788	254.2 examples/second
2022-01-20 17:13:20,575 - INFO - [Step=21250]	Loss=1.1474	277.6 examples/second
2022-01-20 17:15:16,373 - INFO - [Step=21500]	Loss=1.1541	276.3 examples/second
2022-01-20 17:17:01,168 - INFO - Test Loss=1.1256, Test top-1 acc=0.6978
2022-01-20 17:17:01,168 - INFO - Group Accuracy:

2022-01-20 17:17:01,168 - INFO - [0.7481928 0.9366265 0.9881928]
2022-01-20 17:17:01,169 - INFO - Saving...
2022-01-20 17:17:01,452 - INFO - Epoch time: 396.47850275039673
2022-01-20 17:17:01,452 - INFO - 
Epoch: 26
2022-01-20 17:17:01,452 - INFO - 
Learning Rate: 0.1000
2022-01-20 17:17:22,258 - INFO - [Step=21750]	Loss=1.1676	254.2 examples/second
2022-01-20 17:19:17,751 - INFO - [Step=22000]	Loss=1.1474	277.1 examples/second
2022-01-20 17:21:13,359 - INFO - [Step=22250]	Loss=1.1381	276.8 examples/second
2022-01-20 17:23:09,204 - INFO - [Step=22500]	Loss=1.1419	276.2 examples/second
2022-01-20 17:23:37,658 - INFO - Test Loss=1.0847, Test top-1 acc=0.6986
2022-01-20 17:23:37,658 - INFO - Group Accuracy:

2022-01-20 17:23:37,658 - INFO - [0.7525301 0.9351807 0.9889157]
2022-01-20 17:23:37,659 - INFO - Saving...
2022-01-20 17:23:37,930 - INFO - Epoch time: 396.4775559902191
2022-01-20 17:23:37,930 - INFO - 
Epoch: 27
2022-01-20 17:23:37,930 - INFO - 
Learning Rate: 0.1000
2022-01-20 17:25:15,291 - INFO - [Step=22750]	Loss=1.1334	253.8 examples/second
2022-01-20 17:27:10,672 - INFO - [Step=23000]	Loss=1.1194	277.3 examples/second
2022-01-20 17:29:06,448 - INFO - [Step=23250]	Loss=1.1383	276.4 examples/second
2022-01-20 17:30:14,675 - INFO - Test Loss=1.1325, Test top-1 acc=0.7053
2022-01-20 17:30:14,676 - INFO - Group Accuracy:

2022-01-20 17:30:14,676 - INFO - [0.75783134 0.9313253  0.9881928 ]
2022-01-20 17:30:14,677 - INFO - Saving...
2022-01-20 17:30:14,959 - INFO - Epoch time: 397.02886033058167
2022-01-20 17:30:14,959 - INFO - 
Epoch: 28
2022-01-20 17:30:14,959 - INFO - 
Learning Rate: 0.1000
2022-01-20 17:31:12,306 - INFO - [Step=23500]	Loss=1.1106	254.3 examples/second
2022-01-20 17:33:07,897 - INFO - [Step=23750]	Loss=1.1270	276.8 examples/second
2022-01-20 17:35:03,666 - INFO - [Step=24000]	Loss=1.1304	276.4 examples/second
2022-01-20 17:36:51,235 - INFO - Test Loss=1.2112, Test top-1 acc=0.6636
2022-01-20 17:36:51,235 - INFO - Group Accuracy:

2022-01-20 17:36:51,235 - INFO - [0.7221687  0.9320482  0.98289156]
2022-01-20 17:36:51,236 - INFO - Epoch time: 396.2768075466156
2022-01-20 17:36:51,236 - INFO - 
Epoch: 29
2022-01-20 17:36:51,236 - INFO - 
Learning Rate: 0.0100
2022-01-20 17:37:09,613 - INFO - [Step=24250]	Loss=1.1205	254.1 examples/second
2022-01-20 17:39:05,121 - INFO - [Step=24500]	Loss=0.8816	277.0 examples/second
2022-01-20 17:41:00,592 - INFO - [Step=24750]	Loss=0.8140	277.1 examples/second
2022-01-20 17:42:56,076 - INFO - [Step=25000]	Loss=0.7757	277.1 examples/second
2022-01-20 17:43:27,232 - INFO - Test Loss=0.7224, Test top-1 acc=0.7925
2022-01-20 17:43:27,233 - INFO - Group Accuracy:

2022-01-20 17:43:27,233 - INFO - [0.8315663 0.9561446 0.993253 ]
2022-01-20 17:43:27,233 - INFO - Saving...
2022-01-20 17:43:27,496 - INFO - Epoch time: 396.2596185207367
2022-01-20 17:43:27,496 - INFO - 
Epoch: 30
2022-01-20 17:43:27,496 - INFO - 
Learning Rate: 0.0100
2022-01-20 17:45:02,439 - INFO - [Step=25250]	Loss=0.7610	253.2 examples/second
2022-01-20 17:46:57,807 - INFO - [Step=25500]	Loss=0.7428	277.4 examples/second
2022-01-20 17:48:53,535 - INFO - [Step=25750]	Loss=0.7431	276.5 examples/second
2022-01-20 17:50:03,989 - INFO - Test Loss=0.7074, Test top-1 acc=0.7911
2022-01-20 17:50:03,990 - INFO - Group Accuracy:

2022-01-20 17:50:03,990 - INFO - [0.8303614  0.95421684 0.993494  ]
2022-01-20 17:50:03,990 - INFO - Epoch time: 396.49440360069275
2022-01-20 17:50:03,990 - INFO - 
Epoch: 31
2022-01-20 17:50:03,990 - INFO - 
Learning Rate: 0.0100
2022-01-20 17:50:59,029 - INFO - [Step=26000]	Loss=0.7172	255.0 examples/second
2022-01-20 17:52:54,617 - INFO - [Step=26250]	Loss=0.7096	276.8 examples/second
2022-01-20 17:54:50,100 - INFO - [Step=26500]	Loss=0.7174	277.1 examples/second
2022-01-20 17:56:39,905 - INFO - Test Loss=0.7005, Test top-1 acc=0.7961
2022-01-20 17:56:39,905 - INFO - Group Accuracy:

2022-01-20 17:56:39,905 - INFO - [0.83228916 0.96048194 0.99373496]
2022-01-20 17:56:39,906 - INFO - Saving...
2022-01-20 17:56:40,102 - INFO - Epoch time: 396.11208176612854
2022-01-20 17:56:40,102 - INFO - 
Epoch: 32
2022-01-20 17:56:40,102 - INFO - 
Learning Rate: 0.0100
2022-01-20 17:56:56,222 - INFO - [Step=26750]	Loss=0.7151	253.7 examples/second
2022-01-20 17:58:51,799 - INFO - [Step=27000]	Loss=0.6835	276.9 examples/second
2022-01-20 18:00:47,018 - INFO - [Step=27250]	Loss=0.6857	277.7 examples/second
2022-01-20 18:02:42,730 - INFO - [Step=27500]	Loss=0.7031	276.6 examples/second
2022-01-20 18:03:15,931 - INFO - Test Loss=0.6866, Test top-1 acc=0.8007
2022-01-20 18:03:15,932 - INFO - Group Accuracy:

2022-01-20 18:03:15,932 - INFO - [0.83638555 0.9595181  0.99445784]
2022-01-20 18:03:15,933 - INFO - Saving...
2022-01-20 18:03:16,183 - INFO - Epoch time: 396.0806477069855
2022-01-20 18:03:16,183 - INFO - 
Epoch: 33
2022-01-20 18:03:16,183 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:04:48,657 - INFO - [Step=27750]	Loss=0.6859	254.1 examples/second
2022-01-20 18:06:44,116 - INFO - [Step=28000]	Loss=0.6759	277.2 examples/second
2022-01-20 18:08:39,889 - INFO - [Step=28250]	Loss=0.6725	276.4 examples/second
2022-01-20 18:09:52,483 - INFO - Test Loss=0.6799, Test top-1 acc=0.8043
2022-01-20 18:09:52,483 - INFO - Group Accuracy:

2022-01-20 18:09:52,483 - INFO - [0.83975905 0.9590362  0.9939759 ]
2022-01-20 18:09:52,484 - INFO - Saving...
2022-01-20 18:09:52,702 - INFO - Epoch time: 396.518856048584
2022-01-20 18:09:52,702 - INFO - 
Epoch: 34
2022-01-20 18:09:52,702 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:10:45,901 - INFO - [Step=28500]	Loss=0.6557	253.9 examples/second
2022-01-20 18:12:41,328 - INFO - [Step=28750]	Loss=0.6459	277.2 examples/second
2022-01-20 18:14:36,492 - INFO - [Step=29000]	Loss=0.6728	277.9 examples/second
2022-01-20 18:16:28,668 - INFO - Test Loss=0.6828, Test top-1 acc=0.8027
2022-01-20 18:16:28,669 - INFO - Group Accuracy:

2022-01-20 18:16:28,669 - INFO - [0.8378313  0.95975906 0.9946988 ]
2022-01-20 18:16:28,670 - INFO - Epoch time: 395.9675006866455
2022-01-20 18:16:28,670 - INFO - 
Epoch: 35
2022-01-20 18:16:28,670 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:16:42,549 - INFO - [Step=29250]	Loss=0.6688	253.9 examples/second
2022-01-20 18:18:38,137 - INFO - [Step=29500]	Loss=0.6488	276.8 examples/second
2022-01-20 18:20:33,486 - INFO - [Step=29750]	Loss=0.6556	277.4 examples/second
2022-01-20 18:22:29,241 - INFO - [Step=30000]	Loss=0.6583	276.4 examples/second
2022-01-20 18:23:04,797 - INFO - Test Loss=0.6709, Test top-1 acc=0.8043
2022-01-20 18:23:04,797 - INFO - Group Accuracy:

2022-01-20 18:23:04,797 - INFO - [0.8385542 0.9619277 0.993494 ]
2022-01-20 18:23:04,798 - INFO - Epoch time: 396.1280143260956
2022-01-20 18:23:04,798 - INFO - 
Epoch: 36
2022-01-20 18:23:04,798 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:24:34,495 - INFO - [Step=30250]	Loss=0.6434	255.5 examples/second
2022-01-20 18:26:29,878 - INFO - [Step=30500]	Loss=0.6321	277.3 examples/second
2022-01-20 18:28:25,582 - INFO - [Step=30750]	Loss=0.6400	276.6 examples/second
2022-01-20 18:29:40,437 - INFO - Test Loss=0.6727, Test top-1 acc=0.8043
2022-01-20 18:29:40,437 - INFO - Group Accuracy:

2022-01-20 18:29:40,437 - INFO - [0.83903617 0.9612048  0.9930121 ]
2022-01-20 18:29:40,438 - INFO - Epoch time: 395.6394045352936
2022-01-20 18:29:40,438 - INFO - 
Epoch: 37
2022-01-20 18:29:40,438 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:30:31,133 - INFO - [Step=31000]	Loss=0.6425	254.9 examples/second
2022-01-20 18:32:26,687 - INFO - [Step=31250]	Loss=0.6301	276.9 examples/second
2022-01-20 18:34:21,971 - INFO - [Step=31500]	Loss=0.6330	277.6 examples/second
2022-01-20 18:36:16,246 - INFO - Test Loss=0.6758, Test top-1 acc=0.8019
2022-01-20 18:36:16,247 - INFO - Group Accuracy:

2022-01-20 18:36:16,247 - INFO - [0.8373494  0.96024096 0.99421686]
2022-01-20 18:36:16,248 - INFO - Epoch time: 395.80994987487793
2022-01-20 18:36:16,248 - INFO - 
Epoch: 38
2022-01-20 18:36:16,248 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:36:28,062 - INFO - [Step=31750]	Loss=0.6339	253.8 examples/second
2022-01-20 18:38:23,554 - INFO - [Step=32000]	Loss=0.6187	277.1 examples/second
2022-01-20 18:40:19,137 - INFO - [Step=32250]	Loss=0.6172	276.9 examples/second
2022-01-20 18:42:14,935 - INFO - [Step=32500]	Loss=0.6192	276.3 examples/second
2022-01-20 18:42:52,700 - INFO - Test Loss=0.6850, Test top-1 acc=0.8039
2022-01-20 18:42:52,700 - INFO - Group Accuracy:

2022-01-20 18:42:52,700 - INFO - [0.83710843 0.9619277  0.9925301 ]
2022-01-20 18:42:52,700 - INFO - Epoch time: 396.45285844802856
2022-01-20 18:42:52,701 - INFO - 
Epoch: 39
2022-01-20 18:42:52,701 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:44:20,035 - INFO - [Step=32750]	Loss=0.6146	255.8 examples/second
2022-01-20 18:46:15,496 - INFO - [Step=33000]	Loss=0.6096	277.2 examples/second
2022-01-20 18:48:10,903 - INFO - [Step=33250]	Loss=0.6113	277.3 examples/second
2022-01-20 18:49:28,233 - INFO - Test Loss=0.6744, Test top-1 acc=0.8048
2022-01-20 18:49:28,233 - INFO - Group Accuracy:

2022-01-20 18:49:28,233 - INFO - [0.8373494  0.96409637 0.99421686]
2022-01-20 18:49:28,234 - INFO - Saving...
2022-01-20 18:49:28,495 - INFO - Epoch time: 395.7946705818176
2022-01-20 18:49:28,495 - INFO - 
Epoch: 40
2022-01-20 18:49:28,496 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:50:17,182 - INFO - [Step=33500]	Loss=0.6137	253.4 examples/second
2022-01-20 18:52:12,951 - INFO - [Step=33750]	Loss=0.5987	276.4 examples/second
2022-01-20 18:54:08,439 - INFO - [Step=34000]	Loss=0.6013	277.1 examples/second
2022-01-20 18:56:05,355 - INFO - Test Loss=0.6783, Test top-1 acc=0.8053
2022-01-20 18:56:05,355 - INFO - Group Accuracy:

2022-01-20 18:56:05,356 - INFO - [0.8387952 0.9624096 0.993253 ]
2022-01-20 18:56:05,356 - INFO - Saving...
2022-01-20 18:56:05,636 - INFO - Epoch time: 397.14046716690063
2022-01-20 18:56:05,636 - INFO - 
Epoch: 41
2022-01-20 18:56:05,636 - INFO - 
Learning Rate: 0.0100
2022-01-20 18:56:14,498 - INFO - [Step=34250]	Loss=0.6034	253.9 examples/second
2022-01-20 18:58:10,103 - INFO - [Step=34500]	Loss=0.5900	276.8 examples/second
2022-01-20 19:00:05,758 - INFO - [Step=34750]	Loss=0.5973	276.7 examples/second
2022-01-20 19:02:01,499 - INFO - [Step=35000]	Loss=0.5929	276.5 examples/second
2022-01-20 19:02:41,949 - INFO - Test Loss=0.6771, Test top-1 acc=0.8080
2022-01-20 19:02:41,949 - INFO - Group Accuracy:

2022-01-20 19:02:41,949 - INFO - [0.8419277  0.9619277  0.99373496]
2022-01-20 19:02:41,950 - INFO - Saving...
2022-01-20 19:02:42,213 - INFO - Epoch time: 396.57638120651245
2022-01-20 19:02:42,213 - INFO - 
Epoch: 42
2022-01-20 19:02:42,213 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:04:07,457 - INFO - [Step=35250]	Loss=0.5824	254.1 examples/second
2022-01-20 19:06:02,990 - INFO - [Step=35500]	Loss=0.5866	277.0 examples/second
2022-01-20 19:07:58,420 - INFO - [Step=35750]	Loss=0.5925	277.2 examples/second
2022-01-20 19:09:17,911 - INFO - Test Loss=0.6803, Test top-1 acc=0.8065
2022-01-20 19:09:17,911 - INFO - Group Accuracy:

2022-01-20 19:09:17,911 - INFO - [0.84096384 0.9624096  0.9930121 ]
2022-01-20 19:09:17,912 - INFO - Epoch time: 395.699156999588
2022-01-20 19:09:17,912 - INFO - 
Epoch: 43
2022-01-20 19:09:17,912 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:10:04,008 - INFO - [Step=36000]	Loss=0.5796	254.8 examples/second
2022-01-20 19:11:59,413 - INFO - [Step=36250]	Loss=0.5852	277.3 examples/second
2022-01-20 19:13:54,859 - INFO - [Step=36500]	Loss=0.5790	277.2 examples/second
2022-01-20 19:15:53,879 - INFO - Test Loss=0.6789, Test top-1 acc=0.8010
2022-01-20 19:15:53,879 - INFO - Group Accuracy:

2022-01-20 19:15:53,879 - INFO - [0.833253   0.9633735  0.99421686]
2022-01-20 19:15:53,880 - INFO - Epoch time: 395.9678680896759
2022-01-20 19:15:53,880 - INFO - 
Epoch: 44
2022-01-20 19:15:53,880 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:16:00,956 - INFO - [Step=36750]	Loss=0.5803	253.8 examples/second
2022-01-20 19:17:56,447 - INFO - [Step=37000]	Loss=0.5731	277.1 examples/second
2022-01-20 19:19:51,835 - INFO - [Step=37250]	Loss=0.5724	277.3 examples/second
2022-01-20 19:21:47,337 - INFO - [Step=37500]	Loss=0.5826	277.1 examples/second
2022-01-20 19:22:29,978 - INFO - Test Loss=0.6843, Test top-1 acc=0.8065
2022-01-20 19:22:29,978 - INFO - Group Accuracy:

2022-01-20 19:22:29,978 - INFO - [0.8392771 0.9621687 0.9946988]
2022-01-20 19:22:29,979 - INFO - Epoch time: 396.0988938808441
2022-01-20 19:22:29,979 - INFO - 
Epoch: 45
2022-01-20 19:22:29,979 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:23:53,057 - INFO - [Step=37750]	Loss=0.5684	254.5 examples/second
2022-01-20 19:25:48,533 - INFO - [Step=38000]	Loss=0.5719	277.1 examples/second
2022-01-20 19:27:44,167 - INFO - [Step=38250]	Loss=0.5630	276.7 examples/second
2022-01-20 19:29:05,812 - INFO - Test Loss=0.6765, Test top-1 acc=0.8041
2022-01-20 19:29:05,812 - INFO - Group Accuracy:

2022-01-20 19:29:05,812 - INFO - [0.83903617 0.9621687  0.99373496]
2022-01-20 19:29:05,813 - INFO - Epoch time: 395.8338806629181
2022-01-20 19:29:05,813 - INFO - 
Epoch: 46
2022-01-20 19:29:05,813 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:29:49,523 - INFO - [Step=38500]	Loss=0.5654	255.3 examples/second
2022-01-20 19:31:45,071 - INFO - [Step=38750]	Loss=0.5531	276.9 examples/second
2022-01-20 19:33:40,560 - INFO - [Step=39000]	Loss=0.5546	277.1 examples/second
2022-01-20 19:35:41,524 - INFO - Test Loss=0.6796, Test top-1 acc=0.8058
2022-01-20 19:35:41,525 - INFO - Group Accuracy:

2022-01-20 19:35:41,525 - INFO - [0.8395181  0.9621687  0.99421686]
2022-01-20 19:35:41,525 - INFO - Epoch time: 395.7124865055084
2022-01-20 19:35:41,525 - INFO - 
Epoch: 47
2022-01-20 19:35:41,525 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:35:45,788 - INFO - [Step=39250]	Loss=0.5739	255.5 examples/second
2022-01-20 19:37:41,278 - INFO - [Step=39500]	Loss=0.5353	277.1 examples/second
2022-01-20 19:39:36,925 - INFO - [Step=39750]	Loss=0.5509	276.7 examples/second
2022-01-20 19:41:32,435 - INFO - [Step=40000]	Loss=0.5578	277.0 examples/second
2022-01-20 19:42:17,247 - INFO - Test Loss=0.6828, Test top-1 acc=0.8077
2022-01-20 19:42:17,248 - INFO - Group Accuracy:

2022-01-20 19:42:17,248 - INFO - [0.8385542  0.96433735 0.9939759 ]
2022-01-20 19:42:17,248 - INFO - Epoch time: 395.7229976654053
2022-01-20 19:42:17,249 - INFO - 
Epoch: 48
2022-01-20 19:42:17,249 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:43:37,814 - INFO - [Step=40250]	Loss=0.5642	255.2 examples/second
2022-01-20 19:45:33,315 - INFO - [Step=40500]	Loss=0.5451	277.1 examples/second
2022-01-20 19:47:28,841 - INFO - [Step=40750]	Loss=0.5540	277.0 examples/second
2022-01-20 19:48:52,986 - INFO - Test Loss=0.6895, Test top-1 acc=0.8022
2022-01-20 19:48:52,986 - INFO - Group Accuracy:

2022-01-20 19:48:52,986 - INFO - [0.83686745 0.9628916  0.9946988 ]
2022-01-20 19:48:52,987 - INFO - Epoch time: 395.7381570339203
2022-01-20 19:48:52,987 - INFO - 
Epoch: 49
2022-01-20 19:48:52,987 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:49:34,237 - INFO - [Step=41000]	Loss=0.5523	255.2 examples/second
2022-01-20 19:51:29,843 - INFO - [Step=41250]	Loss=0.5354	276.8 examples/second
2022-01-20 19:53:25,431 - INFO - [Step=41500]	Loss=0.5446	276.8 examples/second
2022-01-20 19:55:20,816 - INFO - [Step=41750]	Loss=0.5492	277.3 examples/second
2022-01-20 19:55:28,664 - INFO - Test Loss=0.6742, Test top-1 acc=0.8104
2022-01-20 19:55:28,664 - INFO - Group Accuracy:

2022-01-20 19:55:28,664 - INFO - [0.84361446 0.9631325  0.99373496]
2022-01-20 19:55:28,665 - INFO - Saving...
2022-01-20 19:55:28,868 - INFO - Epoch time: 395.88122487068176
2022-01-20 19:55:28,868 - INFO - 
Epoch: 50
2022-01-20 19:55:28,868 - INFO - 
Learning Rate: 0.0100
2022-01-20 19:57:26,718 - INFO - [Step=42000]	Loss=0.5305	254.2 examples/second
2022-01-20 19:59:22,449 - INFO - [Step=42250]	Loss=0.5322	276.5 examples/second
2022-01-20 20:01:18,416 - INFO - [Step=42500]	Loss=0.5390	275.9 examples/second
2022-01-20 20:02:05,481 - INFO - Test Loss=0.6807, Test top-1 acc=0.8094
2022-01-20 20:02:05,481 - INFO - Group Accuracy:

2022-01-20 20:02:05,481 - INFO - [0.8416867  0.96481925 0.99445784]
2022-01-20 20:02:05,482 - INFO - Epoch time: 396.6134581565857
2022-01-20 20:02:05,482 - INFO - 
Epoch: 51
2022-01-20 20:02:05,482 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:03:24,040 - INFO - [Step=42750]	Loss=0.5258	254.7 examples/second
2022-01-20 20:05:19,647 - INFO - [Step=43000]	Loss=0.5323	276.8 examples/second
2022-01-20 20:07:15,189 - INFO - [Step=43250]	Loss=0.5429	277.0 examples/second
2022-01-20 20:08:41,432 - INFO - Test Loss=0.6824, Test top-1 acc=0.8072
2022-01-20 20:08:41,432 - INFO - Group Accuracy:

2022-01-20 20:08:41,432 - INFO - [0.84096384 0.9626506  0.99445784]
2022-01-20 20:08:41,433 - INFO - Epoch time: 395.9510061740875
2022-01-20 20:08:41,433 - INFO - 
Epoch: 52
2022-01-20 20:08:41,433 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:09:20,692 - INFO - [Step=43500]	Loss=0.5371	255.0 examples/second
2022-01-20 20:11:16,332 - INFO - [Step=43750]	Loss=0.5204	276.7 examples/second
2022-01-20 20:13:12,077 - INFO - [Step=44000]	Loss=0.5309	276.5 examples/second
2022-01-20 20:15:07,773 - INFO - [Step=44250]	Loss=0.5368	276.6 examples/second
2022-01-20 20:15:18,066 - INFO - Test Loss=0.6963, Test top-1 acc=0.8060
2022-01-20 20:15:18,066 - INFO - Group Accuracy:

2022-01-20 20:15:18,066 - INFO - [0.84096384 0.9633735  0.9939759 ]
2022-01-20 20:15:18,067 - INFO - Epoch time: 396.6340446472168
2022-01-20 20:15:18,067 - INFO - 
Epoch: 53
2022-01-20 20:15:18,067 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:17:13,631 - INFO - [Step=44500]	Loss=0.5347	254.3 examples/second
2022-01-20 20:19:09,198 - INFO - [Step=44750]	Loss=0.5309	276.9 examples/second
2022-01-20 20:21:04,924 - INFO - [Step=45000]	Loss=0.5206	276.5 examples/second
2022-01-20 20:21:54,374 - INFO - Test Loss=0.7076, Test top-1 acc=0.8084
2022-01-20 20:21:54,374 - INFO - Group Accuracy:

2022-01-20 20:21:54,374 - INFO - [0.8412048 0.9628916 0.9927711]
2022-01-20 20:21:54,374 - INFO - Epoch time: 396.30746483802795
2022-01-20 20:21:54,374 - INFO - 
Epoch: 54
2022-01-20 20:21:54,374 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:23:10,685 - INFO - [Step=45250]	Loss=0.5164	254.5 examples/second
2022-01-20 20:25:06,529 - INFO - [Step=45500]	Loss=0.5179	276.2 examples/second
2022-01-20 20:27:02,129 - INFO - [Step=45750]	Loss=0.5077	276.8 examples/second
2022-01-20 20:28:30,891 - INFO - Test Loss=0.6945, Test top-1 acc=0.8029
2022-01-20 20:28:30,891 - INFO - Group Accuracy:

2022-01-20 20:28:30,891 - INFO - [0.8385542  0.96096385 0.9930121 ]
2022-01-20 20:28:30,892 - INFO - Epoch time: 396.5176169872284
2022-01-20 20:28:30,892 - INFO - 
Epoch: 55
2022-01-20 20:28:30,892 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:29:07,568 - INFO - [Step=46000]	Loss=0.5222	255.1 examples/second
2022-01-20 20:31:03,127 - INFO - [Step=46250]	Loss=0.5108	276.9 examples/second
2022-01-20 20:32:58,682 - INFO - [Step=46500]	Loss=0.5159	276.9 examples/second
2022-01-20 20:34:54,376 - INFO - [Step=46750]	Loss=0.5252	276.6 examples/second
2022-01-20 20:35:06,866 - INFO - Test Loss=0.7219, Test top-1 acc=0.7969
2022-01-20 20:35:06,866 - INFO - Group Accuracy:

2022-01-20 20:35:06,866 - INFO - [0.82963854 0.96361446 0.9925301 ]
2022-01-20 20:35:06,866 - INFO - Epoch time: 395.97427916526794
2022-01-20 20:35:06,866 - INFO - 
Epoch: 56
2022-01-20 20:35:06,867 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:36:59,706 - INFO - [Step=47000]	Loss=0.5058	255.3 examples/second
2022-01-20 20:38:55,404 - INFO - [Step=47250]	Loss=0.5074	276.6 examples/second
2022-01-20 20:40:51,133 - INFO - [Step=47500]	Loss=0.5070	276.5 examples/second
2022-01-20 20:41:44,587 - INFO - Test Loss=0.7132, Test top-1 acc=0.8000
2022-01-20 20:41:44,588 - INFO - Group Accuracy:

2022-01-20 20:41:44,588 - INFO - [0.83277106 0.96096385 0.99421686]
2022-01-20 20:41:44,589 - INFO - Epoch time: 397.7222204208374
2022-01-20 20:41:44,589 - INFO - 
Epoch: 57
2022-01-20 20:41:44,589 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:42:59,580 - INFO - [Step=47750]	Loss=0.4979	249.1 examples/second
2022-01-20 20:44:56,548 - INFO - [Step=48000]	Loss=0.5053	273.6 examples/second
2022-01-20 20:46:52,289 - INFO - [Step=48250]	Loss=0.5111	276.5 examples/second
2022-01-20 20:48:23,773 - INFO - Test Loss=0.7061, Test top-1 acc=0.8077
2022-01-20 20:48:23,773 - INFO - Group Accuracy:

2022-01-20 20:48:23,773 - INFO - [0.84048194 0.9633735  0.9930121 ]
2022-01-20 20:48:23,774 - INFO - Epoch time: 399.1846868991852
2022-01-20 20:48:23,774 - INFO - 
Epoch: 58
2022-01-20 20:48:23,774 - INFO - 
Learning Rate: 0.0100
2022-01-20 20:48:58,499 - INFO - [Step=48500]	Loss=0.5116	253.5 examples/second
2022-01-20 20:50:54,052 - INFO - [Step=48750]	Loss=0.4953	276.9 examples/second
2022-01-20 20:52:49,642 - INFO - [Step=49000]	Loss=0.5080	276.8 examples/second
2022-01-20 20:54:45,363 - INFO - [Step=49250]	Loss=0.5235	276.5 examples/second
2022-01-20 20:55:00,343 - INFO - Test Loss=0.7097, Test top-1 acc=0.8101
2022-01-20 20:55:00,343 - INFO - Group Accuracy:

2022-01-20 20:55:00,343 - INFO - [0.8421687  0.96433735 0.9930121 ]
2022-01-20 20:55:00,344 - INFO - Epoch time: 396.56991481781006
2022-01-20 20:55:00,344 - INFO - 
Epoch: 59
2022-01-20 20:55:00,344 - INFO - 
Learning Rate: 0.0010
2022-01-20 20:56:51,269 - INFO - [Step=49500]	Loss=0.4559	254.2 examples/second
2022-01-20 20:58:46,893 - INFO - [Step=49750]	Loss=0.4501	276.8 examples/second
2022-01-20 21:00:42,605 - INFO - [Step=50000]	Loss=0.4362	276.5 examples/second
2022-01-20 21:01:36,617 - INFO - Test Loss=0.6643, Test top-1 acc=0.8166
2022-01-20 21:01:36,617 - INFO - Group Accuracy:

2022-01-20 21:01:36,617 - INFO - [0.84698796 0.9657831  0.99373496]
2022-01-20 21:01:36,618 - INFO - Saving...
2022-01-20 21:01:36,926 - INFO - Epoch time: 396.58269810676575
2022-01-20 21:01:36,927 - INFO - 
Epoch: 60
2022-01-20 21:01:36,927 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:02:47,659 - INFO - [Step=50250]	Loss=0.4292	255.9 examples/second
2022-01-20 21:04:42,064 - INFO - [Step=50500]	Loss=0.4199	279.7 examples/second
2022-01-20 21:06:36,036 - INFO - [Step=50750]	Loss=0.4208	280.8 examples/second
2022-01-20 21:08:07,495 - INFO - Test Loss=0.6591, Test top-1 acc=0.8176
2022-01-20 21:08:07,496 - INFO - Group Accuracy:

2022-01-20 21:08:07,496 - INFO - [0.84746987 0.966747   0.99373496]
2022-01-20 21:08:07,497 - INFO - Saving...
2022-01-20 21:08:07,734 - INFO - Epoch time: 390.80746245384216
2022-01-20 21:08:07,734 - INFO - 
Epoch: 61
2022-01-20 21:08:07,734 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:08:39,409 - INFO - [Step=51000]	Loss=0.4290	259.4 examples/second
2022-01-20 21:10:33,656 - INFO - [Step=51250]	Loss=0.4222	280.1 examples/second
2022-01-20 21:12:27,874 - INFO - [Step=51500]	Loss=0.4152	280.2 examples/second
2022-01-20 21:14:22,161 - INFO - [Step=51750]	Loss=0.4178	280.0 examples/second
2022-01-20 21:14:38,462 - INFO - Test Loss=0.6618, Test top-1 acc=0.8137
2022-01-20 21:14:38,462 - INFO - Group Accuracy:

2022-01-20 21:14:38,462 - INFO - [0.84698796 0.96481925 0.993494  ]
2022-01-20 21:14:38,463 - INFO - Epoch time: 390.72834873199463
2022-01-20 21:14:38,463 - INFO - 
Epoch: 62
2022-01-20 21:14:38,463 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:16:25,265 - INFO - [Step=52000]	Loss=0.4189	259.9 examples/second
2022-01-20 21:18:19,165 - INFO - [Step=52250]	Loss=0.4120	280.9 examples/second
2022-01-20 21:20:12,866 - INFO - [Step=52500]	Loss=0.4139	281.4 examples/second
2022-01-20 21:21:07,880 - INFO - Test Loss=0.6601, Test top-1 acc=0.8171
2022-01-20 21:21:07,880 - INFO - Group Accuracy:

2022-01-20 21:21:07,880 - INFO - [0.84746987 0.9672289  0.99373496]
2022-01-20 21:21:07,881 - INFO - Epoch time: 389.4183602333069
2022-01-20 21:21:07,881 - INFO - 
Epoch: 63
2022-01-20 21:21:07,881 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:22:15,946 - INFO - [Step=52750]	Loss=0.4094	260.0 examples/second
2022-01-20 21:24:09,467 - INFO - [Step=53000]	Loss=0.4141	281.9 examples/second
2022-01-20 21:26:03,160 - INFO - [Step=53250]	Loss=0.4087	281.5 examples/second
2022-01-20 21:27:36,519 - INFO - Test Loss=0.6638, Test top-1 acc=0.8154
2022-01-20 21:27:36,519 - INFO - Group Accuracy:

2022-01-20 21:27:36,519 - INFO - [0.8479518  0.9653012  0.99373496]
2022-01-20 21:27:36,520 - INFO - Epoch time: 388.63850498199463
2022-01-20 21:27:36,520 - INFO - 
Epoch: 64
2022-01-20 21:27:36,520 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:28:06,086 - INFO - [Step=53500]	Loss=0.4015	260.3 examples/second
2022-01-20 21:30:01,129 - INFO - [Step=53750]	Loss=0.4040	278.2 examples/second
2022-01-20 21:31:56,208 - INFO - [Step=54000]	Loss=0.4073	278.1 examples/second
2022-01-20 21:33:51,234 - INFO - [Step=54250]	Loss=0.4065	278.2 examples/second
2022-01-20 21:34:10,436 - INFO - Test Loss=0.6612, Test top-1 acc=0.8159
2022-01-20 21:34:10,437 - INFO - Group Accuracy:

2022-01-20 21:34:10,437 - INFO - [0.8493976 0.9660241 0.9939759]
2022-01-20 21:34:10,437 - INFO - Epoch time: 393.91770005226135
2022-01-20 21:34:10,438 - INFO - 
Epoch: 65
2022-01-20 21:34:10,438 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:35:55,792 - INFO - [Step=54500]	Loss=0.4048	256.9 examples/second
2022-01-20 21:37:50,689 - INFO - [Step=54750]	Loss=0.4122	278.5 examples/second
2022-01-20 21:39:45,678 - INFO - [Step=55000]	Loss=0.4048	278.3 examples/second
2022-01-20 21:40:43,379 - INFO - Test Loss=0.6626, Test top-1 acc=0.8193
2022-01-20 21:40:43,379 - INFO - Group Accuracy:

2022-01-20 21:40:43,379 - INFO - [0.8501205 0.966747  0.9939759]
2022-01-20 21:40:43,380 - INFO - Saving...
2022-01-20 21:40:43,635 - INFO - Epoch time: 393.1974513530731
2022-01-20 21:40:43,635 - INFO - 
Epoch: 66
2022-01-20 21:40:43,635 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:41:49,807 - INFO - [Step=55250]	Loss=0.4015	257.8 examples/second
2022-01-20 21:43:44,449 - INFO - [Step=55500]	Loss=0.3903	279.1 examples/second
2022-01-20 21:45:39,219 - INFO - [Step=55750]	Loss=0.4037	278.8 examples/second
2022-01-20 21:47:16,253 - INFO - Test Loss=0.6611, Test top-1 acc=0.8176
2022-01-20 21:47:16,253 - INFO - Group Accuracy:

2022-01-20 21:47:16,253 - INFO - [0.8493976  0.966747   0.99421686]
2022-01-20 21:47:16,254 - INFO - Epoch time: 392.61855912208557
2022-01-20 21:47:16,254 - INFO - 
Epoch: 67
2022-01-20 21:47:16,254 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:47:43,733 - INFO - [Step=56000]	Loss=0.4059	257.0 examples/second
2022-01-20 21:49:37,611 - INFO - [Step=56250]	Loss=0.4007	281.0 examples/second
2022-01-20 21:51:31,444 - INFO - [Step=56500]	Loss=0.3970	281.1 examples/second
2022-01-20 21:53:25,188 - INFO - [Step=56750]	Loss=0.3967	281.3 examples/second
2022-01-20 21:53:46,561 - INFO - Test Loss=0.6642, Test top-1 acc=0.8183
2022-01-20 21:53:46,561 - INFO - Group Accuracy:

2022-01-20 21:53:46,562 - INFO - [0.8496386 0.9672289 0.9939759]
2022-01-20 21:53:46,562 - INFO - Epoch time: 390.30851197242737
2022-01-20 21:53:46,563 - INFO - 
Epoch: 68
2022-01-20 21:53:46,563 - INFO - 
Learning Rate: 0.0010
2022-01-20 21:55:28,895 - INFO - [Step=57000]	Loss=0.3872	258.7 examples/second
2022-01-20 21:57:22,494 - INFO - [Step=57250]	Loss=0.3943	281.7 examples/second
2022-01-20 21:59:16,263 - INFO - [Step=57500]	Loss=0.3953	281.3 examples/second
2022-01-20 22:00:16,017 - INFO - Test Loss=0.6591, Test top-1 acc=0.8161
2022-01-20 22:00:16,017 - INFO - Group Accuracy:

2022-01-20 22:00:16,017 - INFO - [0.84698796 0.9674699  0.9939759 ]
2022-01-20 22:00:16,018 - INFO - Epoch time: 389.45574498176575
2022-01-20 22:00:16,018 - INFO - 
Epoch: 69
2022-01-20 22:00:16,018 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:01:19,795 - INFO - [Step=57750]	Loss=0.3936	259.0 examples/second
2022-01-20 22:03:13,899 - INFO - [Step=58000]	Loss=0.3881	280.4 examples/second
2022-01-20 22:05:08,028 - INFO - [Step=58250]	Loss=0.3910	280.4 examples/second
2022-01-20 22:06:46,488 - INFO - Test Loss=0.6628, Test top-1 acc=0.8169
2022-01-20 22:06:46,488 - INFO - Group Accuracy:

2022-01-20 22:06:46,488 - INFO - [0.84843373 0.9662651  0.99445784]
2022-01-20 22:06:46,489 - INFO - Epoch time: 390.4705693721771
2022-01-20 22:06:46,489 - INFO - 
Epoch: 70
2022-01-20 22:06:46,489 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:07:11,279 - INFO - [Step=58500]	Loss=0.3851	259.6 examples/second
2022-01-20 22:09:05,980 - INFO - [Step=58750]	Loss=0.3825	279.0 examples/second
2022-01-20 22:11:00,520 - INFO - [Step=59000]	Loss=0.3940	279.4 examples/second
2022-01-20 22:12:55,023 - INFO - [Step=59250]	Loss=0.3954	279.5 examples/second
2022-01-20 22:13:18,532 - INFO - Test Loss=0.6639, Test top-1 acc=0.8149
2022-01-20 22:13:18,532 - INFO - Group Accuracy:

2022-01-20 22:13:18,532 - INFO - [0.84698796 0.9657831  0.9939759 ]
2022-01-20 22:13:18,533 - INFO - Epoch time: 392.0437340736389
2022-01-20 22:13:18,533 - INFO - 
Epoch: 71
2022-01-20 22:13:18,533 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:14:59,509 - INFO - [Step=59500]	Loss=0.3803	257.1 examples/second
2022-01-20 22:16:53,542 - INFO - [Step=59750]	Loss=0.3854	280.6 examples/second
2022-01-20 22:18:47,507 - INFO - [Step=60000]	Loss=0.3770	280.8 examples/second
2022-01-20 22:19:49,375 - INFO - Test Loss=0.6708, Test top-1 acc=0.8147
2022-01-20 22:19:49,375 - INFO - Group Accuracy:

2022-01-20 22:19:49,376 - INFO - [0.846506   0.9662651  0.99445784]
2022-01-20 22:19:49,376 - INFO - Epoch time: 390.84333753585815
2022-01-20 22:19:49,376 - INFO - 
Epoch: 72
2022-01-20 22:19:49,376 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:20:51,153 - INFO - [Step=60250]	Loss=0.3823	258.8 examples/second
2022-01-20 22:22:46,483 - INFO - [Step=60500]	Loss=0.3771	277.5 examples/second
2022-01-20 22:24:41,638 - INFO - [Step=60750]	Loss=0.3805	277.9 examples/second
2022-01-20 22:26:23,737 - INFO - Test Loss=0.6732, Test top-1 acc=0.8176
2022-01-20 22:26:23,738 - INFO - Group Accuracy:

2022-01-20 22:26:23,738 - INFO - [0.84819275 0.966506   0.99445784]
2022-01-20 22:26:23,739 - INFO - Epoch time: 394.3623206615448
2022-01-20 22:26:23,739 - INFO - 
Epoch: 73
2022-01-20 22:26:23,739 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:26:46,250 - INFO - [Step=61000]	Loss=0.3805	256.8 examples/second
2022-01-20 22:28:40,868 - INFO - [Step=61250]	Loss=0.3821	279.2 examples/second
2022-01-20 22:30:35,390 - INFO - [Step=61500]	Loss=0.3841	279.4 examples/second
2022-01-20 22:32:29,935 - INFO - [Step=61750]	Loss=0.3799	279.4 examples/second
2022-01-20 22:32:55,425 - INFO - Test Loss=0.6748, Test top-1 acc=0.8152
2022-01-20 22:32:55,425 - INFO - Group Accuracy:

2022-01-20 22:32:55,425 - INFO - [0.84722894 0.9660241  0.99421686]
2022-01-20 22:32:55,425 - INFO - Epoch time: 391.68670892715454
2022-01-20 22:32:55,425 - INFO - 
Epoch: 74
2022-01-20 22:32:55,426 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:34:33,017 - INFO - [Step=62000]	Loss=0.3753	260.0 examples/second
2022-01-20 22:36:26,670 - INFO - [Step=62250]	Loss=0.3989	281.6 examples/second
2022-01-20 22:38:20,274 - INFO - [Step=62500]	Loss=0.3879	281.7 examples/second
2022-01-20 22:39:24,439 - INFO - Test Loss=0.6699, Test top-1 acc=0.8152
2022-01-20 22:39:24,440 - INFO - Group Accuracy:

2022-01-20 22:39:24,440 - INFO - [0.8460241  0.96698797 0.99421686]
2022-01-20 22:39:24,441 - INFO - Epoch time: 389.01508140563965
2022-01-20 22:39:24,441 - INFO - 
Epoch: 75
2022-01-20 22:39:24,441 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:40:23,578 - INFO - [Step=62750]	Loss=0.3724	259.5 examples/second
2022-01-20 22:42:17,936 - INFO - [Step=63000]	Loss=0.3763	279.8 examples/second
2022-01-20 22:44:12,288 - INFO - [Step=63250]	Loss=0.3819	279.8 examples/second
2022-01-20 22:45:55,945 - INFO - Test Loss=0.6702, Test top-1 acc=0.8152
2022-01-20 22:45:55,945 - INFO - Group Accuracy:

2022-01-20 22:45:55,945 - INFO - [0.84481925 0.96843374 0.9939759 ]
2022-01-20 22:45:55,947 - INFO - Epoch time: 391.5059254169464
2022-01-20 22:45:55,947 - INFO - 
Epoch: 76
2022-01-20 22:45:55,947 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:46:16,243 - INFO - [Step=63500]	Loss=0.3695	258.2 examples/second
2022-01-20 22:48:10,392 - INFO - [Step=63750]	Loss=0.3802	280.3 examples/second
2022-01-20 22:50:04,398 - INFO - [Step=64000]	Loss=0.3824	280.7 examples/second
2022-01-20 22:51:58,432 - INFO - [Step=64250]	Loss=0.3693	280.6 examples/second
2022-01-20 22:52:26,511 - INFO - Test Loss=0.6678, Test top-1 acc=0.8166
2022-01-20 22:52:26,511 - INFO - Group Accuracy:

2022-01-20 22:52:26,511 - INFO - [0.84722894 0.96698797 0.993494  ]
2022-01-20 22:52:26,512 - INFO - Epoch time: 390.5653405189514
2022-01-20 22:52:26,512 - INFO - 
Epoch: 77
2022-01-20 22:52:26,512 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:54:02,245 - INFO - [Step=64500]	Loss=0.3736	258.5 examples/second
2022-01-20 22:55:55,932 - INFO - [Step=64750]	Loss=0.3676	281.5 examples/second
2022-01-20 22:57:49,743 - INFO - [Step=65000]	Loss=0.3758	281.2 examples/second
2022-01-20 22:58:56,141 - INFO - Test Loss=0.6756, Test top-1 acc=0.8133
2022-01-20 22:58:56,141 - INFO - Group Accuracy:

2022-01-20 22:58:56,141 - INFO - [0.84481925 0.966506   0.99373496]
2022-01-20 22:58:56,142 - INFO - Epoch time: 389.6302139759064
2022-01-20 22:58:56,142 - INFO - 
Epoch: 78
2022-01-20 22:58:56,143 - INFO - 
Learning Rate: 0.0010
2022-01-20 22:59:52,922 - INFO - [Step=65250]	Loss=0.3716	259.8 examples/second
2022-01-20 23:01:46,772 - INFO - [Step=65500]	Loss=0.3724	281.1 examples/second
2022-01-20 23:03:40,635 - INFO - [Step=65750]	Loss=0.3675	281.0 examples/second
2022-01-20 23:05:26,047 - INFO - Test Loss=0.6743, Test top-1 acc=0.8205
2022-01-20 23:05:26,047 - INFO - Group Accuracy:

2022-01-20 23:05:26,047 - INFO - [0.85084337 0.96795183 0.9939759 ]
2022-01-20 23:05:26,048 - INFO - Saving...
2022-01-20 23:05:26,323 - INFO - Epoch time: 390.180335521698
2022-01-20 23:05:26,323 - INFO - 
Epoch: 79
2022-01-20 23:05:26,323 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:05:44,372 - INFO - [Step=66000]	Loss=0.3705	258.6 examples/second
2022-01-20 23:07:38,905 - INFO - [Step=66250]	Loss=0.3662	279.4 examples/second
2022-01-20 23:09:33,371 - INFO - [Step=66500]	Loss=0.3794	279.6 examples/second
2022-01-20 23:11:27,794 - INFO - [Step=66750]	Loss=0.3693	279.7 examples/second
2022-01-20 23:11:58,150 - INFO - Test Loss=0.6681, Test top-1 acc=0.8159
2022-01-20 23:11:58,150 - INFO - Group Accuracy:

2022-01-20 23:11:58,151 - INFO - [0.84722894 0.9662651  0.9939759 ]
2022-01-20 23:11:58,151 - INFO - Epoch time: 391.82837080955505
2022-01-20 23:11:58,151 - INFO - 
Epoch: 80
2022-01-20 23:11:58,152 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:13:31,445 - INFO - [Step=67000]	Loss=0.3777	258.8 examples/second
2022-01-20 23:15:25,254 - INFO - [Step=67250]	Loss=0.3733	281.2 examples/second
2022-01-20 23:17:19,148 - INFO - [Step=67500]	Loss=0.3659	281.0 examples/second
2022-01-20 23:18:27,964 - INFO - Test Loss=0.6671, Test top-1 acc=0.8207
2022-01-20 23:18:27,964 - INFO - Group Accuracy:

2022-01-20 23:18:27,964 - INFO - [0.85180724 0.9672289  0.9939759 ]
2022-01-20 23:18:27,965 - INFO - Saving...
2022-01-20 23:18:28,271 - INFO - Epoch time: 390.1195855140686
2022-01-20 23:18:28,271 - INFO - 
Epoch: 81
2022-01-20 23:18:28,271 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:19:22,801 - INFO - [Step=67750]	Loss=0.3739	258.8 examples/second
2022-01-20 23:21:17,010 - INFO - [Step=68000]	Loss=0.3707	280.2 examples/second
2022-01-20 23:23:11,057 - INFO - [Step=68250]	Loss=0.3629	280.6 examples/second
2022-01-20 23:24:59,224 - INFO - Test Loss=0.6700, Test top-1 acc=0.8193
2022-01-20 23:24:59,225 - INFO - Group Accuracy:

2022-01-20 23:24:59,225 - INFO - [0.8486747  0.9674699  0.99421686]
2022-01-20 23:24:59,226 - INFO - Epoch time: 390.9543762207031
2022-01-20 23:24:59,226 - INFO - 
Epoch: 82
2022-01-20 23:24:59,226 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:25:15,193 - INFO - [Step=68500]	Loss=0.3668	257.8 examples/second
2022-01-20 23:27:09,112 - INFO - [Step=68750]	Loss=0.3614	280.9 examples/second
2022-01-20 23:29:02,903 - INFO - [Step=69000]	Loss=0.3631	281.2 examples/second
2022-01-20 23:30:56,734 - INFO - [Step=69250]	Loss=0.3724	281.1 examples/second
2022-01-20 23:31:29,015 - INFO - Test Loss=0.6732, Test top-1 acc=0.8178
2022-01-20 23:31:29,015 - INFO - Group Accuracy:

2022-01-20 23:31:29,015 - INFO - [0.8479518 0.9674699 0.9939759]
2022-01-20 23:31:29,016 - INFO - Epoch time: 389.7901244163513
2022-01-20 23:31:29,016 - INFO - 
Epoch: 83
2022-01-20 23:31:29,016 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:32:59,923 - INFO - [Step=69500]	Loss=0.3632	259.8 examples/second
2022-01-20 23:34:53,885 - INFO - [Step=69750]	Loss=0.3651	280.8 examples/second
2022-01-20 23:36:47,737 - INFO - [Step=70000]	Loss=0.3643	281.1 examples/second
2022-01-20 23:37:58,835 - INFO - Test Loss=0.6781, Test top-1 acc=0.8159
2022-01-20 23:37:58,836 - INFO - Group Accuracy:

2022-01-20 23:37:58,836 - INFO - [0.8455422  0.9672289  0.99445784]
2022-01-20 23:37:58,836 - INFO - Epoch time: 389.82032084465027
2022-01-20 23:37:58,836 - INFO - 
Epoch: 84
2022-01-20 23:37:58,836 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:38:50,946 - INFO - [Step=70250]	Loss=0.3622	259.7 examples/second
2022-01-20 23:40:44,859 - INFO - [Step=70500]	Loss=0.3756	280.9 examples/second
2022-01-20 23:42:38,723 - INFO - [Step=70750]	Loss=0.3646	281.0 examples/second
2022-01-20 23:44:28,669 - INFO - Test Loss=0.6783, Test top-1 acc=0.8166
2022-01-20 23:44:28,669 - INFO - Group Accuracy:

2022-01-20 23:44:28,670 - INFO - [0.84746987 0.96698797 0.9939759 ]
2022-01-20 23:44:28,670 - INFO - Epoch time: 389.8337125778198
2022-01-20 23:44:28,670 - INFO - 
Epoch: 85
2022-01-20 23:44:28,670 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:44:42,133 - INFO - [Step=71000]	Loss=0.3679	259.3 examples/second
2022-01-20 23:46:35,949 - INFO - [Step=71250]	Loss=0.3666	281.2 examples/second
2022-01-20 23:48:29,840 - INFO - [Step=71500]	Loss=0.3627	281.0 examples/second
2022-01-20 23:50:23,702 - INFO - [Step=71750]	Loss=0.3690	281.0 examples/second
2022-01-20 23:50:58,320 - INFO - Test Loss=0.6771, Test top-1 acc=0.8157
2022-01-20 23:50:58,321 - INFO - Group Accuracy:

2022-01-20 23:50:58,321 - INFO - [0.84722894 0.966506   0.99445784]
2022-01-20 23:50:58,322 - INFO - Epoch time: 389.65157866477966
2022-01-20 23:50:58,322 - INFO - 
Epoch: 86
2022-01-20 23:50:58,322 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:52:27,666 - INFO - [Step=72000]	Loss=0.3554	258.1 examples/second
2022-01-20 23:54:22,844 - INFO - [Step=72250]	Loss=0.3575	277.8 examples/second
2022-01-20 23:56:17,805 - INFO - [Step=72500]	Loss=0.3626	278.4 examples/second
2022-01-20 23:57:31,584 - INFO - Test Loss=0.6804, Test top-1 acc=0.8157
2022-01-20 23:57:31,584 - INFO - Group Accuracy:

2022-01-20 23:57:31,584 - INFO - [0.84771085 0.9657831  0.99421686]
2022-01-20 23:57:31,584 - INFO - Epoch time: 393.2625527381897
2022-01-20 23:57:31,584 - INFO - 
Epoch: 87
2022-01-20 23:57:31,584 - INFO - 
Learning Rate: 0.0010
2022-01-20 23:58:21,710 - INFO - [Step=72750]	Loss=0.3616	258.3 examples/second
2022-01-21 00:00:16,399 - INFO - [Step=73000]	Loss=0.3629	279.0 examples/second
2022-01-21 00:02:11,130 - INFO - [Step=73250]	Loss=0.3676	278.9 examples/second
2022-01-21 00:04:03,525 - INFO - Test Loss=0.6887, Test top-1 acc=0.8181
2022-01-21 00:04:03,525 - INFO - Group Accuracy:

2022-01-21 00:04:03,525 - INFO - [0.8498795  0.9660241  0.99373496]
2022-01-21 00:04:03,526 - INFO - Epoch time: 391.94150853157043
2022-01-21 00:04:03,526 - INFO - 
Epoch: 88
2022-01-21 00:04:03,526 - INFO - 
Learning Rate: 0.0010
2022-01-21 00:04:14,647 - INFO - [Step=73500]	Loss=0.3672	259.1 examples/second
2022-01-21 00:06:08,332 - INFO - [Step=73750]	Loss=0.3591	281.5 examples/second
2022-01-21 00:08:02,480 - INFO - [Step=74000]	Loss=0.3586	280.3 examples/second
2022-01-21 00:09:56,544 - INFO - [Step=74250]	Loss=0.3585	280.5 examples/second
2022-01-21 00:10:33,470 - INFO - Test Loss=0.6778, Test top-1 acc=0.8176
2022-01-21 00:10:33,471 - INFO - Group Accuracy:

2022-01-21 00:10:33,471 - INFO - [0.84771085 0.96795183 0.993494  ]
2022-01-21 00:10:33,472 - INFO - Epoch time: 389.94559264183044
2022-01-21 00:10:33,472 - INFO - 
Epoch: 89
2022-01-21 00:10:33,472 - INFO - 
Learning Rate: 0.0010
2022-01-21 00:12:00,619 - INFO - [Step=74500]	Loss=0.3644	257.9 examples/second
2022-01-21 00:13:55,616 - INFO - [Step=74750]	Loss=0.3544	278.3 examples/second
2022-01-21 00:15:50,716 - INFO - [Step=75000]	Loss=0.3708	278.0 examples/second
2022-01-21 00:17:07,072 - INFO - Test Loss=0.6837, Test top-1 acc=0.8164
2022-01-21 00:17:07,072 - INFO - Group Accuracy:

2022-01-21 00:17:07,072 - INFO - [0.84819275 0.966747   0.99373496]
2022-01-21 00:17:07,073 - INFO - Epoch time: 393.60125374794006
2022-01-21 00:17:17,396 - INFO - Computing OOD Statistics...
2022-01-21 00:17:17,404 - INFO - 	Baseline.          AUROC: 0.6603. TNR@95TPR: 0.0729. AUPR OUT: 0.2423
2022-01-21 00:17:17,410 - INFO - 	ODIN (T=1000).     AUROC: 0.9233. TNR@95TPR: 0.6859. AUPR OUT: 0.7242
2022-01-21 00:17:17,410 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-21 00:17:17,410 - INFO - Top 1 Accuracy:  Min: 0.8207; Max: 0.8207; Avg: 0.8207; Std: 0.0000; Len: 1
2022-01-21 00:17:17,410 - INFO - Top 5 Accuracy:  Min: 0.9377; Max: 0.9377; Avg: 0.9377; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - **********************************************************************
2022-01-21 00:17:17,411 - INFO - 	MSP (auroc): [0.660348405386251] Min: 0.6603; Max: 0.6603; Avg: 0.6603; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - 	MSP (tnr): [0.07294117647058829] Min: 0.0729; Max: 0.0729; Avg: 0.0729; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - 	MSP (aupr): [0.24229475417735197] Min: 0.2423; Max: 0.2423; Avg: 0.2423; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - 	ODIN (auroc): [0.9232961020552799] Min: 0.9233; Max: 0.9233; Avg: 0.9233; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - 	ODIN (tnr): [0.6858823529411764] Min: 0.6859; Max: 0.6859; Avg: 0.6859; Std: 0.0000; Len: 1
2022-01-21 00:17:17,411 - INFO - 	ODIN (aupr): [0.7241933234074528] Min: 0.7242; Max: 0.7242; Avg: 0.7242; Std: 0.0000; Len: 1

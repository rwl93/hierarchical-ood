2022-01-10 08:36:32,516 - INFO - ==> Preparing data..
2022-01-10 08:36:32,940 - INFO - checkpoint filename: experiments/coarse/mos/LRp1_R1/checkpoint.pt
2022-01-10 08:36:32,940 - INFO - log filename: experiments/coarse/mos/LRp1_R1/train.log
2022-01-10 08:36:32,940 - INFO - ********************************************************
2022-01-10 08:36:32,940 - INFO - Starting Iter: 0 / 1
2022-01-10 08:36:32,940 - INFO - ********************************************************
2022-01-10 08:36:36,289 - INFO - 
Epoch: 0
2022-01-10 08:36:36,289 - INFO - 
Learning Rate: 0.0100
2022-01-10 08:38:33,293 - INFO - [Step=250]	Loss=7.2200	273.5 examples/second
2022-01-10 08:40:28,623 - INFO - [Step=500]	Loss=5.4305	277.5 examples/second
2022-01-10 08:42:23,952 - INFO - [Step=750]	Loss=5.3523	277.5 examples/second
2022-01-10 08:43:10,729 - INFO - Test Loss=5.2176, Test top-1 acc=0.0318
2022-01-10 08:43:10,730 - INFO - Group Accuracy:

2022-01-10 08:43:10,730 - INFO - [0.939759  0.939759  0.939759  0.939759  0.939759  0.939759  0.939759
 0.939759  0.939759  0.939759  0.9518072 0.939759  0.939759  0.939759
 0.940241  0.9395181 0.9510843]
2022-01-10 08:43:10,731 - INFO - Saving...
2022-01-10 08:43:10,896 - INFO - Epoch time: 394.6070737838745
2022-01-10 08:43:10,897 - INFO - 
Epoch: 1
2022-01-10 08:43:10,897 - INFO - 
Learning Rate: 0.0280
2022-01-10 08:44:29,150 - INFO - [Step=1000]	Loss=5.2601	255.6 examples/second
2022-01-10 08:46:24,755 - INFO - [Step=1250]	Loss=5.0604	276.8 examples/second
2022-01-10 08:48:20,417 - INFO - [Step=1500]	Loss=4.8332	276.7 examples/second
2022-01-10 08:49:46,847 - INFO - Test Loss=4.9657, Test top-1 acc=0.0634
2022-01-10 08:49:46,847 - INFO - Group Accuracy:

2022-01-10 08:49:46,847 - INFO - [0.939759   0.9395181  0.939759   0.94144577 0.939759   0.9404819
 0.9404819  0.939759   0.93783134 0.939759   0.9518072  0.939759
 0.939759   0.939759   0.9395181  0.939759   0.9518072 ]
2022-01-10 08:49:46,848 - INFO - Saving...
2022-01-10 08:49:47,172 - INFO - Epoch time: 396.2751040458679
2022-01-10 08:49:47,173 - INFO - 
Epoch: 2
2022-01-10 08:49:47,173 - INFO - 
Learning Rate: 0.0460
2022-01-10 08:50:26,696 - INFO - [Step=1750]	Loss=4.6819	253.4 examples/second
2022-01-10 08:52:22,547 - INFO - [Step=2000]	Loss=4.5933	276.2 examples/second
2022-01-10 08:54:18,586 - INFO - [Step=2250]	Loss=4.3517	275.8 examples/second
2022-01-10 08:56:14,622 - INFO - [Step=2500]	Loss=4.1782	275.8 examples/second
2022-01-10 08:56:24,350 - INFO - Test Loss=3.9920, Test top-1 acc=0.1251
2022-01-10 08:56:24,351 - INFO - Group Accuracy:

2022-01-10 08:56:24,351 - INFO - [0.94216865 0.93759036 0.94       0.9513253  0.9395181  0.94626504
 0.94096386 0.94096386 0.9445783  0.939759   0.95277107 0.9404819
 0.939759   0.939759   0.939759   0.94       0.95566267]
2022-01-10 08:56:24,351 - INFO - Saving...
2022-01-10 08:56:24,608 - INFO - Epoch time: 397.43537735939026
2022-01-10 08:56:24,608 - INFO - 
Epoch: 3
2022-01-10 08:56:24,608 - INFO - 
Learning Rate: 0.0640
2022-01-10 08:58:20,947 - INFO - [Step=2750]	Loss=4.0858	253.3 examples/second
2022-01-10 09:00:17,090 - INFO - [Step=3000]	Loss=3.9129	275.5 examples/second
2022-01-10 09:02:13,094 - INFO - [Step=3250]	Loss=3.7556	275.9 examples/second
2022-01-10 09:03:02,346 - INFO - Test Loss=3.5000, Test top-1 acc=0.2053
2022-01-10 09:03:02,347 - INFO - Group Accuracy:

2022-01-10 09:03:02,347 - INFO - [0.94506025 0.94843376 0.94168675 0.9515663  0.9433735  0.95759034
 0.9431325  0.946747   0.95373493 0.94144577 0.95277107 0.9436145
 0.94144577 0.9404819  0.94144577 0.9460241  0.9592771 ]
2022-01-10 09:03:02,348 - INFO - Saving...
2022-01-10 09:03:02,617 - INFO - Epoch time: 398.008104801178
2022-01-10 09:03:02,617 - INFO - 
Epoch: 4
2022-01-10 09:03:02,617 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:04:18,732 - INFO - [Step=3500]	Loss=3.7261	254.7 examples/second
2022-01-10 09:06:14,441 - INFO - [Step=3750]	Loss=3.6090	276.6 examples/second
2022-01-10 09:08:10,414 - INFO - [Step=4000]	Loss=3.4709	275.9 examples/second
2022-01-10 09:09:39,173 - INFO - Test Loss=3.6951, Test top-1 acc=0.2214
2022-01-10 09:09:39,173 - INFO - Group Accuracy:

2022-01-10 09:09:39,173 - INFO - [0.94433737 0.946747   0.9395181  0.96024096 0.94120485 0.9628916
 0.9438554  0.9469879  0.95277107 0.92650604 0.95373493 0.939759
 0.94       0.94120485 0.94192773 0.9520482  0.9561446 ]
2022-01-10 09:09:39,174 - INFO - Saving...
2022-01-10 09:09:39,469 - INFO - Epoch time: 396.8517928123474
2022-01-10 09:09:39,469 - INFO - 
Epoch: 5
2022-01-10 09:09:39,469 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:10:16,229 - INFO - [Step=4250]	Loss=3.3193	254.3 examples/second
2022-01-10 09:12:11,953 - INFO - [Step=4500]	Loss=3.2273	276.5 examples/second
2022-01-10 09:14:07,876 - INFO - [Step=4750]	Loss=3.1165	276.0 examples/second
2022-01-10 09:16:03,836 - INFO - [Step=5000]	Loss=3.0253	276.0 examples/second
2022-01-10 09:16:15,908 - INFO - Test Loss=2.9177, Test top-1 acc=0.3282
2022-01-10 09:16:15,908 - INFO - Group Accuracy:

2022-01-10 09:16:15,908 - INFO - [0.94289154 0.9559036  0.9436145  0.96795183 0.9453012  0.97204816
 0.94891566 0.9544578  0.96457833 0.9469879  0.9546988  0.94843376
 0.94240963 0.9438554  0.9346988  0.9506024  0.9746988 ]
2022-01-10 09:16:15,909 - INFO - Saving...
2022-01-10 09:16:16,223 - INFO - Epoch time: 396.75410413742065
2022-01-10 09:16:16,223 - INFO - 
Epoch: 6
2022-01-10 09:16:16,223 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:18:09,282 - INFO - [Step=5250]	Loss=2.9468	255.1 examples/second
2022-01-10 09:20:05,363 - INFO - [Step=5500]	Loss=2.8568	275.7 examples/second
2022-01-10 09:22:01,551 - INFO - [Step=5750]	Loss=2.7722	275.4 examples/second
2022-01-10 09:22:53,305 - INFO - Test Loss=2.6968, Test top-1 acc=0.3487
2022-01-10 09:22:53,306 - INFO - Group Accuracy:

2022-01-10 09:22:53,306 - INFO - [0.9486747  0.95373493 0.9469879  0.9703615  0.95277107 0.97614455
 0.95253015 0.9501205  0.9657831  0.9549398  0.9614458  0.9501205
 0.9426506  0.94216865 0.9440964  0.96       0.97542167]
2022-01-10 09:22:53,307 - INFO - Saving...
2022-01-10 09:22:53,611 - INFO - Epoch time: 397.38739466667175
2022-01-10 09:22:53,611 - INFO - 
Epoch: 7
2022-01-10 09:22:53,611 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:24:07,537 - INFO - [Step=6000]	Loss=2.6899	254.0 examples/second
2022-01-10 09:26:03,425 - INFO - [Step=6250]	Loss=2.6351	276.1 examples/second
2022-01-10 09:27:59,529 - INFO - [Step=6500]	Loss=2.5787	275.6 examples/second
2022-01-10 09:29:30,889 - INFO - Test Loss=2.5917, Test top-1 acc=0.3875
2022-01-10 09:29:30,889 - INFO - Group Accuracy:

2022-01-10 09:29:30,889 - INFO - [0.95036143 0.95686746 0.95228916 0.9713253  0.9469879  0.9778313
 0.95036143 0.9578313  0.9655422  0.9573494  0.96698797 0.9587952
 0.9477109  0.9433735  0.9477109  0.96       0.9674699 ]
2022-01-10 09:29:30,890 - INFO - Saving...
2022-01-10 09:29:31,203 - INFO - Epoch time: 397.59200716018677
2022-01-10 09:29:31,203 - INFO - 
Epoch: 8
2022-01-10 09:29:31,203 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:30:06,209 - INFO - [Step=6750]	Loss=2.5134	252.6 examples/second
2022-01-10 09:32:02,209 - INFO - [Step=7000]	Loss=2.4506	275.9 examples/second
2022-01-10 09:33:58,202 - INFO - [Step=7250]	Loss=2.4284	275.9 examples/second
2022-01-10 09:35:54,101 - INFO - [Step=7500]	Loss=2.3659	276.1 examples/second
2022-01-10 09:36:08,654 - INFO - Test Loss=2.3091, Test top-1 acc=0.4316
2022-01-10 09:36:08,655 - INFO - Group Accuracy:

2022-01-10 09:36:08,655 - INFO - [0.9578313  0.96457833 0.9573494  0.9787952  0.9506024  0.97614455
 0.9559036  0.96481925 0.97180724 0.95253015 0.96819276 0.9590362
 0.94915664 0.94578314 0.946747   0.96024096 0.9826506 ]
2022-01-10 09:36:08,656 - INFO - Saving...
2022-01-10 09:36:08,938 - INFO - Epoch time: 397.7344877719879
2022-01-10 09:36:08,938 - INFO - 
Epoch: 9
2022-01-10 09:36:08,938 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:38:00,237 - INFO - [Step=7750]	Loss=2.2867	253.7 examples/second
2022-01-10 09:39:55,976 - INFO - [Step=8000]	Loss=2.2765	276.5 examples/second
2022-01-10 09:41:51,907 - INFO - [Step=8250]	Loss=2.2573	276.0 examples/second
2022-01-10 09:42:46,052 - INFO - Test Loss=2.1909, Test top-1 acc=0.4737
2022-01-10 09:42:46,053 - INFO - Group Accuracy:

2022-01-10 09:42:46,053 - INFO - [0.9561446  0.96433735 0.9573494  0.97903615 0.9573494  0.97975904
 0.95662653 0.9655422  0.97518075 0.9590362  0.9662651  0.9628916
 0.94626504 0.94915664 0.95662653 0.96698797 0.97975904]
2022-01-10 09:42:46,054 - INFO - Saving...
2022-01-10 09:42:46,360 - INFO - Epoch time: 397.42182636260986
2022-01-10 09:42:46,360 - INFO - 
Epoch: 10
2022-01-10 09:42:46,360 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:43:58,884 - INFO - [Step=8500]	Loss=2.2166	252.0 examples/second
2022-01-10 09:45:55,322 - INFO - [Step=8750]	Loss=2.1289	274.8 examples/second
2022-01-10 09:47:51,874 - INFO - [Step=9000]	Loss=2.1335	274.6 examples/second
2022-01-10 09:49:25,963 - INFO - Test Loss=2.2022, Test top-1 acc=0.4537
2022-01-10 09:49:25,964 - INFO - Group Accuracy:

2022-01-10 09:49:25,964 - INFO - [0.9580723  0.96168673 0.9554217  0.98024094 0.9561446  0.9812048
 0.95373493 0.9513253  0.97156626 0.9619277  0.9691566  0.9633735
 0.9513253  0.94843376 0.9554217  0.96168673 0.98      ]
2022-01-10 09:49:25,964 - INFO - Epoch time: 399.60423374176025
2022-01-10 09:49:25,964 - INFO - 
Epoch: 11
2022-01-10 09:49:25,965 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:49:58,471 - INFO - [Step=9250]	Loss=2.0967	252.8 examples/second
2022-01-10 09:51:54,519 - INFO - [Step=9500]	Loss=2.0659	275.7 examples/second
2022-01-10 09:53:50,338 - INFO - [Step=9750]	Loss=2.0527	276.3 examples/second
2022-01-10 09:55:46,221 - INFO - [Step=10000]	Loss=2.0212	276.1 examples/second
2022-01-10 09:56:03,129 - INFO - Test Loss=1.9509, Test top-1 acc=0.5084
2022-01-10 09:56:03,129 - INFO - Group Accuracy:

2022-01-10 09:56:03,129 - INFO - [0.96361446 0.9698795  0.9612048  0.97445786 0.9633735  0.98289156
 0.9628916  0.9662651  0.97927713 0.96024096 0.9698795  0.96481925
 0.95036143 0.95036143 0.9554217  0.96361446 0.9814458 ]
2022-01-10 09:56:03,130 - INFO - Saving...
2022-01-10 09:56:03,422 - INFO - Epoch time: 397.4573607444763
2022-01-10 09:56:03,422 - INFO - 
Epoch: 12
2022-01-10 09:56:03,422 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:57:51,912 - INFO - [Step=10250]	Loss=1.9578	254.6 examples/second
2022-01-10 09:59:47,810 - INFO - [Step=10500]	Loss=1.9812	276.1 examples/second
2022-01-10 10:01:43,522 - INFO - [Step=10750]	Loss=1.9529	276.5 examples/second
2022-01-10 10:02:39,781 - INFO - Test Loss=2.1068, Test top-1 acc=0.4928
2022-01-10 10:02:39,782 - INFO - Group Accuracy:

2022-01-10 10:02:39,782 - INFO - [0.9590362  0.9698795  0.95301205 0.97493976 0.9621687  0.9814458
 0.9561446  0.9657831  0.97590363 0.9633735  0.9706024  0.95253015
 0.9510843  0.9431325  0.95975906 0.96433735 0.9840964 ]
2022-01-10 10:02:39,783 - INFO - Epoch time: 396.36047434806824
2022-01-10 10:02:39,783 - INFO - 
Epoch: 13
2022-01-10 10:02:39,783 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:03:49,022 - INFO - [Step=11000]	Loss=1.9304	255.0 examples/second
2022-01-10 10:05:44,923 - INFO - [Step=11250]	Loss=1.8638	276.1 examples/second
2022-01-10 10:07:41,144 - INFO - [Step=11500]	Loss=1.8943	275.3 examples/second
2022-01-10 10:09:17,233 - INFO - Test Loss=1.9939, Test top-1 acc=0.5313
2022-01-10 10:09:17,234 - INFO - Group Accuracy:

2022-01-10 10:09:17,234 - INFO - [0.9655422  0.9739759  0.96457833 0.98024094 0.96506023 0.9855422
 0.95975906 0.9672289  0.973494   0.95975906 0.9768675  0.9660241
 0.9580723  0.9561446  0.9578313  0.9701205  0.9809638 ]
2022-01-10 10:09:17,235 - INFO - Saving...
2022-01-10 10:09:17,612 - INFO - Epoch time: 397.82963728904724
2022-01-10 10:09:17,613 - INFO - 
Epoch: 14
2022-01-10 10:09:17,613 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:09:47,750 - INFO - [Step=11750]	Loss=1.8724	252.8 examples/second
2022-01-10 10:11:43,689 - INFO - [Step=12000]	Loss=1.8300	276.0 examples/second
2022-01-10 10:13:39,576 - INFO - [Step=12250]	Loss=1.8313	276.1 examples/second
2022-01-10 10:15:35,372 - INFO - [Step=12500]	Loss=1.8164	276.3 examples/second
2022-01-10 10:15:54,445 - INFO - Test Loss=1.7502, Test top-1 acc=0.5571
2022-01-10 10:15:54,445 - INFO - Group Accuracy:

2022-01-10 10:15:54,445 - INFO - [0.96457833 0.9787952  0.966747   0.9807229  0.96096385 0.98746985
 0.95638555 0.9686747  0.9780723  0.966747   0.9768675  0.9693976
 0.9587952  0.95638555 0.9612048  0.9713253  0.98771083]
2022-01-10 10:15:54,446 - INFO - Saving...
2022-01-10 10:15:54,750 - INFO - Epoch time: 397.1373498439789
2022-01-10 10:15:54,750 - INFO - 
Epoch: 15
2022-01-10 10:15:54,750 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:17:40,699 - INFO - [Step=12750]	Loss=1.7665	255.3 examples/second
2022-01-10 10:19:36,242 - INFO - [Step=13000]	Loss=1.7758	277.0 examples/second
2022-01-10 10:21:32,154 - INFO - [Step=13250]	Loss=1.7553	276.1 examples/second
2022-01-10 10:22:30,605 - INFO - Test Loss=1.7878, Test top-1 acc=0.5441
2022-01-10 10:22:30,605 - INFO - Group Accuracy:

2022-01-10 10:22:30,605 - INFO - [0.9660241  0.97204816 0.96168673 0.9809638  0.9653012  0.9848193
 0.95710844 0.9727711  0.9773494  0.9672289  0.9703615  0.973253
 0.9583132  0.95710844 0.95373493 0.9674699  0.9853012 ]
2022-01-10 10:22:30,606 - INFO - Epoch time: 395.8558466434479
2022-01-10 10:22:30,606 - INFO - 
Epoch: 16
2022-01-10 10:22:30,606 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:23:37,650 - INFO - [Step=13500]	Loss=1.7375	255.0 examples/second
2022-01-10 10:25:33,036 - INFO - [Step=13750]	Loss=1.7271	277.3 examples/second
2022-01-10 10:27:28,431 - INFO - [Step=14000]	Loss=1.7254	277.3 examples/second
2022-01-10 10:29:06,494 - INFO - Test Loss=1.8603, Test top-1 acc=0.5716
2022-01-10 10:29:06,494 - INFO - Group Accuracy:

2022-01-10 10:29:06,494 - INFO - [0.9686747  0.97951806 0.9693976  0.98433733 0.9662651  0.9886747
 0.9653012  0.9626506  0.9812048  0.9653012  0.9746988  0.9686747
 0.96072286 0.96048194 0.9626506  0.97493976 0.9884337 ]
2022-01-10 10:29:06,495 - INFO - Saving...
2022-01-10 10:29:06,841 - INFO - Epoch time: 396.23495531082153
2022-01-10 10:29:06,842 - INFO - 
Epoch: 17
2022-01-10 10:29:06,842 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:29:34,395 - INFO - [Step=14250]	Loss=1.6861	254.0 examples/second
2022-01-10 10:31:30,276 - INFO - [Step=14500]	Loss=1.6895	276.1 examples/second
2022-01-10 10:33:26,312 - INFO - [Step=14750]	Loss=1.6425	275.8 examples/second
2022-01-10 10:35:22,261 - INFO - [Step=15000]	Loss=1.6525	276.0 examples/second
2022-01-10 10:35:43,829 - INFO - Test Loss=1.9574, Test top-1 acc=0.5494
2022-01-10 10:35:43,829 - INFO - Group Accuracy:

2022-01-10 10:35:43,829 - INFO - [0.9621687  0.9691566  0.9590362  0.98746985 0.9653012  0.9826506
 0.96409637 0.9674699  0.97228914 0.9672289  0.9708434  0.96771085
 0.95638555 0.96024096 0.9578313  0.9657831  0.9855422 ]
2022-01-10 10:35:43,830 - INFO - Epoch time: 396.98805356025696
2022-01-10 10:35:43,830 - INFO - 
Epoch: 18
2022-01-10 10:35:43,830 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:37:27,676 - INFO - [Step=15250]	Loss=1.6440	255.2 examples/second
2022-01-10 10:39:23,708 - INFO - [Step=15500]	Loss=1.6271	275.8 examples/second
2022-01-10 10:41:19,607 - INFO - [Step=15750]	Loss=1.6335	276.1 examples/second
2022-01-10 10:42:20,730 - INFO - Test Loss=1.7433, Test top-1 acc=0.5636
2022-01-10 10:42:20,730 - INFO - Group Accuracy:

2022-01-10 10:42:20,745 - INFO - [0.9660241  0.97493976 0.9691566  0.9826506  0.9626506  0.9879518
 0.9549398  0.973494   0.97204816 0.9662651  0.9746988  0.97228914
 0.95373493 0.9539759  0.9626506  0.9725301  0.9881928 ]
2022-01-10 10:42:20,746 - INFO - Epoch time: 396.91632056236267
2022-01-10 10:42:20,746 - INFO - 
Epoch: 19
2022-01-10 10:42:20,746 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:43:25,270 - INFO - [Step=16000]	Loss=1.6076	254.6 examples/second
2022-01-10 10:45:21,110 - INFO - [Step=16250]	Loss=1.6124	276.2 examples/second
2022-01-10 10:47:16,965 - INFO - [Step=16500]	Loss=1.5822	276.2 examples/second
2022-01-10 10:48:57,816 - INFO - Test Loss=1.6388, Test top-1 acc=0.5952
2022-01-10 10:48:57,816 - INFO - Group Accuracy:

2022-01-10 10:48:57,816 - INFO - [0.9703615  0.9809638  0.9686747  0.9816868  0.9713253  0.9886747
 0.96506023 0.96048194 0.9778313  0.9693976  0.9737349  0.97180724
 0.9592771  0.9551807  0.9628916  0.9737349  0.9879518 ]
2022-01-10 10:48:57,817 - INFO - Saving...
2022-01-10 10:48:58,145 - INFO - Epoch time: 397.39908170700073
2022-01-10 10:48:58,146 - INFO - 
Epoch: 20
2022-01-10 10:48:58,146 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:49:23,310 - INFO - [Step=16750]	Loss=1.5666	253.3 examples/second
2022-01-10 10:51:19,115 - INFO - [Step=17000]	Loss=1.5837	276.3 examples/second
2022-01-10 10:53:14,932 - INFO - [Step=17250]	Loss=1.5578	276.3 examples/second
2022-01-10 10:55:11,175 - INFO - [Step=17500]	Loss=1.5666	275.3 examples/second
2022-01-10 10:55:35,240 - INFO - Test Loss=1.5844, Test top-1 acc=0.5892
2022-01-10 10:55:35,240 - INFO - Group Accuracy:

2022-01-10 10:55:35,240 - INFO - [0.96409637 0.9737349  0.9693976  0.9860241  0.96891564 0.98746985
 0.97108436 0.97156626 0.98313254 0.96819276 0.9785542  0.9725301
 0.9559036  0.9633735  0.9628916  0.96698797 0.9884337 ]
2022-01-10 10:55:35,241 - INFO - Epoch time: 397.09543323516846
2022-01-10 10:55:35,241 - INFO - 
Epoch: 21
2022-01-10 10:55:35,241 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:57:17,562 - INFO - [Step=17750]	Loss=1.5279	253.2 examples/second
2022-01-10 10:59:13,308 - INFO - [Step=18000]	Loss=1.5437	276.5 examples/second
2022-01-10 11:01:09,364 - INFO - [Step=18250]	Loss=1.5367	275.7 examples/second
2022-01-10 11:02:12,528 - INFO - Test Loss=1.5788, Test top-1 acc=0.6149
2022-01-10 11:02:12,529 - INFO - Group Accuracy:

2022-01-10 11:02:12,529 - INFO - [0.966747   0.96819276 0.9701205  0.98578316 0.9727711  0.9893976
 0.9653012  0.9701205  0.9816868  0.9698795  0.97301203 0.9660241
 0.9631325  0.9624096  0.9628916  0.9771084  0.9889157 ]
2022-01-10 11:02:12,530 - INFO - Saving...
2022-01-10 11:02:12,833 - INFO - Epoch time: 397.5914611816406
2022-01-10 11:02:12,833 - INFO - 
Epoch: 22
2022-01-10 11:02:12,833 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:03:15,675 - INFO - [Step=18500]	Loss=1.5095	253.3 examples/second
2022-01-10 11:05:11,492 - INFO - [Step=18750]	Loss=1.5103	276.3 examples/second
2022-01-10 11:07:07,294 - INFO - [Step=19000]	Loss=1.5096	276.3 examples/second
2022-01-10 11:08:49,921 - INFO - Test Loss=1.6691, Test top-1 acc=0.6113
2022-01-10 11:08:49,921 - INFO - Group Accuracy:

2022-01-10 11:08:49,921 - INFO - [0.96506023 0.97927713 0.9696385  0.9812048  0.96       0.98746985
 0.9592771  0.9626506  0.9809638  0.9696385  0.97228914 0.97518075
 0.96361446 0.9621687  0.96385545 0.9780723  0.9879518 ]
2022-01-10 11:08:49,923 - INFO - Epoch time: 397.08976221084595
2022-01-10 11:08:49,923 - INFO - 
Epoch: 23
2022-01-10 11:08:49,923 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:09:12,882 - INFO - [Step=19250]	Loss=1.4943	254.8 examples/second
2022-01-10 11:11:08,819 - INFO - [Step=19500]	Loss=1.4730	276.0 examples/second
2022-01-10 11:13:04,823 - INFO - [Step=19750]	Loss=1.4927	275.9 examples/second
2022-01-10 11:15:00,838 - INFO - [Step=20000]	Loss=1.4962	275.8 examples/second
2022-01-10 11:15:27,112 - INFO - Test Loss=1.5651, Test top-1 acc=0.6166
2022-01-10 11:15:27,112 - INFO - Group Accuracy:

2022-01-10 11:15:27,112 - INFO - [0.9698795  0.9713253  0.9698795  0.9819277  0.9657831  0.98361444
 0.96457833 0.9725301  0.9826506  0.9672289  0.9773494  0.9725301
 0.9657831  0.9660241  0.9628916  0.97566265 0.9884337 ]
2022-01-10 11:15:27,113 - INFO - Saving...
2022-01-10 11:15:27,604 - INFO - Epoch time: 397.68170261383057
2022-01-10 11:15:27,605 - INFO - 
Epoch: 24
2022-01-10 11:15:27,605 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:17:07,408 - INFO - [Step=20250]	Loss=1.4493	252.8 examples/second
2022-01-10 11:19:03,514 - INFO - [Step=20500]	Loss=1.4505	275.6 examples/second
2022-01-10 11:20:59,342 - INFO - [Step=20750]	Loss=1.4626	276.3 examples/second
2022-01-10 11:22:05,267 - INFO - Test Loss=1.5368, Test top-1 acc=0.6347
2022-01-10 11:22:05,267 - INFO - Group Accuracy:

2022-01-10 11:22:05,267 - INFO - [0.96843374 0.9775904  0.9691566  0.98433733 0.9701205  0.98746985
 0.97108436 0.9742169  0.98361444 0.9698795  0.9746988  0.973494
 0.96506023 0.96506023 0.9628916  0.973494   0.9893976 ]
2022-01-10 11:22:05,268 - INFO - Saving...
2022-01-10 11:22:05,564 - INFO - Epoch time: 397.9598002433777
2022-01-10 11:22:05,565 - INFO - 
Epoch: 25
2022-01-10 11:22:05,565 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:23:05,741 - INFO - [Step=21000]	Loss=1.4497	253.2 examples/second
2022-01-10 11:25:01,741 - INFO - [Step=21250]	Loss=1.4457	275.9 examples/second
2022-01-10 11:26:57,833 - INFO - [Step=21500]	Loss=1.4553	275.6 examples/second
2022-01-10 11:28:43,256 - INFO - Test Loss=1.6058, Test top-1 acc=0.6267
2022-01-10 11:28:43,256 - INFO - Group Accuracy:

2022-01-10 11:28:43,256 - INFO - [0.9706024  0.9814458  0.96168673 0.9819277  0.9708434  0.98698795
 0.95373493 0.9727711  0.98433733 0.9631325  0.9833735  0.96795183
 0.9624096  0.9655422  0.96481925 0.9773494  0.98746985]
2022-01-10 11:28:43,257 - INFO - Epoch time: 397.69225025177
2022-01-10 11:28:43,257 - INFO - 
Epoch: 26
2022-01-10 11:28:43,257 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:29:04,168 - INFO - [Step=21750]	Loss=1.4354	253.3 examples/second
2022-01-10 11:31:00,125 - INFO - [Step=22000]	Loss=1.4321	276.0 examples/second
2022-01-10 11:32:55,959 - INFO - [Step=22250]	Loss=1.4300	276.3 examples/second
2022-01-10 11:34:51,868 - INFO - [Step=22500]	Loss=1.4469	276.1 examples/second
2022-01-10 11:35:20,421 - INFO - Test Loss=1.7510, Test top-1 acc=0.5916
2022-01-10 11:35:20,422 - INFO - Group Accuracy:

2022-01-10 11:35:20,422 - INFO - [0.96048194 0.97301203 0.9549398  0.9771084  0.9674699  0.98771083
 0.96433735 0.96771085 0.9804819  0.9672289  0.97108436 0.96795183
 0.95975906 0.96168673 0.9619277  0.9737349  0.9884337 ]
2022-01-10 11:35:20,424 - INFO - Epoch time: 397.1664848327637
2022-01-10 11:35:20,424 - INFO - 
Epoch: 27
2022-01-10 11:35:20,424 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:36:57,432 - INFO - [Step=22750]	Loss=1.3960	254.9 examples/second
2022-01-10 11:38:53,204 - INFO - [Step=23000]	Loss=1.3999	276.4 examples/second
2022-01-10 11:40:49,151 - INFO - [Step=23250]	Loss=1.4154	276.0 examples/second
2022-01-10 11:41:57,014 - INFO - Test Loss=1.5331, Test top-1 acc=0.6229
2022-01-10 11:41:57,014 - INFO - Group Accuracy:

2022-01-10 11:41:57,015 - INFO - [0.9686747  0.9809638  0.9691566  0.98650604 0.97445786 0.9901205
 0.96843374 0.9727711  0.97951806 0.9706024  0.97903615 0.9708434
 0.96481925 0.9660241  0.96048194 0.97156626 0.9893976 ]
2022-01-10 11:41:57,016 - INFO - Epoch time: 396.59180212020874
2022-01-10 11:41:57,016 - INFO - 
Epoch: 28
2022-01-10 11:41:57,016 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:42:54,720 - INFO - [Step=23500]	Loss=1.4002	254.8 examples/second
2022-01-10 11:44:50,338 - INFO - [Step=23750]	Loss=1.3873	276.8 examples/second
2022-01-10 11:46:46,135 - INFO - [Step=24000]	Loss=1.4149	276.3 examples/second
2022-01-10 11:48:33,465 - INFO - Test Loss=1.5670, Test top-1 acc=0.6335
2022-01-10 11:48:33,465 - INFO - Group Accuracy:

2022-01-10 11:48:33,465 - INFO - [0.96795183 0.97951806 0.9725301  0.9845783  0.9739759  0.9860241
 0.9698795  0.9725301  0.9821687  0.96771085 0.9773494  0.966506
 0.95759034 0.96843374 0.9672289  0.9775904  0.98626506]
2022-01-10 11:48:33,466 - INFO - Epoch time: 396.45025992393494
2022-01-10 11:48:33,466 - INFO - 
Epoch: 29
2022-01-10 11:48:33,466 - INFO - 
Learning Rate: 0.0100
2022-01-10 11:48:51,914 - INFO - [Step=24250]	Loss=1.3487	254.4 examples/second
2022-01-10 11:50:47,622 - INFO - [Step=24500]	Loss=1.0814	276.6 examples/second
2022-01-10 11:52:43,571 - INFO - [Step=24750]	Loss=1.0159	276.0 examples/second
2022-01-10 11:54:40,029 - INFO - [Step=25000]	Loss=0.9848	274.8 examples/second
2022-01-10 11:55:11,141 - INFO - Test Loss=0.9852, Test top-1 acc=0.7494
2022-01-10 11:55:11,142 - INFO - Group Accuracy:

2022-01-10 11:55:11,142 - INFO - [0.9766265  0.98963857 0.9821687  0.9927711  0.9816868  0.9939759
 0.9773494  0.98313254 0.98963857 0.97614455 0.98746985 0.98240966
 0.9746988  0.97903615 0.97493976 0.9848193  0.9920482 ]
2022-01-10 11:55:11,142 - INFO - Saving...
2022-01-10 11:55:11,441 - INFO - Epoch time: 397.97540616989136
2022-01-10 11:55:11,442 - INFO - 
Epoch: 30
2022-01-10 11:55:11,442 - INFO - 
Learning Rate: 0.0100
2022-01-10 11:56:46,691 - INFO - [Step=25250]	Loss=0.9455	252.6 examples/second
2022-01-10 11:58:42,926 - INFO - [Step=25500]	Loss=0.9419	275.3 examples/second
2022-01-10 12:00:39,118 - INFO - [Step=25750]	Loss=0.9284	275.4 examples/second
2022-01-10 12:01:49,436 - INFO - Test Loss=0.9071, Test top-1 acc=0.7506
2022-01-10 12:01:49,436 - INFO - Group Accuracy:

2022-01-10 12:01:49,436 - INFO - [0.97566265 0.9889157  0.98313254 0.9930121  0.9821687  0.99445784
 0.97927713 0.98289156 0.9893976  0.97638553 0.9879518  0.9833735
 0.97638553 0.97903615 0.9742169  0.98578316 0.993494  ]
2022-01-10 12:01:49,438 - INFO - Saving...
2022-01-10 12:01:49,740 - INFO - Epoch time: 398.29775309562683
2022-01-10 12:01:49,740 - INFO - 
Epoch: 31
2022-01-10 12:01:49,740 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:02:45,452 - INFO - [Step=26000]	Loss=0.9303	253.3 examples/second
2022-01-10 12:04:41,401 - INFO - [Step=26250]	Loss=0.9079	276.0 examples/second
2022-01-10 12:06:37,275 - INFO - [Step=26500]	Loss=0.9137	276.2 examples/second
2022-01-10 12:08:27,315 - INFO - Test Loss=0.9445, Test top-1 acc=0.7564
2022-01-10 12:08:27,316 - INFO - Group Accuracy:

2022-01-10 12:08:27,316 - INFO - [0.9773494  0.9898795  0.9833735  0.9930121  0.9816868  0.99421686
 0.98       0.9826506  0.99036145 0.9766265  0.9893976  0.98289156
 0.97638553 0.98       0.97518075 0.9848193  0.993253  ]
2022-01-10 12:08:27,317 - INFO - Saving...
2022-01-10 12:08:27,613 - INFO - Epoch time: 397.8734471797943
2022-01-10 12:08:27,614 - INFO - 
Epoch: 32
2022-01-10 12:08:27,614 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:08:43,784 - INFO - [Step=26750]	Loss=0.8976	252.9 examples/second
2022-01-10 12:10:39,608 - INFO - [Step=27000]	Loss=0.8906	276.3 examples/second
2022-01-10 12:12:35,418 - INFO - [Step=27250]	Loss=0.8868	276.3 examples/second
2022-01-10 12:14:31,268 - INFO - [Step=27500]	Loss=0.8809	276.2 examples/second
2022-01-10 12:15:04,399 - INFO - Test Loss=0.9690, Test top-1 acc=0.7605
2022-01-10 12:15:04,400 - INFO - Group Accuracy:

2022-01-10 12:15:04,400 - INFO - [0.9775904  0.98963857 0.9840964  0.9922892  0.9821687  0.99421686
 0.98       0.98289156 0.99036145 0.9768675  0.98722893 0.9838554
 0.97638553 0.9807229  0.97493976 0.98771083 0.9946988 ]
2022-01-10 12:15:04,400 - INFO - Saving...
2022-01-10 12:15:04,694 - INFO - Epoch time: 397.07992792129517
2022-01-10 12:15:04,694 - INFO - 
Epoch: 33
2022-01-10 12:15:04,694 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:16:37,261 - INFO - [Step=27750]	Loss=0.8559	254.0 examples/second
2022-01-10 12:18:33,376 - INFO - [Step=28000]	Loss=0.8555	275.6 examples/second
2022-01-10 12:20:29,325 - INFO - [Step=28250]	Loss=0.8657	276.0 examples/second
2022-01-10 12:21:42,148 - INFO - Test Loss=0.9263, Test top-1 acc=0.7547
2022-01-10 12:21:42,148 - INFO - Group Accuracy:

2022-01-10 12:21:42,148 - INFO - [0.9771084  0.9891566  0.9838554  0.9925301  0.9819277  0.99445784
 0.9804819  0.98240966 0.9891566  0.97566265 0.98771083 0.9840964
 0.9746988  0.9807229  0.97542167 0.98650604 0.993494  ]
2022-01-10 12:21:42,149 - INFO - Epoch time: 397.4551296234131
2022-01-10 12:21:42,149 - INFO - 
Epoch: 34
2022-01-10 12:21:42,149 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:22:35,640 - INFO - [Step=28500]	Loss=0.8437	253.3 examples/second
2022-01-10 12:24:31,462 - INFO - [Step=28750]	Loss=0.8389	276.3 examples/second
2022-01-10 12:26:27,595 - INFO - [Step=29000]	Loss=0.8533	275.5 examples/second
2022-01-10 12:28:19,994 - INFO - Test Loss=0.8930, Test top-1 acc=0.7622
2022-01-10 12:28:19,994 - INFO - Group Accuracy:

2022-01-10 12:28:19,994 - INFO - [0.97951806 0.9898795  0.9845783  0.9918072  0.9812048  0.99493974
 0.9814458  0.98313254 0.99036145 0.9780723  0.9879518  0.98289156
 0.97493976 0.9780723  0.9768675  0.9884337  0.9922892 ]
2022-01-10 12:28:19,995 - INFO - Saving...
2022-01-10 12:28:20,307 - INFO - Epoch time: 398.1577522754669
2022-01-10 12:28:20,307 - INFO - 
Epoch: 35
2022-01-10 12:28:20,307 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:28:33,851 - INFO - [Step=29250]	Loss=0.8656	253.5 examples/second
2022-01-10 12:30:30,124 - INFO - [Step=29500]	Loss=0.8337	275.2 examples/second
2022-01-10 12:32:26,708 - INFO - [Step=29750]	Loss=0.8312	274.5 examples/second
2022-01-10 12:34:23,347 - INFO - [Step=30000]	Loss=0.8373	274.4 examples/second
2022-01-10 12:34:58,835 - INFO - Test Loss=0.8722, Test top-1 acc=0.7619
2022-01-10 12:34:58,835 - INFO - Group Accuracy:

2022-01-10 12:34:58,835 - INFO - [0.97903615 0.99084336 0.98313254 0.993253   0.9816868  0.99421686
 0.97927713 0.9840964  0.9898795  0.9773494  0.9886747  0.98433733
 0.9768675  0.98       0.97638553 0.98722893 0.99493974]
2022-01-10 12:34:58,836 - INFO - Epoch time: 398.5292897224426
2022-01-10 12:34:58,836 - INFO - 
Epoch: 36
2022-01-10 12:34:58,837 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:36:30,027 - INFO - [Step=30250]	Loss=0.8372	252.6 examples/second
2022-01-10 12:38:26,002 - INFO - [Step=30500]	Loss=0.8225	275.9 examples/second
2022-01-10 12:40:22,049 - INFO - [Step=30750]	Loss=0.8208	275.8 examples/second
2022-01-10 12:41:37,372 - INFO - Test Loss=0.9038, Test top-1 acc=0.7670
2022-01-10 12:41:37,372 - INFO - Group Accuracy:

2022-01-10 12:41:37,372 - INFO - [0.9775904  0.98963857 0.9838554  0.9922892  0.9821687  0.993253
 0.9809638  0.9826506  0.99108434 0.97445786 0.9879518  0.9833735
 0.97542167 0.9807229  0.9746988  0.98771083 0.99421686]
2022-01-10 12:41:37,373 - INFO - Saving...
2022-01-10 12:41:37,649 - INFO - Epoch time: 398.81297278404236
2022-01-10 12:41:37,650 - INFO - 
Epoch: 37
2022-01-10 12:41:37,650 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:42:28,290 - INFO - [Step=31000]	Loss=0.8219	253.5 examples/second
2022-01-10 12:44:23,637 - INFO - [Step=31250]	Loss=0.7958	277.4 examples/second
2022-01-10 12:46:18,859 - INFO - [Step=31500]	Loss=0.8129	277.7 examples/second
2022-01-10 12:48:12,554 - INFO - Test Loss=0.8946, Test top-1 acc=0.7701
2022-01-10 12:48:12,554 - INFO - Group Accuracy:

2022-01-10 12:48:12,554 - INFO - [0.97927713 0.99036145 0.98289156 0.9918072  0.9816868  0.99445784
 0.98240966 0.98313254 0.99060243 0.97493976 0.98771083 0.98289156
 0.97831327 0.97975904 0.9771084  0.98722893 0.99445784]
2022-01-10 12:48:12,555 - INFO - Saving...
2022-01-10 12:48:12,822 - INFO - Epoch time: 395.17203664779663
2022-01-10 12:48:12,822 - INFO - 
Epoch: 38
2022-01-10 12:48:12,822 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:48:24,140 - INFO - [Step=31750]	Loss=0.8129	255.4 examples/second
2022-01-10 12:50:19,244 - INFO - [Step=32000]	Loss=0.7870	278.0 examples/second
2022-01-10 12:52:14,233 - INFO - [Step=32250]	Loss=0.7968	278.3 examples/second
2022-01-10 12:54:09,352 - INFO - [Step=32500]	Loss=0.8104	278.0 examples/second
2022-01-10 12:54:46,887 - INFO - Test Loss=1.0613, Test top-1 acc=0.7641
2022-01-10 12:54:46,888 - INFO - Group Accuracy:

2022-01-10 12:54:46,888 - INFO - [0.9778313  0.9889157  0.9833735  0.993494   0.98240966 0.993253
 0.97903615 0.9833735  0.99084336 0.9766265  0.9893976  0.9845783
 0.9773494  0.97927713 0.97518075 0.98746985 0.99421686]
2022-01-10 12:54:46,889 - INFO - Epoch time: 394.0668752193451
2022-01-10 12:54:46,889 - INFO - 
Epoch: 39
2022-01-10 12:54:46,889 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:56:14,119 - INFO - [Step=32750]	Loss=0.7861	256.5 examples/second
2022-01-10 12:58:09,183 - INFO - [Step=33000]	Loss=0.7952	278.1 examples/second
2022-01-10 13:00:04,275 - INFO - [Step=33250]	Loss=0.7753	278.0 examples/second
2022-01-10 13:01:20,779 - INFO - Test Loss=0.9331, Test top-1 acc=0.7646
2022-01-10 13:01:20,779 - INFO - Group Accuracy:

2022-01-10 13:01:20,779 - INFO - [0.9771084  0.9901205  0.98433733 0.99421686 0.9812048  0.993494
 0.9814458  0.98361444 0.9893976  0.9771084  0.9901205  0.98313254
 0.9771084  0.97951806 0.9778313  0.98722893 0.99445784]
2022-01-10 13:01:20,781 - INFO - Epoch time: 393.8916277885437
2022-01-10 13:01:20,781 - INFO - 
Epoch: 40
2022-01-10 13:01:20,781 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:02:08,917 - INFO - [Step=33500]	Loss=0.7883	256.7 examples/second
2022-01-10 13:04:04,230 - INFO - [Step=33750]	Loss=0.7671	277.5 examples/second
2022-01-10 13:05:59,312 - INFO - [Step=34000]	Loss=0.7801	278.1 examples/second
2022-01-10 13:07:55,012 - INFO - Test Loss=0.9061, Test top-1 acc=0.7576
2022-01-10 13:07:55,012 - INFO - Group Accuracy:

2022-01-10 13:07:55,012 - INFO - [0.97903615 0.98963857 0.98433733 0.9939759  0.9809638  0.9939759
 0.9814458  0.9814458  0.9901205  0.9775904  0.9898795  0.9838554
 0.97590363 0.9780723  0.97518075 0.98771083 0.99493974]
2022-01-10 13:07:55,013 - INFO - Epoch time: 394.2319800853729
2022-01-10 13:07:55,013 - INFO - 
Epoch: 41
2022-01-10 13:07:55,013 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:08:03,842 - INFO - [Step=34250]	Loss=0.7784	257.0 examples/second
2022-01-10 13:09:59,012 - INFO - [Step=34500]	Loss=0.7626	277.8 examples/second
2022-01-10 13:11:54,147 - INFO - [Step=34750]	Loss=0.7732	277.9 examples/second
2022-01-10 13:13:49,275 - INFO - [Step=35000]	Loss=0.7714	278.0 examples/second
2022-01-10 13:14:29,017 - INFO - Test Loss=0.9103, Test top-1 acc=0.7670
2022-01-10 13:14:29,018 - INFO - Group Accuracy:

2022-01-10 13:14:29,018 - INFO - [0.9787952  0.99084336 0.9860241  0.9925301  0.98289156 0.99421686
 0.9826506  0.98240966 0.9901205  0.9746988  0.98771083 0.9848193
 0.97566265 0.9819277  0.97542167 0.98698795 0.9954217 ]
2022-01-10 13:14:29,019 - INFO - Epoch time: 394.0061240196228
2022-01-10 13:14:29,019 - INFO - 
Epoch: 42
2022-01-10 13:14:29,019 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:15:53,932 - INFO - [Step=35250]	Loss=0.7538	256.7 examples/second
2022-01-10 13:17:49,079 - INFO - [Step=35500]	Loss=0.7587	277.9 examples/second
2022-01-10 13:19:44,249 - INFO - [Step=35750]	Loss=0.7753	277.9 examples/second
2022-01-10 13:21:03,016 - INFO - Test Loss=0.8756, Test top-1 acc=0.7634
2022-01-10 13:21:03,017 - INFO - Group Accuracy:

2022-01-10 13:21:03,017 - INFO - [0.98       0.99060243 0.9848193  0.9913253  0.98289156 0.9939759
 0.9809638  0.98433733 0.99060243 0.97518075 0.99036145 0.98289156
 0.9773494  0.9787952  0.9768675  0.98626506 0.9954217 ]
2022-01-10 13:21:03,019 - INFO - Epoch time: 393.9997138977051
2022-01-10 13:21:03,019 - INFO - 
Epoch: 43
2022-01-10 13:21:03,019 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:21:48,634 - INFO - [Step=36000]	Loss=0.7336	257.3 examples/second
2022-01-10 13:23:43,716 - INFO - [Step=36250]	Loss=0.7359	278.1 examples/second
2022-01-10 13:25:38,897 - INFO - [Step=36500]	Loss=0.7534	277.8 examples/second
2022-01-10 13:27:37,100 - INFO - Test Loss=0.8854, Test top-1 acc=0.7711
2022-01-10 13:27:37,101 - INFO - Group Accuracy:

2022-01-10 13:27:37,101 - INFO - [0.97831327 0.9901205  0.9855422  0.993494   0.98289156 0.9939759
 0.98024094 0.9816868  0.99156624 0.97590363 0.98963857 0.98578316
 0.97831327 0.97975904 0.97566265 0.9884337  0.9959036 ]
2022-01-10 13:27:37,102 - INFO - Saving...
2022-01-10 13:27:37,437 - INFO - Epoch time: 394.41748881340027
2022-01-10 13:27:37,437 - INFO - 
Epoch: 44
2022-01-10 13:27:37,437 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:27:44,107 - INFO - [Step=36750]	Loss=0.7488	255.6 examples/second
2022-01-10 13:29:39,132 - INFO - [Step=37000]	Loss=0.7196	278.2 examples/second
2022-01-10 13:31:34,226 - INFO - [Step=37250]	Loss=0.7442	278.0 examples/second
2022-01-10 13:33:29,534 - INFO - [Step=37500]	Loss=0.7455	277.5 examples/second
2022-01-10 13:34:11,557 - INFO - Test Loss=0.8504, Test top-1 acc=0.7660
2022-01-10 13:34:11,558 - INFO - Group Accuracy:

2022-01-10 13:34:11,558 - INFO - [0.9778313  0.9893976  0.9838554  0.9927711  0.9819277  0.9939759
 0.9814458  0.9812048  0.9893976  0.97445786 0.9884337  0.9840964
 0.9778313  0.97927713 0.97590363 0.98746985 0.9956626 ]
2022-01-10 13:34:11,559 - INFO - Epoch time: 394.1220393180847
2022-01-10 13:34:11,559 - INFO - 
Epoch: 45
2022-01-10 13:34:11,559 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:35:34,296 - INFO - [Step=37750]	Loss=0.7270	256.5 examples/second
2022-01-10 13:37:29,412 - INFO - [Step=38000]	Loss=0.7388	278.0 examples/second
2022-01-10 13:39:24,740 - INFO - [Step=38250]	Loss=0.7493	277.5 examples/second
2022-01-10 13:40:46,308 - INFO - Test Loss=0.8632, Test top-1 acc=0.7701
2022-01-10 13:40:46,309 - INFO - Group Accuracy:

2022-01-10 13:40:46,309 - INFO - [0.9785542  0.9893976  0.98240966 0.993253   0.98289156 0.993494
 0.9814458  0.9840964  0.9901205  0.97542167 0.9893976  0.98433733
 0.9771084  0.9812048  0.97614455 0.9891566  0.9939759 ]
2022-01-10 13:40:46,310 - INFO - Epoch time: 394.7506904602051
2022-01-10 13:40:46,310 - INFO - 
Epoch: 46
2022-01-10 13:40:46,310 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:41:30,139 - INFO - [Step=38500]	Loss=0.7276	255.2 examples/second
2022-01-10 13:43:25,334 - INFO - [Step=38750]	Loss=0.7291	277.8 examples/second
2022-01-10 13:45:20,389 - INFO - [Step=39000]	Loss=0.7124	278.1 examples/second
2022-01-10 13:47:21,119 - INFO - Test Loss=0.8934, Test top-1 acc=0.7655
2022-01-10 13:47:21,120 - INFO - Group Accuracy:

2022-01-10 13:47:21,120 - INFO - [0.97903615 0.9898795  0.98289156 0.9925301  0.98240966 0.9930121
 0.9814458  0.98433733 0.9893976  0.9737349  0.9898795  0.98240966
 0.97614455 0.9809638  0.97590363 0.98771083 0.9946988 ]
2022-01-10 13:47:21,121 - INFO - Epoch time: 394.810911655426
2022-01-10 13:47:21,121 - INFO - 
Epoch: 47
2022-01-10 13:47:21,121 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:47:25,563 - INFO - [Step=39250]	Loss=0.7242	255.6 examples/second
2022-01-10 13:49:20,760 - INFO - [Step=39500]	Loss=0.7178	277.8 examples/second
2022-01-10 13:51:15,836 - INFO - [Step=39750]	Loss=0.7192	278.1 examples/second
2022-01-10 13:53:11,053 - INFO - [Step=40000]	Loss=0.7175	277.7 examples/second
2022-01-10 13:53:55,352 - INFO - Test Loss=0.9133, Test top-1 acc=0.7704
2022-01-10 13:53:55,353 - INFO - Group Accuracy:

2022-01-10 13:53:55,353 - INFO - [0.97975904 0.9889157  0.98240966 0.9930121  0.98289156 0.993494
 0.98240966 0.9812048  0.9893976  0.97614455 0.9913253  0.9845783
 0.97614455 0.9821687  0.97228914 0.9884337  0.9963855 ]
2022-01-10 13:53:55,353 - INFO - Epoch time: 394.23265743255615
2022-01-10 13:53:55,353 - INFO - 
Epoch: 48
2022-01-10 13:53:55,354 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:55:15,578 - INFO - [Step=40250]	Loss=0.6992	257.0 examples/second
2022-01-10 13:57:10,868 - INFO - [Step=40500]	Loss=0.7085	277.6 examples/second
2022-01-10 13:59:06,101 - INFO - [Step=40750]	Loss=0.7067	277.7 examples/second
2022-01-10 14:00:29,657 - INFO - Test Loss=0.9447, Test top-1 acc=0.7624
2022-01-10 14:00:29,657 - INFO - Group Accuracy:

2022-01-10 14:00:29,657 - INFO - [0.9778313  0.98746985 0.9845783  0.9913253  0.98313254 0.9939759
 0.9814458  0.9804819  0.9893976  0.97614455 0.9886747  0.9850602
 0.9778313  0.9807229  0.9742169  0.9879518  0.99421686]
2022-01-10 14:00:29,658 - INFO - Epoch time: 394.3040659427643
2022-01-10 14:00:29,658 - INFO - 
Epoch: 49
2022-01-10 14:00:29,658 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:01:10,756 - INFO - [Step=41000]	Loss=0.7034	256.7 examples/second
2022-01-10 14:03:05,896 - INFO - [Step=41250]	Loss=0.7006	277.9 examples/second
2022-01-10 14:05:01,093 - INFO - [Step=41500]	Loss=0.7045	277.8 examples/second
2022-01-10 14:06:56,213 - INFO - [Step=41750]	Loss=0.7066	278.0 examples/second
2022-01-10 14:07:03,687 - INFO - Test Loss=0.8689, Test top-1 acc=0.7694
2022-01-10 14:07:03,687 - INFO - Group Accuracy:

2022-01-10 14:07:03,687 - INFO - [0.97903615 0.99084336 0.98289156 0.9930121  0.9838554  0.99421686
 0.97927713 0.9819277  0.99036145 0.9742169  0.9879518  0.9840964
 0.9773494  0.9819277  0.9737349  0.98626506 0.99493974]
2022-01-10 14:07:03,688 - INFO - Epoch time: 394.0307900905609
2022-01-10 14:07:03,688 - INFO - 
Epoch: 50
2022-01-10 14:07:03,689 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:09:00,825 - INFO - [Step=42000]	Loss=0.6965	256.8 examples/second
2022-01-10 14:10:55,890 - INFO - [Step=42250]	Loss=0.6959	278.1 examples/second
2022-01-10 14:12:51,152 - INFO - [Step=42500]	Loss=0.7135	277.6 examples/second
2022-01-10 14:13:37,751 - INFO - Test Loss=0.9356, Test top-1 acc=0.7629
2022-01-10 14:13:37,752 - INFO - Group Accuracy:

2022-01-10 14:13:37,752 - INFO - [0.9804819  0.9889157  0.9821687  0.9922892  0.9821687  0.99373496
 0.98       0.98       0.9893976  0.9778313  0.98746985 0.9833735
 0.9746988  0.97903615 0.97614455 0.98674697 0.99445784]
2022-01-10 14:13:37,753 - INFO - Epoch time: 394.0643346309662
2022-01-10 14:13:37,753 - INFO - 
Epoch: 51
2022-01-10 14:13:37,753 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:14:55,637 - INFO - [Step=42750]	Loss=0.6799	257.1 examples/second
2022-01-10 14:16:50,644 - INFO - [Step=43000]	Loss=0.6882	278.2 examples/second
2022-01-10 14:18:45,677 - INFO - [Step=43250]	Loss=0.6973	278.2 examples/second
2022-01-10 14:20:11,755 - INFO - Test Loss=0.9607, Test top-1 acc=0.7682
2022-01-10 14:20:11,756 - INFO - Group Accuracy:

2022-01-10 14:20:11,756 - INFO - [0.9807229  0.9884337  0.9838554  0.9939759  0.9812048  0.9939759
 0.9814458  0.9804819  0.9886747  0.9766265  0.9891566  0.9848193
 0.97542167 0.9804819  0.9746988  0.9879518  0.9954217 ]
2022-01-10 14:20:11,757 - INFO - Epoch time: 394.0038278102875
2022-01-10 14:20:11,757 - INFO - 
Epoch: 52
2022-01-10 14:20:11,757 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:20:51,078 - INFO - [Step=43500]	Loss=0.7137	255.2 examples/second
2022-01-10 14:22:46,586 - INFO - [Step=43750]	Loss=0.6782	277.0 examples/second
2022-01-10 14:24:41,969 - INFO - [Step=44000]	Loss=0.7157	277.3 examples/second
2022-01-10 14:26:37,393 - INFO - [Step=44250]	Loss=0.6896	277.2 examples/second
2022-01-10 14:26:47,536 - INFO - Test Loss=0.9215, Test top-1 acc=0.7692
2022-01-10 14:26:47,537 - INFO - Group Accuracy:

2022-01-10 14:26:47,537 - INFO - [0.97903615 0.99108434 0.9848193  0.9927711  0.9821687  0.99493974
 0.9812048  0.98361444 0.98963857 0.97518075 0.9889157  0.9826506
 0.9766265  0.9809638  0.97590363 0.98698795 0.99445784]
2022-01-10 14:26:47,538 - INFO - Epoch time: 395.7811453342438
2022-01-10 14:26:47,538 - INFO - 
Epoch: 53
2022-01-10 14:26:47,538 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:28:43,017 - INFO - [Step=44500]	Loss=0.6632	254.7 examples/second
2022-01-10 14:30:38,250 - INFO - [Step=44750]	Loss=0.6750	277.7 examples/second
2022-01-10 14:32:33,516 - INFO - [Step=45000]	Loss=0.6858	277.6 examples/second
2022-01-10 14:33:22,603 - INFO - Test Loss=0.9124, Test top-1 acc=0.7680
2022-01-10 14:33:22,604 - INFO - Group Accuracy:

2022-01-10 14:33:22,604 - INFO - [0.9785542  0.9901205  0.98289156 0.99373496 0.98289156 0.993494
 0.97903615 0.9821687  0.9884337  0.9768675  0.9891566  0.9838554
 0.97493976 0.9812048  0.97638553 0.98578316 0.99445784]
2022-01-10 14:33:22,605 - INFO - Epoch time: 395.0666129589081
2022-01-10 14:33:22,605 - INFO - 
Epoch: 54
2022-01-10 14:33:22,605 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:34:38,648 - INFO - [Step=45250]	Loss=0.6749	255.7 examples/second
2022-01-10 14:36:34,069 - INFO - [Step=45500]	Loss=0.6711	277.2 examples/second
2022-01-10 14:38:29,247 - INFO - [Step=45750]	Loss=0.6847	277.8 examples/second
2022-01-10 14:39:57,514 - INFO - Test Loss=0.8997, Test top-1 acc=0.7754
2022-01-10 14:39:57,515 - INFO - Group Accuracy:

2022-01-10 14:39:57,525 - INFO - [0.98024094 0.98963857 0.9819277  0.9925301  0.9816868  0.9939759
 0.9821687  0.9838554  0.99060243 0.97566265 0.99036145 0.9833735
 0.9787952  0.9807229  0.97542167 0.98722893 0.9968675 ]
2022-01-10 14:39:57,526 - INFO - Saving...
2022-01-10 14:39:57,786 - INFO - Epoch time: 395.18142676353455
2022-01-10 14:39:57,787 - INFO - 
Epoch: 55
2022-01-10 14:39:57,787 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:40:34,652 - INFO - [Step=46000]	Loss=0.6801	255.2 examples/second
2022-01-10 14:42:29,867 - INFO - [Step=46250]	Loss=0.6599	277.7 examples/second
2022-01-10 14:44:24,924 - INFO - [Step=46500]	Loss=0.6784	278.1 examples/second
2022-01-10 14:46:20,174 - INFO - [Step=46750]	Loss=0.6800	277.7 examples/second
2022-01-10 14:46:32,270 - INFO - Test Loss=0.9784, Test top-1 acc=0.7740
2022-01-10 14:46:32,270 - INFO - Group Accuracy:

2022-01-10 14:46:32,270 - INFO - [0.9778313  0.9893976  0.9853012  0.9925301  0.9833735  0.9939759
 0.9814458  0.9816868  0.9891566  0.9778313  0.9891566  0.9838554
 0.9771084  0.98024094 0.97590363 0.98771083 0.9954217 ]
2022-01-10 14:46:32,271 - INFO - Epoch time: 394.48457765579224
2022-01-10 14:46:32,271 - INFO - 
Epoch: 56
2022-01-10 14:46:32,271 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:48:24,894 - INFO - [Step=47000]	Loss=0.6495	256.6 examples/second
2022-01-10 14:50:20,111 - INFO - [Step=47250]	Loss=0.6540	277.7 examples/second
2022-01-10 14:52:15,500 - INFO - [Step=47500]	Loss=0.6778	277.3 examples/second
2022-01-10 14:53:06,580 - INFO - Test Loss=0.9144, Test top-1 acc=0.7648
2022-01-10 14:53:06,580 - INFO - Group Accuracy:

2022-01-10 14:53:06,580 - INFO - [0.97927713 0.99036145 0.9850602  0.9922892  0.9804819  0.993494
 0.9809638  0.98       0.9879518  0.97542167 0.9889157  0.98433733
 0.9768675  0.9780723  0.97614455 0.9879518  0.99373496]
2022-01-10 14:53:06,581 - INFO - Epoch time: 394.30992913246155
2022-01-10 14:53:06,581 - INFO - 
Epoch: 57
2022-01-10 14:53:06,581 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:54:20,057 - INFO - [Step=47750]	Loss=0.6562	256.9 examples/second
2022-01-10 14:56:15,247 - INFO - [Step=48000]	Loss=0.6485	277.8 examples/second
2022-01-10 14:58:10,526 - INFO - [Step=48250]	Loss=0.6705	277.6 examples/second
2022-01-10 14:59:41,256 - INFO - Test Loss=0.9159, Test top-1 acc=0.7720
2022-01-10 14:59:41,257 - INFO - Group Accuracy:

2022-01-10 14:59:41,257 - INFO - [0.98       0.9898795  0.9855422  0.993253   0.98289156 0.99445784
 0.9804819  0.9819277  0.9891566  0.9766265  0.99156624 0.98361444
 0.97638553 0.9773494  0.9766265  0.98746985 0.9959036 ]
2022-01-10 14:59:41,258 - INFO - Epoch time: 394.67689538002014
2022-01-10 14:59:41,258 - INFO - 
Epoch: 58
2022-01-10 14:59:41,258 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:00:15,344 - INFO - [Step=48500]	Loss=0.6685	256.4 examples/second
2022-01-10 15:02:10,237 - INFO - [Step=48750]	Loss=0.6667	278.5 examples/second
2022-01-10 15:04:05,391 - INFO - [Step=49000]	Loss=0.6610	277.9 examples/second
2022-01-10 15:06:00,873 - INFO - [Step=49250]	Loss=0.6645	277.1 examples/second
2022-01-10 15:06:15,393 - INFO - Test Loss=0.9303, Test top-1 acc=0.7687
2022-01-10 15:06:15,394 - INFO - Group Accuracy:

2022-01-10 15:06:15,394 - INFO - [0.98       0.9901205  0.98313254 0.9930121  0.9816868  0.99421686
 0.98       0.98289156 0.9898795  0.9773494  0.9901205  0.9838554
 0.97566265 0.97831327 0.9746988  0.9855422  0.9963855 ]
2022-01-10 15:06:15,395 - INFO - Epoch time: 394.1364948749542
2022-01-10 15:06:15,395 - INFO - 
Epoch: 59
2022-01-10 15:06:15,395 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:08:05,977 - INFO - [Step=49500]	Loss=0.6147	255.8 examples/second
2022-01-10 15:10:01,001 - INFO - [Step=49750]	Loss=0.5906	278.2 examples/second
2022-01-10 15:11:56,385 - INFO - [Step=50000]	Loss=0.5684	277.3 examples/second
2022-01-10 15:12:50,284 - INFO - Test Loss=0.8335, Test top-1 acc=0.7901
2022-01-10 15:12:50,284 - INFO - Group Accuracy:

2022-01-10 15:12:50,299 - INFO - [0.98240966 0.9922892  0.9848193  0.9939759  0.9845783  0.9946988
 0.9821687  0.98313254 0.9898795  0.9773494  0.9918072  0.9860241
 0.9773494  0.9804819  0.9768675  0.9898795  0.9968675 ]
2022-01-10 15:12:50,300 - INFO - Saving...
2022-01-10 15:12:51,015 - INFO - Epoch time: 395.620689868927
2022-01-10 15:12:51,016 - INFO - 
Epoch: 60
2022-01-10 15:12:51,016 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:14:02,324 - INFO - [Step=50250]	Loss=0.5645	254.1 examples/second
2022-01-10 15:15:57,413 - INFO - [Step=50500]	Loss=0.5647	278.0 examples/second
2022-01-10 15:17:52,679 - INFO - [Step=50750]	Loss=0.5524	277.6 examples/second
2022-01-10 15:19:25,341 - INFO - Test Loss=0.8064, Test top-1 acc=0.7899
2022-01-10 15:19:25,341 - INFO - Group Accuracy:

2022-01-10 15:19:25,341 - INFO - [0.98289156 0.9920482  0.9853012  0.99373496 0.98433733 0.9946988
 0.9833735  0.98361444 0.99036145 0.97638553 0.9918072  0.9853012
 0.9768675  0.9809638  0.97590363 0.9886747  0.99710846]
2022-01-10 15:19:25,342 - INFO - Epoch time: 394.32583475112915
2022-01-10 15:19:25,342 - INFO - 
Epoch: 61
2022-01-10 15:19:25,342 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:19:57,297 - INFO - [Step=51000]	Loss=0.5609	256.8 examples/second
2022-01-10 15:21:52,373 - INFO - [Step=51250]	Loss=0.5645	278.1 examples/second
2022-01-10 15:23:47,432 - INFO - [Step=51500]	Loss=0.5536	278.1 examples/second
2022-01-10 15:25:42,632 - INFO - [Step=51750]	Loss=0.5591	277.8 examples/second
2022-01-10 15:25:59,468 - INFO - Test Loss=0.8802, Test top-1 acc=0.7918
2022-01-10 15:25:59,469 - INFO - Group Accuracy:

2022-01-10 15:25:59,469 - INFO - [0.9812048  0.99156624 0.9855422  0.99373496 0.98361444 0.99445784
 0.9833735  0.9833735  0.99084336 0.9768675  0.9922892  0.9855422
 0.9775904  0.9809638  0.97638553 0.98963857 0.9966265 ]
2022-01-10 15:25:59,469 - INFO - Saving...
2022-01-10 15:25:59,771 - INFO - Epoch time: 394.42913842201233
2022-01-10 15:25:59,771 - INFO - 
Epoch: 62
2022-01-10 15:25:59,771 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:27:47,822 - INFO - [Step=52000]	Loss=0.5520	255.6 examples/second
2022-01-10 15:29:42,811 - INFO - [Step=52250]	Loss=0.5387	278.3 examples/second
2022-01-10 15:31:37,890 - INFO - [Step=52500]	Loss=0.5414	278.1 examples/second
2022-01-10 15:32:33,691 - INFO - Test Loss=0.8686, Test top-1 acc=0.7904
2022-01-10 15:32:33,692 - INFO - Group Accuracy:

2022-01-10 15:32:33,692 - INFO - [0.9814458  0.9918072  0.9855422  0.9939759  0.9845783  0.9946988
 0.9833735  0.9821687  0.99036145 0.9766265  0.993253   0.9850602
 0.97831327 0.9814458  0.97566265 0.9889157  0.9966265 ]
2022-01-10 15:32:33,693 - INFO - Epoch time: 393.9214870929718
2022-01-10 15:32:33,693 - INFO - 
Epoch: 63
2022-01-10 15:32:33,693 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:33:42,623 - INFO - [Step=52750]	Loss=0.5406	256.5 examples/second
2022-01-10 15:35:38,175 - INFO - [Step=53000]	Loss=0.5397	276.9 examples/second
2022-01-10 15:37:33,568 - INFO - [Step=53250]	Loss=0.5516	277.3 examples/second
2022-01-10 15:39:09,110 - INFO - Test Loss=0.8505, Test top-1 acc=0.7916
2022-01-10 15:39:09,110 - INFO - Group Accuracy:

2022-01-10 15:39:09,110 - INFO - [0.9809638  0.9918072  0.98578316 0.9946988  0.9845783  0.9951807
 0.9840964  0.98289156 0.98963857 0.97638553 0.9922892  0.9850602
 0.9773494  0.9816868  0.9780723  0.9893976  0.9966265 ]
2022-01-10 15:39:09,111 - INFO - Epoch time: 395.41854977607727
2022-01-10 15:39:09,111 - INFO - 
Epoch: 64
2022-01-10 15:39:09,111 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:39:38,757 - INFO - [Step=53500]	Loss=0.5458	255.6 examples/second
2022-01-10 15:41:33,875 - INFO - [Step=53750]	Loss=0.5396	278.0 examples/second
2022-01-10 15:43:29,296 - INFO - [Step=54000]	Loss=0.5287	277.2 examples/second
2022-01-10 15:45:24,447 - INFO - [Step=54250]	Loss=0.5438	277.9 examples/second
2022-01-10 15:45:43,411 - INFO - Test Loss=0.8112, Test top-1 acc=0.7892
2022-01-10 15:45:43,411 - INFO - Group Accuracy:

2022-01-10 15:45:43,411 - INFO - [0.9807229  0.9920482  0.9853012  0.99445784 0.9845783  0.99493974
 0.98433733 0.9821687  0.9898795  0.9766265  0.9918072  0.9848193
 0.9768675  0.9812048  0.9773494  0.98963857 0.9963855 ]
2022-01-10 15:45:43,412 - INFO - Epoch time: 394.30094933509827
2022-01-10 15:45:43,412 - INFO - 
Epoch: 65
2022-01-10 15:45:43,412 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:47:29,249 - INFO - [Step=54500]	Loss=0.5493	256.4 examples/second
2022-01-10 15:49:24,583 - INFO - [Step=54750]	Loss=0.5308	277.5 examples/second
2022-01-10 15:51:19,994 - INFO - [Step=55000]	Loss=0.5329	277.3 examples/second
2022-01-10 15:52:18,386 - INFO - Test Loss=0.8677, Test top-1 acc=0.7877
2022-01-10 15:52:18,387 - INFO - Group Accuracy:

2022-01-10 15:52:18,387 - INFO - [0.9807229  0.9922892  0.9853012  0.9946988  0.9838554  0.9951807
 0.9840964  0.9812048  0.99060243 0.97590363 0.9930121  0.9850602
 0.9778313  0.9814458  0.9766265  0.9893976  0.9968675 ]
2022-01-10 15:52:18,389 - INFO - Epoch time: 394.9763329029083
2022-01-10 15:52:18,389 - INFO - 
Epoch: 66
2022-01-10 15:52:18,389 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:53:25,048 - INFO - [Step=55250]	Loss=0.5325	255.9 examples/second
2022-01-10 15:55:20,293 - INFO - [Step=55500]	Loss=0.5314	277.7 examples/second
2022-01-10 15:57:15,891 - INFO - [Step=55750]	Loss=0.5358	276.8 examples/second
2022-01-10 15:58:53,198 - INFO - Test Loss=0.8432, Test top-1 acc=0.7904
2022-01-10 15:58:53,198 - INFO - Group Accuracy:

2022-01-10 15:58:53,198 - INFO - [0.9809638  0.9922892  0.9845783  0.99373496 0.98361444 0.99445784
 0.9840964  0.9819277  0.99084336 0.9771084  0.9927711  0.9853012
 0.9773494  0.98289156 0.9775904  0.9889157  0.9968675 ]
2022-01-10 15:58:53,199 - INFO - Epoch time: 394.8101096153259
2022-01-10 15:58:53,199 - INFO - 
Epoch: 67
2022-01-10 15:58:53,199 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:59:20,457 - INFO - [Step=56000]	Loss=0.5252	256.9 examples/second
2022-01-10 16:01:15,440 - INFO - [Step=56250]	Loss=0.5214	278.3 examples/second
2022-01-10 16:03:10,575 - INFO - [Step=56500]	Loss=0.5201	277.9 examples/second
2022-01-10 16:05:06,096 - INFO - [Step=56750]	Loss=0.5350	277.0 examples/second
2022-01-10 16:05:27,664 - INFO - Test Loss=0.9016, Test top-1 acc=0.7933
2022-01-10 16:05:27,664 - INFO - Group Accuracy:

2022-01-10 16:05:27,664 - INFO - [0.9804819  0.9920482  0.9855422  0.99421686 0.98361444 0.99493974
 0.9845783  0.9814458  0.98963857 0.97638553 0.9922892  0.9848193
 0.9775904  0.98361444 0.9768675  0.98963857 0.99710846]
2022-01-10 16:05:27,665 - INFO - Saving...
2022-01-10 16:05:28,103 - INFO - Epoch time: 394.9034311771393
2022-01-10 16:05:28,103 - INFO - 
Epoch: 68
2022-01-10 16:05:28,103 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:07:11,492 - INFO - [Step=57000]	Loss=0.5145	255.2 examples/second
2022-01-10 16:09:06,482 - INFO - [Step=57250]	Loss=0.5222	278.3 examples/second
2022-01-10 16:11:01,604 - INFO - [Step=57500]	Loss=0.5247	278.0 examples/second
2022-01-10 16:12:02,336 - INFO - Test Loss=0.8274, Test top-1 acc=0.7889
2022-01-10 16:12:02,336 - INFO - Group Accuracy:

2022-01-10 16:12:02,336 - INFO - [0.9819277  0.9918072  0.9855422  0.99445784 0.9853012  0.99493974
 0.98313254 0.9821687  0.99036145 0.97614455 0.9918072  0.9845783
 0.9785542  0.9814458  0.9771084  0.9893976  0.9968675 ]
2022-01-10 16:12:02,337 - INFO - Epoch time: 394.234032869339
2022-01-10 16:12:02,337 - INFO - 
Epoch: 69
2022-01-10 16:12:02,337 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:13:06,392 - INFO - [Step=57750]	Loss=0.5258	256.4 examples/second
2022-01-10 16:15:01,497 - INFO - [Step=58000]	Loss=0.5165	278.0 examples/second
2022-01-10 16:16:56,567 - INFO - [Step=58250]	Loss=0.5199	278.1 examples/second
2022-01-10 16:18:36,133 - INFO - Test Loss=0.8489, Test top-1 acc=0.7928
2022-01-10 16:18:36,133 - INFO - Group Accuracy:

2022-01-10 16:18:36,133 - INFO - [0.9809638  0.99156624 0.98626506 0.9939759  0.9848193  0.99445784
 0.9838554  0.9819277  0.99108434 0.9768675  0.9927711  0.9845783
 0.9787952  0.9819277  0.9771084  0.9891566  0.9963855 ]
2022-01-10 16:18:36,134 - INFO - Epoch time: 393.7972466945648
2022-01-10 16:18:36,134 - INFO - 
Epoch: 70
2022-01-10 16:18:36,134 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:19:01,174 - INFO - [Step=58500]	Loss=0.5225	256.8 examples/second
2022-01-10 16:20:56,338 - INFO - [Step=58750]	Loss=0.5132	277.9 examples/second
2022-01-10 16:22:51,324 - INFO - [Step=59000]	Loss=0.5292	278.3 examples/second
2022-01-10 16:24:46,651 - INFO - [Step=59250]	Loss=0.5272	277.5 examples/second
2022-01-10 16:25:10,489 - INFO - Test Loss=0.8245, Test top-1 acc=0.7911
2022-01-10 16:25:10,489 - INFO - Group Accuracy:

2022-01-10 16:25:10,489 - INFO - [0.9812048  0.9927711  0.98578316 0.9939759  0.9850602  0.99493974
 0.98361444 0.9819277  0.99108434 0.9768675  0.9918072  0.9855422
 0.9768675  0.98240966 0.9768675  0.9893976  0.9966265 ]
2022-01-10 16:25:10,490 - INFO - Epoch time: 394.3560252189636
2022-01-10 16:25:10,490 - INFO - 
Epoch: 71
2022-01-10 16:25:10,490 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:26:51,835 - INFO - [Step=59500]	Loss=0.5223	255.6 examples/second
2022-01-10 16:28:46,979 - INFO - [Step=59750]	Loss=0.5230	277.9 examples/second
2022-01-10 16:30:42,082 - INFO - [Step=60000]	Loss=0.5161	278.0 examples/second
2022-01-10 16:31:44,920 - INFO - Test Loss=0.8987, Test top-1 acc=0.7904
2022-01-10 16:31:44,921 - INFO - Group Accuracy:

2022-01-10 16:31:44,921 - INFO - [0.9816868  0.9930121  0.98578316 0.99421686 0.9840964  0.9946988
 0.98240966 0.98313254 0.99036145 0.9766265  0.9925301  0.9850602
 0.9773494  0.9819277  0.9766265  0.9901205  0.9963855 ]
2022-01-10 16:31:44,922 - INFO - Epoch time: 394.4315116405487
2022-01-10 16:31:44,922 - INFO - 
Epoch: 72
2022-01-10 16:31:44,922 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:32:46,695 - INFO - [Step=60250]	Loss=0.5178	256.8 examples/second
2022-01-10 16:34:41,890 - INFO - [Step=60500]	Loss=0.5177	277.8 examples/second
2022-01-10 16:36:37,452 - INFO - [Step=60750]	Loss=0.5170	276.9 examples/second
2022-01-10 16:38:19,305 - INFO - Test Loss=0.8091, Test top-1 acc=0.7889
2022-01-10 16:38:19,305 - INFO - Group Accuracy:

2022-01-10 16:38:19,305 - INFO - [0.9812048  0.9927711  0.9848193  0.99421686 0.9853012  0.9951807
 0.98289156 0.98       0.99036145 0.97542167 0.9920482  0.9855422
 0.9778313  0.9819277  0.9778313  0.99060243 0.9963855 ]
2022-01-10 16:38:19,306 - INFO - Epoch time: 394.3842797279358
2022-01-10 16:38:19,306 - INFO - 
Epoch: 73
2022-01-10 16:38:19,306 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:38:42,338 - INFO - [Step=61000]	Loss=0.5115	256.2 examples/second
2022-01-10 16:40:37,482 - INFO - [Step=61250]	Loss=0.5084	277.9 examples/second
2022-01-10 16:42:32,555 - INFO - [Step=61500]	Loss=0.5084	278.1 examples/second
2022-01-10 16:44:27,800 - INFO - [Step=61750]	Loss=0.5261	277.7 examples/second
2022-01-10 16:44:53,828 - INFO - Test Loss=0.8741, Test top-1 acc=0.7908
2022-01-10 16:44:53,828 - INFO - Group Accuracy:

2022-01-10 16:44:53,828 - INFO - [0.9826506  0.9918072  0.9860241  0.99373496 0.98578316 0.9946988
 0.98289156 0.9812048  0.99084336 0.9766265  0.9920482  0.9855422
 0.9785542  0.9819277  0.9768675  0.98963857 0.9963855 ]
2022-01-10 16:44:53,829 - INFO - Epoch time: 394.5228202342987
2022-01-10 16:44:53,829 - INFO - 
Epoch: 74
2022-01-10 16:44:53,829 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:46:32,627 - INFO - [Step=62000]	Loss=0.5058	256.4 examples/second
2022-01-10 16:48:27,821 - INFO - [Step=62250]	Loss=0.5163	277.8 examples/second
2022-01-10 16:50:23,100 - INFO - [Step=62500]	Loss=0.5062	277.6 examples/second
2022-01-10 16:51:28,266 - INFO - Test Loss=0.8229, Test top-1 acc=0.7904
2022-01-10 16:51:28,267 - INFO - Group Accuracy:

2022-01-10 16:51:28,267 - INFO - [0.9819277  0.9925301  0.9848193  0.9939759  0.9845783  0.99493974
 0.98313254 0.9809638  0.98963857 0.97614455 0.9922892  0.9853012
 0.9780723  0.9819277  0.9768675  0.98963857 0.9968675 ]
2022-01-10 16:51:28,267 - INFO - Epoch time: 394.438148021698
2022-01-10 16:51:28,267 - INFO - 
Epoch: 75
2022-01-10 16:51:28,267 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:52:28,416 - INFO - [Step=62750]	Loss=0.5042	255.4 examples/second
2022-01-10 16:54:23,855 - INFO - [Step=63000]	Loss=0.5039	277.2 examples/second
2022-01-10 16:56:19,309 - INFO - [Step=63250]	Loss=0.5002	277.2 examples/second
2022-01-10 16:58:03,916 - INFO - Test Loss=0.8440, Test top-1 acc=0.7894
2022-01-10 16:58:03,916 - INFO - Group Accuracy:

2022-01-10 16:58:03,916 - INFO - [0.9826506  0.99156624 0.9848193  0.9939759  0.9845783  0.99493974
 0.9826506  0.9812048  0.9901205  0.9771084  0.9922892  0.9848193
 0.9771084  0.9821687  0.97614455 0.98963857 0.9963855 ]
2022-01-10 16:58:03,917 - INFO - Epoch time: 395.64962100982666
2022-01-10 16:58:03,917 - INFO - 
Epoch: 76
2022-01-10 16:58:03,917 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:58:24,601 - INFO - [Step=63500]	Loss=0.5148	255.4 examples/second
2022-01-10 17:00:19,670 - INFO - [Step=63750]	Loss=0.5002	278.1 examples/second
2022-01-10 17:02:14,920 - INFO - [Step=64000]	Loss=0.5005	277.7 examples/second
2022-01-10 17:04:10,215 - INFO - [Step=64250]	Loss=0.5037	277.6 examples/second
2022-01-10 17:04:38,371 - INFO - Test Loss=0.9083, Test top-1 acc=0.7887
2022-01-10 17:04:38,371 - INFO - Group Accuracy:

2022-01-10 17:04:38,371 - INFO - [0.9819277  0.99156624 0.9840964  0.99373496 0.98361444 0.99493974
 0.98289156 0.9816868  0.9901205  0.97614455 0.9922892  0.9860241
 0.9768675  0.9826506  0.9766265  0.9898795  0.9966265 ]
2022-01-10 17:04:38,372 - INFO - Epoch time: 394.4548382759094
2022-01-10 17:04:38,372 - INFO - 
Epoch: 77
2022-01-10 17:04:38,372 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:06:15,445 - INFO - [Step=64500]	Loss=0.5027	255.5 examples/second
2022-01-10 17:08:10,608 - INFO - [Step=64750]	Loss=0.4956	277.9 examples/second
2022-01-10 17:10:06,125 - INFO - [Step=65000]	Loss=0.5110	277.0 examples/second
2022-01-10 17:11:13,639 - INFO - Test Loss=0.8241, Test top-1 acc=0.7913
2022-01-10 17:11:13,640 - INFO - Group Accuracy:

2022-01-10 17:11:13,640 - INFO - [0.9814458  0.9922892  0.9845783  0.99445784 0.9840964  0.99493974
 0.98240966 0.98240966 0.9901205  0.97566265 0.9925301  0.98578316
 0.9773494  0.9826506  0.9766265  0.98963857 0.9966265 ]
2022-01-10 17:11:13,641 - INFO - Epoch time: 395.26875615119934
2022-01-10 17:11:13,641 - INFO - 
Epoch: 78
2022-01-10 17:11:13,641 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:12:10,893 - INFO - [Step=65250]	Loss=0.5092	256.5 examples/second
2022-01-10 17:14:06,081 - INFO - [Step=65500]	Loss=0.5085	277.8 examples/second
2022-01-10 17:16:01,402 - INFO - [Step=65750]	Loss=0.4972	277.5 examples/second
2022-01-10 17:17:48,193 - INFO - Test Loss=0.8043, Test top-1 acc=0.7930
2022-01-10 17:17:48,194 - INFO - Group Accuracy:

2022-01-10 17:17:48,194 - INFO - [0.9807229  0.9920482  0.9853012  0.99373496 0.9845783  0.99445784
 0.98313254 0.9819277  0.99060243 0.9766265  0.9918072  0.9853012
 0.9773494  0.9819277  0.9775904  0.98963857 0.9959036 ]
2022-01-10 17:17:48,195 - INFO - Epoch time: 394.5545699596405
2022-01-10 17:17:48,196 - INFO - 
Epoch: 79
2022-01-10 17:17:48,196 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:18:06,347 - INFO - [Step=66000]	Loss=0.5104	256.1 examples/second
2022-01-10 17:20:01,665 - INFO - [Step=66250]	Loss=0.5009	277.5 examples/second
2022-01-10 17:21:56,978 - INFO - [Step=66500]	Loss=0.4958	277.5 examples/second
2022-01-10 17:23:52,358 - INFO - [Step=66750]	Loss=0.5120	277.3 examples/second
2022-01-10 17:24:23,280 - INFO - Test Loss=0.8333, Test top-1 acc=0.7911
2022-01-10 17:24:23,280 - INFO - Group Accuracy:

2022-01-10 17:24:23,280 - INFO - [0.9804819  0.9925301  0.9848193  0.99493974 0.9850602  0.99493974
 0.98289156 0.9816868  0.9901205  0.9766265  0.9925301  0.9848193
 0.9778313  0.9809638  0.9771084  0.9893976  0.9966265 ]
2022-01-10 17:24:23,281 - INFO - Epoch time: 395.08553814888
2022-01-10 17:24:23,281 - INFO - 
Epoch: 80
2022-01-10 17:24:23,281 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:25:57,434 - INFO - [Step=67000]	Loss=0.4933	255.8 examples/second
2022-01-10 17:27:52,641 - INFO - [Step=67250]	Loss=0.5042	277.8 examples/second
2022-01-10 17:29:47,862 - INFO - [Step=67500]	Loss=0.4963	277.7 examples/second
2022-01-10 17:30:57,878 - INFO - Test Loss=0.8820, Test top-1 acc=0.7930
2022-01-10 17:30:57,879 - INFO - Group Accuracy:

2022-01-10 17:30:57,879 - INFO - [0.9819277  0.993253   0.98626506 0.99445784 0.9850602  0.9946988
 0.98313254 0.98240966 0.98963857 0.97590363 0.9925301  0.9848193
 0.97903615 0.98240966 0.9778313  0.9886747  0.9966265 ]
2022-01-10 17:30:57,880 - INFO - Epoch time: 394.59862184524536
2022-01-10 17:30:57,880 - INFO - 
Epoch: 81
2022-01-10 17:30:57,880 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:31:53,360 - INFO - [Step=67750]	Loss=0.4963	255.0 examples/second
2022-01-10 17:33:48,475 - INFO - [Step=68000]	Loss=0.4947	278.0 examples/second
2022-01-10 17:35:43,855 - INFO - [Step=68250]	Loss=0.5004	277.3 examples/second
2022-01-10 17:37:32,434 - INFO - Test Loss=0.8647, Test top-1 acc=0.7935
2022-01-10 17:37:32,434 - INFO - Group Accuracy:

2022-01-10 17:37:32,434 - INFO - [0.9812048  0.9922892  0.98626506 0.9939759  0.98578316 0.99493974
 0.98313254 0.9819277  0.98963857 0.97590363 0.9930121  0.9845783
 0.9775904  0.98289156 0.9766265  0.98963857 0.9966265 ]
2022-01-10 17:37:32,435 - INFO - Saving...
2022-01-10 17:37:32,707 - INFO - Epoch time: 394.82690596580505
2022-01-10 17:37:32,707 - INFO - 
Epoch: 82
2022-01-10 17:37:32,707 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:37:48,613 - INFO - [Step=68500]	Loss=0.4963	256.5 examples/second
2022-01-10 17:39:44,065 - INFO - [Step=68750]	Loss=0.4832	277.2 examples/second
2022-01-10 17:41:39,251 - INFO - [Step=69000]	Loss=0.4899	277.8 examples/second
2022-01-10 17:43:34,563 - INFO - [Step=69250]	Loss=0.4927	277.5 examples/second
2022-01-10 17:44:07,525 - INFO - Test Loss=0.9077, Test top-1 acc=0.7901
2022-01-10 17:44:07,526 - INFO - Group Accuracy:

2022-01-10 17:44:07,526 - INFO - [0.9812048  0.9927711  0.9855422  0.9939759  0.9848193  0.99445784
 0.98433733 0.9826506  0.9901205  0.97614455 0.9922892  0.9855422
 0.97831327 0.9826506  0.97638553 0.98963857 0.99710846]
2022-01-10 17:44:07,527 - INFO - Epoch time: 394.8194959163666
2022-01-10 17:44:07,527 - INFO - 
Epoch: 83
2022-01-10 17:44:07,527 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:45:40,124 - INFO - [Step=69500]	Loss=0.4903	254.9 examples/second
2022-01-10 17:47:35,602 - INFO - [Step=69750]	Loss=0.4920	277.1 examples/second
2022-01-10 17:49:30,959 - INFO - [Step=70000]	Loss=0.5020	277.4 examples/second
2022-01-10 17:50:43,031 - INFO - Test Loss=0.8676, Test top-1 acc=0.7896
2022-01-10 17:50:43,031 - INFO - Group Accuracy:

2022-01-10 17:50:43,031 - INFO - [0.9814458  0.9920482  0.9853012  0.99421686 0.9848193  0.9946988
 0.9826506  0.9816868  0.99060243 0.97566265 0.9918072  0.9848193
 0.97831327 0.9821687  0.9771084  0.9886747  0.9966265 ]
2022-01-10 17:50:43,033 - INFO - Epoch time: 395.5058739185333
2022-01-10 17:50:43,033 - INFO - 
Epoch: 84
2022-01-10 17:50:43,033 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:51:35,683 - INFO - [Step=70250]	Loss=0.4932	256.6 examples/second
2022-01-10 17:53:31,004 - INFO - [Step=70500]	Loss=0.4803	277.5 examples/second
2022-01-10 17:55:26,369 - INFO - [Step=70750]	Loss=0.4801	277.4 examples/second
2022-01-10 17:57:17,386 - INFO - Test Loss=0.8389, Test top-1 acc=0.7911
2022-01-10 17:57:17,387 - INFO - Group Accuracy:

2022-01-10 17:57:17,387 - INFO - [0.9816868  0.9930121  0.98674697 0.993253   0.98578316 0.99445784
 0.98361444 0.98313254 0.99036145 0.97542167 0.9913253  0.9845783
 0.9780723  0.98240966 0.97590363 0.9893976  0.9968675 ]
2022-01-10 17:57:17,388 - INFO - Epoch time: 394.3553133010864
2022-01-10 17:57:17,388 - INFO - 
Epoch: 85
2022-01-10 17:57:17,388 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:57:31,215 - INFO - [Step=71000]	Loss=0.4878	256.3 examples/second
2022-01-10 17:59:26,672 - INFO - [Step=71250]	Loss=0.4816	277.2 examples/second
2022-01-10 18:01:22,108 - INFO - [Step=71500]	Loss=0.4777	277.2 examples/second
2022-01-10 18:03:17,666 - INFO - [Step=71750]	Loss=0.4857	276.9 examples/second
2022-01-10 18:03:52,729 - INFO - Test Loss=0.8659, Test top-1 acc=0.7928
2022-01-10 18:03:52,729 - INFO - Group Accuracy:

2022-01-10 18:03:52,729 - INFO - [0.9814458  0.9925301  0.9860241  0.99373496 0.9855422  0.9951807
 0.9819277  0.98240966 0.99084336 0.9766265  0.9930121  0.9853012
 0.9775904  0.98313254 0.97590363 0.9884337  0.9966265 ]
2022-01-10 18:03:52,731 - INFO - Epoch time: 395.34252429008484
2022-01-10 18:03:52,731 - INFO - 
Epoch: 86
2022-01-10 18:03:52,731 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:05:22,509 - INFO - [Step=72000]	Loss=0.4828	256.3 examples/second
2022-01-10 18:07:17,658 - INFO - [Step=72250]	Loss=0.4782	277.9 examples/second
2022-01-10 18:09:13,274 - INFO - [Step=72500]	Loss=0.4876	276.8 examples/second
2022-01-10 18:10:27,466 - INFO - Test Loss=0.9205, Test top-1 acc=0.7887
2022-01-10 18:10:27,467 - INFO - Group Accuracy:

2022-01-10 18:10:27,467 - INFO - [0.9809638  0.9922892  0.98674697 0.9927711  0.9848193  0.9946988
 0.9826506  0.9816868  0.99108434 0.97638553 0.99108434 0.9853012
 0.97614455 0.98289156 0.9768675  0.9886747  0.9966265 ]
2022-01-10 18:10:27,467 - INFO - Epoch time: 394.73658323287964
2022-01-10 18:10:27,467 - INFO - 
Epoch: 87
2022-01-10 18:10:27,467 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:11:18,090 - INFO - [Step=72750]	Loss=0.4865	256.4 examples/second
2022-01-10 18:13:13,515 - INFO - [Step=73000]	Loss=0.4915	277.2 examples/second
2022-01-10 18:15:09,111 - INFO - [Step=73250]	Loss=0.4803	276.8 examples/second
2022-01-10 18:17:03,168 - INFO - Test Loss=0.9206, Test top-1 acc=0.7937
2022-01-10 18:17:03,169 - INFO - Group Accuracy:

2022-01-10 18:17:03,169 - INFO - [0.9816868  0.9920482  0.98626506 0.9939759  0.9850602  0.99493974
 0.98289156 0.9826506  0.99036145 0.97590363 0.9922892  0.98433733
 0.9771084  0.98289156 0.97831327 0.98963857 0.9968675 ]
2022-01-10 18:17:03,170 - INFO - Saving...
2022-01-10 18:17:03,458 - INFO - Epoch time: 395.99036860466003
2022-01-10 18:17:03,458 - INFO - 
Epoch: 88
2022-01-10 18:17:03,458 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:17:14,936 - INFO - [Step=73500]	Loss=0.4765	254.3 examples/second
2022-01-10 18:19:10,309 - INFO - [Step=73750]	Loss=0.4717	277.4 examples/second
2022-01-10 18:21:05,369 - INFO - [Step=74000]	Loss=0.4755	278.1 examples/second
2022-01-10 18:23:00,864 - INFO - [Step=74250]	Loss=0.4760	277.1 examples/second
2022-01-10 18:23:38,025 - INFO - Test Loss=0.8887, Test top-1 acc=0.7904
2022-01-10 18:23:38,026 - INFO - Group Accuracy:

2022-01-10 18:23:38,026 - INFO - [0.9819277  0.9920482  0.9848193  0.9939759  0.9845783  0.99493974
 0.9826506  0.98313254 0.99060243 0.97542167 0.9922892  0.9840964
 0.9778313  0.9826506  0.9771084  0.9901205  0.9963855 ]
2022-01-10 18:23:38,026 - INFO - Epoch time: 394.5682055950165
2022-01-10 18:23:38,026 - INFO - 
Epoch: 89
2022-01-10 18:23:38,026 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:25:05,202 - INFO - [Step=74500]	Loss=0.4746	257.4 examples/second
2022-01-10 18:27:00,454 - INFO - [Step=74750]	Loss=0.4636	277.7 examples/second
2022-01-10 18:28:55,746 - INFO - [Step=75000]	Loss=0.4861	277.6 examples/second
2022-01-10 18:30:12,386 - INFO - Test Loss=0.9128, Test top-1 acc=0.7901
2022-01-10 18:30:12,386 - INFO - Group Accuracy:

2022-01-10 18:30:12,386 - INFO - [0.9807229  0.9918072  0.9850602  0.99373496 0.9838554  0.9951807
 0.9833735  0.9826506  0.9898795  0.97566265 0.99108434 0.9850602
 0.9780723  0.9821687  0.9778313  0.9893976  0.9963855 ]
2022-01-10 18:30:12,387 - INFO - Epoch time: 394.3610632419586
2022-01-10 18:30:23,008 - INFO - Computing OOD Statistics...
2022-01-10 18:30:23,018 - INFO - 	Baseline.          AUROC: 0.4188. TNR@95TPR: 0.0341. AUPR OUT: 0.1405
2022-01-10 18:30:23,023 - INFO - 	ODIN (T=1000).     AUROC: 0.8926. TNR@95TPR: 0.5271. AUPR OUT: 0.6304
2022-01-10 18:30:23,023 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-10 18:30:23,023 - INFO - Top 1 Accuracy:  Min: 0.7937; Max: 0.7937; Avg: 0.7937; Std: 0.0000; Len: 1
2022-01-10 18:30:23,023 - INFO - Top 5 Accuracy:  Min: 0.9863; Max: 0.9863; Avg: 0.9863; Std: 0.0000; Len: 1
2022-01-10 18:30:23,023 - INFO - **********************************************************************
2022-01-10 18:30:23,023 - INFO - 	MSP (auroc): [0.41884904323175054] Min: 0.4188; Max: 0.4188; Avg: 0.4188; Std: 0.0000; Len: 1
2022-01-10 18:30:23,023 - INFO - 	MSP (tnr): [0.034117647058823475] Min: 0.0341; Max: 0.0341; Avg: 0.0341; Std: 0.0000; Len: 1
2022-01-10 18:30:23,023 - INFO - 	MSP (aupr): [0.14047988554752755] Min: 0.1405; Max: 0.1405; Avg: 0.1405; Std: 0.0000; Len: 1
2022-01-10 18:30:23,023 - INFO - 	ODIN (auroc): [0.8926228206945429] Min: 0.8926; Max: 0.8926; Avg: 0.8926; Std: 0.0000; Len: 1
2022-01-10 18:30:23,024 - INFO - 	ODIN (tnr): [0.5270588235294118] Min: 0.5271; Max: 0.5271; Avg: 0.5271; Std: 0.0000; Len: 1
2022-01-10 18:30:23,024 - INFO - 	ODIN (aupr): [0.6304116986850208] Min: 0.6304; Max: 0.6304; Avg: 0.6304; Std: 0.0000; Len: 1

2022-01-10 08:36:39,547 - INFO - ==> Preparing data..
2022-01-10 08:36:39,942 - INFO - checkpoint filename: experiments/coarse/mos/LRp1_R2/checkpoint.pt
2022-01-10 08:36:39,942 - INFO - log filename: experiments/coarse/mos/LRp1_R2/train.log
2022-01-10 08:36:39,942 - INFO - ********************************************************
2022-01-10 08:36:39,942 - INFO - Starting Iter: 0 / 1
2022-01-10 08:36:39,942 - INFO - ********************************************************
2022-01-10 08:36:43,404 - INFO - 
Epoch: 0
2022-01-10 08:36:43,404 - INFO - 
Learning Rate: 0.0100
2022-01-10 08:38:42,573 - INFO - [Step=250]	Loss=7.0399	268.5 examples/second
2022-01-10 08:40:39,985 - INFO - [Step=500]	Loss=5.4650	272.5 examples/second
2022-01-10 08:42:37,840 - INFO - [Step=750]	Loss=5.3206	271.5 examples/second
2022-01-10 08:43:25,336 - INFO - Test Loss=5.2153, Test top-1 acc=0.0361
2022-01-10 08:43:25,336 - INFO - Group Accuracy:

2022-01-10 08:43:25,336 - INFO - [0.93903613 0.93903613 0.93831325 0.9385542  0.93759036 0.9361446
 0.9368675  0.93807226 0.939759   0.9387952  0.9518072  0.939759
 0.939759   0.93759036 0.939759   0.9395181  0.9518072 ]
2022-01-10 08:43:25,337 - INFO - Saving...
2022-01-10 08:43:25,501 - INFO - Epoch time: 402.0975363254547
2022-01-10 08:43:25,501 - INFO - 
Epoch: 1
2022-01-10 08:43:25,501 - INFO - 
Learning Rate: 0.0280
2022-01-10 08:44:45,026 - INFO - [Step=1000]	Loss=5.1327	251.6 examples/second
2022-01-10 08:46:40,559 - INFO - [Step=1250]	Loss=4.9967	277.0 examples/second
2022-01-10 08:48:36,188 - INFO - [Step=1500]	Loss=4.7947	276.7 examples/second
2022-01-10 08:50:02,469 - INFO - Test Loss=4.5111, Test top-1 acc=0.0687
2022-01-10 08:50:02,469 - INFO - Group Accuracy:

2022-01-10 08:50:02,469 - INFO - [0.939759   0.9404819  0.939759   0.9436145  0.939759   0.94120485
 0.939759   0.939759   0.939759   0.939759   0.9518072  0.939759
 0.939759   0.939759   0.939759   0.93903613 0.9518072 ]
2022-01-10 08:50:02,470 - INFO - Saving...
2022-01-10 08:50:02,758 - INFO - Epoch time: 397.25704431533813
2022-01-10 08:50:02,759 - INFO - 
Epoch: 2
2022-01-10 08:50:02,759 - INFO - 
Learning Rate: 0.0460
2022-01-10 08:50:41,426 - INFO - [Step=1750]	Loss=4.6756	255.5 examples/second
2022-01-10 08:52:37,007 - INFO - [Step=2000]	Loss=4.5438	276.9 examples/second
2022-01-10 08:54:32,717 - INFO - [Step=2250]	Loss=4.3798	276.6 examples/second
2022-01-10 08:56:28,787 - INFO - [Step=2500]	Loss=4.2037	275.7 examples/second
2022-01-10 08:56:38,807 - INFO - Test Loss=4.3964, Test top-1 acc=0.1427
2022-01-10 08:56:38,808 - INFO - Group Accuracy:

2022-01-10 08:56:38,808 - INFO - [0.94289154 0.9426506  0.9359036  0.9520482  0.94120485 0.9501205
 0.94120485 0.94289154 0.9453012  0.940241   0.95036143 0.9407229
 0.94       0.93831325 0.939759   0.940241   0.95373493]
2022-01-10 08:56:38,809 - INFO - Saving...
2022-01-10 08:56:39,111 - INFO - Epoch time: 396.35204792022705
2022-01-10 08:56:39,111 - INFO - 
Epoch: 3
2022-01-10 08:56:39,111 - INFO - 
Learning Rate: 0.0640
2022-01-10 08:58:34,247 - INFO - [Step=2750]	Loss=4.1382	255.1 examples/second
2022-01-10 09:00:29,890 - INFO - [Step=3000]	Loss=3.9567	276.7 examples/second
2022-01-10 09:02:25,287 - INFO - [Step=3250]	Loss=3.8012	277.3 examples/second
2022-01-10 09:03:14,427 - INFO - Test Loss=3.4684, Test top-1 acc=0.1957
2022-01-10 09:03:14,427 - INFO - Group Accuracy:

2022-01-10 09:03:14,427 - INFO - [0.94240963 0.94626504 0.9404819  0.9554217  0.9436145  0.96048194
 0.94168675 0.9481928  0.9506024  0.94216865 0.9551807  0.94192773
 0.94144577 0.9404819  0.94120485 0.9474699  0.95638555]
2022-01-10 09:03:14,428 - INFO - Saving...
2022-01-10 09:03:14,738 - INFO - Epoch time: 395.6268353462219
2022-01-10 09:03:14,738 - INFO - 
Epoch: 4
2022-01-10 09:03:14,738 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:04:30,448 - INFO - [Step=3500]	Loss=3.7495	255.7 examples/second
2022-01-10 09:06:26,021 - INFO - [Step=3750]	Loss=3.6244	276.9 examples/second
2022-01-10 09:08:21,668 - INFO - [Step=4000]	Loss=3.5238	276.7 examples/second
2022-01-10 09:09:50,130 - INFO - Test Loss=4.2682, Test top-1 acc=0.2419
2022-01-10 09:09:50,131 - INFO - Group Accuracy:

2022-01-10 09:09:50,131 - INFO - [0.94289154 0.9481928  0.94096386 0.9486747  0.9438554  0.95228916
 0.94192773 0.9518072  0.9554217  0.94216865 0.95686746 0.94433737
 0.94192773 0.9440964  0.9433735  0.94554216 0.96698797]
2022-01-10 09:09:50,132 - INFO - Saving...
2022-01-10 09:09:50,445 - INFO - Epoch time: 395.70704984664917
2022-01-10 09:09:50,445 - INFO - 
Epoch: 5
2022-01-10 09:09:50,446 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:10:27,108 - INFO - [Step=4250]	Loss=3.3973	255.1 examples/second
2022-01-10 09:12:22,967 - INFO - [Step=4500]	Loss=3.2573	276.2 examples/second
2022-01-10 09:14:18,871 - INFO - [Step=4750]	Loss=3.1123	276.1 examples/second
2022-01-10 09:16:14,767 - INFO - [Step=5000]	Loss=3.0442	276.1 examples/second
2022-01-10 09:16:26,701 - INFO - Test Loss=2.9770, Test top-1 acc=0.2923
2022-01-10 09:16:26,701 - INFO - Group Accuracy:

2022-01-10 09:16:26,701 - INFO - [0.9506024  0.95686746 0.9431325  0.9655422  0.94289154 0.9698795
 0.946506   0.94626504 0.95662653 0.9472289  0.96072286 0.94939756
 0.94120485 0.9433735  0.946506   0.95277107 0.97108436]
2022-01-10 09:16:26,702 - INFO - Saving...
2022-01-10 09:16:26,973 - INFO - Epoch time: 396.5279619693756
2022-01-10 09:16:26,974 - INFO - 
Epoch: 6
2022-01-10 09:16:26,974 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:18:19,723 - INFO - [Step=5250]	Loss=2.9489	256.1 examples/second
2022-01-10 09:20:15,401 - INFO - [Step=5500]	Loss=2.8790	276.6 examples/second
2022-01-10 09:22:11,200 - INFO - [Step=5750]	Loss=2.7967	276.3 examples/second
2022-01-10 09:23:03,467 - INFO - Test Loss=2.7658, Test top-1 acc=0.3407
2022-01-10 09:23:03,467 - INFO - Group Accuracy:

2022-01-10 09:23:03,467 - INFO - [0.9513253  0.9554217  0.9477109  0.9698795  0.9506024  0.97493976
 0.9479518  0.95662653 0.9701205  0.9486747  0.9580723  0.9359036
 0.94120485 0.9481928  0.9460241  0.94963855 0.9746988 ]
2022-01-10 09:23:03,469 - INFO - Saving...
2022-01-10 09:23:03,743 - INFO - Epoch time: 396.7694802284241
2022-01-10 09:23:03,743 - INFO - 
Epoch: 7
2022-01-10 09:23:03,743 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:24:17,477 - INFO - [Step=6000]	Loss=2.7392	253.4 examples/second
2022-01-10 09:26:13,154 - INFO - [Step=6250]	Loss=2.6652	276.6 examples/second
2022-01-10 09:28:08,748 - INFO - [Step=6500]	Loss=2.6416	276.8 examples/second
2022-01-10 09:29:40,397 - INFO - Test Loss=2.5255, Test top-1 acc=0.3793
2022-01-10 09:29:40,398 - INFO - Group Accuracy:

2022-01-10 09:29:40,398 - INFO - [0.95325303 0.96168673 0.94433737 0.97638553 0.94915664 0.97566265
 0.95277107 0.9587952  0.9693976  0.95421684 0.9626506  0.95325303
 0.9404819  0.94240963 0.9460241  0.95662653 0.9807229 ]
2022-01-10 09:29:40,399 - INFO - Saving...
2022-01-10 09:29:40,718 - INFO - Epoch time: 396.974568605423
2022-01-10 09:29:40,718 - INFO - 
Epoch: 8
2022-01-10 09:29:40,718 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:30:15,147 - INFO - [Step=6750]	Loss=2.5520	253.2 examples/second
2022-01-10 09:32:10,855 - INFO - [Step=7000]	Loss=2.5113	276.6 examples/second
2022-01-10 09:34:06,863 - INFO - [Step=7250]	Loss=2.4416	275.8 examples/second
2022-01-10 09:36:03,071 - INFO - [Step=7500]	Loss=2.4021	275.4 examples/second
2022-01-10 09:36:18,154 - INFO - Test Loss=2.4034, Test top-1 acc=0.4333
2022-01-10 09:36:18,155 - INFO - Group Accuracy:

2022-01-10 09:36:18,155 - INFO - [0.9559036  0.96096385 0.95373493 0.97445786 0.95228916 0.98
 0.9506024  0.9628916  0.9691566  0.94240963 0.9633735  0.96072286
 0.94433737 0.9506024  0.95228916 0.9628916  0.98240966]
2022-01-10 09:36:18,156 - INFO - Saving...
2022-01-10 09:36:18,484 - INFO - Epoch time: 397.76530599594116
2022-01-10 09:36:18,484 - INFO - 
Epoch: 9
2022-01-10 09:36:18,484 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:38:09,150 - INFO - [Step=7750]	Loss=2.3258	253.8 examples/second
2022-01-10 09:40:04,634 - INFO - [Step=8000]	Loss=2.2911	277.1 examples/second
2022-01-10 09:42:00,284 - INFO - [Step=8250]	Loss=2.2680	276.7 examples/second
2022-01-10 09:42:54,781 - INFO - Test Loss=2.2038, Test top-1 acc=0.4667
2022-01-10 09:42:54,782 - INFO - Group Accuracy:

2022-01-10 09:42:54,782 - INFO - [0.9595181  0.95759034 0.9583132  0.9706024  0.95686746 0.9845783
 0.9559036  0.96       0.97301203 0.96024096 0.96506023 0.96361446
 0.9508434  0.9486747  0.9580723  0.9626506  0.9819277 ]
2022-01-10 09:42:54,783 - INFO - Saving...
2022-01-10 09:42:55,080 - INFO - Epoch time: 396.59594655036926
2022-01-10 09:42:55,080 - INFO - 
Epoch: 10
2022-01-10 09:42:55,080 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:44:06,707 - INFO - [Step=8500]	Loss=2.2238	253.1 examples/second
2022-01-10 09:46:02,906 - INFO - [Step=8750]	Loss=2.2162	275.4 examples/second
2022-01-10 09:48:00,076 - INFO - [Step=9000]	Loss=2.1732	273.1 examples/second
2022-01-10 09:49:35,661 - INFO - Test Loss=2.1004, Test top-1 acc=0.4651
2022-01-10 09:49:35,661 - INFO - Group Accuracy:

2022-01-10 09:49:35,661 - INFO - [0.96048194 0.9655422  0.95710844 0.97542167 0.96481925 0.97903615
 0.9546988  0.96409637 0.9703615  0.96096385 0.9691566  0.95686746
 0.94963855 0.95373493 0.9578313  0.96506023 0.9850602 ]
2022-01-10 09:49:35,662 - INFO - Epoch time: 400.58210372924805
2022-01-10 09:49:35,662 - INFO - 
Epoch: 11
2022-01-10 09:49:35,662 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:50:07,852 - INFO - [Step=9250]	Loss=2.1282	250.4 examples/second
2022-01-10 09:52:05,345 - INFO - [Step=9500]	Loss=2.0914	272.4 examples/second
2022-01-10 09:54:02,589 - INFO - [Step=9750]	Loss=2.0766	272.9 examples/second
2022-01-10 09:55:59,805 - INFO - [Step=10000]	Loss=2.0575	273.0 examples/second
2022-01-10 09:56:16,409 - INFO - Test Loss=2.0060, Test top-1 acc=0.4925
2022-01-10 09:56:16,409 - INFO - Group Accuracy:

2022-01-10 09:56:16,409 - INFO - [0.9585542  0.96481925 0.9585542  0.97566265 0.9657831  0.9821687
 0.9592771  0.9624096  0.9746988  0.96024096 0.96891564 0.96168673
 0.94963855 0.9559036  0.9583132  0.966747   0.9821687 ]
2022-01-10 09:56:16,410 - INFO - Saving...
2022-01-10 09:56:16,704 - INFO - Epoch time: 401.0420069694519
2022-01-10 09:56:16,705 - INFO - 
Epoch: 12
2022-01-10 09:56:16,705 - INFO - 
Learning Rate: 0.1000
2022-01-10 09:58:07,489 - INFO - [Step=10250]	Loss=2.0100	250.6 examples/second
2022-01-10 10:00:04,750 - INFO - [Step=10500]	Loss=1.9705	272.9 examples/second
2022-01-10 10:02:00,828 - INFO - [Step=10750]	Loss=1.9604	275.7 examples/second
2022-01-10 10:02:57,104 - INFO - Test Loss=2.0394, Test top-1 acc=0.4923
2022-01-10 10:02:57,104 - INFO - Group Accuracy:

2022-01-10 10:02:57,104 - INFO - [0.96096385 0.973494   0.9619277  0.97951806 0.9633735  0.9840964
 0.9508434  0.9561446  0.97927713 0.96       0.97108436 0.9626506
 0.9481928  0.9453012  0.95421684 0.96891564 0.9768675 ]
2022-01-10 10:02:57,105 - INFO - Epoch time: 400.4004201889038
2022-01-10 10:02:57,105 - INFO - 
Epoch: 13
2022-01-10 10:02:57,105 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:04:06,235 - INFO - [Step=11000]	Loss=1.9386	255.2 examples/second
2022-01-10 10:06:02,423 - INFO - [Step=11250]	Loss=1.8891	275.4 examples/second
2022-01-10 10:08:00,607 - INFO - [Step=11500]	Loss=1.9095	270.8 examples/second
2022-01-10 10:09:38,152 - INFO - Test Loss=2.2324, Test top-1 acc=0.4733
2022-01-10 10:09:38,152 - INFO - Group Accuracy:

2022-01-10 10:09:38,152 - INFO - [0.9619277  0.966506   0.94915664 0.9804819  0.96168673 0.9814458
 0.9585542  0.946506   0.9706024  0.9631325  0.9693976  0.9612048
 0.95277107 0.95228916 0.95228916 0.96891564 0.97590363]
2022-01-10 10:09:38,153 - INFO - Epoch time: 401.04747462272644
2022-01-10 10:09:38,153 - INFO - 
Epoch: 14
2022-01-10 10:09:38,153 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:10:07,927 - INFO - [Step=11750]	Loss=1.8912	251.3 examples/second
2022-01-10 10:12:04,685 - INFO - [Step=12000]	Loss=1.8491	274.1 examples/second
2022-01-10 10:14:01,900 - INFO - [Step=12250]	Loss=1.8342	273.0 examples/second
2022-01-10 10:15:59,270 - INFO - [Step=12500]	Loss=1.8160	272.6 examples/second
2022-01-10 10:16:18,132 - INFO - Test Loss=1.7574, Test top-1 acc=0.5496
2022-01-10 10:16:18,132 - INFO - Group Accuracy:

2022-01-10 10:16:18,132 - INFO - [0.96409637 0.97566265 0.9686747  0.98       0.9631325  0.98771083
 0.9612048  0.9655422  0.9766265  0.9655422  0.9725301  0.96698797
 0.9438554  0.96072286 0.96409637 0.97301203 0.9884337 ]
2022-01-10 10:16:18,133 - INFO - Saving...
2022-01-10 10:16:18,431 - INFO - Epoch time: 400.2783498764038
2022-01-10 10:16:18,432 - INFO - 
Epoch: 15
2022-01-10 10:16:18,432 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:18:06,957 - INFO - [Step=12750]	Loss=1.7924	250.6 examples/second
2022-01-10 10:20:04,371 - INFO - [Step=13000]	Loss=1.7796	272.5 examples/second
2022-01-10 10:22:01,223 - INFO - [Step=13250]	Loss=1.7655	273.9 examples/second
2022-01-10 10:23:00,697 - INFO - Test Loss=1.9215, Test top-1 acc=0.5431
2022-01-10 10:23:00,698 - INFO - Group Accuracy:

2022-01-10 10:23:00,698 - INFO - [0.9619277  0.96072286 0.96024096 0.9821687  0.96843374 0.9855422
 0.9469879  0.96891564 0.973253   0.9655422  0.973494   0.9655422
 0.9559036  0.9561446  0.95253015 0.9727711  0.9860241 ]
2022-01-10 10:23:00,699 - INFO - Epoch time: 402.26704621315
2022-01-10 10:23:00,699 - INFO - 
Epoch: 16
2022-01-10 10:23:00,699 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:24:24,585 - INFO - [Step=13500]	Loss=1.7398	223.2 examples/second
2022-01-10 10:27:28,829 - INFO - [Step=13750]	Loss=1.7348	173.7 examples/second
2022-01-10 10:30:32,948 - INFO - [Step=14000]	Loss=1.7075	173.8 examples/second
2022-01-10 10:33:08,006 - INFO - Test Loss=1.7488, Test top-1 acc=0.5781
2022-01-10 10:33:08,007 - INFO - Group Accuracy:

2022-01-10 10:33:08,007 - INFO - [0.96481925 0.97445786 0.96771085 0.9787952  0.966506   0.9778313
 0.9614458  0.96819276 0.9778313  0.9691566  0.9768675  0.9674699
 0.95566267 0.9578313  0.9585542  0.9742169  0.98578316]
2022-01-10 10:33:08,008 - INFO - Saving...
2022-01-10 10:33:08,306 - INFO - Epoch time: 607.6076331138611
2022-01-10 10:33:08,307 - INFO - 
Epoch: 17
2022-01-10 10:33:08,307 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:33:50,974 - INFO - [Step=14250]	Loss=1.7169	161.6 examples/second
2022-01-10 10:36:55,629 - INFO - [Step=14500]	Loss=1.6687	173.3 examples/second
2022-01-10 10:39:59,916 - INFO - [Step=14750]	Loss=1.6700	173.6 examples/second
2022-01-10 10:43:04,718 - INFO - [Step=15000]	Loss=1.6709	173.2 examples/second
2022-01-10 10:43:38,115 - INFO - Test Loss=1.6918, Test top-1 acc=0.5745
2022-01-10 10:43:38,116 - INFO - Group Accuracy:

2022-01-10 10:43:38,116 - INFO - [0.96361446 0.973494   0.9691566  0.9804819  0.96481925 0.9853012
 0.9619277  0.9655422  0.97156626 0.9662651  0.97614455 0.9691566
 0.95638555 0.9595181  0.96457833 0.97228914 0.9879518 ]
2022-01-10 10:43:38,117 - INFO - Epoch time: 629.810430765152
2022-01-10 10:43:38,117 - INFO - 
Epoch: 18
2022-01-10 10:43:38,117 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:46:23,083 - INFO - [Step=15250]	Loss=1.6191	161.3 examples/second
2022-01-10 10:49:28,280 - INFO - [Step=15500]	Loss=1.6418	172.8 examples/second
2022-01-10 10:52:33,604 - INFO - [Step=15750]	Loss=1.6309	172.7 examples/second
2022-01-10 10:54:09,660 - INFO - Test Loss=1.7628, Test top-1 acc=0.5583
2022-01-10 10:54:09,660 - INFO - Group Accuracy:

2022-01-10 10:54:09,660 - INFO - [0.96891564 0.97228914 0.97108436 0.97542167 0.9672289  0.98698795
 0.96457833 0.94192773 0.98289156 0.9631325  0.9742169  0.96771085
 0.9587952  0.96048194 0.96361446 0.9742169  0.98674697]
2022-01-10 10:54:09,661 - INFO - Epoch time: 631.5442111492157
2022-01-10 10:54:09,661 - INFO - 
Epoch: 19
2022-01-10 10:54:09,662 - INFO - 
Learning Rate: 0.1000
2022-01-10 10:55:41,418 - INFO - [Step=16000]	Loss=1.6170	170.4 examples/second
2022-01-10 10:57:37,325 - INFO - [Step=16250]	Loss=1.6043	276.1 examples/second
2022-01-10 10:59:32,844 - INFO - [Step=16500]	Loss=1.5849	277.0 examples/second
2022-01-10 11:01:13,092 - INFO - Test Loss=1.7558, Test top-1 acc=0.5776
2022-01-10 11:01:13,093 - INFO - Group Accuracy:

2022-01-10 11:01:13,093 - INFO - [0.96024096 0.9768675  0.9672289  0.9785542  0.96698797 0.98433733
 0.9628916  0.9727711  0.98313254 0.9662651  0.97518075 0.9703615
 0.95421684 0.96361446 0.96433735 0.9727711  0.98746985]
2022-01-10 11:01:13,094 - INFO - Epoch time: 423.4325907230377
2022-01-10 11:01:13,094 - INFO - 
Epoch: 20
2022-01-10 11:01:13,094 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:01:38,422 - INFO - [Step=16750]	Loss=1.5946	254.8 examples/second
2022-01-10 11:03:34,275 - INFO - [Step=17000]	Loss=1.5716	276.2 examples/second
2022-01-10 11:05:29,918 - INFO - [Step=17250]	Loss=1.5602	276.7 examples/second
2022-01-10 11:07:25,528 - INFO - [Step=17500]	Loss=1.5553	276.8 examples/second
2022-01-10 11:07:49,235 - INFO - Test Loss=1.9245, Test top-1 acc=0.5528
2022-01-10 11:07:49,235 - INFO - Group Accuracy:

2022-01-10 11:07:49,235 - INFO - [0.95759034 0.97493976 0.9621687  0.9739759  0.96457833 0.98289156
 0.9672289  0.9713253  0.97831327 0.96072286 0.96843374 0.9626506
 0.9621687  0.9628916  0.95759034 0.96795183 0.9855422 ]
2022-01-10 11:07:49,237 - INFO - Epoch time: 396.1427102088928
2022-01-10 11:07:49,237 - INFO - 
Epoch: 21
2022-01-10 11:07:49,237 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:09:30,799 - INFO - [Step=17750]	Loss=1.5244	255.4 examples/second
2022-01-10 11:11:26,706 - INFO - [Step=18000]	Loss=1.5338	276.1 examples/second
2022-01-10 11:13:22,273 - INFO - [Step=18250]	Loss=1.5416	276.9 examples/second
2022-01-10 11:14:25,376 - INFO - Test Loss=1.6909, Test top-1 acc=0.5824
2022-01-10 11:14:25,376 - INFO - Group Accuracy:

2022-01-10 11:14:25,376 - INFO - [0.96819276 0.9773494  0.96771085 0.9826506  0.9686747  0.98650604
 0.9626506  0.97180724 0.97445786 0.96433735 0.9766265  0.96891564
 0.95759034 0.9587952  0.95325303 0.9698795  0.9879518 ]
2022-01-10 11:14:25,377 - INFO - Saving...
2022-01-10 11:14:25,692 - INFO - Epoch time: 396.45460319519043
2022-01-10 11:14:25,692 - INFO - 
Epoch: 22
2022-01-10 11:14:25,692 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:15:28,231 - INFO - [Step=18500]	Loss=1.4932	254.1 examples/second
2022-01-10 11:17:23,844 - INFO - [Step=18750]	Loss=1.5186	276.8 examples/second
2022-01-10 11:19:19,556 - INFO - [Step=19000]	Loss=1.5256	276.6 examples/second
2022-01-10 11:21:01,842 - INFO - Test Loss=2.0751, Test top-1 acc=0.5627
2022-01-10 11:21:01,842 - INFO - Group Accuracy:

2022-01-10 11:21:01,842 - INFO - [0.9539759  0.98024094 0.9518072  0.9703615  0.96457833 0.98698795
 0.966506   0.9551807  0.97927713 0.96385545 0.97301203 0.97204816
 0.9592771  0.9624096  0.9585542  0.9703615  0.98771083]
2022-01-10 11:21:01,843 - INFO - Epoch time: 396.15129804611206
2022-01-10 11:21:01,843 - INFO - 
Epoch: 23
2022-01-10 11:21:01,843 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:21:24,839 - INFO - [Step=19250]	Loss=1.4948	255.4 examples/second
2022-01-10 11:23:20,618 - INFO - [Step=19500]	Loss=1.4782	276.4 examples/second
2022-01-10 11:25:16,092 - INFO - [Step=19750]	Loss=1.5014	277.1 examples/second
2022-01-10 11:27:11,946 - INFO - [Step=20000]	Loss=1.4856	276.2 examples/second
2022-01-10 11:27:38,146 - INFO - Test Loss=1.4472, Test top-1 acc=0.6267
2022-01-10 11:27:38,147 - INFO - Group Accuracy:

2022-01-10 11:27:38,147 - INFO - [0.96771085 0.98240966 0.9628916  0.98698795 0.97108436 0.9889157
 0.9691566  0.973253   0.97951806 0.96771085 0.9812048  0.97445786
 0.96361446 0.9628916  0.9657831  0.9778313  0.9920482 ]
2022-01-10 11:27:38,148 - INFO - Saving...
2022-01-10 11:27:38,872 - INFO - Epoch time: 397.02891659736633
2022-01-10 11:27:38,873 - INFO - 
Epoch: 24
2022-01-10 11:27:38,873 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:29:18,121 - INFO - [Step=20250]	Loss=1.4533	253.6 examples/second
2022-01-10 11:31:13,717 - INFO - [Step=20500]	Loss=1.4781	276.8 examples/second
2022-01-10 11:33:09,298 - INFO - [Step=20750]	Loss=1.4782	276.9 examples/second
2022-01-10 11:34:15,059 - INFO - Test Loss=1.4942, Test top-1 acc=0.6318
2022-01-10 11:34:15,059 - INFO - Group Accuracy:

2022-01-10 11:34:15,059 - INFO - [0.96819276 0.9727711  0.9746988  0.98       0.9706024  0.9879518
 0.9672289  0.9703615  0.9848193  0.97108436 0.97831327 0.9742169
 0.9655422  0.9660241  0.96385545 0.97566265 0.98771083]
2022-01-10 11:34:15,060 - INFO - Saving...
2022-01-10 11:34:15,391 - INFO - Epoch time: 396.518714427948
2022-01-10 11:34:15,391 - INFO - 
Epoch: 25
2022-01-10 11:34:15,392 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:35:15,269 - INFO - [Step=21000]	Loss=1.4500	254.0 examples/second
2022-01-10 11:37:10,709 - INFO - [Step=21250]	Loss=1.4435	277.2 examples/second
2022-01-10 11:39:06,288 - INFO - [Step=21500]	Loss=1.4592	276.9 examples/second
2022-01-10 11:40:50,971 - INFO - Test Loss=1.5408, Test top-1 acc=0.6294
2022-01-10 11:40:50,972 - INFO - Group Accuracy:

2022-01-10 11:40:50,972 - INFO - [0.9672289  0.96048194 0.97156626 0.98578316 0.9737349  0.9901205
 0.96843374 0.97228914 0.98361444 0.9713253  0.97831327 0.9768675
 0.9573494  0.96698797 0.95277107 0.9746988  0.9893976 ]
2022-01-10 11:40:50,973 - INFO - Epoch time: 395.5817747116089
2022-01-10 11:40:50,973 - INFO - 
Epoch: 26
2022-01-10 11:40:50,973 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:41:11,286 - INFO - [Step=21750]	Loss=1.4620	256.0 examples/second
2022-01-10 11:43:06,737 - INFO - [Step=22000]	Loss=1.4002	277.2 examples/second
2022-01-10 11:45:02,120 - INFO - [Step=22250]	Loss=1.4352	277.3 examples/second
2022-01-10 11:46:57,521 - INFO - [Step=22500]	Loss=1.4407	277.3 examples/second
2022-01-10 11:47:26,029 - INFO - Test Loss=1.4789, Test top-1 acc=0.6410
2022-01-10 11:47:26,029 - INFO - Group Accuracy:

2022-01-10 11:47:26,029 - INFO - [0.966506   0.973494   0.9691566  0.98650604 0.96096385 0.9889157
 0.9691566  0.97518075 0.9826506  0.97108436 0.98024094 0.9693976
 0.9619277  0.966747   0.966747   0.9778313  0.99036145]
2022-01-10 11:47:26,030 - INFO - Saving...
2022-01-10 11:47:26,294 - INFO - Epoch time: 395.320454120636
2022-01-10 11:47:26,294 - INFO - 
Epoch: 27
2022-01-10 11:47:26,294 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:49:03,105 - INFO - [Step=22750]	Loss=1.3826	254.8 examples/second
2022-01-10 11:50:58,816 - INFO - [Step=23000]	Loss=1.4047	276.6 examples/second
2022-01-10 11:52:54,751 - INFO - [Step=23250]	Loss=1.4412	276.0 examples/second
2022-01-10 11:54:02,893 - INFO - Test Loss=1.4264, Test top-1 acc=0.6419
2022-01-10 11:54:02,894 - INFO - Group Accuracy:

2022-01-10 11:54:02,894 - INFO - [0.9693976  0.9778313  0.97180724 0.9848193  0.97180724 0.9881928
 0.9703615  0.97445786 0.97927713 0.9657831  0.9766265  0.97156626
 0.96072286 0.96698797 0.97156626 0.97903615 0.99060243]
2022-01-10 11:54:02,895 - INFO - Saving...
2022-01-10 11:54:03,339 - INFO - Epoch time: 397.0448317527771
2022-01-10 11:54:03,339 - INFO - 
Epoch: 28
2022-01-10 11:54:03,339 - INFO - 
Learning Rate: 0.1000
2022-01-10 11:55:01,547 - INFO - [Step=23500]	Loss=1.3999	252.4 examples/second
2022-01-10 11:56:57,514 - INFO - [Step=23750]	Loss=1.3926	275.9 examples/second
2022-01-10 11:58:53,270 - INFO - [Step=24000]	Loss=1.3949	276.4 examples/second
2022-01-10 12:00:40,455 - INFO - Test Loss=1.3872, Test top-1 acc=0.6701
2022-01-10 12:00:40,456 - INFO - Group Accuracy:

2022-01-10 12:00:40,456 - INFO - [0.9713253  0.9838554  0.9778313  0.9853012  0.9771084  0.98771083
 0.9686747  0.97614455 0.9816868  0.9693976  0.9812048  0.9773494
 0.9657831  0.96048194 0.96771085 0.97831327 0.9930121 ]
2022-01-10 12:00:40,457 - INFO - Saving...
2022-01-10 12:00:41,167 - INFO - Epoch time: 397.82727909088135
2022-01-10 12:00:41,167 - INFO - 
Epoch: 29
2022-01-10 12:00:41,167 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:00:59,389 - INFO - [Step=24250]	Loss=1.3808	253.7 examples/second
2022-01-10 12:02:55,449 - INFO - [Step=24500]	Loss=1.0970	275.7 examples/second
2022-01-10 12:04:51,202 - INFO - [Step=24750]	Loss=1.0242	276.5 examples/second
2022-01-10 12:06:46,841 - INFO - [Step=25000]	Loss=1.0049	276.7 examples/second
2022-01-10 12:07:17,548 - INFO - Test Loss=0.9418, Test top-1 acc=0.7410
2022-01-10 12:07:17,548 - INFO - Group Accuracy:

2022-01-10 12:07:17,548 - INFO - [0.97445786 0.9884337  0.9826506  0.99108434 0.97903615 0.9920482
 0.97831327 0.9814458  0.9884337  0.97566265 0.9884337  0.9833735
 0.9742169  0.9771084  0.9746988  0.98626506 0.99421686]
2022-01-10 12:07:17,550 - INFO - Saving...
2022-01-10 12:07:17,991 - INFO - Epoch time: 396.82450580596924
2022-01-10 12:07:17,992 - INFO - 
Epoch: 30
2022-01-10 12:07:17,992 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:08:52,899 - INFO - [Step=25250]	Loss=0.9548	253.9 examples/second
2022-01-10 12:10:48,411 - INFO - [Step=25500]	Loss=0.9461	277.0 examples/second
2022-01-10 12:12:43,934 - INFO - [Step=25750]	Loss=0.9327	277.0 examples/second
2022-01-10 12:13:54,247 - INFO - Test Loss=0.9471, Test top-1 acc=0.7475
2022-01-10 12:13:54,248 - INFO - Group Accuracy:

2022-01-10 12:13:54,248 - INFO - [0.97614455 0.9901205  0.98361444 0.99156624 0.9819277  0.99373496
 0.9785542  0.9826506  0.9898795  0.97590363 0.98746985 0.9840964
 0.97542167 0.97614455 0.97445786 0.9855422  0.9939759 ]
2022-01-10 12:13:54,249 - INFO - Saving...
2022-01-10 12:13:54,693 - INFO - Epoch time: 396.70188093185425
2022-01-10 12:13:54,694 - INFO - 
Epoch: 31
2022-01-10 12:13:54,694 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:14:49,845 - INFO - [Step=26000]	Loss=0.9456	254.2 examples/second
2022-01-10 12:16:45,903 - INFO - [Step=26250]	Loss=0.9159	275.7 examples/second
2022-01-10 12:18:41,904 - INFO - [Step=26500]	Loss=0.8958	275.9 examples/second
2022-01-10 12:20:31,919 - INFO - Test Loss=0.9328, Test top-1 acc=0.7540
2022-01-10 12:20:31,920 - INFO - Group Accuracy:

2022-01-10 12:20:31,920 - INFO - [0.9771084  0.99036145 0.9845783  0.99156624 0.9826506  0.993253
 0.9787952  0.98289156 0.98963857 0.97614455 0.9891566  0.98433733
 0.97518075 0.9785542  0.97638553 0.98626506 0.9946988 ]
2022-01-10 12:20:31,920 - INFO - Saving...
2022-01-10 12:20:32,234 - INFO - Epoch time: 397.5398564338684
2022-01-10 12:20:32,234 - INFO - 
Epoch: 32
2022-01-10 12:20:32,234 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:20:48,419 - INFO - [Step=26750]	Loss=0.9014	252.9 examples/second
2022-01-10 12:22:44,409 - INFO - [Step=27000]	Loss=0.8777	275.9 examples/second
2022-01-10 12:24:40,041 - INFO - [Step=27250]	Loss=0.8886	276.7 examples/second
2022-01-10 12:26:35,687 - INFO - [Step=27500]	Loss=0.8860	276.7 examples/second
2022-01-10 12:27:09,002 - INFO - Test Loss=0.9135, Test top-1 acc=0.7545
2022-01-10 12:27:09,002 - INFO - Group Accuracy:

2022-01-10 12:27:09,002 - INFO - [0.9775904  0.9898795  0.9840964  0.9920482  0.98289156 0.99421686
 0.9807229  0.9826506  0.9901205  0.97566265 0.98963857 0.9853012
 0.97493976 0.9787952  0.97590363 0.98578316 0.9956626 ]
2022-01-10 12:27:09,003 - INFO - Saving...
2022-01-10 12:27:09,279 - INFO - Epoch time: 397.04497027397156
2022-01-10 12:27:09,279 - INFO - 
Epoch: 33
2022-01-10 12:27:09,279 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:28:42,144 - INFO - [Step=27750]	Loss=0.8642	253.1 examples/second
2022-01-10 12:30:38,270 - INFO - [Step=28000]	Loss=0.8731	275.6 examples/second
2022-01-10 12:32:34,238 - INFO - [Step=28250]	Loss=0.8491	275.9 examples/second
2022-01-10 12:33:46,672 - INFO - Test Loss=0.8764, Test top-1 acc=0.7590
2022-01-10 12:33:46,678 - INFO - Group Accuracy:

2022-01-10 12:33:46,678 - INFO - [0.9780723  0.9898795  0.9840964  0.99156624 0.9833735  0.993494
 0.98240966 0.98289156 0.9881928  0.97590363 0.9901205  0.98433733
 0.9768675  0.97975904 0.97518075 0.98746985 0.9954217 ]
2022-01-10 12:33:46,680 - INFO - Saving...
2022-01-10 12:33:46,954 - INFO - Epoch time: 397.6753137111664
2022-01-10 12:33:46,955 - INFO - 
Epoch: 34
2022-01-10 12:33:46,955 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:34:39,923 - INFO - [Step=28500]	Loss=0.8639	254.6 examples/second
2022-01-10 12:36:36,290 - INFO - [Step=28750]	Loss=0.8706	275.0 examples/second
2022-01-10 12:38:32,353 - INFO - [Step=29000]	Loss=0.8325	275.7 examples/second
2022-01-10 12:40:24,281 - INFO - Test Loss=0.9033, Test top-1 acc=0.7651
2022-01-10 12:40:24,282 - INFO - Group Accuracy:

2022-01-10 12:40:24,282 - INFO - [0.9773494  0.9893976  0.9848193  0.9920482  0.98289156 0.99421686
 0.98024094 0.98240966 0.9901205  0.97542167 0.9898795  0.9848193
 0.9766265  0.9785542  0.97542167 0.98674697 0.9959036 ]
2022-01-10 12:40:24,282 - INFO - Saving...
2022-01-10 12:40:25,007 - INFO - Epoch time: 398.0523946285248
2022-01-10 12:40:25,007 - INFO - 
Epoch: 35
2022-01-10 12:40:25,007 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:40:38,615 - INFO - [Step=29250]	Loss=0.8475	253.4 examples/second
2022-01-10 12:42:34,482 - INFO - [Step=29500]	Loss=0.8417	276.2 examples/second
2022-01-10 12:44:29,724 - INFO - [Step=29750]	Loss=0.8443	277.7 examples/second
2022-01-10 12:46:24,888 - INFO - [Step=30000]	Loss=0.8359	277.9 examples/second
2022-01-10 12:47:00,214 - INFO - Test Loss=0.8695, Test top-1 acc=0.7619
2022-01-10 12:47:00,214 - INFO - Group Accuracy:

2022-01-10 12:47:00,214 - INFO - [0.9771084  0.98963857 0.9848193  0.9920482  0.9833735  0.9946988
 0.9812048  0.9821687  0.99084336 0.97542167 0.9891566  0.9853012
 0.9775904  0.9804819  0.97542167 0.98746985 0.9954217 ]
2022-01-10 12:47:00,215 - INFO - Epoch time: 395.20792055130005
2022-01-10 12:47:00,215 - INFO - 
Epoch: 36
2022-01-10 12:47:00,215 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:48:29,925 - INFO - [Step=30250]	Loss=0.8103	255.9 examples/second
2022-01-10 12:50:24,791 - INFO - [Step=30500]	Loss=0.8246	278.6 examples/second
2022-01-10 12:52:19,538 - INFO - [Step=30750]	Loss=0.8185	278.9 examples/second
2022-01-10 12:53:33,333 - INFO - Test Loss=0.8629, Test top-1 acc=0.7723
2022-01-10 12:53:33,333 - INFO - Group Accuracy:

2022-01-10 12:53:33,333 - INFO - [0.97903615 0.99108434 0.9850602  0.99108434 0.9819277  0.99445784
 0.9819277  0.9821687  0.99108434 0.97566265 0.9898795  0.98433733
 0.97614455 0.9804819  0.97638553 0.98771083 0.9959036 ]
2022-01-10 12:53:33,334 - INFO - Saving...
2022-01-10 12:53:33,616 - INFO - Epoch time: 393.4004611968994
2022-01-10 12:53:33,616 - INFO - 
Epoch: 37
2022-01-10 12:53:33,616 - INFO - 
Learning Rate: 0.0100
2022-01-10 12:54:23,965 - INFO - [Step=31000]	Loss=0.8130	257.2 examples/second
2022-01-10 12:56:19,171 - INFO - [Step=31250]	Loss=0.8151	277.8 examples/second
2022-01-10 12:58:14,167 - INFO - [Step=31500]	Loss=0.8248	278.3 examples/second
2022-01-10 13:00:07,271 - INFO - Test Loss=0.8673, Test top-1 acc=0.7651
2022-01-10 13:00:07,272 - INFO - Group Accuracy:

2022-01-10 13:00:07,272 - INFO - [0.9787952  0.99108434 0.9840964  0.9918072  0.9833735  0.99445784
 0.9812048  0.98289156 0.99036145 0.97614455 0.9901205  0.9853012
 0.9771084  0.97903615 0.97614455 0.98578316 0.9956626 ]
2022-01-10 13:00:07,272 - INFO - Epoch time: 393.65625643730164
2022-01-10 13:00:07,272 - INFO - 
Epoch: 38
2022-01-10 13:00:07,272 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:00:18,824 - INFO - [Step=31750]	Loss=0.7912	256.7 examples/second
2022-01-10 13:02:13,769 - INFO - [Step=32000]	Loss=0.7882	278.4 examples/second
2022-01-10 13:04:08,845 - INFO - [Step=32250]	Loss=0.7983	278.1 examples/second
2022-01-10 13:06:03,772 - INFO - [Step=32500]	Loss=0.8002	278.4 examples/second
2022-01-10 13:06:41,264 - INFO - Test Loss=0.8793, Test top-1 acc=0.7653
2022-01-10 13:06:41,265 - INFO - Group Accuracy:

2022-01-10 13:06:41,265 - INFO - [0.97951806 0.99084336 0.9845783  0.9922892  0.98313254 0.9939759
 0.9807229  0.9826506  0.99036145 0.97566265 0.98963857 0.9853012
 0.9768675  0.97927713 0.97493976 0.98698795 0.9961446 ]
2022-01-10 13:06:41,266 - INFO - Epoch time: 393.9936375617981
2022-01-10 13:06:41,266 - INFO - 
Epoch: 39
2022-01-10 13:06:41,266 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:08:08,456 - INFO - [Step=32750]	Loss=0.7938	256.6 examples/second
2022-01-10 13:10:03,262 - INFO - [Step=33000]	Loss=0.7783	278.7 examples/second
2022-01-10 13:11:58,040 - INFO - [Step=33250]	Loss=0.7766	278.8 examples/second
2022-01-10 13:13:14,263 - INFO - Test Loss=0.8375, Test top-1 acc=0.7704
2022-01-10 13:13:14,263 - INFO - Group Accuracy:

2022-01-10 13:13:14,263 - INFO - [0.9780723  0.9898795  0.98578316 0.9927711  0.98361444 0.9939759
 0.97951806 0.98361444 0.99060243 0.97493976 0.9898795  0.9850602
 0.9766265  0.9785542  0.9768675  0.98650604 0.9968675 ]
2022-01-10 13:13:14,264 - INFO - Epoch time: 392.9982907772064
2022-01-10 13:13:14,265 - INFO - 
Epoch: 40
2022-01-10 13:13:14,265 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:14:01,974 - INFO - [Step=33500]	Loss=0.7880	258.2 examples/second
2022-01-10 13:15:56,822 - INFO - [Step=33750]	Loss=0.7585	278.6 examples/second
2022-01-10 13:17:51,776 - INFO - [Step=34000]	Loss=0.7797	278.4 examples/second
2022-01-10 13:19:47,049 - INFO - Test Loss=0.8302, Test top-1 acc=0.7711
2022-01-10 13:19:47,050 - INFO - Group Accuracy:

2022-01-10 13:19:47,050 - INFO - [0.97903615 0.99036145 0.98650604 0.9920482  0.9821687  0.9946988
 0.9819277  0.98289156 0.99084336 0.97518075 0.9886747  0.9860241
 0.9778313  0.98024094 0.9775904  0.98722893 0.9946988 ]
2022-01-10 13:19:47,050 - INFO - Epoch time: 392.7857060432434
2022-01-10 13:19:47,050 - INFO - 
Epoch: 41
2022-01-10 13:19:47,050 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:19:55,752 - INFO - [Step=34250]	Loss=0.7871	258.1 examples/second
2022-01-10 13:21:50,586 - INFO - [Step=34500]	Loss=0.7716	278.7 examples/second
2022-01-10 13:23:45,511 - INFO - [Step=34750]	Loss=0.7662	278.4 examples/second
2022-01-10 13:25:40,402 - INFO - [Step=35000]	Loss=0.7651	278.5 examples/second
2022-01-10 13:26:20,024 - INFO - Test Loss=0.8146, Test top-1 acc=0.7740
2022-01-10 13:26:20,025 - INFO - Group Accuracy:

2022-01-10 13:26:20,025 - INFO - [0.9787952  0.99036145 0.9845783  0.9918072  0.9838554  0.9939759
 0.98       0.9853012  0.9898795  0.97590363 0.9891566  0.98578316
 0.9775904  0.9819277  0.9785542  0.98698795 0.9963855 ]
2022-01-10 13:26:20,026 - INFO - Saving...
2022-01-10 13:26:20,314 - INFO - Epoch time: 393.26376700401306
2022-01-10 13:26:20,314 - INFO - 
Epoch: 42
2022-01-10 13:26:20,314 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:27:45,151 - INFO - [Step=35250]	Loss=0.7526	256.5 examples/second
2022-01-10 13:29:40,024 - INFO - [Step=35500]	Loss=0.7599	278.6 examples/second
2022-01-10 13:31:35,044 - INFO - [Step=35750]	Loss=0.7599	278.2 examples/second
2022-01-10 13:32:54,098 - INFO - Test Loss=0.8293, Test top-1 acc=0.7720
2022-01-10 13:32:54,098 - INFO - Group Accuracy:

2022-01-10 13:32:54,098 - INFO - [0.9804819  0.99108434 0.9853012  0.993253   0.9833735  0.9946988
 0.9814458  0.9816868  0.9913253  0.9766265  0.9898795  0.9848193
 0.9771084  0.9787952  0.9766265  0.9879518  0.9954217 ]
2022-01-10 13:32:54,099 - INFO - Epoch time: 393.78418803215027
2022-01-10 13:32:54,099 - INFO - 
Epoch: 43
2022-01-10 13:32:54,099 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:33:39,868 - INFO - [Step=36000]	Loss=0.7548	256.4 examples/second
2022-01-10 13:35:35,091 - INFO - [Step=36250]	Loss=0.7454	277.7 examples/second
2022-01-10 13:37:30,065 - INFO - [Step=36500]	Loss=0.7509	278.3 examples/second
2022-01-10 13:39:27,719 - INFO - Test Loss=0.8491, Test top-1 acc=0.7696
2022-01-10 13:39:27,720 - INFO - Group Accuracy:

2022-01-10 13:39:27,720 - INFO - [0.97903615 0.9901205  0.9838554  0.9925301  0.9845783  0.9939759
 0.9814458  0.98289156 0.9901205  0.9746988  0.99036145 0.9833735
 0.9773494  0.97975904 0.9773494  0.98674697 0.9959036 ]
2022-01-10 13:39:27,721 - INFO - Epoch time: 393.62194204330444
2022-01-10 13:39:27,721 - INFO - 
Epoch: 44
2022-01-10 13:39:27,721 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:39:34,228 - INFO - [Step=36750]	Loss=0.7490	257.7 examples/second
2022-01-10 13:41:29,147 - INFO - [Step=37000]	Loss=0.7192	278.5 examples/second
2022-01-10 13:43:24,023 - INFO - [Step=37250]	Loss=0.7462	278.6 examples/second
2022-01-10 13:45:18,875 - INFO - [Step=37500]	Loss=0.7468	278.6 examples/second
2022-01-10 13:46:00,907 - INFO - Test Loss=0.8344, Test top-1 acc=0.7773
2022-01-10 13:46:00,908 - INFO - Group Accuracy:

2022-01-10 13:46:00,908 - INFO - [0.97903615 0.9901205  0.98433733 0.993253   0.9850602  0.9956626
 0.9809638  0.9826506  0.9893976  0.9766265  0.99036145 0.98674697
 0.97614455 0.97927713 0.9778313  0.98722893 0.9966265 ]
2022-01-10 13:46:00,908 - INFO - Saving...
2022-01-10 13:46:01,207 - INFO - Epoch time: 393.4860849380493
2022-01-10 13:46:01,207 - INFO - 
Epoch: 45
2022-01-10 13:46:01,207 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:47:23,491 - INFO - [Step=37750]	Loss=0.7248	256.8 examples/second
2022-01-10 13:49:18,537 - INFO - [Step=38000]	Loss=0.7395	278.2 examples/second
2022-01-10 13:51:13,463 - INFO - [Step=38250]	Loss=0.7376	278.4 examples/second
2022-01-10 13:52:34,405 - INFO - Test Loss=0.8565, Test top-1 acc=0.7660
2022-01-10 13:52:34,406 - INFO - Group Accuracy:

2022-01-10 13:52:34,406 - INFO - [0.9780723  0.99060243 0.9855422  0.9930121  0.9833735  0.9939759
 0.98024094 0.9787952  0.99108434 0.97590363 0.99108434 0.9845783
 0.97542167 0.98024094 0.9785542  0.98746985 0.9963855 ]
2022-01-10 13:52:34,407 - INFO - Epoch time: 393.1997559070587
2022-01-10 13:52:34,407 - INFO - 
Epoch: 46
2022-01-10 13:52:34,407 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:53:18,208 - INFO - [Step=38500]	Loss=0.7436	256.5 examples/second
2022-01-10 13:55:13,202 - INFO - [Step=38750]	Loss=0.7302	278.3 examples/second
2022-01-10 13:57:08,035 - INFO - [Step=39000]	Loss=0.7393	278.7 examples/second
2022-01-10 13:59:08,437 - INFO - Test Loss=0.8782, Test top-1 acc=0.7704
2022-01-10 13:59:08,437 - INFO - Group Accuracy:

2022-01-10 13:59:08,437 - INFO - [0.9787952  0.9913253  0.9821687  0.9927711  0.9826506  0.99373496
 0.97951806 0.98289156 0.99036145 0.97566265 0.9884337  0.9853012
 0.97590363 0.97927713 0.9768675  0.9884337  0.9961446 ]
2022-01-10 13:59:08,439 - INFO - Epoch time: 394.03168630599976
2022-01-10 13:59:08,439 - INFO - 
Epoch: 47
2022-01-10 13:59:08,439 - INFO - 
Learning Rate: 0.0100
2022-01-10 13:59:12,669 - INFO - [Step=39250]	Loss=0.7320	256.8 examples/second
2022-01-10 14:01:07,599 - INFO - [Step=39500]	Loss=0.7143	278.4 examples/second
2022-01-10 14:03:02,489 - INFO - [Step=39750]	Loss=0.7298	278.5 examples/second
2022-01-10 14:04:57,357 - INFO - [Step=40000]	Loss=0.7209	278.6 examples/second
2022-01-10 14:05:41,424 - INFO - Test Loss=0.8811, Test top-1 acc=0.7725
2022-01-10 14:05:41,424 - INFO - Group Accuracy:

2022-01-10 14:05:41,424 - INFO - [0.9785542  0.99084336 0.9848193  0.9930121  0.9826506  0.9951807
 0.98240966 0.9821687  0.9891566  0.9727711  0.99036145 0.9840964
 0.9773494  0.98240966 0.9780723  0.9881928  0.9961446 ]
2022-01-10 14:05:41,425 - INFO - Epoch time: 392.9868049621582
2022-01-10 14:05:41,425 - INFO - 
Epoch: 48
2022-01-10 14:05:41,426 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:07:01,444 - INFO - [Step=40250]	Loss=0.7117	257.9 examples/second
2022-01-10 14:08:56,572 - INFO - [Step=40500]	Loss=0.7053	278.0 examples/second
2022-01-10 14:10:51,353 - INFO - [Step=40750]	Loss=0.7122	278.8 examples/second
2022-01-10 14:12:14,579 - INFO - Test Loss=0.8481, Test top-1 acc=0.7764
2022-01-10 14:12:14,580 - INFO - Group Accuracy:

2022-01-10 14:12:14,580 - INFO - [0.97927713 0.99108434 0.9845783  0.9927711  0.9833735  0.99445784
 0.9814458  0.9840964  0.9898795  0.97638553 0.99060243 0.9845783
 0.97903615 0.9814458  0.97614455 0.9881928  0.9961446 ]
2022-01-10 14:12:14,581 - INFO - Epoch time: 393.1550920009613
2022-01-10 14:12:14,581 - INFO - 
Epoch: 49
2022-01-10 14:12:14,581 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:12:55,450 - INFO - [Step=41000]	Loss=0.7218	257.9 examples/second
2022-01-10 14:14:50,608 - INFO - [Step=41250]	Loss=0.7049	277.9 examples/second
2022-01-10 14:16:45,539 - INFO - [Step=41500]	Loss=0.7000	278.4 examples/second
2022-01-10 14:18:40,389 - INFO - [Step=41750]	Loss=0.7299	278.6 examples/second
2022-01-10 14:18:48,072 - INFO - Test Loss=0.8604, Test top-1 acc=0.7718
2022-01-10 14:18:48,072 - INFO - Group Accuracy:

2022-01-10 14:18:48,072 - INFO - [0.98       0.9898795  0.98433733 0.9922892  0.9833735  0.99421686
 0.9812048  0.9819277  0.9893976  0.97542167 0.9891566  0.9848193
 0.97614455 0.97927713 0.9768675  0.9891566  0.9954217 ]
2022-01-10 14:18:48,073 - INFO - Epoch time: 393.4924657344818
2022-01-10 14:18:48,073 - INFO - 
Epoch: 50
2022-01-10 14:18:48,073 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:20:45,342 - INFO - [Step=42000]	Loss=0.6987	256.1 examples/second
2022-01-10 14:22:40,437 - INFO - [Step=42250]	Loss=0.6934	278.0 examples/second
2022-01-10 14:24:35,279 - INFO - [Step=42500]	Loss=0.7139	278.6 examples/second
2022-01-10 14:25:21,587 - INFO - Test Loss=0.8365, Test top-1 acc=0.7735
2022-01-10 14:25:21,587 - INFO - Group Accuracy:

2022-01-10 14:25:21,587 - INFO - [0.97951806 0.99060243 0.98433733 0.99373496 0.9833735  0.99421686
 0.9787952  0.9819277  0.9901205  0.97638553 0.98771083 0.9850602
 0.9778313  0.9826506  0.97566265 0.9879518  0.9963855 ]
2022-01-10 14:25:21,588 - INFO - Epoch time: 393.514545917511
2022-01-10 14:25:21,588 - INFO - 
Epoch: 51
2022-01-10 14:25:21,588 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:26:39,417 - INFO - [Step=42750]	Loss=0.7103	257.8 examples/second
2022-01-10 14:28:34,457 - INFO - [Step=43000]	Loss=0.6870	278.2 examples/second
2022-01-10 14:30:29,533 - INFO - [Step=43250]	Loss=0.7029	278.1 examples/second
2022-01-10 14:31:55,125 - INFO - Test Loss=0.8347, Test top-1 acc=0.7754
2022-01-10 14:31:55,125 - INFO - Group Accuracy:

2022-01-10 14:31:55,125 - INFO - [0.9807229  0.98963857 0.9840964  0.9920482  0.9819277  0.99493974
 0.9804819  0.9833735  0.9901205  0.9778313  0.9893976  0.9838554
 0.97927713 0.9809638  0.9766265  0.9881928  0.9954217 ]
2022-01-10 14:31:55,126 - INFO - Epoch time: 393.53820848464966
2022-01-10 14:31:55,126 - INFO - 
Epoch: 52
2022-01-10 14:31:55,126 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:32:33,886 - INFO - [Step=43500]	Loss=0.6924	257.3 examples/second
2022-01-10 14:34:29,241 - INFO - [Step=43750]	Loss=0.6918	277.4 examples/second
2022-01-10 14:36:24,276 - INFO - [Step=44000]	Loss=0.6905	278.2 examples/second
2022-01-10 14:38:19,173 - INFO - [Step=44250]	Loss=0.7026	278.5 examples/second
2022-01-10 14:38:28,760 - INFO - Test Loss=0.8339, Test top-1 acc=0.7706
2022-01-10 14:38:28,760 - INFO - Group Accuracy:

2022-01-10 14:38:28,760 - INFO - [0.97903615 0.99084336 0.9860241  0.99156624 0.9814458  0.9951807
 0.97927713 0.98289156 0.9884337  0.97590363 0.9889157  0.98433733
 0.9775904  0.9785542  0.9780723  0.98722893 0.9951807 ]
2022-01-10 14:38:28,761 - INFO - Epoch time: 393.63495779037476
2022-01-10 14:38:28,761 - INFO - 
Epoch: 53
2022-01-10 14:38:28,761 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:40:23,336 - INFO - [Step=44500]	Loss=0.6800	257.7 examples/second
2022-01-10 14:42:18,326 - INFO - [Step=44750]	Loss=0.6809	278.3 examples/second
2022-01-10 14:44:13,366 - INFO - [Step=45000]	Loss=0.7006	278.2 examples/second
2022-01-10 14:45:02,106 - INFO - Test Loss=0.8203, Test top-1 acc=0.7788
2022-01-10 14:45:02,106 - INFO - Group Accuracy:

2022-01-10 14:45:02,106 - INFO - [0.9785542  0.9898795  0.98433733 0.9930121  0.98240966 0.9954217
 0.9807229  0.98       0.99036145 0.9768675  0.9920482  0.9855422
 0.9778313  0.9804819  0.9778313  0.9889157  0.9956626 ]
2022-01-10 14:45:02,108 - INFO - Saving...
2022-01-10 14:45:02,495 - INFO - Epoch time: 393.7340986728668
2022-01-10 14:45:02,496 - INFO - 
Epoch: 54
2022-01-10 14:45:02,496 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:46:18,674 - INFO - [Step=45250]	Loss=0.6725	255.4 examples/second
2022-01-10 14:48:14,039 - INFO - [Step=45500]	Loss=0.6853	277.4 examples/second
2022-01-10 14:50:09,371 - INFO - [Step=45750]	Loss=0.6839	277.5 examples/second
2022-01-10 14:51:37,293 - INFO - Test Loss=0.8799, Test top-1 acc=0.7711
2022-01-10 14:51:37,293 - INFO - Group Accuracy:

2022-01-10 14:51:37,293 - INFO - [0.97903615 0.9893976  0.9848193  0.9925301  0.9840964  0.99373496
 0.9807229  0.98240966 0.9891566  0.97518075 0.9891566  0.9838554
 0.97975904 0.9816868  0.97566265 0.98963857 0.9954217 ]
2022-01-10 14:51:37,294 - INFO - Epoch time: 394.79872703552246
2022-01-10 14:51:37,294 - INFO - 
Epoch: 55
2022-01-10 14:51:37,294 - INFO - 
Learning Rate: 0.0100
2022-01-10 14:52:13,958 - INFO - [Step=46000]	Loss=0.6760	256.8 examples/second
2022-01-10 14:54:08,935 - INFO - [Step=46250]	Loss=0.6753	278.3 examples/second
2022-01-10 14:56:03,873 - INFO - [Step=46500]	Loss=0.6857	278.4 examples/second
2022-01-10 14:57:58,675 - INFO - [Step=46750]	Loss=0.6817	278.7 examples/second
2022-01-10 14:58:10,486 - INFO - Test Loss=0.8461, Test top-1 acc=0.7740
2022-01-10 14:58:10,486 - INFO - Group Accuracy:

2022-01-10 14:58:10,486 - INFO - [0.9775904  0.99084336 0.98240966 0.9930121  0.9833735  0.99421686
 0.9814458  0.9812048  0.9886747  0.97542167 0.99036145 0.9848193
 0.9766265  0.9819277  0.97831327 0.9884337  0.99421686]
2022-01-10 14:58:10,487 - INFO - Epoch time: 393.1929564476013
2022-01-10 14:58:10,487 - INFO - 
Epoch: 56
2022-01-10 14:58:10,488 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:00:03,683 - INFO - [Step=47000]	Loss=0.6582	256.0 examples/second
2022-01-10 15:01:58,738 - INFO - [Step=47250]	Loss=0.6848	278.1 examples/second
2022-01-10 15:03:53,697 - INFO - [Step=47500]	Loss=0.6838	278.4 examples/second
2022-01-10 15:04:44,844 - INFO - Test Loss=0.8794, Test top-1 acc=0.7836
2022-01-10 15:04:44,845 - INFO - Group Accuracy:

2022-01-10 15:04:44,845 - INFO - [0.97831327 0.9901205  0.9833735  0.9913253  0.98313254 0.99493974
 0.9812048  0.98240966 0.9889157  0.9766265  0.9898795  0.98626506
 0.9766265  0.9816868  0.97831327 0.9889157  0.9968675 ]
2022-01-10 15:04:44,846 - INFO - Saving...
2022-01-10 15:04:45,470 - INFO - Epoch time: 394.98290038108826
2022-01-10 15:04:45,471 - INFO - 
Epoch: 57
2022-01-10 15:04:45,471 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:05:58,661 - INFO - [Step=47750]	Loss=0.6694	256.1 examples/second
2022-01-10 15:07:53,679 - INFO - [Step=48000]	Loss=0.6563	278.2 examples/second
2022-01-10 15:09:48,406 - INFO - [Step=48250]	Loss=0.6746	278.9 examples/second
2022-01-10 15:11:18,356 - INFO - Test Loss=0.8734, Test top-1 acc=0.7793
2022-01-10 15:11:18,356 - INFO - Group Accuracy:

2022-01-10 15:11:18,356 - INFO - [0.98       0.9901205  0.98313254 0.9925301  0.98313254 0.99493974
 0.9821687  0.9819277  0.9898795  0.97638553 0.99108434 0.98578316
 0.9771084  0.9807229  0.97590363 0.9879518  0.9959036 ]
2022-01-10 15:11:18,357 - INFO - Epoch time: 392.88674426078796
2022-01-10 15:11:18,357 - INFO - 
Epoch: 58
2022-01-10 15:11:18,358 - INFO - 
Learning Rate: 0.0100
2022-01-10 15:11:52,412 - INFO - [Step=48500]	Loss=0.6713	258.1 examples/second
2022-01-10 15:13:47,594 - INFO - [Step=48750]	Loss=0.6501	277.8 examples/second
2022-01-10 15:15:42,369 - INFO - [Step=49000]	Loss=0.6521	278.8 examples/second
2022-01-10 15:17:37,156 - INFO - [Step=49250]	Loss=0.6653	278.8 examples/second
2022-01-10 15:17:51,699 - INFO - Test Loss=0.8623, Test top-1 acc=0.7737
2022-01-10 15:17:51,699 - INFO - Group Accuracy:

2022-01-10 15:17:51,699 - INFO - [0.9775904  0.98963857 0.9848193  0.9927711  0.9833735  0.99493974
 0.9821687  0.98       0.99060243 0.9780723  0.99036145 0.98433733
 0.9780723  0.9809638  0.97903615 0.98746985 0.9963855 ]
2022-01-10 15:17:51,700 - INFO - Epoch time: 393.34260511398315
2022-01-10 15:17:51,700 - INFO - 
Epoch: 59
2022-01-10 15:17:51,700 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:19:41,786 - INFO - [Step=49500]	Loss=0.6314	256.8 examples/second
2022-01-10 15:21:36,736 - INFO - [Step=49750]	Loss=0.5944	278.4 examples/second
2022-01-10 15:23:31,425 - INFO - [Step=50000]	Loss=0.5706	279.0 examples/second
2022-01-10 15:24:24,631 - INFO - Test Loss=0.7868, Test top-1 acc=0.7918
2022-01-10 15:24:24,632 - INFO - Group Accuracy:

2022-01-10 15:24:24,632 - INFO - [0.97927713 0.9920482  0.9845783  0.993494   0.98433733 0.9951807
 0.9819277  0.9826506  0.9913253  0.9771084  0.9920482  0.98578316
 0.97927713 0.9816868  0.9775904  0.9891566  0.9966265 ]
2022-01-10 15:24:24,633 - INFO - Saving...
2022-01-10 15:24:25,032 - INFO - Epoch time: 393.33163571357727
2022-01-10 15:24:25,032 - INFO - 
Epoch: 60
2022-01-10 15:24:25,032 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:25:35,859 - INFO - [Step=50250]	Loss=0.5692	257.2 examples/second
2022-01-10 15:27:31,074 - INFO - [Step=50500]	Loss=0.5858	277.7 examples/second
2022-01-10 15:29:25,778 - INFO - [Step=50750]	Loss=0.5681	279.0 examples/second
2022-01-10 15:30:58,072 - INFO - Test Loss=0.7761, Test top-1 acc=0.7918
2022-01-10 15:30:58,073 - INFO - Group Accuracy:

2022-01-10 15:30:58,073 - INFO - [0.98       0.9927711  0.9850602  0.9922892  0.98361444 0.9946988
 0.9814458  0.98240966 0.99084336 0.97831327 0.99156624 0.98650604
 0.97903615 0.98240966 0.97903615 0.9901205  0.9968675 ]
2022-01-10 15:30:58,073 - INFO - Epoch time: 393.0412440299988
2022-01-10 15:30:58,073 - INFO - 
Epoch: 61
2022-01-10 15:30:58,073 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:31:30,257 - INFO - [Step=51000]	Loss=0.5680	257.1 examples/second
2022-01-10 15:33:25,168 - INFO - [Step=51250]	Loss=0.5539	278.5 examples/second
2022-01-10 15:35:20,297 - INFO - [Step=51500]	Loss=0.5607	277.9 examples/second
2022-01-10 15:37:15,029 - INFO - [Step=51750]	Loss=0.5525	278.9 examples/second
2022-01-10 15:37:31,559 - INFO - Test Loss=0.7951, Test top-1 acc=0.7911
2022-01-10 15:37:31,559 - INFO - Group Accuracy:

2022-01-10 15:37:31,559 - INFO - [0.97975904 0.9922892  0.9853012  0.9930121  0.9840964  0.99493974
 0.9816868  0.9826506  0.99084336 0.9773494  0.9913253  0.9860241
 0.97903615 0.9821687  0.97903615 0.9901205  0.9968675 ]
2022-01-10 15:37:31,560 - INFO - Epoch time: 393.4869258403778
2022-01-10 15:37:31,560 - INFO - 
Epoch: 62
2022-01-10 15:37:31,560 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:39:19,246 - INFO - [Step=52000]	Loss=0.5477	257.6 examples/second
2022-01-10 15:41:14,151 - INFO - [Step=52250]	Loss=0.5470	278.5 examples/second
2022-01-10 15:43:09,387 - INFO - [Step=52500]	Loss=0.5573	277.7 examples/second
2022-01-10 15:44:05,001 - INFO - Test Loss=0.7868, Test top-1 acc=0.7916
2022-01-10 15:44:05,001 - INFO - Group Accuracy:

2022-01-10 15:44:05,001 - INFO - [0.97975904 0.9927711  0.9840964  0.993253   0.98361444 0.9951807
 0.98240966 0.9826506  0.99060243 0.9773494  0.99084336 0.98626506
 0.97951806 0.98240966 0.97903615 0.9886747  0.9966265 ]
2022-01-10 15:44:05,002 - INFO - Epoch time: 393.4417417049408
2022-01-10 15:44:05,002 - INFO - 
Epoch: 63
2022-01-10 15:44:05,002 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:45:13,435 - INFO - [Step=52750]	Loss=0.5515	258.0 examples/second
2022-01-10 15:47:08,526 - INFO - [Step=53000]	Loss=0.5561	278.0 examples/second
2022-01-10 15:49:03,397 - INFO - [Step=53250]	Loss=0.5523	278.6 examples/second
2022-01-10 15:50:38,257 - INFO - Test Loss=0.7810, Test top-1 acc=0.7930
2022-01-10 15:50:38,257 - INFO - Group Accuracy:

2022-01-10 15:50:38,257 - INFO - [0.97975904 0.9920482  0.9845783  0.993253   0.9855422  0.9956626
 0.9821687  0.9826506  0.99060243 0.9773494  0.9920482  0.98626506
 0.9780723  0.98240966 0.97927713 0.9884337  0.9966265 ]
2022-01-10 15:50:38,258 - INFO - Saving...
2022-01-10 15:50:38,826 - INFO - Epoch time: 393.8240168094635
2022-01-10 15:50:38,827 - INFO - 
Epoch: 64
2022-01-10 15:50:38,827 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:51:08,239 - INFO - [Step=53500]	Loss=0.5414	256.3 examples/second
2022-01-10 15:53:03,168 - INFO - [Step=53750]	Loss=0.5385	278.4 examples/second
2022-01-10 15:54:58,077 - INFO - [Step=54000]	Loss=0.5473	278.5 examples/second
2022-01-10 15:56:53,259 - INFO - [Step=54250]	Loss=0.5291	277.8 examples/second
2022-01-10 15:57:12,057 - INFO - Test Loss=0.7966, Test top-1 acc=0.7911
2022-01-10 15:57:12,058 - INFO - Group Accuracy:

2022-01-10 15:57:12,058 - INFO - [0.9809638  0.9922892  0.9850602  0.993253   0.9848193  0.9951807
 0.9809638  0.98289156 0.99108434 0.9768675  0.99156624 0.98626506
 0.97951806 0.9833735  0.97951806 0.98963857 0.9963855 ]
2022-01-10 15:57:12,059 - INFO - Epoch time: 393.23200941085815
2022-01-10 15:57:12,059 - INFO - 
Epoch: 65
2022-01-10 15:57:12,059 - INFO - 
Learning Rate: 0.0010
2022-01-10 15:58:57,640 - INFO - [Step=54500]	Loss=0.5193	257.3 examples/second
2022-01-10 16:00:52,625 - INFO - [Step=54750]	Loss=0.5354	278.3 examples/second
2022-01-10 16:02:47,551 - INFO - [Step=55000]	Loss=0.5541	278.4 examples/second
2022-01-10 16:03:45,358 - INFO - Test Loss=0.7772, Test top-1 acc=0.7911
2022-01-10 16:03:45,358 - INFO - Group Accuracy:

2022-01-10 16:03:45,359 - INFO - [0.9807229  0.9925301  0.9853012  0.993253   0.98578316 0.9951807
 0.9819277  0.9816868  0.99060243 0.9766265  0.9918072  0.9860241
 0.9780723  0.9833735  0.97903615 0.9879518  0.9963855 ]
2022-01-10 16:03:45,360 - INFO - Epoch time: 393.30091071128845
2022-01-10 16:03:45,360 - INFO - 
Epoch: 66
2022-01-10 16:03:45,360 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:04:51,911 - INFO - [Step=55250]	Loss=0.5312	257.3 examples/second
2022-01-10 16:06:46,942 - INFO - [Step=55500]	Loss=0.5305	278.2 examples/second
2022-01-10 16:08:41,621 - INFO - [Step=55750]	Loss=0.5162	279.0 examples/second
2022-01-10 16:10:18,478 - INFO - Test Loss=0.7731, Test top-1 acc=0.7918
2022-01-10 16:10:18,478 - INFO - Group Accuracy:

2022-01-10 16:10:18,478 - INFO - [0.9804819  0.9927711  0.9850602  0.993253   0.9855422  0.9951807
 0.98240966 0.9826506  0.99084336 0.97614455 0.9918072  0.98650604
 0.9780723  0.9833735  0.97951806 0.9889157  0.99710846]
2022-01-10 16:10:18,479 - INFO - Epoch time: 393.1190845966339
2022-01-10 16:10:18,479 - INFO - 
Epoch: 67
2022-01-10 16:10:18,479 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:10:45,989 - INFO - [Step=56000]	Loss=0.5418	257.3 examples/second
2022-01-10 16:12:41,228 - INFO - [Step=56250]	Loss=0.5273	277.7 examples/second
2022-01-10 16:14:36,024 - INFO - [Step=56500]	Loss=0.5359	278.8 examples/second
2022-01-10 16:16:30,880 - INFO - [Step=56750]	Loss=0.5323	278.6 examples/second
2022-01-10 16:16:51,974 - INFO - Test Loss=0.7841, Test top-1 acc=0.7935
2022-01-10 16:16:51,975 - INFO - Group Accuracy:

2022-01-10 16:16:51,975 - INFO - [0.9807229  0.9927711  0.9848193  0.9930121  0.9855422  0.9959036
 0.9819277  0.9833735  0.99060243 0.97638553 0.99156624 0.98698795
 0.97903615 0.9833735  0.97951806 0.9901205  0.9968675 ]
2022-01-10 16:16:51,975 - INFO - Saving...
2022-01-10 16:16:52,238 - INFO - Epoch time: 393.75868582725525
2022-01-10 16:16:52,238 - INFO - 
Epoch: 68
2022-01-10 16:16:52,238 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:18:35,579 - INFO - [Step=57000]	Loss=0.5249	256.6 examples/second
2022-01-10 16:20:30,557 - INFO - [Step=57250]	Loss=0.5270	278.3 examples/second
2022-01-10 16:22:25,440 - INFO - [Step=57500]	Loss=0.5279	278.5 examples/second
2022-01-10 16:23:25,450 - INFO - Test Loss=0.7862, Test top-1 acc=0.7940
2022-01-10 16:23:25,450 - INFO - Group Accuracy:

2022-01-10 16:23:25,450 - INFO - [0.9809638  0.9925301  0.98433733 0.9927711  0.9853012  0.99493974
 0.9809638  0.98289156 0.9913253  0.9766265  0.99156624 0.98650604
 0.97927713 0.9833735  0.97927713 0.9886747  0.9973494 ]
2022-01-10 16:23:25,451 - INFO - Saving...
2022-01-10 16:23:25,731 - INFO - Epoch time: 393.4935894012451
2022-01-10 16:23:25,732 - INFO - 
Epoch: 69
2022-01-10 16:23:25,732 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:24:29,551 - INFO - [Step=57750]	Loss=0.5405	257.8 examples/second
2022-01-10 16:26:24,698 - INFO - [Step=58000]	Loss=0.5167	277.9 examples/second
2022-01-10 16:28:19,583 - INFO - [Step=58250]	Loss=0.5222	278.5 examples/second
2022-01-10 16:29:58,905 - INFO - Test Loss=0.7913, Test top-1 acc=0.7945
2022-01-10 16:29:58,906 - INFO - Group Accuracy:

2022-01-10 16:29:58,906 - INFO - [0.9821687  0.9918072  0.9848193  0.9922892  0.9850602  0.9956626
 0.9816868  0.9821687  0.99084336 0.9771084  0.9913253  0.9860241
 0.9787952  0.9838554  0.97927713 0.9884337  0.9966265 ]
2022-01-10 16:29:58,907 - INFO - Saving...
2022-01-10 16:29:59,167 - INFO - Epoch time: 393.4352295398712
2022-01-10 16:29:59,167 - INFO - 
Epoch: 70
2022-01-10 16:29:59,167 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:30:24,227 - INFO - [Step=58500]	Loss=0.5221	256.7 examples/second
2022-01-10 16:32:19,296 - INFO - [Step=58750]	Loss=0.5236	278.1 examples/second
2022-01-10 16:34:14,437 - INFO - [Step=59000]	Loss=0.5182	277.9 examples/second
2022-01-10 16:36:09,730 - INFO - [Step=59250]	Loss=0.5276	277.6 examples/second
2022-01-10 16:36:33,324 - INFO - Test Loss=0.7908, Test top-1 acc=0.7913
2022-01-10 16:36:33,324 - INFO - Group Accuracy:

2022-01-10 16:36:33,339 - INFO - [0.9804819  0.9922892  0.9845783  0.9927711  0.98313254 0.9951807
 0.9812048  0.9826506  0.9913253  0.9773494  0.9918072  0.98650604
 0.9785542  0.98313254 0.9785542  0.98963857 0.9968675 ]
2022-01-10 16:36:33,340 - INFO - Epoch time: 394.1728677749634
2022-01-10 16:36:33,340 - INFO - 
Epoch: 71
2022-01-10 16:36:33,340 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:38:14,449 - INFO - [Step=59500]	Loss=0.5112	256.6 examples/second
2022-01-10 16:40:09,278 - INFO - [Step=59750]	Loss=0.5173	278.7 examples/second
2022-01-10 16:42:04,354 - INFO - [Step=60000]	Loss=0.5291	278.1 examples/second
2022-01-10 16:43:07,178 - INFO - Test Loss=0.7690, Test top-1 acc=0.7945
2022-01-10 16:43:07,178 - INFO - Group Accuracy:

2022-01-10 16:43:07,178 - INFO - [0.9816868  0.9925301  0.9848193  0.9930121  0.9848193  0.9951807
 0.9812048  0.9814458  0.99084336 0.9768675  0.9913253  0.9860241
 0.97951806 0.9816868  0.9787952  0.9884337  0.9963855 ]
2022-01-10 16:43:07,179 - INFO - Epoch time: 393.838907957077
2022-01-10 16:43:07,179 - INFO - 
Epoch: 72
2022-01-10 16:43:07,179 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:44:09,268 - INFO - [Step=60250]	Loss=0.5186	256.2 examples/second
2022-01-10 16:46:04,237 - INFO - [Step=60500]	Loss=0.5128	278.3 examples/second
2022-01-10 16:47:59,300 - INFO - [Step=60750]	Loss=0.5114	278.1 examples/second
2022-01-10 16:49:40,809 - INFO - Test Loss=0.7894, Test top-1 acc=0.7935
2022-01-10 16:49:40,809 - INFO - Group Accuracy:

2022-01-10 16:49:40,809 - INFO - [0.9826506  0.9920482  0.98578316 0.9927711  0.9855422  0.99493974
 0.9812048  0.9819277  0.99084336 0.97566265 0.99060243 0.98578316
 0.98024094 0.9826506  0.97831327 0.9886747  0.9966265 ]
2022-01-10 16:49:40,810 - INFO - Epoch time: 393.6310374736786
2022-01-10 16:49:40,810 - INFO - 
Epoch: 73
2022-01-10 16:49:40,810 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:50:03,921 - INFO - [Step=61000]	Loss=0.5293	256.8 examples/second
2022-01-10 16:51:59,004 - INFO - [Step=61250]	Loss=0.5154	278.1 examples/second
2022-01-10 16:53:53,886 - INFO - [Step=61500]	Loss=0.5155	278.5 examples/second
2022-01-10 16:55:48,787 - INFO - [Step=61750]	Loss=0.5141	278.5 examples/second
2022-01-10 16:56:14,046 - INFO - Test Loss=0.7851, Test top-1 acc=0.7969
2022-01-10 16:56:14,047 - INFO - Group Accuracy:

2022-01-10 16:56:14,047 - INFO - [0.98240966 0.9922892  0.9853012  0.9930121  0.98578316 0.9951807
 0.9826506  0.9816868  0.99084336 0.97614455 0.99084336 0.98674697
 0.98       0.9826506  0.97951806 0.9891566  0.9966265 ]
2022-01-10 16:56:14,049 - INFO - Saving...
2022-01-10 16:56:14,327 - INFO - Epoch time: 393.51664447784424
2022-01-10 16:56:14,327 - INFO - 
Epoch: 74
2022-01-10 16:56:14,327 - INFO - 
Learning Rate: 0.0010
2022-01-10 16:57:52,772 - INFO - [Step=62000]	Loss=0.5227	258.1 examples/second
2022-01-10 16:59:47,991 - INFO - [Step=62250]	Loss=0.5035	277.7 examples/second
2022-01-10 17:01:42,762 - INFO - [Step=62500]	Loss=0.5002	278.8 examples/second
2022-01-10 17:02:47,449 - INFO - Test Loss=0.7860, Test top-1 acc=0.7969
2022-01-10 17:02:47,449 - INFO - Group Accuracy:

2022-01-10 17:02:47,449 - INFO - [0.9826506  0.9922892  0.9848193  0.9925301  0.98578316 0.9954217
 0.9814458  0.98289156 0.99060243 0.97614455 0.99060243 0.98650604
 0.97975904 0.9821687  0.98       0.9889157  0.9968675 ]
2022-01-10 17:02:47,450 - INFO - Epoch time: 393.1227033138275
2022-01-10 17:02:47,450 - INFO - 
Epoch: 75
2022-01-10 17:02:47,450 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:03:46,951 - INFO - [Step=62750]	Loss=0.5082	257.7 examples/second
2022-01-10 17:05:41,926 - INFO - [Step=63000]	Loss=0.5037	278.3 examples/second
2022-01-10 17:07:36,948 - INFO - [Step=63250]	Loss=0.5059	278.2 examples/second
2022-01-10 17:09:21,212 - INFO - Test Loss=0.7930, Test top-1 acc=0.7940
2022-01-10 17:09:21,212 - INFO - Group Accuracy:

2022-01-10 17:09:21,213 - INFO - [0.9814458  0.9922892  0.98578316 0.9927711  0.9850602  0.9951807
 0.9819277  0.9816868  0.9913253  0.97590363 0.98963857 0.98698795
 0.98       0.98240966 0.97975904 0.9881928  0.9973494 ]
2022-01-10 17:09:21,213 - INFO - Epoch time: 393.7634687423706
2022-01-10 17:09:21,213 - INFO - 
Epoch: 76
2022-01-10 17:09:21,214 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:09:41,403 - INFO - [Step=63500]	Loss=0.5096	257.1 examples/second
2022-01-10 17:11:36,385 - INFO - [Step=63750]	Loss=0.5027	278.3 examples/second
2022-01-10 17:13:31,267 - INFO - [Step=64000]	Loss=0.4979	278.5 examples/second
2022-01-10 17:15:26,061 - INFO - [Step=64250]	Loss=0.4854	278.8 examples/second
2022-01-10 17:15:54,031 - INFO - Test Loss=0.7833, Test top-1 acc=0.7920
2022-01-10 17:15:54,032 - INFO - Group Accuracy:

2022-01-10 17:15:54,032 - INFO - [0.9812048  0.9918072  0.9853012  0.9925301  0.9840964  0.9954217
 0.9812048  0.9816868  0.99108434 0.97614455 0.99060243 0.9860241
 0.98       0.9826506  0.9787952  0.9884337  0.9973494 ]
2022-01-10 17:15:54,033 - INFO - Epoch time: 392.81953024864197
2022-01-10 17:15:54,033 - INFO - 
Epoch: 77
2022-01-10 17:15:54,033 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:17:30,770 - INFO - [Step=64500]	Loss=0.5070	256.6 examples/second
2022-01-10 17:19:26,206 - INFO - [Step=64750]	Loss=0.5025	277.2 examples/second
2022-01-10 17:21:21,630 - INFO - [Step=65000]	Loss=0.5054	277.2 examples/second
2022-01-10 17:22:28,891 - INFO - Test Loss=0.7918, Test top-1 acc=0.7947
2022-01-10 17:22:28,891 - INFO - Group Accuracy:

2022-01-10 17:22:28,891 - INFO - [0.9812048  0.99156624 0.9853012  0.993253   0.98578316 0.9954217
 0.98240966 0.98240966 0.99060243 0.9778313  0.99036145 0.98626506
 0.97903615 0.9826506  0.9787952  0.9881928  0.9966265 ]
2022-01-10 17:22:28,892 - INFO - Epoch time: 394.8590476512909
2022-01-10 17:22:28,892 - INFO - 
Epoch: 78
2022-01-10 17:22:28,892 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:23:25,997 - INFO - [Step=65250]	Loss=0.5050	257.3 examples/second
2022-01-10 17:25:21,338 - INFO - [Step=65500]	Loss=0.4989	277.4 examples/second
2022-01-10 17:27:16,315 - INFO - [Step=65750]	Loss=0.4987	278.3 examples/second
2022-01-10 17:29:02,899 - INFO - Test Loss=0.7864, Test top-1 acc=0.7913
2022-01-10 17:29:02,899 - INFO - Group Accuracy:

2022-01-10 17:29:02,899 - INFO - [0.98240966 0.9918072  0.9853012  0.9930121  0.9853012  0.9946988
 0.9809638  0.9821687  0.99060243 0.97590363 0.99036145 0.98626506
 0.9778313  0.9826506  0.97927713 0.98963857 0.99710846]
2022-01-10 17:29:02,900 - INFO - Epoch time: 394.00775694847107
2022-01-10 17:29:02,900 - INFO - 
Epoch: 79
2022-01-10 17:29:02,900 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:29:21,093 - INFO - [Step=66000]	Loss=0.5110	256.5 examples/second
2022-01-10 17:31:16,329 - INFO - [Step=66250]	Loss=0.5061	277.7 examples/second
2022-01-10 17:33:11,488 - INFO - [Step=66500]	Loss=0.4954	277.9 examples/second
2022-01-10 17:35:06,646 - INFO - [Step=66750]	Loss=0.5065	277.9 examples/second
2022-01-10 17:35:36,831 - INFO - Test Loss=0.7853, Test top-1 acc=0.7923
2022-01-10 17:35:36,832 - INFO - Group Accuracy:

2022-01-10 17:35:36,832 - INFO - [0.9821687  0.9918072  0.9860241  0.9927711  0.9853012  0.9951807
 0.98240966 0.98289156 0.99060243 0.9766265  0.99084336 0.98674697
 0.97831327 0.98361444 0.9804819  0.9886747  0.9973494 ]
2022-01-10 17:35:36,833 - INFO - Epoch time: 393.9326910972595
2022-01-10 17:35:36,833 - INFO - 
Epoch: 80
2022-01-10 17:35:36,833 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:37:10,890 - INFO - [Step=67000]	Loss=0.4931	257.6 examples/second
2022-01-10 17:39:06,007 - INFO - [Step=67250]	Loss=0.5010	278.0 examples/second
2022-01-10 17:41:01,010 - INFO - [Step=67500]	Loss=0.4984	278.3 examples/second
2022-01-10 17:42:10,399 - INFO - Test Loss=0.7877, Test top-1 acc=0.7933
2022-01-10 17:42:10,399 - INFO - Group Accuracy:

2022-01-10 17:42:10,399 - INFO - [0.9807229  0.99156624 0.9848193  0.9930121  0.9855422  0.9954217
 0.9812048  0.98240966 0.99108434 0.9768675  0.99108434 0.98626506
 0.9780723  0.9826506  0.9787952  0.9889157  0.9966265 ]
2022-01-10 17:42:10,400 - INFO - Epoch time: 393.5673522949219
2022-01-10 17:42:10,400 - INFO - 
Epoch: 81
2022-01-10 17:42:10,400 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:43:05,496 - INFO - [Step=67750]	Loss=0.4948	257.1 examples/second
2022-01-10 17:45:00,739 - INFO - [Step=68000]	Loss=0.4979	277.7 examples/second
2022-01-10 17:46:55,908 - INFO - [Step=68250]	Loss=0.4976	277.9 examples/second
2022-01-10 17:48:44,470 - INFO - Test Loss=0.7950, Test top-1 acc=0.7940
2022-01-10 17:48:44,471 - INFO - Group Accuracy:

2022-01-10 17:48:44,471 - INFO - [0.9807229  0.9918072  0.9850602  0.993253   0.9840964  0.9954217
 0.9821687  0.98289156 0.99060243 0.9766265  0.99108434 0.98674697
 0.9778313  0.9821687  0.97927713 0.9879518  0.9968675 ]
2022-01-10 17:48:44,472 - INFO - Epoch time: 394.0717444419861
2022-01-10 17:48:44,472 - INFO - 
Epoch: 82
2022-01-10 17:48:44,472 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:49:00,301 - INFO - [Step=68500]	Loss=0.4918	257.2 examples/second
2022-01-10 17:50:55,383 - INFO - [Step=68750]	Loss=0.4959	278.1 examples/second
2022-01-10 17:52:50,494 - INFO - [Step=69000]	Loss=0.4975	278.0 examples/second
2022-01-10 17:54:46,274 - INFO - [Step=69250]	Loss=0.4916	276.4 examples/second
2022-01-10 17:55:19,370 - INFO - Test Loss=0.7875, Test top-1 acc=0.7925
2022-01-10 17:55:19,371 - INFO - Group Accuracy:

2022-01-10 17:55:19,371 - INFO - [0.9819277  0.9918072  0.9853012  0.9925301  0.9845783  0.99493974
 0.9814458  0.9812048  0.99060243 0.9775904  0.99060243 0.98650604
 0.9780723  0.98289156 0.97903615 0.9881928  0.9973494 ]
2022-01-10 17:55:19,371 - INFO - Epoch time: 394.8991787433624
2022-01-10 17:55:19,371 - INFO - 
Epoch: 83
2022-01-10 17:55:19,371 - INFO - 
Learning Rate: 0.0010
2022-01-10 17:56:51,211 - INFO - [Step=69500]	Loss=0.4798	256.1 examples/second
2022-01-10 17:58:46,242 - INFO - [Step=69750]	Loss=0.4941	278.2 examples/second
2022-01-10 18:00:41,504 - INFO - [Step=70000]	Loss=0.5153	277.6 examples/second
2022-01-10 18:01:53,076 - INFO - Test Loss=0.7979, Test top-1 acc=0.7930
2022-01-10 18:01:53,077 - INFO - Group Accuracy:

2022-01-10 18:01:53,077 - INFO - [0.9814458  0.9918072  0.98650604 0.993253   0.98650604 0.9946988
 0.9814458  0.9819277  0.99036145 0.9771084  0.99108434 0.98698795
 0.98       0.98289156 0.97903615 0.9893976  0.9973494 ]
2022-01-10 18:01:53,078 - INFO - Epoch time: 393.70656156539917
2022-01-10 18:01:53,078 - INFO - 
Epoch: 84
2022-01-10 18:01:53,078 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:02:45,713 - INFO - [Step=70250]	Loss=0.4911	257.6 examples/second
2022-01-10 18:04:40,946 - INFO - [Step=70500]	Loss=0.4841	277.7 examples/second
2022-01-10 18:06:35,973 - INFO - [Step=70750]	Loss=0.4885	278.2 examples/second
2022-01-10 18:08:26,896 - INFO - Test Loss=0.8010, Test top-1 acc=0.7920
2022-01-10 18:08:26,896 - INFO - Group Accuracy:

2022-01-10 18:08:26,896 - INFO - [0.98024094 0.9920482  0.98578316 0.9927711  0.9853012  0.99493974
 0.9809638  0.9814458  0.9901205  0.97638553 0.99156624 0.98650604
 0.97927713 0.98361444 0.9785542  0.9886747  0.9968675 ]
2022-01-10 18:08:26,898 - INFO - Epoch time: 393.8196725845337
2022-01-10 18:08:26,898 - INFO - 
Epoch: 85
2022-01-10 18:08:26,898 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:08:40,309 - INFO - [Step=71000]	Loss=0.4860	257.4 examples/second
2022-01-10 18:10:35,425 - INFO - [Step=71250]	Loss=0.5077	278.0 examples/second
2022-01-10 18:12:30,456 - INFO - [Step=71500]	Loss=0.4977	278.2 examples/second
2022-01-10 18:14:25,407 - INFO - [Step=71750]	Loss=0.4873	278.4 examples/second
2022-01-10 18:15:00,490 - INFO - Test Loss=0.7971, Test top-1 acc=0.7935
2022-01-10 18:15:00,490 - INFO - Group Accuracy:

2022-01-10 18:15:00,490 - INFO - [0.98024094 0.9920482  0.98626506 0.9930121  0.9853012  0.9946988
 0.98       0.98240966 0.9901205  0.9766265  0.99036145 0.98650604
 0.9787952  0.98313254 0.97975904 0.9884337  0.99710846]
2022-01-10 18:15:00,491 - INFO - Epoch time: 393.5929663181305
2022-01-10 18:15:00,491 - INFO - 
Epoch: 86
2022-01-10 18:15:00,491 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:16:29,656 - INFO - [Step=72000]	Loss=0.4836	257.5 examples/second
2022-01-10 18:18:24,699 - INFO - [Step=72250]	Loss=0.4966	278.2 examples/second
2022-01-10 18:20:19,802 - INFO - [Step=72500]	Loss=0.4855	278.0 examples/second
2022-01-10 18:21:33,993 - INFO - Test Loss=0.7860, Test top-1 acc=0.7933
2022-01-10 18:21:33,993 - INFO - Group Accuracy:

2022-01-10 18:21:33,993 - INFO - [0.9821687  0.99156624 0.9850602  0.9930121  0.98674697 0.99493974
 0.9809638  0.98240966 0.99108434 0.9768675  0.99036145 0.98674697
 0.98       0.9826506  0.9787952  0.9893976  0.99710846]
2022-01-10 18:21:33,995 - INFO - Epoch time: 393.5039210319519
2022-01-10 18:21:33,995 - INFO - 
Epoch: 87
2022-01-10 18:21:33,995 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:22:24,350 - INFO - [Step=72750]	Loss=0.4896	256.9 examples/second
2022-01-10 18:24:19,481 - INFO - [Step=73000]	Loss=0.4869	277.9 examples/second
2022-01-10 18:26:14,540 - INFO - [Step=73250]	Loss=0.4821	278.1 examples/second
2022-01-10 18:28:07,961 - INFO - Test Loss=0.8159, Test top-1 acc=0.7942
2022-01-10 18:28:07,962 - INFO - Group Accuracy:

2022-01-10 18:28:07,962 - INFO - [0.9816868  0.99156624 0.98626506 0.993253   0.9855422  0.9956626
 0.9819277  0.9819277  0.99084336 0.97614455 0.9913253  0.98578316
 0.97927713 0.9826506  0.97951806 0.9889157  0.9966265 ]
2022-01-10 18:28:07,963 - INFO - Epoch time: 393.9680964946747
2022-01-10 18:28:07,963 - INFO - 
Epoch: 88
2022-01-10 18:28:07,963 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:28:19,167 - INFO - [Step=73500]	Loss=0.4871	256.8 examples/second
2022-01-10 18:30:14,265 - INFO - [Step=73750]	Loss=0.4777	278.0 examples/second
2022-01-10 18:32:09,318 - INFO - [Step=74000]	Loss=0.4759	278.1 examples/second
2022-01-10 18:34:04,266 - INFO - [Step=74250]	Loss=0.4837	278.4 examples/second
2022-01-10 18:34:41,240 - INFO - Test Loss=0.8020, Test top-1 acc=0.7957
2022-01-10 18:34:41,241 - INFO - Group Accuracy:

2022-01-10 18:34:41,241 - INFO - [0.9819277  0.9922892  0.9850602  0.9927711  0.9855422  0.9954217
 0.9812048  0.9819277  0.9901205  0.9775904  0.99084336 0.98722893
 0.97951806 0.98289156 0.98       0.9893976  0.9973494 ]
2022-01-10 18:34:41,242 - INFO - Epoch time: 393.27846217155457
2022-01-10 18:34:41,242 - INFO - 
Epoch: 89
2022-01-10 18:34:41,242 - INFO - 
Learning Rate: 0.0010
2022-01-10 18:36:08,271 - INFO - [Step=74500]	Loss=0.4842	258.1 examples/second
2022-01-10 18:38:03,400 - INFO - [Step=74750]	Loss=0.4707	278.0 examples/second
2022-01-10 18:39:58,230 - INFO - [Step=75000]	Loss=0.4927	278.7 examples/second
2022-01-10 18:41:14,462 - INFO - Test Loss=0.7965, Test top-1 acc=0.7949
2022-01-10 18:41:14,463 - INFO - Group Accuracy:

2022-01-10 18:41:14,463 - INFO - [0.98240966 0.9913253  0.98650604 0.9927711  0.98578316 0.9954217
 0.9812048  0.98240966 0.99084336 0.97638553 0.99156624 0.98674697
 0.97903615 0.98361444 0.97903615 0.9891566  0.99710846]
2022-01-10 18:41:14,464 - INFO - Epoch time: 393.22184467315674
2022-01-10 18:41:24,310 - INFO - Computing OOD Statistics...
2022-01-10 18:41:24,317 - INFO - 	Baseline.          AUROC: 0.3216. TNR@95TPR: 0.0224. AUPR OUT: 0.1207
2022-01-10 18:41:24,323 - INFO - 	ODIN (T=1000).     AUROC: 0.8792. TNR@95TPR: 0.4482. AUPR OUT: 0.5931
2022-01-10 18:41:24,323 - INFO - Printing Final Accuracy + OOD Detection stats
2022-01-10 18:41:24,323 - INFO - Top 1 Accuracy:  Min: 0.7969; Max: 0.7969; Avg: 0.7969; Std: 0.0000; Len: 1
2022-01-10 18:41:24,323 - INFO - Top 5 Accuracy:  Min: 0.9865; Max: 0.9865; Avg: 0.9865; Std: 0.0000; Len: 1
2022-01-10 18:41:24,323 - INFO - **********************************************************************
2022-01-10 18:41:24,323 - INFO - 	MSP (auroc): [0.3215586109142452] Min: 0.3216; Max: 0.3216; Avg: 0.3216; Std: 0.0000; Len: 1
2022-01-10 18:41:24,323 - INFO - 	MSP (tnr): [0.022352941176470575] Min: 0.0224; Max: 0.0224; Avg: 0.0224; Std: 0.0000; Len: 1
2022-01-10 18:41:24,324 - INFO - 	MSP (aupr): [0.12070082496206103] Min: 0.1207; Max: 0.1207; Avg: 0.1207; Std: 0.0000; Len: 1
2022-01-10 18:41:24,324 - INFO - 	ODIN (auroc): [0.8791583274273564] Min: 0.8792; Max: 0.8792; Avg: 0.8792; Std: 0.0000; Len: 1
2022-01-10 18:41:24,324 - INFO - 	ODIN (tnr): [0.44823529411764707] Min: 0.4482; Max: 0.4482; Avg: 0.4482; Std: 0.0000; Len: 1
2022-01-10 18:41:24,324 - INFO - 	ODIN (aupr): [0.5930910403716853] Min: 0.5931; Max: 0.5931; Avg: 0.5931; Std: 0.0000; Len: 1

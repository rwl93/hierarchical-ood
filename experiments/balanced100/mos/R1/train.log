2022-09-23 15:40:56,626 - INFO - ==> Preparing data..
2022-09-23 15:41:07,673 - INFO - # ID Train: 89972
2022-09-23 15:41:07,673 - INFO - # ID Test:  3500
2022-09-23 15:41:07,673 - INFO - # OOD Test: 1500
2022-09-23 15:41:07,673 - INFO - checkpoint filename: experiments/balanced100/mos/R1/checkpoint.pt
2022-09-23 15:41:07,674 - INFO - log filename: experiments/balanced100/mos/R1/train.log
2022-09-23 15:41:07,674 - INFO - ********************************************************
2022-09-23 15:41:07,674 - INFO - Starting Iter: 0 / 1
2022-09-23 15:41:07,674 - INFO - ********************************************************
2022-09-23 15:42:10,128 - INFO - cuda
2022-09-23 15:42:10,582 - INFO - 
Epoch: 0
2022-09-23 15:42:10,582 - INFO - 
Learning Rate: 0.0100
2022-09-23 15:44:06,132 - INFO - [Step=250]	Loss=7.1477	276.9 examples/second
2022-09-23 15:45:32,634 - INFO - [Step=500]	Loss=5.2189	369.9 examples/second
2022-09-23 15:46:50,138 - INFO - Test Loss=4.8050, Test top-1 acc=0.0709
2022-09-23 15:46:50,138 - INFO - Group Accuracy:

2022-09-23 15:46:50,138 - INFO - [0.9285714  0.95714283 0.9285714  0.9285714  0.9285714  0.92457145
 0.9285714  0.9285714  0.9285714  0.9714286  0.9285714  0.9285714
 0.9285714  0.9285714  0.95714283 0.9714286 ]
2022-09-23 15:46:50,140 - INFO - Saving...
2022-09-23 15:46:52,337 - INFO - Epoch time: 281.7553188800812
2022-09-23 15:46:52,337 - INFO - 
Epoch: 1
2022-09-23 15:46:52,338 - INFO - 
Learning Rate: 0.0280
2022-09-23 15:47:10,876 - INFO - [Step=750]	Loss=4.9333	1726.3 examples/second
2022-09-23 15:48:37,407 - INFO - [Step=1000]	Loss=4.7684	369.8 examples/second
2022-09-23 15:50:03,973 - INFO - [Step=1250]	Loss=4.5483	369.7 examples/second
2022-09-23 15:51:04,183 - INFO - Test Loss=4.1341, Test top-1 acc=0.1783
2022-09-23 15:51:04,183 - INFO - Group Accuracy:

2022-09-23 15:51:04,183 - INFO - [0.928      0.95714283 0.9285714  0.93314284 0.9285714  0.93685716
 0.9285714  0.92914283 0.9285714  0.9714286  0.9285714  0.9285714
 0.9285714  0.9282857  0.95714283 0.9714286 ]
2022-09-23 15:51:04,185 - INFO - Saving...
2022-09-23 15:51:04,871 - INFO - Epoch time: 252.53351950645447
2022-09-23 15:51:04,871 - INFO - 
Epoch: 2
2022-09-23 15:51:04,871 - INFO - 
Learning Rate: 0.0460
2022-09-23 15:51:40,233 - INFO - [Step=1500]	Loss=4.4218	905.0 examples/second
2022-09-23 15:53:06,813 - INFO - [Step=1750]	Loss=4.2260	369.6 examples/second
2022-09-23 15:54:33,406 - INFO - [Step=2000]	Loss=4.0512	369.5 examples/second
2022-09-23 15:55:18,279 - INFO - Test Loss=3.6668, Test top-1 acc=0.2580
2022-09-23 15:55:18,279 - INFO - Group Accuracy:

2022-09-23 15:55:18,279 - INFO - [0.9308571  0.95942855 0.92971426 0.9457143  0.9308571  0.9491429
 0.9308571  0.93457144 0.93       0.97257143 0.93       0.92914283
 0.9285714  0.9285714  0.9574286  0.97514284]
2022-09-23 15:55:18,280 - INFO - Saving...
2022-09-23 15:55:19,574 - INFO - Epoch time: 254.70248198509216
2022-09-23 15:55:19,574 - INFO - 
Epoch: 3
2022-09-23 15:55:19,574 - INFO - 
Learning Rate: 0.0640
2022-09-23 15:56:10,680 - INFO - [Step=2250]	Loss=3.9411	626.2 examples/second
2022-09-23 15:57:37,377 - INFO - [Step=2500]	Loss=3.7877	369.1 examples/second
2022-09-23 15:59:04,110 - INFO - [Step=2750]	Loss=3.6011	368.9 examples/second
2022-09-23 15:59:32,129 - INFO - Test Loss=3.4464, Test top-1 acc=0.3089
2022-09-23 15:59:32,130 - INFO - Group Accuracy:

2022-09-23 15:59:32,130 - INFO - [0.9337143  0.9628571  0.9334286  0.9457143  0.93314284 0.9505714
 0.93       0.9334286  0.9302857  0.9737143  0.932      0.9294286
 0.9277143  0.93057144 0.966      0.97828573]
2022-09-23 15:59:32,131 - INFO - Saving...
2022-09-23 15:59:32,993 - INFO - Epoch time: 253.41850543022156
2022-09-23 15:59:32,993 - INFO - 
Epoch: 4
2022-09-23 15:59:32,993 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:00:40,401 - INFO - [Step=3000]	Loss=3.5881	474.7 examples/second
2022-09-23 16:02:07,016 - INFO - [Step=3250]	Loss=3.4706	369.5 examples/second
2022-09-23 16:03:33,608 - INFO - [Step=3500]	Loss=3.2976	369.5 examples/second
2022-09-23 16:03:45,023 - INFO - Test Loss=3.5212, Test top-1 acc=0.3163
2022-09-23 16:03:45,023 - INFO - Group Accuracy:

2022-09-23 16:03:45,023 - INFO - [0.93628573 0.964      0.9302857  0.95028573 0.9337143  0.9517143
 0.9365714  0.91085714 0.93       0.97257143 0.932      0.92885715
 0.93314284 0.9294286  0.962      0.9785714 ]
2022-09-23 16:03:45,025 - INFO - Saving...
2022-09-23 16:03:45,581 - INFO - Epoch time: 252.5877275466919
2022-09-23 16:03:45,581 - INFO - 
Epoch: 5
2022-09-23 16:03:45,581 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:05:09,301 - INFO - [Step=3750]	Loss=3.1705	382.2 examples/second
2022-09-23 16:06:35,781 - INFO - [Step=4000]	Loss=3.0756	370.0 examples/second
2022-09-23 16:07:57,378 - INFO - Test Loss=2.8799, Test top-1 acc=0.3891
2022-09-23 16:07:57,378 - INFO - Group Accuracy:

2022-09-23 16:07:57,378 - INFO - [0.9422857  0.96171427 0.93285716 0.9574286  0.93885714 0.96085715
 0.93285716 0.9474286  0.93857145 0.9777143  0.9417143  0.9257143
 0.934      0.9351429  0.97171426 0.97828573]
2022-09-23 16:07:57,379 - INFO - Saving...
2022-09-23 16:07:57,999 - INFO - Epoch time: 252.41793513298035
2022-09-23 16:07:57,999 - INFO - 
Epoch: 6
2022-09-23 16:07:57,999 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:08:11,844 - INFO - [Step=4250]	Loss=2.9325	2311.5 examples/second
2022-09-23 16:09:38,474 - INFO - [Step=4500]	Loss=2.8721	369.4 examples/second
2022-09-23 16:11:05,074 - INFO - [Step=4750]	Loss=2.8115	369.5 examples/second
2022-09-23 16:12:10,870 - INFO - Test Loss=2.6912, Test top-1 acc=0.4363
2022-09-23 16:12:10,870 - INFO - Group Accuracy:

2022-09-23 16:12:10,870 - INFO - [0.944      0.97342855 0.9257143  0.964      0.9425714  0.9637143
 0.9408572  0.9408572  0.93942857 0.9794286  0.9422857  0.932
 0.93628573 0.9374286  0.97257143 0.9851429 ]
2022-09-23 16:12:10,871 - INFO - Saving...
2022-09-23 16:12:12,254 - INFO - Epoch time: 254.254962682724
2022-09-23 16:12:12,254 - INFO - 
Epoch: 7
2022-09-23 16:12:12,254 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:12:41,917 - INFO - [Step=5000]	Loss=2.6774	1078.8 examples/second
2022-09-23 16:14:08,460 - INFO - [Step=5250]	Loss=2.6359	369.8 examples/second
2022-09-23 16:15:35,120 - INFO - [Step=5500]	Loss=2.5793	369.3 examples/second
2022-09-23 16:16:24,830 - INFO - Test Loss=2.5660, Test top-1 acc=0.4729
2022-09-23 16:16:24,831 - INFO - Group Accuracy:

2022-09-23 16:16:24,831 - INFO - [0.9422857  0.97742856 0.94457144 0.9597143  0.9434286  0.95771426
 0.942      0.9517143  0.9474286  0.98       0.952      0.93142855
 0.93885714 0.9408572  0.9574286  0.98714286]
2022-09-23 16:16:24,832 - INFO - Saving...
2022-09-23 16:16:25,638 - INFO - Epoch time: 253.38390398025513
2022-09-23 16:16:25,638 - INFO - 
Epoch: 8
2022-09-23 16:16:25,639 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:17:11,836 - INFO - [Step=5750]	Loss=2.4810	692.7 examples/second
2022-09-23 16:18:38,718 - INFO - [Step=6000]	Loss=2.4482	368.3 examples/second
2022-09-23 16:20:06,848 - INFO - [Step=6250]	Loss=2.3964	363.1 examples/second
2022-09-23 16:20:46,156 - INFO - Test Loss=2.4605, Test top-1 acc=0.4894
2022-09-23 16:20:46,156 - INFO - Group Accuracy:

2022-09-23 16:20:46,157 - INFO - [0.9482857  0.97314286 0.9405714  0.966      0.948      0.978
 0.95028573 0.9425714  0.95085716 0.974      0.942      0.9342857
 0.9408572  0.93285716 0.9777143  0.9877143 ]
2022-09-23 16:20:46,157 - INFO - Saving...
2022-09-23 16:20:46,815 - INFO - Epoch time: 261.1767272949219
2022-09-23 16:20:46,815 - INFO - 
Epoch: 9
2022-09-23 16:20:46,816 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:22:01,188 - INFO - [Step=6500]	Loss=2.3255	430.3 examples/second
2022-09-23 16:23:44,418 - INFO - [Step=6750]	Loss=2.2788	310.0 examples/second
2022-09-23 16:25:27,658 - INFO - [Step=7000]	Loss=2.2318	310.1 examples/second
2022-09-23 16:25:47,776 - INFO - Test Loss=2.1167, Test top-1 acc=0.5229
2022-09-23 16:25:47,776 - INFO - Group Accuracy:

2022-09-23 16:25:47,776 - INFO - [0.9497143  0.9762857  0.9474286  0.97342855 0.9491429  0.9777143
 0.9465714  0.9545714  0.95257145 0.98142856 0.95114285 0.9334286
 0.93857145 0.94457144 0.9817143  0.9885714 ]
2022-09-23 16:25:47,777 - INFO - Saving...
2022-09-23 16:25:48,558 - INFO - Epoch time: 301.74213337898254
2022-09-23 16:25:48,558 - INFO - 
Epoch: 10
2022-09-23 16:25:48,558 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:27:24,068 - INFO - [Step=7250]	Loss=2.1662	335.0 examples/second
2022-09-23 16:29:09,004 - INFO - [Step=7500]	Loss=2.1893	305.0 examples/second
2022-09-23 16:30:54,621 - INFO - Test Loss=2.0438, Test top-1 acc=0.5460
2022-09-23 16:30:54,622 - INFO - Group Accuracy:

2022-09-23 16:30:54,622 - INFO - [0.9514286  0.98057145 0.9517143  0.97257143 0.9505714  0.9811429
 0.9488571  0.9537143  0.9565714  0.98314285 0.95342857 0.93685716
 0.938      0.946      0.98228574 0.99114287]
2022-09-23 16:30:54,623 - INFO - Saving...
2022-09-23 16:30:56,610 - INFO - Epoch time: 308.05226397514343
2022-09-23 16:30:56,610 - INFO - 
Epoch: 11
2022-09-23 16:30:56,610 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:31:06,531 - INFO - [Step=7750]	Loss=2.0572	3225.9 examples/second
2022-09-23 16:32:49,666 - INFO - [Step=8000]	Loss=2.0558	310.3 examples/second
2022-09-23 16:34:32,885 - INFO - [Step=8250]	Loss=2.0528	310.0 examples/second
2022-09-23 16:35:57,352 - INFO - Test Loss=2.1789, Test top-1 acc=0.5480
2022-09-23 16:35:57,352 - INFO - Group Accuracy:

2022-09-23 16:35:57,352 - INFO - [0.948      0.98057145 0.95085716 0.9722857  0.9554286  0.9777143
 0.944      0.95942855 0.95714283 0.9842857  0.95685714 0.93285716
 0.94514287 0.93485713 0.9745714  0.98971426]
2022-09-23 16:35:57,353 - INFO - Saving...
2022-09-23 16:35:58,556 - INFO - Epoch time: 301.9453685283661
2022-09-23 16:35:58,556 - INFO - 
Epoch: 12
2022-09-23 16:35:58,556 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:36:27,662 - INFO - [Step=8500]	Loss=1.9831	1099.5 examples/second
2022-09-23 16:38:11,539 - INFO - [Step=8750]	Loss=1.9563	308.1 examples/second
2022-09-23 16:39:55,120 - INFO - [Step=9000]	Loss=1.9441	308.9 examples/second
2022-09-23 16:41:00,866 - INFO - Test Loss=1.9487, Test top-1 acc=0.5703
2022-09-23 16:41:00,866 - INFO - Group Accuracy:

2022-09-23 16:41:00,866 - INFO - [0.9562857  0.97885716 0.94771427 0.97828573 0.9562857  0.98
 0.94771427 0.9588571  0.95914286 0.97828573 0.9588571  0.9465714
 0.9434286  0.9474286  0.9825714  0.9902857 ]
2022-09-23 16:41:00,868 - INFO - Saving...
2022-09-23 16:41:01,649 - INFO - Epoch time: 303.09282422065735
2022-09-23 16:41:01,649 - INFO - 
Epoch: 13
2022-09-23 16:41:01,649 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:41:50,173 - INFO - [Step=9250]	Loss=1.8627	659.5 examples/second
2022-09-23 16:43:33,727 - INFO - [Step=9500]	Loss=1.8970	309.0 examples/second
2022-09-23 16:45:16,703 - INFO - [Step=9750]	Loss=1.8756	310.8 examples/second
2022-09-23 16:46:01,973 - INFO - Test Loss=1.9318, Test top-1 acc=0.5863
2022-09-23 16:46:01,974 - INFO - Group Accuracy:

2022-09-23 16:46:01,974 - INFO - [0.95514286 0.97514284 0.9562857  0.97514284 0.9565714  0.98085713
 0.95285714 0.9597143  0.96171427 0.9694286  0.96       0.9434286
 0.9448571  0.9517143  0.9817143  0.9908571 ]
2022-09-23 16:46:01,975 - INFO - Saving...
2022-09-23 16:46:02,733 - INFO - Epoch time: 301.0836822986603
2022-09-23 16:46:02,733 - INFO - 
Epoch: 14
2022-09-23 16:46:02,733 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:47:10,989 - INFO - [Step=10000]	Loss=1.8238	468.8 examples/second
2022-09-23 16:48:54,327 - INFO - [Step=10250]	Loss=1.8080	309.7 examples/second
2022-09-23 16:50:37,529 - INFO - [Step=10500]	Loss=1.7941	310.1 examples/second
2022-09-23 16:51:03,810 - INFO - Test Loss=2.1480, Test top-1 acc=0.5894
2022-09-23 16:51:03,810 - INFO - Group Accuracy:

2022-09-23 16:51:03,810 - INFO - [0.95085716 0.9837143  0.9574286  0.9794286  0.9522857  0.9785714
 0.95285714 0.9614286  0.9597143  0.98142856 0.96257144 0.9462857
 0.9442857  0.94771427 0.9837143  0.9925714 ]
2022-09-23 16:51:03,811 - INFO - Saving...
2022-09-23 16:51:04,545 - INFO - Epoch time: 301.81157064437866
2022-09-23 16:51:04,545 - INFO - 
Epoch: 15
2022-09-23 16:51:04,545 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:52:31,909 - INFO - [Step=10750]	Loss=1.7605	366.3 examples/second
2022-09-23 16:54:15,791 - INFO - [Step=11000]	Loss=1.7667	308.0 examples/second
2022-09-23 16:56:05,882 - INFO - Test Loss=1.7002, Test top-1 acc=0.6160
2022-09-23 16:56:05,883 - INFO - Group Accuracy:

2022-09-23 16:56:05,883 - INFO - [0.9548572  0.98228574 0.96       0.97914284 0.95942855 0.9851429
 0.95257145 0.962      0.96114284 0.9885714  0.96657145 0.94857144
 0.94542855 0.95428574 0.9854286  0.99142855]
2022-09-23 16:56:05,884 - INFO - Saving...
2022-09-23 16:56:06,582 - INFO - Epoch time: 302.0371015071869
2022-09-23 16:56:06,582 - INFO - 
Epoch: 16
2022-09-23 16:56:06,583 - INFO - 
Learning Rate: 0.1000
2022-09-23 16:56:10,220 - INFO - [Step=11250]	Loss=1.7026	8815.9 examples/second
2022-09-23 16:57:53,607 - INFO - [Step=11500]	Loss=1.6850	309.5 examples/second
2022-09-23 16:59:37,263 - INFO - [Step=11750]	Loss=1.7213	308.7 examples/second
2022-09-23 17:01:08,052 - INFO - Test Loss=1.9022, Test top-1 acc=0.5940
2022-09-23 17:01:08,052 - INFO - Group Accuracy:

2022-09-23 17:01:08,052 - INFO - [0.9597143  0.982      0.95514286 0.9754286  0.95942855 0.9802857
 0.9554286  0.9588571  0.9462857  0.9842857  0.96257144 0.9488571
 0.94857144 0.954      0.98285717 0.9877143 ]
2022-09-23 17:01:08,053 - INFO - Epoch time: 301.4703767299652
2022-09-23 17:01:08,053 - INFO - 
Epoch: 17
2022-09-23 17:01:08,053 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:01:31,055 - INFO - [Step=12000]	Loss=1.6034	1391.2 examples/second
2022-09-23 17:03:14,424 - INFO - [Step=12250]	Loss=1.6806	309.6 examples/second
2022-09-23 17:04:57,798 - INFO - [Step=12500]	Loss=1.6658	309.6 examples/second
2022-09-23 17:06:08,788 - INFO - Test Loss=1.8567, Test top-1 acc=0.5969
2022-09-23 17:06:08,789 - INFO - Group Accuracy:

2022-09-23 17:06:08,789 - INFO - [0.956      0.98057145 0.96257144 0.9771429  0.9588571  0.98314285
 0.9548572  0.964      0.94314283 0.98485714 0.954      0.9457143
 0.9531429  0.9522857  0.98742855 0.9925714 ]
2022-09-23 17:06:08,789 - INFO - Epoch time: 300.736407995224
2022-09-23 17:06:08,789 - INFO - 
Epoch: 18
2022-09-23 17:06:08,789 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:06:51,355 - INFO - [Step=12750]	Loss=1.5913	751.8 examples/second
2022-09-23 17:08:34,686 - INFO - [Step=13000]	Loss=1.6191	309.7 examples/second
2022-09-23 17:10:17,748 - INFO - [Step=13250]	Loss=1.6296	310.6 examples/second
2022-09-23 17:11:09,251 - INFO - Test Loss=1.6221, Test top-1 acc=0.6380
2022-09-23 17:11:09,252 - INFO - Group Accuracy:

2022-09-23 17:11:09,252 - INFO - [0.9622857  0.98       0.9554286  0.9762857  0.9657143  0.9825714
 0.9622857  0.96685714 0.96485716 0.9882857  0.966      0.9491429
 0.95342857 0.9548572  0.9862857  0.99142855]
2022-09-23 17:11:09,253 - INFO - Saving...
2022-09-23 17:11:09,902 - INFO - Epoch time: 301.1128716468811
2022-09-23 17:11:09,902 - INFO - 
Epoch: 19
2022-09-23 17:11:09,903 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:12:12,167 - INFO - [Step=13500]	Loss=1.5914	513.9 examples/second
2022-09-23 17:13:55,935 - INFO - [Step=13750]	Loss=1.5830	308.4 examples/second
2022-09-23 17:15:39,946 - INFO - [Step=14000]	Loss=1.5855	307.7 examples/second
2022-09-23 17:16:12,652 - INFO - Test Loss=1.8324, Test top-1 acc=0.6214
2022-09-23 17:16:12,652 - INFO - Group Accuracy:

2022-09-23 17:16:12,652 - INFO - [0.9614286  0.98228574 0.9425714  0.9802857  0.95685714 0.98314285
 0.954      0.964      0.9622857  0.9868571  0.9631429  0.95085716
 0.95285714 0.9565714  0.98485714 0.9925714 ]
2022-09-23 17:16:12,652 - INFO - Epoch time: 302.74997878074646
2022-09-23 17:16:12,652 - INFO - 
Epoch: 20
2022-09-23 17:16:12,653 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:17:33,673 - INFO - [Step=14250]	Loss=1.5312	395.0 examples/second
2022-09-23 17:19:16,322 - INFO - [Step=14500]	Loss=1.5547	311.7 examples/second
2022-09-23 17:20:59,851 - INFO - [Step=14750]	Loss=1.5517	309.1 examples/second
2022-09-23 17:21:13,032 - INFO - Test Loss=1.5341, Test top-1 acc=0.6631
2022-09-23 17:21:13,032 - INFO - Group Accuracy:

2022-09-23 17:21:13,032 - INFO - [0.95685714 0.9842857  0.9582857  0.98285717 0.9657143  0.9877143
 0.9614286  0.9677143  0.96657145 0.9902857  0.9702857  0.9582857
 0.9557143  0.96       0.9842857  0.9942857 ]
2022-09-23 17:21:13,033 - INFO - Saving...
2022-09-23 17:21:15,414 - INFO - Epoch time: 302.76117610931396
2022-09-23 17:21:15,414 - INFO - 
Epoch: 21
2022-09-23 17:21:15,414 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:22:42,904 - INFO - [Step=15000]	Loss=1.5128	365.8 examples/second
2022-09-23 17:24:11,307 - INFO - [Step=15250]	Loss=1.5232	362.0 examples/second
2022-09-23 17:25:34,021 - INFO - Test Loss=1.5311, Test top-1 acc=0.6569
2022-09-23 17:25:34,021 - INFO - Group Accuracy:

2022-09-23 17:25:34,021 - INFO - [0.9654286  0.9882857  0.9685714  0.98       0.964      0.9842857
 0.958      0.9582857  0.96428573 0.9908571  0.96685714 0.9545714
 0.95514286 0.9605714  0.988      0.9937143 ]
2022-09-23 17:25:34,023 - INFO - Epoch time: 258.6085319519043
2022-09-23 17:25:34,023 - INFO - 
Epoch: 22
2022-09-23 17:25:34,023 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:25:48,454 - INFO - [Step=15500]	Loss=1.4884	2217.7 examples/second
2022-09-23 17:27:15,625 - INFO - [Step=15750]	Loss=1.4757	367.1 examples/second
2022-09-23 17:28:43,093 - INFO - [Step=16000]	Loss=1.5030	365.8 examples/second
2022-09-23 17:29:50,038 - INFO - Test Loss=1.4868, Test top-1 acc=0.6554
2022-09-23 17:29:50,038 - INFO - Group Accuracy:

2022-09-23 17:29:50,038 - INFO - [0.96485716 0.98714286 0.96685714 0.98457146 0.95914286 0.9862857
 0.96171427 0.96       0.9662857  0.9877143  0.9637143  0.956
 0.95857143 0.9582857  0.98714286 0.9922857 ]
2022-09-23 17:29:50,039 - INFO - Epoch time: 256.0163769721985
2022-09-23 17:29:50,039 - INFO - 
Epoch: 23
2022-09-23 17:29:50,039 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:30:21,421 - INFO - [Step=16250]	Loss=1.4623	1019.8 examples/second
2022-09-23 17:31:48,296 - INFO - [Step=16500]	Loss=1.4590	368.3 examples/second
2022-09-23 17:33:15,125 - INFO - [Step=16750]	Loss=1.4705	368.5 examples/second
2022-09-23 17:34:04,667 - INFO - Test Loss=1.8976, Test top-1 acc=0.6071
2022-09-23 17:34:04,667 - INFO - Group Accuracy:

2022-09-23 17:34:04,667 - INFO - [0.9605714  0.98085713 0.9588571  0.97257143 0.95942855 0.9851429
 0.96114284 0.9482857  0.96428573 0.98314285 0.95914286 0.93942857
 0.95342857 0.95514286 0.98485714 0.9917143 ]
2022-09-23 17:34:04,668 - INFO - Epoch time: 254.62894082069397
2022-09-23 17:34:04,668 - INFO - 
Epoch: 24
2022-09-23 17:34:04,668 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:34:51,930 - INFO - [Step=17000]	Loss=1.3869	677.1 examples/second
2022-09-23 17:36:18,662 - INFO - [Step=17250]	Loss=1.4639	369.0 examples/second
2022-09-23 17:37:46,120 - INFO - [Step=17500]	Loss=1.4561	365.9 examples/second
2022-09-23 17:38:18,083 - INFO - Test Loss=2.2662, Test top-1 acc=0.6097
2022-09-23 17:38:18,083 - INFO - Group Accuracy:

2022-09-23 17:38:18,083 - INFO - [0.95257145 0.9794286  0.95342857 0.9811429  0.954      0.9837143
 0.9554286  0.9631429  0.95857143 0.99       0.96342856 0.9545714
 0.9582857  0.94942856 0.982      0.9925714 ]
2022-09-23 17:38:18,084 - INFO - Epoch time: 253.41613459587097
2022-09-23 17:38:18,084 - INFO - 
Epoch: 25
2022-09-23 17:38:18,084 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:39:21,334 - INFO - [Step=17750]	Loss=1.4137	505.9 examples/second
2022-09-23 17:40:48,243 - INFO - [Step=18000]	Loss=1.4219	368.2 examples/second
2022-09-23 17:42:14,986 - INFO - [Step=18250]	Loss=1.4354	368.9 examples/second
2022-09-23 17:42:30,798 - INFO - Test Loss=1.4313, Test top-1 acc=0.6711
2022-09-23 17:42:30,798 - INFO - Group Accuracy:

2022-09-23 17:42:30,798 - INFO - [0.9545714  0.9854286  0.9714286  0.97914284 0.96428573 0.9885714
 0.9588571  0.9697143  0.96657145 0.9902857  0.9702857  0.9557143
 0.96085715 0.9637143  0.9882857  0.99457145]
2022-09-23 17:42:30,800 - INFO - Saving...
2022-09-23 17:42:31,656 - INFO - Epoch time: 253.5712833404541
2022-09-23 17:42:31,656 - INFO - 
Epoch: 26
2022-09-23 17:42:31,656 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:43:52,452 - INFO - [Step=18500]	Loss=1.3991	396.1 examples/second
2022-09-23 17:45:21,042 - INFO - [Step=18750]	Loss=1.4008	361.2 examples/second
2022-09-23 17:46:47,549 - INFO - Test Loss=1.5545, Test top-1 acc=0.6543
2022-09-23 17:46:47,549 - INFO - Group Accuracy:

2022-09-23 17:46:47,549 - INFO - [0.96257144 0.984      0.9631429  0.97571427 0.9628571  0.986
 0.954      0.9702857  0.9654286  0.98657143 0.9645714  0.95028573
 0.95685714 0.964      0.9882857  0.9925714 ]
2022-09-23 17:46:47,550 - INFO - Epoch time: 255.8940761089325
2022-09-23 17:46:47,550 - INFO - 
Epoch: 27
2022-09-23 17:46:47,550 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:46:56,460 - INFO - [Step=19000]	Loss=1.3651	3591.8 examples/second
2022-09-23 17:48:24,994 - INFO - [Step=19250]	Loss=1.3964	361.4 examples/second
2022-09-23 17:49:52,522 - INFO - [Step=19500]	Loss=1.3935	365.6 examples/second
2022-09-23 17:51:03,007 - INFO - Test Loss=1.6015, Test top-1 acc=0.6337
2022-09-23 17:51:03,008 - INFO - Group Accuracy:

2022-09-23 17:51:03,008 - INFO - [0.95514286 0.9842857  0.958      0.9811429  0.9605714  0.986
 0.96171427 0.96428573 0.9662857  0.9854286  0.9671429  0.9491429
 0.9597143  0.9574286  0.98971426 0.992     ]
2022-09-23 17:51:03,008 - INFO - Epoch time: 255.45839619636536
2022-09-23 17:51:03,008 - INFO - 
Epoch: 28
2022-09-23 17:51:03,008 - INFO - 
Learning Rate: 0.1000
2022-09-23 17:51:28,925 - INFO - [Step=19750]	Loss=1.3238	1234.8 examples/second
2022-09-23 17:52:57,090 - INFO - [Step=20000]	Loss=1.3786	363.0 examples/second
2022-09-23 17:54:24,117 - INFO - [Step=20250]	Loss=1.3721	367.7 examples/second
2022-09-23 17:55:18,510 - INFO - Test Loss=1.7483, Test top-1 acc=0.6266
2022-09-23 17:55:18,510 - INFO - Group Accuracy:

2022-09-23 17:55:18,510 - INFO - [0.96085715 0.9797143  0.95       0.97657144 0.9628571  0.9817143
 0.9531429  0.9645714  0.96342856 0.98485714 0.9662857  0.9517143
 0.95942855 0.95342857 0.9834286  0.9925714 ]
2022-09-23 17:55:18,511 - INFO - Epoch time: 255.50265550613403
2022-09-23 17:55:18,511 - INFO - 
Epoch: 29
2022-09-23 17:55:18,511 - INFO - 
Learning Rate: 0.0100
2022-09-23 17:56:00,972 - INFO - [Step=20500]	Loss=1.1485	753.7 examples/second
2022-09-23 17:57:28,132 - INFO - [Step=20750]	Loss=1.0342	367.1 examples/second
2022-09-23 17:58:55,528 - INFO - [Step=21000]	Loss=1.0031	366.2 examples/second
2022-09-23 17:59:34,472 - INFO - Test Loss=0.9398, Test top-1 acc=0.7637
2022-09-23 17:59:34,472 - INFO - Group Accuracy:

2022-09-23 17:59:34,472 - INFO - [0.97171426 0.9934286  0.98057145 0.9882857  0.97828573 0.9937143
 0.97342855 0.9762857  0.97571427 0.99485713 0.97828573 0.9702857
 0.974      0.96742857 0.9934286  0.9957143 ]
2022-09-23 17:59:34,474 - INFO - Saving...
2022-09-23 17:59:35,418 - INFO - Epoch time: 256.90705490112305
2022-09-23 17:59:35,418 - INFO - 
Epoch: 30
2022-09-23 17:59:35,419 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:00:33,447 - INFO - [Step=21250]	Loss=0.9576	551.5 examples/second
2022-09-23 18:02:00,844 - INFO - [Step=21500]	Loss=0.9363	366.1 examples/second
2022-09-23 18:03:28,108 - INFO - [Step=21750]	Loss=0.9350	366.7 examples/second
2022-09-23 18:03:50,806 - INFO - Test Loss=0.9134, Test top-1 acc=0.7694
2022-09-23 18:03:50,807 - INFO - Group Accuracy:

2022-09-23 18:03:50,807 - INFO - [0.97257143 0.9922857  0.98085713 0.98885715 0.97657144 0.9922857
 0.9745714  0.9771429  0.9742857  0.99485713 0.9802857  0.96885717
 0.9742857  0.96742857 0.994      0.99628574]
2022-09-23 18:03:50,808 - INFO - Saving...
2022-09-23 18:03:51,706 - INFO - Epoch time: 256.2875030040741
2022-09-23 18:03:51,706 - INFO - 
Epoch: 31
2022-09-23 18:03:51,706 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:05:06,678 - INFO - [Step=22000]	Loss=0.8928	426.8 examples/second
2022-09-23 18:06:34,527 - INFO - [Step=22250]	Loss=0.9164	364.3 examples/second
2022-09-23 18:08:08,065 - INFO - Test Loss=0.8995, Test top-1 acc=0.7809
2022-09-23 18:08:08,066 - INFO - Group Accuracy:

2022-09-23 18:08:08,066 - INFO - [0.97257143 0.99142855 0.98085713 0.98971426 0.9794286  0.994
 0.97571427 0.9797143  0.976      0.9942857  0.97914284 0.97
 0.97514284 0.97085714 0.9934286  0.99714285]
2022-09-23 18:08:08,067 - INFO - Saving...
2022-09-23 18:08:08,670 - INFO - Epoch time: 256.9639720916748
2022-09-23 18:08:08,671 - INFO - 
Epoch: 32
2022-09-23 18:08:08,671 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:08:12,803 - INFO - [Step=22500]	Loss=0.8329	7747.4 examples/second
2022-09-23 18:09:39,747 - INFO - [Step=22750]	Loss=0.8884	368.1 examples/second
2022-09-23 18:11:07,241 - INFO - [Step=23000]	Loss=0.8765	365.7 examples/second
2022-09-23 18:12:24,696 - INFO - Test Loss=0.8821, Test top-1 acc=0.7769
2022-09-23 18:12:24,696 - INFO - Group Accuracy:

2022-09-23 18:12:24,696 - INFO - [0.97342855 0.992      0.9825714  0.99       0.9802857  0.9925714
 0.976      0.978      0.97514284 0.9942857  0.98       0.9697143
 0.9768571  0.9702857  0.9937143  0.9957143 ]
2022-09-23 18:12:24,697 - INFO - Epoch time: 256.02609729766846
2022-09-23 18:12:24,697 - INFO - 
Epoch: 33
2022-09-23 18:12:24,697 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:12:45,104 - INFO - [Step=23250]	Loss=0.8490	1568.2 examples/second
2022-09-23 18:14:12,312 - INFO - [Step=23500]	Loss=0.8653	366.9 examples/second
2022-09-23 18:15:40,119 - INFO - [Step=23750]	Loss=0.8555	364.4 examples/second
2022-09-23 18:16:41,469 - INFO - Test Loss=0.8720, Test top-1 acc=0.7743
2022-09-23 18:16:41,469 - INFO - Group Accuracy:

2022-09-23 18:16:41,469 - INFO - [0.9742857  0.9922857  0.9811429  0.98914284 0.9785714  0.9934286
 0.97571427 0.978      0.9754286  0.99485713 0.98057145 0.9714286
 0.976      0.9702857  0.99314284 0.9965714 ]
2022-09-23 18:16:41,471 - INFO - Epoch time: 256.7743556499481
2022-09-23 18:16:41,471 - INFO - 
Epoch: 34
2022-09-23 18:16:41,471 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:17:19,128 - INFO - [Step=24000]	Loss=0.8524	849.8 examples/second
2022-09-23 18:18:45,283 - INFO - [Step=24250]	Loss=0.8440	371.4 examples/second
2022-09-23 18:20:12,582 - INFO - [Step=24500]	Loss=0.8478	366.6 examples/second
2022-09-23 18:20:55,199 - INFO - Test Loss=0.8718, Test top-1 acc=0.7740
2022-09-23 18:20:55,199 - INFO - Group Accuracy:

2022-09-23 18:20:55,199 - INFO - [0.97257143 0.99142855 0.98142856 0.99057144 0.97885716 0.9937143
 0.9762857  0.978      0.9742857  0.9957143  0.982      0.97085714
 0.97514284 0.96885717 0.994      0.9974286 ]
2022-09-23 18:20:55,200 - INFO - Epoch time: 253.7284700870514
2022-09-23 18:20:55,200 - INFO - 
Epoch: 35
2022-09-23 18:20:55,200 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:21:48,438 - INFO - [Step=24750]	Loss=0.8267	601.1 examples/second
2022-09-23 18:23:15,923 - INFO - [Step=25000]	Loss=0.8304	365.8 examples/second
2022-09-23 18:24:42,295 - INFO - [Step=25250]	Loss=0.8239	370.5 examples/second
2022-09-23 18:25:10,051 - INFO - Test Loss=0.8665, Test top-1 acc=0.7823
2022-09-23 18:25:10,051 - INFO - Group Accuracy:

2022-09-23 18:25:10,052 - INFO - [0.976      0.9922857  0.98057145 0.98971426 0.9802857  0.9942857
 0.97571427 0.9785714  0.97657144 0.99542856 0.9811429  0.9697143
 0.97571427 0.97       0.99457145 0.99628574]
2022-09-23 18:25:10,052 - INFO - Saving...
2022-09-23 18:25:10,958 - INFO - Epoch time: 255.7580783367157
2022-09-23 18:25:10,958 - INFO - 
Epoch: 36
2022-09-23 18:25:10,958 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:26:20,457 - INFO - [Step=25500]	Loss=0.8074	460.4 examples/second
2022-09-23 18:27:47,335 - INFO - [Step=25750]	Loss=0.8235	368.3 examples/second
2022-09-23 18:29:15,313 - INFO - [Step=26000]	Loss=0.8114	363.7 examples/second
2022-09-23 18:29:26,045 - INFO - Test Loss=0.8735, Test top-1 acc=0.7797
2022-09-23 18:29:26,045 - INFO - Group Accuracy:

2022-09-23 18:29:26,045 - INFO - [0.974      0.99114287 0.97914284 0.98971426 0.9802857  0.99285716
 0.9771429  0.98057145 0.9762857  0.99485713 0.9811429  0.9697143
 0.97657144 0.9711428  0.994      0.99685717]
2022-09-23 18:29:26,046 - INFO - Epoch time: 255.08768963813782
2022-09-23 18:29:26,046 - INFO - 
Epoch: 37
2022-09-23 18:29:26,046 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:30:51,731 - INFO - [Step=26250]	Loss=0.7922	373.5 examples/second
2022-09-23 18:32:19,138 - INFO - [Step=26500]	Loss=0.8152	366.1 examples/second
2022-09-23 18:33:42,005 - INFO - Test Loss=0.8768, Test top-1 acc=0.7777
2022-09-23 18:33:42,005 - INFO - Group Accuracy:

2022-09-23 18:33:42,005 - INFO - [0.974      0.992      0.978      0.98885715 0.97885716 0.9937143
 0.97571427 0.97885716 0.97514284 0.9951429  0.9817143  0.9685714
 0.97742856 0.9722857  0.994      0.9965714 ]
2022-09-23 18:33:42,006 - INFO - Epoch time: 255.96027398109436
2022-09-23 18:33:42,006 - INFO - 
Epoch: 38
2022-09-23 18:33:42,006 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:33:57,399 - INFO - [Step=26750]	Loss=0.7885	2079.1 examples/second
2022-09-23 18:35:24,473 - INFO - [Step=27000]	Loss=0.7847	367.5 examples/second
2022-09-23 18:36:52,364 - INFO - [Step=27250]	Loss=0.8003	364.1 examples/second
2022-09-23 18:37:58,937 - INFO - Test Loss=0.8759, Test top-1 acc=0.7780
2022-09-23 18:37:58,938 - INFO - Group Accuracy:

2022-09-23 18:37:58,938 - INFO - [0.97571427 0.9925714  0.9811429  0.9902857  0.9785714  0.994
 0.9745714  0.98       0.9754286  0.9957143  0.9794286  0.968
 0.9754286  0.9714286  0.99485713 0.99714285]
2022-09-23 18:37:58,940 - INFO - Epoch time: 256.9332814216614
2022-09-23 18:37:58,940 - INFO - 
Epoch: 39
2022-09-23 18:37:58,940 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:38:30,974 - INFO - [Step=27500]	Loss=0.7787	999.0 examples/second
2022-09-23 18:39:57,220 - INFO - [Step=27750]	Loss=0.7777	371.0 examples/second
2022-09-23 18:41:24,781 - INFO - [Step=28000]	Loss=0.7732	365.5 examples/second
2022-09-23 18:42:13,454 - INFO - Test Loss=0.8611, Test top-1 acc=0.7817
2022-09-23 18:42:13,454 - INFO - Group Accuracy:

2022-09-23 18:42:13,454 - INFO - [0.97657144 0.9942857  0.9785714  0.98914284 0.97885716 0.9937143
 0.97485715 0.9762857  0.97571427 0.9957143  0.9817143  0.97171426
 0.97571427 0.9711428  0.99457145 0.99714285]
2022-09-23 18:42:13,455 - INFO - Epoch time: 254.51513385772705
2022-09-23 18:42:13,455 - INFO - 
Epoch: 40
2022-09-23 18:42:13,455 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:43:00,864 - INFO - [Step=28250]	Loss=0.7433	675.0 examples/second
2022-09-23 18:44:28,457 - INFO - [Step=28500]	Loss=0.7739	365.3 examples/second
2022-09-23 18:45:55,151 - INFO - [Step=28750]	Loss=0.7724	369.1 examples/second
2022-09-23 18:46:26,691 - INFO - Test Loss=0.8551, Test top-1 acc=0.7831
2022-09-23 18:46:26,691 - INFO - Group Accuracy:

2022-09-23 18:46:26,691 - INFO - [0.9742857  0.9937143  0.98       0.99057144 0.98057145 0.9934286
 0.9768571  0.97885716 0.97485715 0.99457145 0.98       0.9722857
 0.9768571  0.972      0.99457145 0.9965714 ]
2022-09-23 18:46:26,692 - INFO - Saving...
2022-09-23 18:46:27,289 - INFO - Epoch time: 253.83429479599
2022-09-23 18:46:27,290 - INFO - 
Epoch: 41
2022-09-23 18:46:27,290 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:47:31,420 - INFO - [Step=29000]	Loss=0.7673	499.0 examples/second
2022-09-23 18:48:58,509 - INFO - [Step=29250]	Loss=0.7555	367.4 examples/second
2022-09-23 18:50:25,719 - INFO - [Step=29500]	Loss=0.7629	366.9 examples/second
2022-09-23 18:50:41,479 - INFO - Test Loss=0.8386, Test top-1 acc=0.7846
2022-09-23 18:50:41,479 - INFO - Group Accuracy:

2022-09-23 18:50:41,479 - INFO - [0.97485715 0.99457145 0.9797143  0.9902857  0.98       0.9942857
 0.9762857  0.97914284 0.97571427 0.99628574 0.98085713 0.9722857
 0.9771429  0.9702857  0.99485713 0.99685717]
2022-09-23 18:50:41,480 - INFO - Saving...
2022-09-23 18:50:42,041 - INFO - Epoch time: 254.75080132484436
2022-09-23 18:50:42,041 - INFO - 
Epoch: 42
2022-09-23 18:50:42,041 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:52:03,586 - INFO - [Step=29750]	Loss=0.7554	392.4 examples/second
2022-09-23 18:53:31,097 - INFO - [Step=30000]	Loss=0.7517	365.7 examples/second
2022-09-23 18:54:56,285 - INFO - Test Loss=0.8327, Test top-1 acc=0.7849
2022-09-23 18:54:56,285 - INFO - Group Accuracy:

2022-09-23 18:54:56,285 - INFO - [0.97314286 0.9922857  0.98085713 0.99057144 0.9794286  0.9942857
 0.97742856 0.9794286  0.9768571  0.99628574 0.98       0.9728571
 0.97828573 0.972      0.9942857  0.9965714 ]
2022-09-23 18:54:56,286 - INFO - Saving...
2022-09-23 18:54:56,987 - INFO - Epoch time: 254.94659805297852
2022-09-23 18:54:56,988 - INFO - 
Epoch: 43
2022-09-23 18:54:56,988 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:55:06,467 - INFO - [Step=30250]	Loss=0.7343	3376.3 examples/second
2022-09-23 18:56:34,034 - INFO - [Step=30500]	Loss=0.7456	365.4 examples/second
2022-09-23 18:58:02,449 - INFO - [Step=30750]	Loss=0.7428	361.9 examples/second
2022-09-23 18:59:12,227 - INFO - Test Loss=0.8668, Test top-1 acc=0.7817
2022-09-23 18:59:12,227 - INFO - Group Accuracy:

2022-09-23 18:59:12,227 - INFO - [0.97342855 0.994      0.98057145 0.9894286  0.9802857  0.994
 0.97571427 0.97914284 0.9768571  0.99542856 0.98085713 0.9711428
 0.97514284 0.97257143 0.994      0.9977143 ]
2022-09-23 18:59:12,228 - INFO - Epoch time: 255.24066877365112
2022-09-23 18:59:12,228 - INFO - 
Epoch: 44
2022-09-23 18:59:12,228 - INFO - 
Learning Rate: 0.0100
2022-09-23 18:59:38,441 - INFO - [Step=31000]	Loss=0.7088	1220.8 examples/second
2022-09-23 19:01:06,606 - INFO - [Step=31250]	Loss=0.7341	363.0 examples/second
2022-09-23 19:02:34,926 - INFO - [Step=31500]	Loss=0.7430	362.3 examples/second
2022-09-23 19:03:27,835 - INFO - Test Loss=0.8771, Test top-1 acc=0.7834
2022-09-23 19:03:27,835 - INFO - Group Accuracy:

2022-09-23 19:03:27,835 - INFO - [0.97514284 0.9922857  0.98228574 0.9894286  0.98228574 0.9937143
 0.9777143  0.97885716 0.9754286  0.99485713 0.9802857  0.97085714
 0.9745714  0.97257143 0.99457145 0.99685717]
2022-09-23 19:03:27,836 - INFO - Epoch time: 255.60797548294067
2022-09-23 19:03:27,836 - INFO - 
Epoch: 45
2022-09-23 19:03:27,836 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:04:10,345 - INFO - [Step=31750]	Loss=0.7265	752.8 examples/second
2022-09-23 19:05:37,875 - INFO - [Step=32000]	Loss=0.7354	365.6 examples/second
2022-09-23 19:07:05,096 - INFO - [Step=32250]	Loss=0.7342	366.9 examples/second
2022-09-23 19:07:41,784 - INFO - Test Loss=0.8839, Test top-1 acc=0.7840
2022-09-23 19:07:41,784 - INFO - Group Accuracy:

2022-09-23 19:07:41,784 - INFO - [0.9754286  0.99457145 0.9794286  0.98971426 0.98057145 0.9934286
 0.9768571  0.97828573 0.97571427 0.99628574 0.98057145 0.97171426
 0.97571427 0.9722857  0.994      0.99685717]
2022-09-23 19:07:41,785 - INFO - Epoch time: 253.9483766555786
2022-09-23 19:07:41,785 - INFO - 
Epoch: 46
2022-09-23 19:07:41,785 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:08:41,272 - INFO - [Step=32500]	Loss=0.7237	537.9 examples/second
2022-09-23 19:10:07,652 - INFO - [Step=32750]	Loss=0.7228	370.5 examples/second
2022-09-23 19:11:34,183 - INFO - [Step=33000]	Loss=0.7153	370.2 examples/second
2022-09-23 19:11:55,041 - INFO - Test Loss=0.8694, Test top-1 acc=0.7820
2022-09-23 19:11:55,042 - INFO - Group Accuracy:

2022-09-23 19:11:55,042 - INFO - [0.9754286  0.9925714  0.9794286  0.99142855 0.9794286  0.994
 0.9771429  0.9797143  0.9754286  0.996      0.98085713 0.97171426
 0.97514284 0.9711428  0.99485713 0.9974286 ]
2022-09-23 19:11:55,043 - INFO - Epoch time: 253.25811791419983
2022-09-23 19:11:55,043 - INFO - 
Epoch: 47
2022-09-23 19:11:55,043 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:13:09,827 - INFO - [Step=33250]	Loss=0.6993	427.9 examples/second
2022-09-23 19:14:36,655 - INFO - [Step=33500]	Loss=0.7296	368.5 examples/second
2022-09-23 19:16:08,421 - INFO - Test Loss=0.8700, Test top-1 acc=0.7803
2022-09-23 19:16:08,422 - INFO - Group Accuracy:

2022-09-23 19:16:08,422 - INFO - [0.9728571  0.9922857  0.98228574 0.98971426 0.98057145 0.99314284
 0.97885716 0.9785714  0.97657144 0.9965714  0.9817143  0.97171426
 0.976      0.97       0.9951429  0.99714285]
2022-09-23 19:16:08,422 - INFO - Epoch time: 253.37944388389587
2022-09-23 19:16:08,423 - INFO - 
Epoch: 48
2022-09-23 19:16:08,423 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:16:13,723 - INFO - [Step=33750]	Loss=0.7320	6038.8 examples/second
2022-09-23 19:17:40,302 - INFO - [Step=34000]	Loss=0.7070	369.6 examples/second
2022-09-23 19:19:06,569 - INFO - [Step=34250]	Loss=0.7118	370.9 examples/second
2022-09-23 19:20:21,587 - INFO - Test Loss=0.8935, Test top-1 acc=0.7791
2022-09-23 19:20:21,587 - INFO - Group Accuracy:

2022-09-23 19:20:21,587 - INFO - [0.9722857  0.9925714  0.98142856 0.98885715 0.9785714  0.9925714
 0.9771429  0.9785714  0.9754286  0.99685717 0.98085713 0.9722857
 0.97571427 0.9702857  0.99485713 0.996     ]
2022-09-23 19:20:21,588 - INFO - Epoch time: 253.16548585891724
2022-09-23 19:20:21,588 - INFO - 
Epoch: 49
2022-09-23 19:20:21,588 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:20:42,352 - INFO - [Step=34500]	Loss=0.6928	1541.3 examples/second
2022-09-23 19:22:08,956 - INFO - [Step=34750]	Loss=0.7055	369.5 examples/second
2022-09-23 19:23:35,599 - INFO - [Step=35000]	Loss=0.7034	369.3 examples/second
2022-09-23 19:24:33,900 - INFO - Test Loss=0.8645, Test top-1 acc=0.7849
2022-09-23 19:24:33,900 - INFO - Group Accuracy:

2022-09-23 19:24:33,900 - INFO - [0.9742857  0.9934286  0.982      0.9894286  0.98085713 0.99314284
 0.9762857  0.9802857  0.9762857  0.996      0.982      0.9737143
 0.9754286  0.97       0.99485713 0.9965714 ]
2022-09-23 19:24:33,901 - INFO - Epoch time: 252.31274223327637
2022-09-23 19:24:33,901 - INFO - 
Epoch: 50
2022-09-23 19:24:33,901 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:25:10,964 - INFO - [Step=35250]	Loss=0.6859	863.4 examples/second
2022-09-23 19:26:37,620 - INFO - [Step=35500]	Loss=0.6962	369.3 examples/second
2022-09-23 19:28:04,302 - INFO - [Step=35750]	Loss=0.6936	369.2 examples/second
2022-09-23 19:28:46,117 - INFO - Test Loss=0.8679, Test top-1 acc=0.7851
2022-09-23 19:28:46,117 - INFO - Group Accuracy:

2022-09-23 19:28:46,117 - INFO - [0.976      0.99314284 0.9811429  0.99       0.982      0.9942857
 0.97742856 0.9785714  0.976      0.9965714  0.982      0.96914285
 0.9785714  0.9714286  0.99457145 0.9965714 ]
2022-09-23 19:28:46,118 - INFO - Saving...
2022-09-23 19:28:46,943 - INFO - Epoch time: 253.04162192344666
2022-09-23 19:28:46,943 - INFO - 
Epoch: 51
2022-09-23 19:28:46,943 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:29:40,772 - INFO - [Step=36000]	Loss=0.6875	594.5 examples/second
2022-09-23 19:31:07,418 - INFO - [Step=36250]	Loss=0.6985	369.3 examples/second
2022-09-23 19:32:34,109 - INFO - [Step=36500]	Loss=0.6844	369.1 examples/second
2022-09-23 19:32:59,753 - INFO - Test Loss=0.8567, Test top-1 acc=0.7909
2022-09-23 19:32:59,754 - INFO - Group Accuracy:

2022-09-23 19:32:59,754 - INFO - [0.9771429  0.9922857  0.9811429  0.99       0.9817143  0.994
 0.9768571  0.97885716 0.9771429  0.99628574 0.98142856 0.97057146
 0.97828573 0.97257143 0.9951429  0.99628574]
2022-09-23 19:32:59,755 - INFO - Saving...
2022-09-23 19:33:00,728 - INFO - Epoch time: 253.7847867012024
2022-09-23 19:33:00,728 - INFO - 
Epoch: 52
2022-09-23 19:33:00,728 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:34:10,836 - INFO - [Step=36750]	Loss=0.6898	456.4 examples/second
2022-09-23 19:35:37,513 - INFO - [Step=37000]	Loss=0.6845	369.2 examples/second
2022-09-23 19:37:04,129 - INFO - [Step=37250]	Loss=0.6940	369.4 examples/second
2022-09-23 19:37:13,444 - INFO - Test Loss=0.9021, Test top-1 acc=0.7831
2022-09-23 19:37:13,444 - INFO - Group Accuracy:

2022-09-23 19:37:13,444 - INFO - [0.9737143  0.99285716 0.98       0.98885715 0.9802857  0.99457145
 0.978      0.98085713 0.9745714  0.996      0.9817143  0.9697143
 0.974      0.97171426 0.994      0.9965714 ]
2022-09-23 19:37:13,445 - INFO - Epoch time: 252.71739149093628
2022-09-23 19:37:13,445 - INFO - 
Epoch: 53
2022-09-23 19:37:13,445 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:38:39,312 - INFO - [Step=37500]	Loss=0.6663	372.7 examples/second
2022-09-23 19:40:05,941 - INFO - [Step=37750]	Loss=0.6719	369.4 examples/second
2022-09-23 19:41:25,920 - INFO - Test Loss=0.8985, Test top-1 acc=0.7863
2022-09-23 19:41:25,920 - INFO - Group Accuracy:

2022-09-23 19:41:25,920 - INFO - [0.9754286  0.9937143  0.98       0.9902857  0.98       0.99314284
 0.97485715 0.97742856 0.97571427 0.99685717 0.9802857  0.972
 0.97514284 0.9722857  0.99542856 0.99714285]
2022-09-23 19:41:25,921 - INFO - Epoch time: 252.4757161140442
2022-09-23 19:41:25,921 - INFO - 
Epoch: 54
2022-09-23 19:41:25,921 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:41:41,795 - INFO - [Step=38000]	Loss=0.6531	2016.0 examples/second
2022-09-23 19:43:08,504 - INFO - [Step=38250]	Loss=0.6733	369.1 examples/second
2022-09-23 19:44:35,107 - INFO - [Step=38500]	Loss=0.6808	369.5 examples/second
2022-09-23 19:45:38,503 - INFO - Test Loss=0.8968, Test top-1 acc=0.7851
2022-09-23 19:45:38,503 - INFO - Group Accuracy:

2022-09-23 19:45:38,503 - INFO - [0.97742856 0.99314284 0.9825714  0.99114287 0.9811429  0.9934286
 0.9768571  0.9794286  0.97342855 0.996      0.9811429  0.9702857
 0.9745714  0.972      0.9937143  0.9965714 ]
2022-09-23 19:45:38,504 - INFO - Epoch time: 252.58290934562683
2022-09-23 19:45:38,504 - INFO - 
Epoch: 55
2022-09-23 19:45:38,504 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:46:10,563 - INFO - [Step=38750]	Loss=0.6392	998.2 examples/second
2022-09-23 19:47:37,328 - INFO - [Step=39000]	Loss=0.6615	368.8 examples/second
2022-09-23 19:49:03,939 - INFO - [Step=39250]	Loss=0.6764	369.5 examples/second
2022-09-23 19:49:51,027 - INFO - Test Loss=0.9078, Test top-1 acc=0.7777
2022-09-23 19:49:51,027 - INFO - Group Accuracy:

2022-09-23 19:49:51,027 - INFO - [0.9754286  0.9922857  0.98057145 0.98914284 0.9811429  0.99314284
 0.9762857  0.97885716 0.97742856 0.9965714  0.978      0.9714286
 0.97571427 0.9694286  0.99457145 0.99714285]
2022-09-23 19:49:51,028 - INFO - Epoch time: 252.5235459804535
2022-09-23 19:49:51,028 - INFO - 
Epoch: 56
2022-09-23 19:49:51,028 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:50:39,066 - INFO - [Step=39500]	Loss=0.6661	666.1 examples/second
2022-09-23 19:52:05,757 - INFO - [Step=39750]	Loss=0.6535	369.1 examples/second
2022-09-23 19:53:32,390 - INFO - [Step=40000]	Loss=0.6624	369.4 examples/second
2022-09-23 19:54:03,093 - INFO - Test Loss=0.8948, Test top-1 acc=0.7831
2022-09-23 19:54:03,094 - INFO - Group Accuracy:

2022-09-23 19:54:03,094 - INFO - [0.9777143  0.992      0.982      0.99057144 0.9817143  0.9934286
 0.976      0.9771429  0.97657144 0.996      0.9785714  0.97
 0.976      0.97171426 0.99285716 0.99714285]
2022-09-23 19:54:03,094 - INFO - Epoch time: 252.06643533706665
2022-09-23 19:54:03,094 - INFO - 
Epoch: 57
2022-09-23 19:54:03,094 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:55:07,431 - INFO - [Step=40250]	Loss=0.6501	497.4 examples/second
2022-09-23 19:56:34,077 - INFO - [Step=40500]	Loss=0.6478	369.3 examples/second
2022-09-23 19:58:00,687 - INFO - [Step=40750]	Loss=0.6553	369.5 examples/second
2022-09-23 19:58:15,114 - INFO - Test Loss=0.9508, Test top-1 acc=0.7691
2022-09-23 19:58:15,115 - INFO - Group Accuracy:

2022-09-23 19:58:15,115 - INFO - [0.9745714  0.9925714  0.982      0.9894286  0.97657144 0.9934286
 0.974      0.9745714  0.976      0.99628574 0.9797143  0.9702857
 0.97571427 0.9728571  0.9934286  0.996     ]
2022-09-23 19:58:15,116 - INFO - Epoch time: 252.02160549163818
2022-09-23 19:58:15,116 - INFO - 
Epoch: 58
2022-09-23 19:58:15,116 - INFO - 
Learning Rate: 0.0100
2022-09-23 19:59:36,780 - INFO - [Step=41000]	Loss=0.6459	391.9 examples/second
2022-09-23 20:01:03,591 - INFO - [Step=41250]	Loss=0.6599	368.6 examples/second
2022-09-23 20:02:28,766 - INFO - Test Loss=0.8960, Test top-1 acc=0.7809
2022-09-23 20:02:28,766 - INFO - Group Accuracy:

2022-09-23 20:02:28,766 - INFO - [0.9737143  0.9934286  0.98228574 0.99142855 0.9785714  0.99485713
 0.9745714  0.97885716 0.976      0.99628574 0.98085713 0.9694286
 0.97342855 0.97171426 0.9942857  0.99628574]
2022-09-23 20:02:28,767 - INFO - Epoch time: 253.6509075164795
2022-09-23 20:02:28,767 - INFO - 
Epoch: 59
2022-09-23 20:02:28,767 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:02:39,049 - INFO - [Step=41500]	Loss=0.6506	3112.5 examples/second
2022-09-23 20:04:05,582 - INFO - [Step=41750]	Loss=0.5966	369.8 examples/second
2022-09-23 20:05:32,177 - INFO - [Step=42000]	Loss=0.5814	369.5 examples/second
2022-09-23 20:06:40,772 - INFO - Test Loss=0.8500, Test top-1 acc=0.7874
2022-09-23 20:06:40,773 - INFO - Group Accuracy:

2022-09-23 20:06:40,773 - INFO - [0.9762857  0.994      0.9834286  0.9908571  0.97914284 0.9942857
 0.9771429  0.9762857  0.97657144 0.9965714  0.982      0.97257143
 0.976      0.97085714 0.9934286  0.9974286 ]
2022-09-23 20:06:40,774 - INFO - Epoch time: 252.00709629058838
2022-09-23 20:06:40,774 - INFO - 
Epoch: 60
2022-09-23 20:06:40,774 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:07:07,367 - INFO - [Step=42250]	Loss=0.5716	1203.4 examples/second
2022-09-23 20:08:33,960 - INFO - [Step=42500]	Loss=0.5740	369.5 examples/second
2022-09-23 20:10:00,595 - INFO - [Step=42750]	Loss=0.5678	369.4 examples/second
2022-09-23 20:10:52,854 - INFO - Test Loss=0.8411, Test top-1 acc=0.7886
2022-09-23 20:10:52,855 - INFO - Group Accuracy:

2022-09-23 20:10:52,855 - INFO - [0.9768571  0.9937143  0.98285717 0.9908571  0.98057145 0.994
 0.97828573 0.9777143  0.9768571  0.9974286  0.9817143  0.972
 0.9785714  0.9722857  0.9937143  0.9974286 ]
2022-09-23 20:10:52,856 - INFO - Epoch time: 252.0816068649292
2022-09-23 20:10:52,856 - INFO - 
Epoch: 61
2022-09-23 20:10:52,856 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:11:35,882 - INFO - [Step=43000]	Loss=0.5430	743.7 examples/second
2022-09-23 20:13:02,466 - INFO - [Step=43250]	Loss=0.5617	369.6 examples/second
2022-09-23 20:14:29,068 - INFO - [Step=43500]	Loss=0.5706	369.5 examples/second
2022-09-23 20:15:05,152 - INFO - Test Loss=0.8424, Test top-1 acc=0.7931
2022-09-23 20:15:05,152 - INFO - Group Accuracy:

2022-09-23 20:15:05,152 - INFO - [0.9777143  0.99457145 0.9842857  0.99114287 0.98142856 0.9942857
 0.97885716 0.9768571  0.9762857  0.9974286  0.9825714  0.97171426
 0.97885716 0.972      0.99314284 0.99685717]
2022-09-23 20:15:05,153 - INFO - Saving...
2022-09-23 20:15:05,729 - INFO - Epoch time: 252.8730571269989
2022-09-23 20:15:05,729 - INFO - 
Epoch: 62
2022-09-23 20:15:05,729 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:16:05,221 - INFO - [Step=43750]	Loss=0.5531	537.9 examples/second
2022-09-23 20:17:32,099 - INFO - [Step=44000]	Loss=0.5560	368.3 examples/second
2022-09-23 20:18:58,925 - INFO - [Step=44250]	Loss=0.5515	368.6 examples/second
2022-09-23 20:19:19,291 - INFO - Test Loss=0.8398, Test top-1 acc=0.7946
2022-09-23 20:19:19,291 - INFO - Group Accuracy:

2022-09-23 20:19:19,291 - INFO - [0.97657144 0.99457145 0.9837143  0.99142855 0.9817143  0.994
 0.978      0.97828573 0.97657144 0.9974286  0.9817143  0.97171426
 0.97885716 0.97257143 0.99285716 0.99685717]
2022-09-23 20:19:19,292 - INFO - Saving...
2022-09-23 20:19:19,971 - INFO - Epoch time: 254.24185156822205
2022-09-23 20:19:19,971 - INFO - 
Epoch: 63
2022-09-23 20:19:19,971 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:20:36,086 - INFO - [Step=44500]	Loss=0.5497	420.4 examples/second
2022-09-23 20:22:02,720 - INFO - [Step=44750]	Loss=0.5604	369.4 examples/second
2022-09-23 20:23:32,864 - INFO - Test Loss=0.8402, Test top-1 acc=0.7891
2022-09-23 20:23:32,864 - INFO - Group Accuracy:

2022-09-23 20:23:32,864 - INFO - [0.976      0.9942857  0.98228574 0.99114287 0.9802857  0.9942857
 0.978      0.978      0.9768571  0.9974286  0.98142856 0.9702857
 0.97885716 0.9711428  0.9934286  0.99714285]
2022-09-23 20:23:32,865 - INFO - Epoch time: 252.89399886131287
2022-09-23 20:23:32,865 - INFO - 
Epoch: 64
2022-09-23 20:23:32,865 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:23:38,132 - INFO - [Step=45000]	Loss=0.5590	6076.8 examples/second
2022-09-23 20:25:04,731 - INFO - [Step=45250]	Loss=0.5335	369.5 examples/second
2022-09-23 20:26:31,333 - INFO - [Step=45500]	Loss=0.5425	369.5 examples/second
2022-09-23 20:27:45,135 - INFO - Test Loss=0.8364, Test top-1 acc=0.7934
2022-09-23 20:27:45,135 - INFO - Group Accuracy:

2022-09-23 20:27:45,135 - INFO - [0.97571427 0.9942857  0.9842857  0.9917143  0.982      0.994
 0.9785714  0.97828573 0.9762857  0.9977143  0.9825714  0.97085714
 0.97828573 0.9714286  0.9934286  0.9974286 ]
2022-09-23 20:27:45,136 - INFO - Epoch time: 252.2711317539215
2022-09-23 20:27:45,137 - INFO - 
Epoch: 65
2022-09-23 20:27:45,137 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:28:06,860 - INFO - [Step=45750]	Loss=0.5529	1473.1 examples/second
2022-09-23 20:29:33,659 - INFO - [Step=46000]	Loss=0.5465	368.7 examples/second
2022-09-23 20:31:00,504 - INFO - [Step=46250]	Loss=0.5288	368.5 examples/second
2022-09-23 20:31:58,279 - INFO - Test Loss=0.8332, Test top-1 acc=0.7960
2022-09-23 20:31:58,279 - INFO - Group Accuracy:

2022-09-23 20:31:58,279 - INFO - [0.9771429  0.994      0.9842857  0.99114287 0.98057145 0.99457145
 0.9794286  0.978      0.9771429  0.9974286  0.9825714  0.97171426
 0.9785714  0.97257143 0.9934286  0.99685717]
2022-09-23 20:31:58,280 - INFO - Saving...
2022-09-23 20:31:58,936 - INFO - Epoch time: 253.79892539978027
2022-09-23 20:31:58,936 - INFO - 
Epoch: 66
2022-09-23 20:31:58,936 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:32:36,955 - INFO - [Step=46500]	Loss=0.5405	841.7 examples/second
2022-09-23 20:34:03,754 - INFO - [Step=46750]	Loss=0.5279	368.7 examples/second
2022-09-23 20:35:30,592 - INFO - [Step=47000]	Loss=0.5434	368.5 examples/second
2022-09-23 20:36:11,870 - INFO - Test Loss=0.8367, Test top-1 acc=0.7931
2022-09-23 20:36:11,870 - INFO - Group Accuracy:

2022-09-23 20:36:11,870 - INFO - [0.9768571  0.994      0.98314285 0.99142855 0.9817143  0.99485713
 0.9785714  0.97828573 0.976      0.99714285 0.984      0.9711428
 0.97885716 0.97171426 0.99314284 0.99714285]
2022-09-23 20:36:11,872 - INFO - Epoch time: 252.93579268455505
2022-09-23 20:36:11,872 - INFO - 
Epoch: 67
2022-09-23 20:36:11,872 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:37:05,900 - INFO - [Step=47250]	Loss=0.5174	592.3 examples/second
2022-09-23 20:38:32,529 - INFO - [Step=47500]	Loss=0.5399	369.4 examples/second
2022-09-23 20:39:59,240 - INFO - [Step=47750]	Loss=0.5303	369.0 examples/second
2022-09-23 20:40:24,263 - INFO - Test Loss=0.8394, Test top-1 acc=0.8006
2022-09-23 20:40:24,263 - INFO - Group Accuracy:

2022-09-23 20:40:24,263 - INFO - [0.97742856 0.994      0.9842857  0.99142855 0.9842857  0.9942857
 0.97914284 0.97885716 0.9777143  0.99685717 0.9834286  0.97257143
 0.97914284 0.9728571  0.9934286  0.99714285]
2022-09-23 20:40:24,264 - INFO - Saving...
2022-09-23 20:40:24,918 - INFO - Epoch time: 253.04588437080383
2022-09-23 20:40:24,918 - INFO - 
Epoch: 68
2022-09-23 20:40:24,918 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:41:35,345 - INFO - [Step=48000]	Loss=0.5311	454.4 examples/second
2022-09-23 20:43:01,989 - INFO - [Step=48250]	Loss=0.5250	369.3 examples/second
2022-09-23 20:44:28,588 - INFO - [Step=48500]	Loss=0.5284	369.5 examples/second
2022-09-23 20:44:37,567 - INFO - Test Loss=0.8356, Test top-1 acc=0.7940
2022-09-23 20:44:37,567 - INFO - Group Accuracy:

2022-09-23 20:44:37,567 - INFO - [0.9771429  0.99485713 0.984      0.99114287 0.98142856 0.99457145
 0.978      0.97742856 0.97742856 0.9974286  0.9834286  0.972
 0.97885716 0.9722857  0.994      0.9965714 ]
2022-09-23 20:44:37,568 - INFO - Epoch time: 252.65053153038025
2022-09-23 20:44:37,568 - INFO - 
Epoch: 69
2022-09-23 20:44:37,568 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:46:04,614 - INFO - [Step=48750]	Loss=0.5302	367.6 examples/second
2022-09-23 20:47:31,282 - INFO - [Step=49000]	Loss=0.5287	369.5 examples/second
2022-09-23 20:48:50,606 - INFO - Test Loss=0.8403, Test top-1 acc=0.7997
2022-09-23 20:48:50,606 - INFO - Group Accuracy:

2022-09-23 20:48:50,606 - INFO - [0.97828573 0.9942857  0.98457146 0.99114287 0.98142856 0.99457145
 0.978      0.978      0.97742856 0.99685717 0.9837143  0.972
 0.98       0.97257143 0.9934286  0.99714285]
2022-09-23 20:48:50,607 - INFO - Epoch time: 253.03858613967896
2022-09-23 20:48:50,607 - INFO - 
Epoch: 70
2022-09-23 20:48:50,607 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:49:07,681 - INFO - [Step=49250]	Loss=0.5097	1874.4 examples/second
2022-09-23 20:50:34,639 - INFO - [Step=49500]	Loss=0.5307	368.0 examples/second
2022-09-23 20:52:01,528 - INFO - [Step=49750]	Loss=0.5360	368.3 examples/second
2022-09-23 20:53:04,657 - INFO - Test Loss=0.8405, Test top-1 acc=0.7946
2022-09-23 20:53:04,657 - INFO - Group Accuracy:

2022-09-23 20:53:04,657 - INFO - [0.9771429  0.9937143  0.98457146 0.9902857  0.98314285 0.9942857
 0.978      0.97885716 0.9771429  0.9974286  0.982      0.972
 0.97885716 0.9728571  0.9934286  0.9974286 ]
2022-09-23 20:53:04,658 - INFO - Epoch time: 254.0507528781891
2022-09-23 20:53:04,658 - INFO - 
Epoch: 71
2022-09-23 20:53:04,658 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:53:37,354 - INFO - [Step=50000]	Loss=0.5133	978.7 examples/second
2022-09-23 20:55:04,019 - INFO - [Step=50250]	Loss=0.5160	369.2 examples/second
2022-09-23 20:56:30,842 - INFO - [Step=50500]	Loss=0.5210	368.6 examples/second
2022-09-23 20:57:17,356 - INFO - Test Loss=0.8377, Test top-1 acc=0.7954
2022-09-23 20:57:17,356 - INFO - Group Accuracy:

2022-09-23 20:57:17,356 - INFO - [0.9771429  0.9937143  0.98485714 0.992      0.98285717 0.994
 0.97828573 0.9785714  0.97828573 0.9974286  0.98314285 0.9722857
 0.9785714  0.9728571  0.99314284 0.99685717]
2022-09-23 20:57:17,357 - INFO - Epoch time: 252.69948315620422
2022-09-23 20:57:17,357 - INFO - 
Epoch: 72
2022-09-23 20:57:17,357 - INFO - 
Learning Rate: 0.0010
2022-09-23 20:58:06,176 - INFO - [Step=50750]	Loss=0.5105	655.5 examples/second
2022-09-23 20:59:32,739 - INFO - [Step=51000]	Loss=0.5094	369.7 examples/second
2022-09-23 21:00:59,456 - INFO - [Step=51250]	Loss=0.5248	369.0 examples/second
2022-09-23 21:01:29,637 - INFO - Test Loss=0.8357, Test top-1 acc=0.7960
2022-09-23 21:01:29,637 - INFO - Group Accuracy:

2022-09-23 21:01:29,637 - INFO - [0.978      0.99457145 0.9842857  0.99114287 0.9817143  0.99457145
 0.978      0.9785714  0.9768571  0.9977143  0.9837143  0.97314286
 0.9785714  0.9711428  0.9934286  0.9977143 ]
2022-09-23 21:01:29,638 - INFO - Epoch time: 252.28094148635864
2022-09-23 21:01:29,638 - INFO - 
Epoch: 73
2022-09-23 21:01:29,639 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:02:34,852 - INFO - [Step=51500]	Loss=0.5140	490.7 examples/second
2022-09-23 21:04:01,641 - INFO - [Step=51750]	Loss=0.5262	368.7 examples/second
2022-09-23 21:05:28,378 - INFO - [Step=52000]	Loss=0.5220	368.9 examples/second
2022-09-23 21:05:42,235 - INFO - Test Loss=0.8419, Test top-1 acc=0.7940
2022-09-23 21:05:42,236 - INFO - Group Accuracy:

2022-09-23 21:05:42,236 - INFO - [0.9762857  0.99457145 0.98485714 0.99       0.9825714  0.99485713
 0.978      0.97828573 0.9777143  0.9977143  0.98457146 0.9714286
 0.97885716 0.9714286  0.99314284 0.9974286 ]
2022-09-23 21:05:42,237 - INFO - Epoch time: 252.59804391860962
2022-09-23 21:05:42,237 - INFO - 
Epoch: 74
2022-09-23 21:05:42,237 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:07:03,715 - INFO - [Step=52250]	Loss=0.5123	392.7 examples/second
2022-09-23 21:08:30,404 - INFO - [Step=52500]	Loss=0.5183	369.1 examples/second
2022-09-23 21:09:54,640 - INFO - Test Loss=0.8383, Test top-1 acc=0.7997
2022-09-23 21:09:54,640 - INFO - Group Accuracy:

2022-09-23 21:09:54,640 - INFO - [0.978      0.9942857  0.98457146 0.99142855 0.982      0.99485713
 0.9794286  0.9797143  0.9777143  0.9974286  0.9834286  0.9728571
 0.97885716 0.972      0.9937143  0.99714285]
2022-09-23 21:09:54,641 - INFO - Epoch time: 252.40459036827087
2022-09-23 21:09:54,641 - INFO - 
Epoch: 75
2022-09-23 21:09:54,641 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:10:05,767 - INFO - [Step=52750]	Loss=0.5543	2876.4 examples/second
2022-09-23 21:11:32,541 - INFO - [Step=53000]	Loss=0.5148	368.8 examples/second
2022-09-23 21:12:59,351 - INFO - [Step=53250]	Loss=0.5145	368.6 examples/second
2022-09-23 21:14:07,805 - INFO - Test Loss=0.8429, Test top-1 acc=0.7974
2022-09-23 21:14:07,805 - INFO - Group Accuracy:

2022-09-23 21:14:07,805 - INFO - [0.978      0.994      0.9834286  0.99114287 0.9837143  0.9951429
 0.9777143  0.978      0.9768571  0.99685717 0.9825714  0.972
 0.9777143  0.9714286  0.9934286  0.9965714 ]
2022-09-23 21:14:07,807 - INFO - Epoch time: 253.16540479660034
2022-09-23 21:14:07,807 - INFO - 
Epoch: 76
2022-09-23 21:14:07,807 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:14:35,728 - INFO - [Step=53500]	Loss=0.4986	1146.1 examples/second
2022-09-23 21:16:02,323 - INFO - [Step=53750]	Loss=0.5142	369.5 examples/second
2022-09-23 21:17:29,017 - INFO - [Step=54000]	Loss=0.5110	369.1 examples/second
2022-09-23 21:18:20,713 - INFO - Test Loss=0.8508, Test top-1 acc=0.7943
2022-09-23 21:18:20,713 - INFO - Group Accuracy:

2022-09-23 21:18:20,713 - INFO - [0.97657144 0.99457145 0.98314285 0.99114287 0.9817143  0.9951429
 0.9785714  0.97914284 0.978      0.99714285 0.9817143  0.97257143
 0.97657144 0.9722857  0.99314284 0.9965714 ]
2022-09-23 21:18:20,715 - INFO - Epoch time: 252.90785932540894
2022-09-23 21:18:20,715 - INFO - 
Epoch: 77
2022-09-23 21:18:20,715 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:19:04,238 - INFO - [Step=54250]	Loss=0.5206	735.3 examples/second
2022-09-23 21:20:30,756 - INFO - [Step=54500]	Loss=0.5082	369.9 examples/second
2022-09-23 21:21:57,493 - INFO - [Step=54750]	Loss=0.5132	368.9 examples/second
2022-09-23 21:22:32,770 - INFO - Test Loss=0.8447, Test top-1 acc=0.7957
2022-09-23 21:22:32,770 - INFO - Group Accuracy:

2022-09-23 21:22:32,770 - INFO - [0.97828573 0.99457145 0.98485714 0.99114287 0.98228574 0.9957143
 0.97828573 0.978      0.978      0.99714285 0.9825714  0.9714286
 0.978      0.97314286 0.99314284 0.99714285]
2022-09-23 21:22:32,771 - INFO - Epoch time: 252.05639362335205
2022-09-23 21:22:32,771 - INFO - 
Epoch: 78
2022-09-23 21:22:32,771 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:23:32,703 - INFO - [Step=55000]	Loss=0.5067	533.9 examples/second
2022-09-23 21:24:59,273 - INFO - [Step=55250]	Loss=0.4998	369.6 examples/second
2022-09-23 21:26:26,114 - INFO - [Step=55500]	Loss=0.5044	368.5 examples/second
2022-09-23 21:26:45,829 - INFO - Test Loss=0.8437, Test top-1 acc=0.7917
2022-09-23 21:26:45,829 - INFO - Group Accuracy:

2022-09-23 21:26:45,829 - INFO - [0.9754286  0.994      0.984      0.99057144 0.984      0.99485713
 0.9777143  0.97914284 0.97742856 0.99714285 0.9825714  0.9722857
 0.97742856 0.972      0.9937143  0.99685717]
2022-09-23 21:26:45,830 - INFO - Epoch time: 253.05857586860657
2022-09-23 21:26:45,830 - INFO - 
Epoch: 79
2022-09-23 21:26:45,830 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:28:02,025 - INFO - [Step=55750]	Loss=0.5000	420.0 examples/second
2022-09-23 21:29:28,591 - INFO - [Step=56000]	Loss=0.5023	369.7 examples/second
2022-09-23 21:30:58,728 - INFO - Test Loss=0.8456, Test top-1 acc=0.7937
2022-09-23 21:30:58,729 - INFO - Group Accuracy:

2022-09-23 21:30:58,729 - INFO - [0.9762857  0.9942857  0.9842857  0.99142855 0.98285717 0.99457145
 0.97742856 0.9785714  0.97742856 0.9974286  0.982      0.9728571
 0.97742856 0.9728571  0.994      0.99685717]
2022-09-23 21:30:58,730 - INFO - Epoch time: 252.9000985622406
2022-09-23 21:30:58,730 - INFO - 
Epoch: 80
2022-09-23 21:30:58,730 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:31:04,599 - INFO - [Step=56250]	Loss=0.5233	5453.8 examples/second
2022-09-23 21:32:31,251 - INFO - [Step=56500]	Loss=0.4985	369.4 examples/second
2022-09-23 21:33:57,876 - INFO - [Step=56750]	Loss=0.5098	369.4 examples/second
2022-09-23 21:35:11,441 - INFO - Test Loss=0.8517, Test top-1 acc=0.7971
2022-09-23 21:35:11,441 - INFO - Group Accuracy:

2022-09-23 21:35:11,442 - INFO - [0.97742856 0.9942857  0.9837143  0.9908571  0.98228574 0.9951429
 0.97828573 0.9785714  0.9777143  0.99714285 0.9834286  0.9728571
 0.97742856 0.9722857  0.994      0.9974286 ]
2022-09-23 21:35:11,443 - INFO - Epoch time: 252.71276593208313
2022-09-23 21:35:11,443 - INFO - 
Epoch: 81
2022-09-23 21:35:11,443 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:35:33,654 - INFO - [Step=57000]	Loss=0.5087	1440.8 examples/second
2022-09-23 21:37:00,245 - INFO - [Step=57250]	Loss=0.5192	369.6 examples/second
2022-09-23 21:38:26,864 - INFO - [Step=57500]	Loss=0.4999	369.4 examples/second
2022-09-23 21:39:24,242 - INFO - Test Loss=0.8496, Test top-1 acc=0.7977
2022-09-23 21:39:24,243 - INFO - Group Accuracy:

2022-09-23 21:39:24,243 - INFO - [0.9762857  0.9942857  0.9851429  0.99114287 0.982      0.99485713
 0.978      0.97914284 0.97828573 0.9977143  0.98228574 0.97314286
 0.978      0.9722857  0.9937143  0.9977143 ]
2022-09-23 21:39:24,244 - INFO - Epoch time: 252.8011817932129
2022-09-23 21:39:24,244 - INFO - 
Epoch: 82
2022-09-23 21:39:24,244 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:40:03,885 - INFO - [Step=57750]	Loss=0.4827	807.3 examples/second
2022-09-23 21:41:30,452 - INFO - [Step=58000]	Loss=0.5090	369.7 examples/second
2022-09-23 21:42:57,174 - INFO - [Step=58250]	Loss=0.4948	369.0 examples/second
2022-09-23 21:43:37,678 - INFO - Test Loss=0.8489, Test top-1 acc=0.7966
2022-09-23 21:43:37,678 - INFO - Group Accuracy:

2022-09-23 21:43:37,678 - INFO - [0.9762857  0.9937143  0.9842857  0.9917143  0.9834286  0.9951429
 0.97742856 0.9797143  0.97742856 0.99714285 0.982      0.9728571
 0.97885716 0.97057146 0.9934286  0.9977143 ]
2022-09-23 21:43:37,679 - INFO - Epoch time: 253.4352240562439
2022-09-23 21:43:37,679 - INFO - 
Epoch: 83
2022-09-23 21:43:37,680 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:44:32,516 - INFO - [Step=58500]	Loss=0.4961	583.6 examples/second
2022-09-23 21:45:59,111 - INFO - [Step=58750]	Loss=0.4900	369.5 examples/second
2022-09-23 21:47:25,885 - INFO - [Step=59000]	Loss=0.4972	368.8 examples/second
2022-09-23 21:47:50,264 - INFO - Test Loss=0.8471, Test top-1 acc=0.7974
2022-09-23 21:47:50,264 - INFO - Group Accuracy:

2022-09-23 21:47:50,264 - INFO - [0.97657144 0.9942857  0.9837143  0.9917143  0.9825714  0.99542856
 0.9777143  0.9797143  0.97742856 0.9977143  0.9837143  0.9745714
 0.97885716 0.97171426 0.9937143  0.99714285]
2022-09-23 21:47:50,265 - INFO - Epoch time: 252.5858166217804
2022-09-23 21:47:50,265 - INFO - 
Epoch: 84
2022-09-23 21:47:50,265 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:49:01,282 - INFO - [Step=59250]	Loss=0.4938	450.6 examples/second
2022-09-23 21:50:27,930 - INFO - [Step=59500]	Loss=0.5035	369.3 examples/second
2022-09-23 21:51:54,729 - INFO - [Step=59750]	Loss=0.4939	368.7 examples/second
2022-09-23 21:52:02,790 - INFO - Test Loss=0.8556, Test top-1 acc=0.7969
2022-09-23 21:52:02,790 - INFO - Group Accuracy:

2022-09-23 21:52:02,791 - INFO - [0.97828573 0.9942857  0.98457146 0.9917143  0.98228574 0.99485713
 0.9777143  0.9794286  0.97742856 0.9974286  0.98314285 0.9728571
 0.9771429  0.972      0.9937143  0.99685717]
2022-09-23 21:52:02,792 - INFO - Epoch time: 252.52621269226074
2022-09-23 21:52:02,792 - INFO - 
Epoch: 85
2022-09-23 21:52:02,792 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:53:30,263 - INFO - [Step=60000]	Loss=0.5004	365.8 examples/second
2022-09-23 21:54:57,206 - INFO - [Step=60250]	Loss=0.4915	368.4 examples/second
2022-09-23 21:56:15,866 - INFO - Test Loss=0.8538, Test top-1 acc=0.7974
2022-09-23 21:56:15,866 - INFO - Group Accuracy:

2022-09-23 21:56:15,866 - INFO - [0.978      0.9942857  0.98457146 0.9917143  0.98285717 0.99457145
 0.9777143  0.97914284 0.9768571  0.9974286  0.98314285 0.9728571
 0.97742856 0.9714286  0.9937143  0.99714285]
2022-09-23 21:56:15,868 - INFO - Epoch time: 253.07618880271912
2022-09-23 21:56:15,868 - INFO - 
Epoch: 86
2022-09-23 21:56:15,868 - INFO - 
Learning Rate: 0.0010
2022-09-23 21:56:33,163 - INFO - [Step=60500]	Loss=0.5011	1850.4 examples/second
2022-09-23 21:57:59,875 - INFO - [Step=60750]	Loss=0.4780	369.0 examples/second
2022-09-23 21:59:26,553 - INFO - [Step=61000]	Loss=0.4865	369.2 examples/second
2022-09-23 22:00:29,680 - INFO - Test Loss=0.8466, Test top-1 acc=0.7966
2022-09-23 22:00:29,681 - INFO - Group Accuracy:

2022-09-23 22:00:29,681 - INFO - [0.9768571  0.9942857  0.98457146 0.9922857  0.9834286  0.99457145
 0.9777143  0.97885716 0.978      0.99714285 0.98314285 0.97171426
 0.9768571  0.972      0.994      0.9974286 ]
2022-09-23 22:00:29,682 - INFO - Epoch time: 253.8142237663269
2022-09-23 22:00:29,682 - INFO - 
Epoch: 87
2022-09-23 22:00:29,682 - INFO - 
Learning Rate: 0.0010
2022-09-23 22:01:03,132 - INFO - [Step=61250]	Loss=0.4839	956.7 examples/second
2022-09-23 22:02:29,766 - INFO - [Step=61500]	Loss=0.4901	369.4 examples/second
2022-09-23 22:03:56,337 - INFO - [Step=61750]	Loss=0.4844	369.6 examples/second
2022-09-23 22:04:42,229 - INFO - Test Loss=0.8493, Test top-1 acc=0.7969
2022-09-23 22:04:42,230 - INFO - Group Accuracy:

2022-09-23 22:04:42,230 - INFO - [0.978      0.99457145 0.9854286  0.9917143  0.98142856 0.99457145
 0.978      0.97742856 0.97828573 0.9974286  0.9834286  0.97342855
 0.97742856 0.9722857  0.9937143  0.9977143 ]
2022-09-23 22:04:42,231 - INFO - Epoch time: 252.5488896369934
2022-09-23 22:04:42,231 - INFO - 
Epoch: 88
2022-09-23 22:04:42,231 - INFO - 
Learning Rate: 0.0010
2022-09-23 22:05:32,024 - INFO - [Step=62000]	Loss=0.4919	642.7 examples/second
2022-09-23 22:06:58,664 - INFO - [Step=62250]	Loss=0.4920	369.3 examples/second
2022-09-23 22:08:25,370 - INFO - [Step=62500]	Loss=0.4821	369.1 examples/second
2022-09-23 22:08:54,889 - INFO - Test Loss=0.8472, Test top-1 acc=0.7951
2022-09-23 22:08:54,889 - INFO - Group Accuracy:

2022-09-23 22:08:54,889 - INFO - [0.9768571  0.9942857  0.9854286  0.992      0.9817143  0.99485713
 0.97742856 0.97742856 0.9768571  0.9974286  0.9834286  0.972
 0.97742856 0.97314286 0.9937143  0.9974286 ]
2022-09-23 22:08:54,891 - INFO - Epoch time: 252.6593554019928
2022-09-23 22:08:54,891 - INFO - 
Epoch: 89
2022-09-23 22:08:54,891 - INFO - 
Learning Rate: 0.0010
2022-09-23 22:10:00,857 - INFO - [Step=62750]	Loss=0.4892	485.1 examples/second
2022-09-23 22:11:27,533 - INFO - [Step=63000]	Loss=0.4852	369.2 examples/second
2022-09-23 22:12:54,205 - INFO - [Step=63250]	Loss=0.4886	369.2 examples/second
2022-09-23 22:13:07,465 - INFO - Test Loss=0.8473, Test top-1 acc=0.7943
2022-09-23 22:13:07,465 - INFO - Group Accuracy:

2022-09-23 22:13:07,465 - INFO - [0.97742856 0.9942857  0.98485714 0.99142855 0.98285717 0.99542856
 0.97828573 0.978      0.9771429  0.9977143  0.9825714  0.97257143
 0.97657144 0.97171426 0.9937143  0.9974286 ]
2022-09-23 22:13:07,466 - INFO - Epoch time: 252.57581400871277
2022-09-23 22:13:07,468 - INFO - Printing Final Accuracy + OOD Detection stats
2022-09-23 22:13:07,468 - INFO - Top 1 Accuracy:  Min: 0.8006; Max: 0.8006; Avg: 0.8006; Std: 0.0000; Len: 1
2022-09-23 22:13:07,468 - INFO - Top 5 Accuracy:  Min: 0.9848; Max: 0.9848; Avg: 0.9848; Std: 0.0000; Len: 1
